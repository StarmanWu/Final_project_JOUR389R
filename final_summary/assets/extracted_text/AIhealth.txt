User Name: =
Date and Time: = 2024-10-29
Job Number: = 237201700



Documents (156)

  Client/Matter: -None-
  Search Terms: AI, health
  Search Type: NaturalAnd
  Content Type                       Narrowed by
  news                               : Newspapers : Newswires & Press Releases : Industry
                                     Trade Press : Magazines : Webnews Timeline: 01 Jan,
                                     2024 to 28 Oct, 2024 Source Location: North America
                                     Source Location: United States Source Language: English
                                     Source Type: Newspapers


  1. Microsoft unveils health care AI tools


  2. Techstars, Hopkins, CareFirst bringing health care AI accelerator to Baltimore


  3. Altman, Huffington launching AI health coach


  4. Most Older Americans Don't Trust AI-Generated Health Info, Survey Finds


  5. UC Regents committee evaluates implications of AI in health care


  6. AI and Public Health Series: Introduction


  7. Meet UCSD Health's first chief AI officer


  8. Meet UCSD Health's first chief AI officer


  9. AI pilot program aims to widen health care access How AI health care chatbots learn
  from the questions of an Indian women's organization




              | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

10. Health care is where AI struggles to be helpful


11. Maternal health exec discusses using AI to address Black maternal mortality


12. Adding Up AI's Impact on Health Care


13. Panel discusses implementation of AI into healthcare for underserved communities -
The Daily Texan


14. Slowing down AI for the health of the planet - The DePaulia


15. AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform
health care, soon your doctor may use an algorithm before deciding on your treatment


16. Student-led Bruincare initiative uses AI to enhance mental health support services


17. Campus community uses AI to address mental health


18. AI technologies are giving some doctors more time for patients, improving health care


19. Report: Few health care systems have formal policies on AI use


20. Report: Few health care systems have formal policies on AI use


21. Opinion: AI has a home in Utah , and it's creating newfound prosperity for all


22. The doctor will see you now, and the robot is listening The prospect of AI freeing
physicians and nurses from the need to manually document everything has clinical
executives at UChicago and Rush envisioning a return to 'real-time' patient care


23. AI research could personalize disease care


24. Researchers receive funding to improve trustworthiness of AI - The GW Hatchet
Donation Button


25. Does AI have a place in the classroom?


26. Guardians of the Grid: AI's Cyber Shield for Homeland Security


           | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

27. Health leaders gather for dialogue


28. How AI helps hospitals keep a watchful eye on patients


29. Byte-sized Care: Is AI the key to cracking the mental health crisis? - The Tribune


30. AI CHATBOTS WORK TO WIDEN ACCESS TO CARE TECHNOLOGY | HEALTH


31. Young Utahns struggle with their mental health. Is a new A.I. chatbot the answer?


32. How can generative AI impact students' learning? Four student panelists weigh in. -
The Brown Daily Herald


33. ADVANCING CANCER DIAGNOSIS, TREATMENT WITH AI


34. AI and imaging: 'It takes radiology to the next level'


35. S. Korean science ministry opens joint AI research lab with NYU


36. Will Tufts follow in other universities' footsteps with an AI major?


37. Emmes Group partners with Miimansa AI to accelerate adoption of generative AI in
clinical research


38. Dr. David C. Miller announced to be the new EVP and CEO of Michigan Medicine


39. Penn addresses technology's future UPenn med school names first vice dean of AI,
senior VP for data, tech solutions.


40. Cleveland Clinic explores using AI in patient-caregiver interactions


41. Southeast's first graduate degree program focused on AI in medicine launched at UAB


42. Opinion: Artificial intelligence will radically improve health care, but only if managed
carefully




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

43. The computer will see you now: Artificial intelligence usage grows at Central Florida
hospitals A lot of people are alarmed by the prospect of AI being used in their health care,
according to a 2023 Pew Research poll, which found ...


44. Opinion: ASU should not be the testing ground for teaching counselors with AI


45. Is AI Ready to Replace Human Policy Advisers?


46. What should we fear with AI in medicine? Commentary


47. USA doctor addresses students at University of Science and Technology , Meghalaya


48. CHI Saint Joseph Health named among Nation's 15 Top Health Systems by Fortune
and PINC AI™


49. Report: Area lacks skilled workers, training St. Louis area companies need skilled
workers. But they don't spend on training, report says.


50. Dr. AI will see you now


51. Skeptical about AI in healthcare? Here's how some doctors and hospitals are using it


52. Stay human as AI joins humanity


53. Absence of AI hospital rules worries nurses


54. AI pilot aims to widen health access


55. MEET THE MUSCLE BEHIND PITTSBURGH'S AI STEEL CITY INNOVATION IS BUILT ON
ONE CHIPMAKER'S POPULAR TOOL


56. Research Roundup: Searching the stars and the brain Login or create an account


57. AI shows promise but remains limited for heart and stroke care


58. Your doctor might not be listening to you. AI can help change that.




           | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

59. AI devices connect patients, care team Forget ringing the button for the nurse.
Patients now stay connected by wearing one


60. Unleash the power of our 'super region' Unleash the power of our 'super region'


61. Amid collaboration with Northwell, Aegis Ventures launches new effort


62. Joseph Vukov: Worried about AI? Here are things you need to know (copy)


63. AI interviews are changing the job search - The DePaulia


64. What jobs are safe from AI? Here are 4 career fields to consider


65. University of Dayton to present 3 learning events this week


66. Mammography AI can cost patients extra. Is it worth the money?


67. UHG 's trade secret lawsuit dismissed


68. House lawmakers warn VA officials about data privacy risks for veterans posed by AI


69. House lawmakers warn VA officials about data privacy risks for veterans posed by AI


70. Opinion: AI already plays a vital role in medical imaging and is effectively regulated


71. Opinion: Don't hate artificial intelligence. Enlist AI to support victims of hate.


72. AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS


73. AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS


74. Reforming Federal Health Care


75. Is Your Government AI-Ready? An Interactive Tracker of AI Action


76. AI could revolutionize diagnosis in medicine



            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

77. How AI is reshaping healthcare in South Florida AI is changing how patients receive
care. It's helping doctors with paperwork. And it can translate the jargon found in medical
bills.


78. How artificial intelligence can help doctors treat you better


79. Teens are using AI a lot more than parents think


80. Health startup raises $60M to automate clinical tasks with AI


81. Techstars Equitech Accelerator to culminate with Demo Day in Baltimore


82. AI algorithm helps detect risks of percutaneous coronary intervention


83. Bloustein event discusses opportunities, ramifications associated with AI


84. Can AI chatbots help address mental health issues?


85. A.I. May Offer a Solution to America 's Gaping Mental Health Care Shortage


86. Pair of UWO TEDxOshkosh speakers to deliver thought-provoking talks on AI, politics -
UW Oshkosh Today University of Wisconsin Oshkosh Pair of UWO TEDxOshkosh speakers
to deliver thought-provoking talks on AI, politics - UW Oshkosh Today


87. Meet Pepper and Bernard: The robots shaping AI research at SDSU - The Daily Aztec


88. Your doctor (and ChatGPT) will see you now. A peek into AI-assisted medical visits.


89. Governor Abbott appoints four to Artificial Intelligence advisory council


90. Governor Abbott appoints four to Artificial Intelligence advisory council


91. Doctors cautiously adopt AI-aided care For many, its value is about more time with
patients


92. Doctors cautiously adopt AI-aided care For many, its value is about more time with
patients



            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

93. Franklin Institute is pumped for return of the Giant Heart


94. Franklin Institute getting pumped Museum bringing back its iconic Giant Heart exhibit
after major renovations


95. Fool Me Once: How AI Models Threaten Information Integrity


96. Officials launch artificial intelligence research initiative - The GW Hatchet


97. Fortune rates Intermountain Health top large health system


98. AI in healthcare: Balancing innovation and consequence


99. Combatting the use of AI internationally - The Charger Bulletin


100. Cleveland 's MIM Software to be acquired by GE HealthCare


101. Opinion: It’s open season on personal data: We need a Data Protection Agency now


102. WPI Awards President's Research Catalyst Grants to Three Teams


103. Digital Health Care: can we Avoid this Revolution?


104. Climate change is a class issue


105. UChicago community welcomes more than 4,500 attendees to third annual event


106. The Hickenlooper AI Auditing Bill and the Expanding Role of the Commerce
Department in AI Policy


107. In Lehigh Valley, some doctors turn to AI


108. Opinion: ‘Superbugs’ could devastate livestock globally


109. (Un)true love: When AI enters the dating scene




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

110. Guest Perspective: Forward-looking businesses leverage AI to increase efficiency


111. WPI Awards President's Research Catalyst Grants to Three Teams


112. New Penn master's program will focus on AI The online degree program aims to prep
students for 'jobs that we can't yet imagine.' Applications open in June, with classes
beginning next spring.


113. White House holds creator conference


114. Why this dad's walking across five cities with his pony


115. App fine-tuned at Lancaster innovation lab uses AI to spot skin cancer


116. Using AI to create fake celebrity ads can get you in trouble Using AI to create fake
celebrity advertisements can get you in trouble


117. Wharton professor is teaching 'accountable AI' Kevin Werbach's new course will
focus on the practice of understanding and addressing artificial intelligence's risks and
limitations.


118. A Policy Primer for the 2024 Legislative Session


119. The Startling Deterioration of American Philosophy Departments


120. Your professor also is getting help from AI


121. In Our View: Artificial intelligence tech requires regulation


122. AI has role in hospital patient care Hartford HealthCare says system can predict
'patient deterioration'


123. MetroHealth CEO on rebuilding trust, workforce challenges


124. Artificial intelligence and data misuse


125. AI and the Academic Landscape




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

126. NMMC implements cutting-edge heart procedures


127. ‘Back to business as usual’: Hello Alice expands capital access programming after
lawsuit dismissal


128. ‘Back to business as usual’: Hello Alice expands capital access programming after
lawsuit dismissal


129. ‘Back to business as usual’: Hello Alice expands capital access programming after
lawsuit dismissal


130. Research reveals humans have loved carbs for over 800,000 years


131. Golden Connections takes home $30,000 in the 2024 Mayo Business Plan
Competition


132. 2024 to be hottest year on record - The DePaulia


133. DRIVING INVESTMENTS REPORT: RECORD YEAR SPURRED BY AUTONOMOUS
VEHICLE STARTUPS


134. Social Media Is Hurting Social-Emotional Skills. How 4 School Districts Are Fighting
Back


135. U.S. Senate candidate questionnaires


136. The Transformative Role of AI in Cybersecurity: Anticipating and Preparing for Future
Applications and Benefits


137. UC regents committee meets to discuss funding, alumni engagement


138. Deliberative democracy could help mend divide


139. Community, isolation and politics: The mental health of queer students at UNCW -
The Seahawk


140. Digital Counties 2024: Winners Push Transparency, Engagement


141. Cleveland Clinic names first chief AI officer


            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

142. Samsung Electronics' affiliate completes acquisition of French startup Sonio


143. 34th annual Beautiful Bakersfield Awards to honor individuals, organizations building
a better Bakersfield


144. Neurotech startup looks to open clinical trials center in Bakersfield


145. Neurotech startup looks to open clinical trials center in Bakersfield


146. Neurotech startup looks to open clinical trials center in Bakersfield


147. Social media stars get access at DNC Northridge performer and L.A. drag queen are
among influencers wooed by Democrats.


148. Neurotech startup looks to open clinical trials center in Bakersfield


149. Samsung Electronics ' affiliate acquires French AI medtech startup Sonio


150. Bethesda‘s The Centers for Advanced Orthopaedics to expand digital therapy
solutions


151. EIU student government swears in new senator


152. Student government discusses fees, approves RSO


153. Construction happening all around EIU


154. The geological Avenger on EIU's campus


155. On-campus enrollment down 7%, administration feeling positive


156. No Headline In Original




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

                                                                                                       Page 1 of 2
                                           Microsoft unveils health care AI tools




                                Microsoft unveils health care AI tools
                                                        TheHill.com
                                                October 10, 2024 Thursday



Copyright 2024 NEXSTAR MEDIA INC. All Rights Reserved




Length: 460 words

Body


Microsoft unveiled several new artificial intelligence (AI) tools on Thursday aiming to support health care
organizations through medical imaging models, health care agent services and an AI-driven workflow solution for
nurses.

The announcement detailed how each tool will improve workflow for busy health care professionals.

The AI imaging tool, developed in collaboration with partners like Providence and Paige.ai, enables health care
organizations to integrate and analyze various data types beyond just text, including medical images, clinical
records and genomic data. Microsoft says the tool would allow health care organizations to “rapidly build, fine-tune
and deploy AI solutions tailored to their specific needs.”

Carlo Bifulco, chief medical officer of Providence Genomics and a co-author of the Prov-GigaPath study, noted the
models may help with cancer research and diagnostics.

“These models can complement human expertise by providing insights beyond traditional visual interpretation and,
as we move toward a more integrated, multimodal approach, will reshape the future of medicine,” he said.

The AI tools will also help nurses and clinicians time on administrative tasks. According to a report from the Office
of the Surgeon General, nurses will spend 41 percent of their time on documentation alone. The tools aim to rapidly
decrease that strain on medical professionals by streamlining those administrative tasks, such as through drafting
flow sheets for review.

Additionally, Microsoft announced a new public preview of an AI health care agent service, which would aid in
appointment scheduling, clinical trial matching, patient triaging and more.

The statement detailed that medical organizations can “leverage the health care agent service to help create
connected patient experiences, improve clinical workflows, and empower healthcare professionals.”

                                                                                                    Page 2 of 2
                                       Microsoft unveils health care AI tools

“We are at an inflection point where AI breakthroughs are fundamentally changing the way we work and live,” said
Joe Petro, corporate vice president of healthcare and life sciences solutions and platforms at Microsoft, in a
statement.

“Microsoft’s AI-powered solutions are helping lead these efforts by streamlining workflows, improving data
integration, and utilizing AI to deliver better outcomes for healthcare professionals, researchers and scientists,
payors, providers, medtech developers, and ultimately the patients they all serve,” he added.

While many of the newly announced solutions are in the early stages of development, healthcare organizations will
be testing and analyzing the systems “to avoid undesirable behaviors, such as harmful content, bias, misuse and
other unintended risks,” Microsoft noted.

For the latest news, weather, sports, and streaming video, head to The Hill.


Load-Date: October 10, 2024


  End of Document

                                                                                                       Page 1 of 1
                      Techstars, Hopkins, CareFirst bringing health care AI accelerator to Baltimore




        Techstars, Hopkins, CareFirst bringing health care AI accelerator to
                                    Baltimore
                                               Daily Record, The (Baltimore, MD)
                                                       August 23, 2024 Friday



Copyright 2024 BridgeTower Media All Rights Reserved

Section: NEWS
Length: 252 words
Byline: Daily Record Staff

Body


Techstars,Johns Hopkins University andCareFirst BlueCross BlueShieldFriday announced a collaboration to launch
a new health care accelerator program in Baltimore designed to support early-stage entrepreneurs building
pathways to better care through artificial intelligence.

Techstars AI Health Baltimore powered by Johns Hopkins and CareFirstcombines the university’s expertise in
transforming research into commercially viable businesses, CareFirst’s experience in advancing access to
affordable, equitable, high-quality health care and Techstars’ accelerator model that has helped entrepreneurs
build thousands of successful companies, including more than 600 in health care.
This new program builds on the success of Techstars Equitech, a three-cohort series in partnership with UpSurge
Baltimore that concluded in May. In its capacity as Baltimore’s technology ecosystem builder, UpSurge will continue
to ensure that Techstars founders can leverage the wide continuum of assets that exist in greater Baltimore.

Techstars AI Health Baltimore will serve as Techstars’ new flagship health care accelerator. Adam Phillips, the
former managing director of Techstars Equitech, will lead the 13-week program focused on supporting
entrepreneurs leading healthtech, medtech, and biotech startups. Startups will receive capital, guidance from
experts, and other support required to navigate the complexities of the health care ecosystem and regulatory
environment.

Copyright © 2024 BridgeTower Media. All Rights Reserved.


Load-Date: August 29, 2024


  End of Document

                                                                                                      Page 1 of 2
                                      Altman, Huffington launching AI health coach




                         Altman, Huffington launching AI health coach
                                                        TheHill.com
                                                   July 8, 2024 Monday



Copyright 2024 NEXSTAR MEDIA INC. All Rights Reserved




Section: TECH LATEST
Length: 280 words
Byline: Nick Robertson

Body


OpenAI CEO Sam Altman and Arianna Huffington announced a new startup venture to create an artificial
intelligence-driven health coach as an attempt to use “hyper-personalization” to better behavioral health.

Thrive AI Health, a cooperation between OpenAI and Huffington’s Thrive Global, will create an app to focus on
habit-forming and behavior change, the pair announced in a Time magazine editorial on Monday.

“Yes, behavior change is hard. But through hyper-personalization, it’s also something that AI is uniquely positioned
to solve,” the two wrote.

“Every aspect of our health is deeply influenced by the five foundational daily behaviors of sleep, food, movement,
stress management, and social connection,” they continued. “And AI, by using the power of hyper-personalization,
can significantly improve these behaviors.”

Altman and Huffington said the startup’s eventual product will be trained on a person’s biometric data and personal
preferences to give recommendations around sleep and food, among other health priorities.

Personalized notes from the health coach could be a reminder to go to bed early in order to get enough sleep for
an early flight, the pair said, using AI to bring together health and calendar data, for example.

“AI-driven diagnostics have already reduced error rates and improved patient outcomes,” they argued. “Now, by
focusing AI on healthy behavior promotion and taking advantage of its ability to process potentially several billion
data points, we put in our hands a powerful tool for positive change, ensuring technology works for our well-being
rather than against it.”

For the latest news, weather, sports, and streaming video, head to The Hill.

                                                                         Page 2 of 2
                          Altman, Huffington launching AI health coach


Load-Date: July 8, 2024


  End of Document

                                                                                                       Page 1 of 2
                        Most Older Americans Don't Trust AI-Generated Health Info, Survey Finds




   Most Older Americans Don't Trust AI-Generated Health Info, Survey Finds
                                     The Griffon News: Missouri Western State College
                                                 October 16, 2024 Wednesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: LIFESTYLES; Pg. 1
Length: 626 words

Body

Key Takeaways
     •    Most people 50 and older are skeptical of health information generated by AI
     •    About 74% say they have little to no trust in AI-provided health advice
     •    Trusted sources of info online include health care systems, medical schools, nonprofits and the federal
          government

WEDNESDAY, Oct. 16, 2024 (HealthDay News) -- Most Americans 50 and older don't place much trust in health
advice generated by artificial intelligence, a new survey finds.

About 74% of middle-aged and senior Americans would have very little to no trust in health info generated by AI,
the University of Michigan poll found.

At the same time, these older adults have a lot of confidence in their ability to suss out bad info about health
matters.

Only 20% said they had little to no confidence they could spot misinformation about a health topic if they came
across it.

Among all older adults who'd scanned the web recently for health info, only 32% said it's very easy to find accurate
advice.

"Amid this lack of trust, our findings also highlight the key role that health care providers and pharmacists play as
trusted health messengers in older adults' lives, and even the role that friends or family with medical backgrounds
can play," said poll director Dr. Jeffrey Kullgren, an associate professor of internal medicine at the University of
Michigan.

"We also find that websites run by health organizations are seen by most who use them as very trustworthy, which
suggests a need to encourage more people to use them," Kullgren added in a university news release.

Most of those polled, 84%, said they'd gotten health info directly from a health care provider, pharmacist, friend or
family member in the past year.

                                                                                                      Page 2 of 2
                    Most Older Americans Don't Trust AI-Generated Health Info, Survey Finds

More than 70% rated their health professionals as very trustworthy, while just 62% said the same about friends and
family members.

More from this section

ERs See More Trauma Patients on Smog-Filled Days

Could Dad's Sperm Raise Odds for Common Complications of Pregnancy?

Most Older Americans Don't Trust AI-Generated Health Info, Survey Finds

About 58% said they'd used a website for health information -- most (39%) turning to .com sites like WebMD or
Healthline or a health system's website (31%).

About 36% of those who used a .com site felt its information was trustworthy, compared with 59% of those who
used a health care system site.

Far fewer visited health sites run by the federal government (21%), nonprofits like the American Heart Association
(14%) or universities or medical schools (11%). However, about 60% of those who went to those sites felt their info
was very trustworthy.

"Older adults are increasingly turning to the internet for health information, yet there is a significant trust gap,
particularly with AI-generated content," said Indira Venkat, AARP's senior vice president of research.

"While AI advancements offer promising opportunities to support healthy aging, this poll underscores the urgent
need for reliable, accessible health resources," Venkat added. "Ensuring that older adults have trustworthy
information from health care providers and credible websites is crucial as we navigate the evolving landscape of
digital health."

The report is based on findings from a poll conducted by NORC at the University of Chicago. It involved 3,379
adults aged 50 and older surveyed online and via phone in February and March.

More information

The National Institutes of Health has more on where to find health information.

SOURCE: University of Michigan, news release, Oct. 16, 2024

What This Means For You

Health information provided by websites run by the federal government, nonprofits, and universities or medical
schools are considered very trustworthy by most older adults.

Originally published on healthday.com, part of the BLOX Digital Content Exchange.


Load-Date: October 16, 2024


  End of Document

                                                                                                        Page 1 of 2
                            UC Regents committee evaluates implications of AI in health care




          UC Regents committee evaluates implications of AI in health care
                                      Daily Bruin: University of California - Los Angeles
                                                      July 23, 2024 Tuesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 743 words
Byline: Dylan Winward

Body


The UC Regents Public Engagement and Development Committee discussed the use of artificial intelligence in
health care Wednesday.

Three leading data scientists answered questions from the UC Board of Regents about how the UC Health system
uses artificial intelligence, the implications of AI usage on underrepresented communities and oversight for artificial
intelligence usage. The panel also discussed funding for research relating to AI and health care.

Dr. Atul Butte, the chief data scientist at UC Health, said an increasing number of AIs are training using clinical
data which has been anonymized following approvals from the Food and Drug Administration. He added that
existing algorithms developed within the UC system predict intestinal lung disease, immunodeficiency and Covid-19
patient reactions.

Butte, a professor at UC San Francisco, said UC Health is also responsible for systemwide governance of AI use in
health care and has been involved in briefing Congress on the ramifications of artificial intelligence usage.

"It's not just going to be about the physicians. It's also going to be about the patients, the nurses and all of our
clinical disciplines," Butte said.

Dr. Christopher Longhurst, the chief clinical and innovation officer at UC San Diego Health, said AI is being used to
help clinicians draft messages to patients for virtual care. Within the trial, the AI generated messages would then be
edited by physicians before being sent, he added.

Patients participating in the study were told that the responses were partly generated by AI, Longhurst said. He
added that trials found the AI would help create longer messages to patients, which were made to seem more
empathetic in nature than ones written solely by physicians.

"Many of our patients told us they know that our physicians are busy. They're glad that they have a co-pilot helping
them out, but also glad that the messages are being reviewed by a doctor before they leave," Longhurst said.

                                                                                                           Page 2 of 2
                          UC Regents committee evaluates implications of AI in health care

Although the study found that the tool did not save significant time for doctors, it did help reduce their cognitive load,
Longhurst said, adding that the University is now looking for ways to implement the findings from the trial.

Janet Reilly, the chair of the UC Board of Regents, asked the panelists how the UC as a public university plans to
stay at the cutting edge of AI despite gaps in funding.

Dr. Matthew Lungren, the chief data science officer for health and life sciences at Microsoft, said during the panel
that one way the University can ensure continuous funding is through public-private partnerships. After Regent
Alfonso Salazar asked the panel about what they were doing to protect patient privacy within public-private
partnerships, Butte said privacy contracts are drawn up on a case-by-case basis.

Longhurst said existing funding for AI within UC Health is being prioritized to areas where there are existing
doctoral failures, such as in postoperative sepsis treatment. Butte said the UC is also trying to obtain more funding
from the National Institutes of Health.

The systemwide integration of AI into health care can help eliminate biases in healthcare, Butte said. Student
Regent-Designate Sonya Brooks asked the panel to elaborate on UC Health's commitment to using AI in a
responsible way when it comes to underrepresented communities.

Butte replied by saying the University is working to increase study participation by rural patients, including through
the UC Davis Health system.

Longhurst also said the use of AI in remote patient monitoring can increase access to preventative care, an
important aspect of increasing healthcare access. One potential implication of the AI rollout is that it will increase
access to affordable healthcare, Butte said.

"We can learn what we do at UC (with) our best doctors, our best nurses, treat patients, create those AI models,
and then put those AI models wherever we can, so that that level of care is delivered, not necessarily here in
Mission Bay at UCSF but in all of our partners around the world," Butte said.

However, Mayté Frías - the staff advisor-designate to the Regents - said she was skeptical about the ability of AI
models to avoid negatively impacting health equity.

"This is moving really quickly, and at the same time, we've been carrying systems of oppression for centuries, and
we can't quite figure that out," she said. "I am very suspicious that with AI, we're going to be able to account for all
of that."


Load-Date: July 25, 2024


  End of Document

                                                                                                       Page 1 of 2
                                              AI and Public Health Series: Introduction




                                 AI and Public Health Series: Introduction
                                                             R Street Institute
                                                         July 9, 2024 Tuesday



Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 R Street Institute, USA All Rights Reserved

Length: 785 words
Byline: Adam Thierer

Body



Artificial intelligence (AI) and machine learning (ML)-enabled medical technologies and processes hold the potential
to significantly improve individual patient care and public health. This R Street series explores how AI/ML systems
are already advancing medical capabilities and health outcomes in important ways.

The Profound Potential for AI-Enabled Health

While definitions vary, AI generally involves the exhibition of learning and problem-solving by a machine. ML is an
approach to AI that involves a process by which a computer, using large amounts of data, can train and improve an
algorithm or model without step-by-step human involvement. AI/ML systems are constantly learning and improving
through ongoing experiments and new data inputs.

As these systems become more advanced and data science grows more sophisticated, the ramifications for public
health could be profound. Some analysts argue that AI/ML presents "a once-in-a-century opportunity" and estimate
that the technology could generate $60 billion to $110 billion a year in economic value across life sciences and
various subsectors, which "promises unquantifiable effects on human health and well-being." Other medical
science experts have estimated that "widespread AI adoption within the next five years using the technology
available today could result in savings of 5% to 10% of healthcare spending, or $200 to $360 billion annually."

Policymakers Take Notice

A major 2022 report from the U.S. Government Accountability Office and National Academy of Medicine examined
the potential for AI to address various challenges in the U.S. health care system, including demographic shifts,
burgeoning costs, and other problems that "illustrate the critical need to better address the effectiveness and
efficiency of our nation's health care delivery systems." The Biden administration also issued a major executive
order on AI last year that highlighted the opportunity to "[a]dvance the responsible use of AI in healthcare and the
development of affordable and life-saving drugs." This series will explore these opportunities in more detail.

When considering the role of public policy for AI/ML-enabled technologies, it is important to identify the trade-offs
associated with various proposed or existing rules. Safeguards are needed, but when lawmakers contemplate

                                                                                                      Page 2 of 2
                                     AI and Public Health Series: Introduction

policies for AI, they must keep in mind the potential unintended effects of regulation. The question they should be
asking themselves is: Will the policies we are considering-or those that already exist-hold back promising new
algorithmic innovations and treatments that could improve or even save lives?

For example, at a recent R Street Institute event, Sen. Mike Rounds (R-S.D.) noted that AI holds the potential to
achieve administrative savings for federal health insurance programs or, better yet, reduce the number of people
dependent on them by identifying and treating ailments sooner. This is important because federal healthcare
spending accounted for 29 percent of net federal outlays in fiscal year 2023.

Flexible, bottom-up public policies are essential if our nation hopes to maximize health outcomes while also making
care more affordable. In 2023, Senator Bill Cassidy, M.D. (R-La.), who serves as Ranking Member of the Senate
Committee on Health, Education, Labor and Pensions, released the "Framework for the Future of AI." "A sweeping,
one-size-fits-all approach for regulating AI will not work and will stifle, not foster, innovation," Cassidy argued.
"Likewise, we must adapt our current frameworks to leverage the benefits and mitigate the risks of how AI is
applied to achieve certain goals. And only if our current frameworks are unable to accommodate continually
changing AI, should Congress look to create new ones or modernize existing ones," he concluded.

Letting Technology Work Its Magic

Fear-based policies that delay innovations could limit AI's potential to advance meaningful health outcomes. As
Sen. Cassidy suggests, policymakers should tap existing rules and regulations to address concerns as needed and
work also understand how those policies-or newly proposed rules-could compromise health outcomes and cost
savings.

We hold the power in our hands to significantly expand the horizons of human health and well-being with the power
of path-breaking AI innovations. This series will explain how it can happen-if we let it.
    •   Part 1: How AI Can Advance Medical Knowledge and Improve the Patient Experience

Coming Soon:
    •   How AI Can Help Tackle Major Causes of Suffering and Death
    •   How AI Can Revolutionize Drug Discovery
    •   How AI Can Make Healthcare More Affordable and Accessible
    •   How the FDA Is Approaching AI/ML-Enabled Medical Devices


Load-Date: July 10, 2024


  End of Document

                                                                                                      Page 1 of 4
                                             Meet UCSD Health's first chief AI officer




                                 Meet UCSD Health's first chief AI officer
                                                  The San Diego Union-Tribune
                                                    January 2, 2024 Tuesday



Copyright 2024 The San Diego Union-Tribune

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 1741 words
Byline: Paul Sisson, The San Diego Union-Tribune

Body


For the record:

4:18 p.m. Jan. 7, 2024: A previous version of this story stated that Singh published a paper in the Journal of the
American Medical Association. The correct reference is the Journal of the American Medical Informatics
Association.

UC San Diego Health is importing a sharp mind to help guide its efforts in artificial intelligence.

The university health system recently announced the recruitment of Dr. Karandeep Singh to serve as its first "Chief
Health AI Officer," appointing the University of Michigan researcher and clinician to fill the Joan and Irwin Jacobs
Endowed Chair in Digital Health Innovation at the UCSD School of Medicine.

Singh, states Dr. John M. Carethers, vice chancellor for Health Sciences at UCSD in a recent university
announcement, is known for his expertise in this rapidly growing field.

"Having worked with Dr. Singh previously in our careers, I have witnessed his impressive track record and deep
expertise in health care technology firsthand," Carethers said. "He has become a national leader in the evaluation
of proprietary AI technologies, a specialist in AI governance and has actively engaged in influencing AI policy with
considerable experience and impact."

That work includes a paper in the Journal of the American Medical Informatics Association this year on developing
a method to precisely assess the net benefit of machine learning models when health care resources are
constrained. A piece last year in Nature Machine Intelligence covered using such technology to predict acute kidney
injury across health systems, and Singh also participated in a 2021 article in the Journal of the American Medical
Association that found deficiencies in a model said to be able to predict sepsis, a deadly condition that can cause
organ-damaging inflammation.

                                                                                                        Page 2 of 4
                                      Meet UCSD Health's first chief AI officer

A nephrologist trained at the University of Michigan who completed his internal medicine residency at UCLA
Medical Center, Singh also earned a master's degree in biomedical informatics from Harvard Medical School. At
Michigan, he served as the university's chief medical information officer of artificial intelligence.

With his new role effective last week, Singh said he plans to move his family to San Diego. His wife, Dr. Tejpreet
Kaur Nakai, a primary care and internal medicine specialist, also plans to practice in San Diego. The couple has
two children, ages 7 and 10.

UC San Diego Health is no stranger to using new AI technology in its operations, deploying software in its
emergency departments to help predict which patients might develop sepsis. A pilot program with Epic Systems,
maker of the nation's most popular electronic records system, is already using ChatGPT AI systems to draft routine
emails to patients. The system helps doctors save time with correspondence while maintaining oversight of their
messaging.

UCSD is investing heavily in the infrastructure to make itself among the leading locations for research into how AI
can increase the efficiency and accuracy of health care delivery, and a big part of that push will be a high-tech hub
set up to collect and collate disparate data sources generated at the bedside and in clinics. That effort is enhanced
by a $22 million grant from the Joan and Irwin Jacobs Center for Health Innovation on campus.

Singh's role will be twofold: helping guide the oversight and integration of already vetted AI technology into UCSD
operations and conducting research into the safety and effectiveness of newly developed models and methods.

UCSD is the third University of California campus to add a Chief Health AI Officer position, following UC San
Francisco Health and UC Davis Health, which made similar hires in 2023.

Singh recently took some time to discuss his approach to AI in health care with The San Diego Union-Tribune.
What follows is an edited question-and-answer session with the new executive:

Q: Your work has recently been cited in national policy around AI in health care. Given that this city is about as far
from Washington as one can get and still be in the United States, why UC San Diego?

A: The University of California has a big footprint in D.C. (Dr.) Chris Longhurst (UCSD chief medical and digital
officer) has been in D.C. on this topic more in the last year than I have, so I think there is actually plenty of
opportunity to participate in policy discussions. But, while policy is an important part of our mission, the primary
goal, I think, is taking care of the community. And that's what drew me to UCSD, the opportunity to really think big
about how we use AI to make both receiving and delivering care a better experience.

Q: What would you say to someone who asserted that this type of position is something of an extravagance in the
current climate of worker shortages that have permeated health care since the COVID-19 pandemic?

A: When people first hear about it they're like, "wait, why do we need someone in a leadership role for AI?" I think
there are two reasons why this position needs to exist. The first is that you need someone in health systems who's
knowledgeable and accountable for how this technology is used. The second is really about planning and strategy,
needing to have someone in the room when decisions are being made about how we organize our care, who is up
to speed with the AI tools that are available, what's coming and what might we want to consider using.

Q: With the sudden arrival of generative AI, especially as embodied by ChatGPT, it seems that there is a sort of
digital gold rush mentality going on at the moment with new products announced daily. How does an AI director
recognize true promise among so much hype?

A: A lot of our work which has been cited at the federal level has involved trying to evaluate systems and make sure
they actually work as well as they're supposed to. I hope to bring some of that rigor to this job so that we're not
solely relying on what's being told to us by companies but that we're actually going to verify those claims through
our own research and investigation.

                                                                                                          Page 3 of 4
                                       Meet UCSD Health's first chief AI officer

I come from a place of optimism but also skepticism about any one tool. I think a lot of what I'll be doing in my role
is going to be trying to help us cut through the clutter, rigorously looking at what's out there so we can be leaders in
helping others identify what works and what doesn't.

Q: Recent guidance from the Biden administration says that AI should "lead to health care outcomes that are fair,
appropriate, valid, effective and safe." Given that even their creators would say that these AI models are black
boxes, no one perfectly understands their inner workings, how do you make sure that these goals, especially safety
and accuracy, are upheld?

A: Even if it is a black box, I think we can evaluate any system. We can run it silently, meaning that we just hook it
up to see how well it does with real-world information, but we don't actually make any decisions based on what it
finds. By comparing real-world results with what the model finds, we can validate if it's a good system or not.

Q: Increasing efficiency is one of the biggest promises of integrating machine learning and artificial intelligence
models into day-to-day health care. But, in the early going, we've already seen that some models can end up
creating more work. For example, systems used to evaluate chest X-rays, while able to find anomalies that humans
might miss, also have been shown to kick up many more false positives. Is there a danger that some uses of AI will
require so much human oversight that they will not meaningfully increase efficiency?

A: Absolutely, and I think you've got to look at things in the way you intend to use them. The same tool used in two
different workflows might have very different effects. A radiologist is not going to be happy having to stop their work
and react to an algorithm that's flagging abnormalities that aren't that abnormal. That's just making more work. But
what if, instead of interrupting the radiologists, instead we're using the algorithm to order their work so that the next
image they get to review is the one that's most likely to have an abnormality? They're still reading all of the same
images, but they might just be reading them in a more efficient order.

Q: Given your work understanding and validating AI technology, what is one area of health care that you think is on
the cusp of change, and what is one area where you feel like we're still a long ways away from ever being able to
use AI to influence patient care?

A: Large language and multimodal models that respond with text explanations are probably what anyone would say
are on the cusp. Obviously, using these models to draft written replies to patients has already been piloted at
UCSD, and summarizing information is another one that's being tested right now. Let's say someone is ready to go
home, and they've been in the hospital for a month. It can be a lot of work to accurately pull together, sort of in a
nutshell, everything that happened to this person during that time. And that can also be a challenge when a patient
is handed off from one doctor to another. So accurate summarization to reduce the documentation burden is
another idea that's coming soon. Ambient documentation is another one that is right on the cusp. That's where,
instead of clinicians taking notes while staring at a computer screen, you can just talk to the patient naturally and
the encounter is being processed in real time, not just pure transcription but also formatting that information in a
way that the clinician needs to do in order to document that encounter. That kind of technology is being tested now
in a few places, but we haven't yet seen the big study that tells us whether it works or not. I think automated
decision making is very far away. There is just so much that clinicians do that isn't like math. They're trying to
understand that person in front of them, and what is that person's value system? What's important to them? What
information or advice can you give them to help them make the best possible decision for themselves? A lot of what
AI is about in health care today is what (chief AI officer) Sara Murray at UCSF calls "keyboard liberation." It's about
getting us away from keyboards and letting us spend more time with patients.

This story originally appeared in San Diego Union-Tribune.

©2024 The San Diego Union-Tribune. Visit sandiegouniontribune.com. Distributed by Tribune Content Agency,
LLC.


Load-Date: January 8, 2024

                                                              Page 4 of 4
                  Meet UCSD Health's first chief AI officer


End of Document

                                                                                                      Page 1 of 3
                                             Meet UCSD Health's first chief AI officer




                                 Meet UCSD Health's first chief AI officer
                                                  The San Diego Union-Tribune
                                                    January 2, 2024 Tuesday



Copyright 2024 The San Diego Union-Tribune

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 1695 words
Byline: Paul Sisson, The San Diego Union-Tribune

Body


UC San Diego Health is importing a sharp mind to help guide its efforts in artificial intelligence.

The university health system recently announced the recruitment of Dr. Karandeep Singh to serve as its first "Chief
Health AI Officer," appointing the University of Michigan researcher and clinician to fill the Joan and Irwin Jacobs
Endowed Chair in Digital Health Innovation at the UCSD School of Medicine.

Singh, states Dr. John M. Carethers, vice chancellor for Health Sciences at UCSD in a recent university
announcement, is known for his expertise in this rapidly growing field.

"Having worked with Dr. Singh previously in our careers, I have witnessed his impressive track record and deep
expertise in health care technology firsthand," Carethers said. "He has become a national leader in the evaluation
of proprietary AI technologies, a specialist in AI governance and has actively engaged in influencing AI policy with
considerable experience and impact."

That work includes a paper in the New England Journal of Medicine this year on developing a method to precisely
assess the net benefit of machine learning models when health care resources are constrained. A piece last year in
Nature Machine Intelligence covered using such technology to predict acute kidney injury across health systems,
and Singh also participated in a 2021 article in the Journal of the American Medical Association that found
deficiencies in a model said to be able to predict sepsis, a deadly condition that can cause organ-damaging
inflammation.

A nephrologist trained at the University of Michigan who completed his internal medicine residency at UCLA
Medical Center, Singh also earned a master's degree in biomedical informatics from Harvard Medical School. At
Michigan, he served as the university's chief medical information officer of artificial intelligence.

With his new role effective last week, Singh said he plans to move his family to San Diego. His wife, Dr. Tejpreet
Kaur Nakai, a primary care and internal medicine specialist, also plans to practice in San Diego. The couple has
two children, ages 7 and 10.

                                                                                                         Page 2 of 3
                                       Meet UCSD Health's first chief AI officer

UC San Diego Health is no stranger to using new AI technology in its operations, deploying software in its
emergency departments to help predict which patients might develop sepsis. A pilot program with Epic Systems,
maker of the nation's most popular electronic records system, is already using ChatGPT AI systems to draft routine
emails to patients. The system helps doctors save time with correspondence while maintaining oversight of their
messaging.

UCSD is investing heavily in the infrastructure to make itself among the leading locations for research into how AI
can increase the efficiency and accuracy of health care delivery, and a big part of that push will be a high-tech hub
set up to collect and collate disparate data sources generated at the bedside and in clinics. That effort is enhanced
by a $22 million grant from the Joan and Irwin Jacobs Center for Health Innovation on campus.

Singh's role will be twofold: helping guide the oversight and integration of already vetted AI technology into UCSD
operations and conducting research into the safety and effectiveness of newly developed models and methods.

UCSD is the third University of California campus to add a Chief Health AI Officer position, following UC San
Francisco Health and UC Davis Health, which made similar hires in 2023.

Singh recently took some time to discuss his approach to AI in health care with The San Diego Union-Tribune.
What follows is an edited question-and-answer session with the new executive:

Q: Your work has recently been cited in national policy around AI in health care. Given that this city is about as far
from Washington as one can get and still be in the United States, why UC San Diego?

A: The University of California has a big footprint in D.C. (Dr.) Chris Longhurst (UCSD chief medical and digital
officer) has been in D.C. on this topic more in the last year than I have, so I think there is actually plenty of
opportunity to participate in policy discussions. But, while policy is an important part of our mission, the primary
goal, I think, is taking care of the community. And that's what drew me to UCSD, the opportunity to really think big
about how we use AI to make both receiving and delivering care a better experience.

Q: What would you say to someone who asserted that this type of position is something of an extravagance in the
current climate of worker shortages that have permeated health care since the COVID-19 pandemic?

A: When people first hear about it they're like, "wait, why do we need someone in a leadership role for AI?" I think
there are two reasons why this position needs to exist. The first is that you need someone in health systems who's
knowledgeable and accountable for how this technology is used. The second is really about planning and strategy,
needing to have someone in the room when decisions are being made about how we organize our care, who is up
to speed with the AI tools that are available, what's coming and what might we want to consider using.

Q: With the sudden arrival of generative AI, especially as embodied by ChatGPT, it seems that there is a sort of
digital gold rush mentality going on at the moment with new products announced daily. How does an AI director
recognize true promise among so much hype?

A: A lot of our work which has been cited at the federal level has involved trying to evaluate systems and make sure
they actually work as well as they're supposed to. I hope to bring some of that rigor to this job so that we're not
solely relying on what's being told to us by companies but that we're actually going to verify those claims through
our own research and investigation.

I come from a place of optimism but also skepticism about any one tool. I think a lot of what I'll be doing in my role
is going to be trying to help us cut through the clutter, rigorously looking at what's out there so we can be leaders in
helping others identify what works and what doesn't.

Q: Recent guidance from the Biden administration says that AI should "lead to health care outcomes that are fair,
appropriate, valid, effective and safe." Given that even their creators would say that these AI models are black
boxes, no one perfectly understands their inner workings, how do you make sure that these goals, especially safety
and accuracy, are upheld?

                                                                                                          Page 3 of 3
                                       Meet UCSD Health's first chief AI officer

A: Even if it is a black box, I think we can evaluate any system. We can run it silently, meaning that we just hook it
up to see how well it does with real-world information, but we don't actually make any decisions based on what it
finds. By comparing real-world results with what the model finds, we can validate if it's a good system or not.

Q: Increasing efficiency is one of the biggest promises of integrating machine learning and artificial intelligence
models into day-to-day health care. But, in the early going, we've already seen that some models can end up
creating more work. For example, systems used to evaluate chest X-rays, while able to find anomalies that humans
might miss, also have been shown to kick up many more false positives. Is there a danger that some uses of AI will
require so much human oversight that they will not meaningfully increase efficiency?

A: Absolutely, and I think you've got to look at things in the way you intend to use them. The same tool used in two
different workflows might have very different effects. A radiologist is not going to be happy having to stop their work
and react to an algorithm that's flagging abnormalities that aren't that abnormal. That's just making more work. But
what if, instead of interrupting the radiologists, instead we're using the algorithm to order their work so that the next
image they get to review is the one that's most likely to have an abnormality? They're still reading all of the same
images, but they might just be reading them in a more efficient order.

Q: Given your work understanding and validating AI technology, what is one area of health care that you think is on
the cusp of change, and what is one area where you feel like we're still a long ways away from ever being able to
use AI to influence patient care?

A: Large language and multimodal models that respond with text explanations are probably what anyone would say
are on the cusp. Obviously, using these models to draft written replies to patients has already been piloted at
UCSD, and summarizing information is another one that's being tested right now. Let's say someone is ready to go
home, and they've been in the hospital for a month. It can be a lot of work to accurately pull together, sort of in a
nutshell, everything that happened to this person during that time. And that can also be a challenge when a patient
is handed off from one doctor to another. So accurate summarization to reduce the documentation burden is
another idea that's coming soon. Ambient documentation is another one that is right on the cusp. That's where,
instead of clinicians taking notes while staring at a computer screen, you can just talk to the patient naturally and
the encounter is being processed in real time, not just pure transcription but also formatting that information in a
way that the clinician needs to do in order to document that encounter. That kind of technology is being tested now
in a few places, but we haven't yet seen the big study that tells us whether it works or not. I think automated
decision making is very far away. There is just so much that clinicians do that isn't like math. They're trying to
understand that person in front of them, and what is that person's value system? What's important to them? What
information or advice can you give them to help them make the best possible decision for themselves? A lot of what
AI is about in health care today is what (chief AI officer) Sara Murray at UCSF calls "keyboard liberation." It's about
getting us away from keyboards and letting us spend more time with patients.

This story originally appeared in San Diego Union-Tribune.

©2024 The San Diego Union-Tribune. Visit sandiegouniontribune.com. Distributed by Tribune Content Agency,
LLC.


Load-Date: January 2, 2024


  End of Document

                                                                                                    Page 1 of 2
   AI pilot program aims to widen health care access How AI health care chatbots learn from the questions of an
                                           Indian women's organization




      AI pilot program aims to widen health care access How AI health care
      chatbots learn from the questions of an Indian women's organization
                                                  St. Louis Post-Dispatch (Missouri)
                                                          March 1, 2024 Friday
                                                               01 EDITION



Copyright 2024 St. Louis Post-Dispatch, Inc. All Rights Reserved

Section: A; Pg. 13
Length: 887 words
Byline: THALIA BEATY Associated Press

Body


NEW YORK - Komal Vilas Thatkare says she doesn't have anyone to ask about her most private health questions.

"There are only men in my home - no ladies," said the 32-year-old mother and housewife in Mumbai. "I don't speak
to anyone here. So I used this app as it helps me in my personal problems."

The      app    she     uses   is    powered      by    artificial intelligence  running    on     OpenAI's     <a
href="https://apnews.com/article/what-is-chat-gpt-ac4967a4fb41fda31c4d27f015e32660">ChatGPT model</a>, that
Myna Mahila Foundation, a local women's organization, is developing. Thatkare asks the Myna Bolo chatbot
questions and it offers answers. Through those interactions, Thatkare learned about a contraceptive pill and how to
take it.

Thatkare is one of 80 test users the foundation recruited to help train the chatbot. It draws on a customized
database of medical information about sexual health, but the chatbot's potential success relies on test users like
Thatkare to train it.

The chatbot, currently a pilot project, represents what many hope will be part of the <a
href="https://apnews.com/article/ai-chatbots-racist-medicine-chatgpt-bard-
6f2a330086acd0a1f8955ac995bdde4d">impact of AI on health care</a> around the globe: to deliver accurate
medical information in personalized responses that can reach many more people than in-person clinics or trained
medical workers. In this case, the chatbot's focus on reproductive health also offers vital information that - because
of social norms - is difficult to access elsewhere.

"If this actually could provide this nonjudgmental, private advice to women, then it could really be a gamechanger
when it comes to accessing information about sexual reproductive health," said Suhani Jalota, founder and CEO of
the Myna Mahila Foundation, which received a $100,000 grant from the Bill &amp; Melinda Gates Foundation last
summer to develop the chatbot, as part of a cohort of organizations in low- and middle-income countries trying to
use AI to solve problems in their communities.

                                                                                                    Page 2 of 2
   AI pilot program aims to widen health care access How AI health care chatbots learn from the questions of an
                                           Indian women's organization

Funders like the Gates Foundation, the Patrick J. McGovern Foundation and Data.org, are seeking to build up this
"missing middle" in AI development, especially in areas like health and education. These philanthropic initiatives
offer developers access to AI tools they otherwise could not afford so they can solve problems that are a low priority
for corporations and researchers - if they are on their radars at all - because they don't have high profit potential.

"No longer can the global north and high-income countries drive the agenda and decide what does and does not
need to be addressed in local communities in the global south," wrote Trevor Mundel, president for global health at
the Gates Foundation in an October online post, adding, "We cannot risk creating another chasm of inequity when it
comes to AI."

The Associated Press receives financial support for news coverage in Africa from the Bill &amp; Melinda Gates
Foundation.

The Myna Mahila Foundation recruited test users like Thatkare to write real questions they have. For example,
"Does using a condom cause HIV?" or "Can I have sex during periods?" The foundation's staff then closely monitor
the chatbot's responses, developing a customized database of verified questions and answers along the way that
helps improve future responses.

The chatbot is not yet ready for wider release. The accuracy of its responses is not good enough and there are
issues with translation, Jalota said. Users often write questions in a mix of languages and may not provide the
chatbot with enough information for it to offer a relevant response.

"We are not yet fully sure on whether or not women can understand everything clearly and whether or not it's fully
medically accurate all of the information that we're sending out," Jalota said. They are considering training some
women to help ask the chatbot prompts on behalf of someone else, though still aim to improve the chatbot so it can
be released on its own.

Dr. Christopher Longhurst, chief medical officer at the UC San Diego Health, has led the implementation of AI tools
in health care settings and said it is important to test and measure the impact of these new tools on patient health
outcomes.

"We can't just assume or trust or hope that these things are going to be good. You actually have to test it,"
Longhurst said. He thinks the promise of AI in health care is overestimated in the next two to three years, "But I
think long term, over the next decade, AI is going to be as impactful as the introduction of penicillin in health care."

Jalota's team consulted with other projects funded by the Gates Foundation that were designing chatbots for health
care settings so they could solve similar problems together, said Zameer Brey, interim deputy director for
technology diffusion for the Gates Foundation.

The Myna Mahila Foundation is also partnering with another Gates grantee to propose developing privacy
standards for handling data for reproductive health. The foundation, which is working with an outside technology
firm to develop the chatbot, is also considering other steps to help ensure the privacy of users.

"We've been discussing whether we should delete messages within a certain time frame of women sending it to add
to this privacy," Jalota said, as some women share phones with family members.


Load-Date: March 1, 2024


  End of Document

                                                                                                           Page 1 of 2
                                         Health care is where AI struggles to be helpful




                           Health care is where AI struggles to be helpful
                                                  Star Tribune (Minneapolis, MN)
                                                    April 24, 2024 Wednesday
                                                        METRO EDITION



Copyright 2024 Star Tribune All Rights Reserved

Section: BUSINESS; Pg. 1D
Length: 755 words
Byline: EVAN RAMSTAD; STAFF WRITER, STAR TRIBUNE (Mpls.-St. Paul)

Body


It was a warp-speed tour of what's happening with artificial intelligence in medicine.

Chris Manrodt, an R&D manager for Philips' medical imaging business in Plymouth, last Friday gave a presentation
to several hundred Twin Cities software developers and health care executives and then declared, "I feel like I've
said about 50 controversial things, so let me take your questions."

It was the opening session of a daylong gathering of about 1,200 people from the local data science community, the
first time in five years that MinneAnalytics, the local association of software developers, staged a conference
devoted to health care and medical technology.

"The promise is there. The challenge we face is that our track record kind of sucks," Manrodt said. "I don't want to
pick on anybody in particular, but I'll point to this headline: 'AI failed to live up to its potential in the pandemic.' "

In short, don't expect AI to replace doctors.

"The opportunity to turn the data from the administration of health care into the care of patients is actually a much
wider gap than I think any of us anticipated back in the middle of the last decade," he said.

Like many people, I'm frequently confused by what I read and hear about AI. Seeing investors pour so much money
into companies associated with it gives me fear of missing out, not just with my own investments but simply in
understanding what is going on.

My takeaway from Friday's conference is that medical technology developers are working on some great devices to
bring down the cost of diagnosing illness.

Executives from Twin Cities-based startup VoxCi Health described their device that will detect disease by sensing
chemicals in a person's breath - specifically what they exhale. Its initial target market is patients suspected of
having lung cancer.

Peerbridge Health, based

                                                                                                        Page 2 of 2
                                   Health care is where AI struggles to be helpful

in Nashville, promoted a small wearable device that measures cardiac output, potentially replacing the need for
people to go to a hospital or clinic for electrocardiograph (ECG) tests.

It seems, though, that it will be a long time for AI to be able to provide diagnoses or recommendations. In his
speech and a conversation afterward, Manrodt made it clear that people like him are at the start of a long climb. I
found his perspective helpful to hear with so much hype swirling.

"Health care has been the place where it has been most difficult to get AI to really make an impact," he said.

Generative AI, the kind that can create new ideas or things like conversations and stories and images, needs really
good data to build the connections and make diagnoses when someone is sick.

Unfortunately for creating an AI model, people seek health care in differing, unpredictable ways. There's no way to
track what makes people decide to go to a doctor or hospital or clinic in the first place.

"There is a complex set of social, psychological and economic factors before you decide to seek care and when
data collection in health care starts after you have sought care," Manrodt said.

Then, after a visit to a doctor or hospital, people also behave in different ways. Some will go back when their
physician says, and others won't. Many doctors don't ever know how well their patients fare after a visit.

"Most of the time when the patient leaves the care setting we don't know whether they've improved or not, unless
they come back and tell us," Manrodt said. For an AI model to be useful, he added, "The data on outcomes has to
be good."

One area where AI is moving quickly in health care, he said, is radiology. Artificial intelligence models are being
trained to analyze images in many fields. He also said that AI may prove useful in helping doctors and nurses
reduce errors in caregiving, akin to a collision warning system in a car.

"You still have to hit the brakes," Manrodt said. "But if you get the collision warning, you know something's up. If we
even save one more life with something like that, it's worth it."

An adviser to the University of Minnesota's Carlson School of Management, Manrodt said he's been amazed by
colleagues in other industries who also work with the school's faculty and students on AI.

He reminded me of an announcement Cargill made a few years ago about using facial recognition technology with
cattle to determine things about their feeding and health. The data scientists pushing that technology forward have
at least one big advantage on those trying to improve human health.

"You don't have to get a consent form from any of those cows," Manrodt said.

Evan Ramstad · 612-673-4241


Load-Date: April 24, 2024


  End of Document

                                                                                                        Page 1 of 2
                      Maternal health exec discusses using AI to address Black maternal mortality




Maternal health exec discusses using AI to address Black maternal mortality
                                                   Crain's New York Business
                                                          April 22, 2024
                                                          Print Version



Copyright 2024 Crain Communications All Rights Reserved




Section: Pg. 11; Vol. 40
Length: 758 words
Byline: Amanda D'Ambrosio

Body


Despite known issues of racial bias in AI, Dr. Dawnette Lewis says it can still help address wide racial disparities in
maternal health outcomes.

Black people in New York face five times the risk of dying because of pregnancy complications compared to white
people - a signal that there's a lot of work to be done, said Lewis, a maternal-fetal medicine specialist and the
director of Northwell's Center for Maternal Health. But she added that health systems are using technology to
develop solutions to this crisis - and are making strides.

Lewis said Northwell's Maternal Outcomes Navigation program, also known as MOMS, for example, uses AI to
increase communication with patients and identify pregnancy complications early. The combination of an AI chatbot
and a corresponding team of medical professionals has monitored 6,500 postpartum patients in the two years since
it launched - and has reduced hospital readmission rates within a month among Black patients by 60%.

Lewis spoke to Crain's about how the medical community can leverage AI to improve maternal health, despite its
current limitations. This interview has been edited for length and clarity.

There's been attention on the U.S. maternal mortality rate and worse outcomes among Black birthing people for
decades. Why do you think this has persisted?

I think mainly it's related to systemic racism and bias. Oftentimes I think we've made the assumption that chronic
conditions are a driver, but even when you look at Black birthing patients who are healthy, the disparity remains.
There's more than one element that drives the disparity.

Where do you see examples of systemic racism and bias?

                                                                                                          Page 2 of 2
                    Maternal health exec discusses using AI to address Black maternal mortality

A couple of years ago the NIH had a conference about how AI continues to perpetuate disparities. One of the
focuses was on calculators we use in medicine to quantify risks [of certain diseases.] For example, one of the
calculators was used to prioritize who gets a kidney transplant, but there was a [figure that placed a bias] on Black
patients [in the diagnostic equation.] What happened was Black patients ended up lower on the transplant list even
though they were just as in need of a kidney as anyone else. Those calculators are embedded into our medical
system and many don't help but actually hurt [existing disparities.] We have to revisit those, because they are built
into all of our electronic medical records.

How do current diagnostic tools like this exacerbate health disparities in the OB-GYN field?

For patients who had a prior cesarean delivery and wish to have a vaginal delivery in their next pregnancy, there's
also a calculator that factors in race. We think it increases the disparity, because when you put in race for a Black
patient, it lowers the success rate of a vaginal birth after cesarean [and may be contributing to higher C-section
rates among Black birthing people.] When you look at data in the U.S., in whatever state you look at, the cesarean
rate for Black patients is higher. There's currently work to remove that from the calculator.

Northwell uses AI through its MOMS program to identify postpartum patients who need care. What are the benefits
of this technology?

When we use AI in the MOMS program, we think about how to use it to help patients communicate with us if they
have any issues. We use it as a way to call for help.

I think the boundary is when you use race as a surrogate to help make medical decisions. If you're predicting a
condition like heart disease, then you should factor in risk factors for heart disease - not use race or ethnicity as one
of those risk factors.

Where do you see opportunities for investments to address the maternal mortality crisis?

I think AI is a good place to start. Even though this issue is something that's been talked about, it's not well-funded.
But everyone has a smartphone. I think [making AI chatbots or other technologies available on personal devices]
could be a way to bridge the cost.

What are you optimistic about?

When I started in maternal-fetal medicine, we couldn't get any other disciplines to even look at a pregnant patient.
Now, there are articles published in internal medicine journals, hypertension journals, which recognize that
pregnancy conditions are risk factors for cardiovascular conditions later on in life. I'm heartened that the American
Heart Association takes this seriously, specifically for Black mothers. Specialists aside from obstetricians in
maternal-fetal medicine are now investing in women's health and recognizing that women's health is not just about
nine months of pregnancy.


Load-Date: April 25, 2024


  End of Document

                                                                                                        Page 1 of 2
                                            Adding Up AI's Impact on Health Care




                                  Adding Up AI's Impact on Health Care
                                             The Dickinsonian: Dickinson College
                                                      June 6, 2024 Thursday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 563 words
Byline: Judith Faulkner '65, CEO and founder of Epic

Body


by Judith Faulkner '65, CEO and founder of Epic

As a math major at Dickinson, I was fortunate, with the help of my math professors, to be accepted for a summer
research job at the University of Rochester sponsored by the National Science Foundation. But the job needed a
programmer, and at that time I had never seen a computer. It was the 1960s, and Dickinson didn't have any. Yet.

When I explained that I knew nothing about programming, the people at Rochester gave me a FORTRAN book and
a week of access to the computer. By the end of the summer, the principal investigator had published a couple of
papers, and I went on to complete my B.S. and go to graduate school in computer science. After grad school, I, with
the help of a few others, started Epic, which most people know as the company that produces MyChart, their health
care provider's portal.

Since then, there have been many significant advances in IT, including PCs, graphical user interface, smartphones
and now generative artificial intelligence .

You are all familiar with AI. If you go to a hotel and wait for one of the elevators to come to your floor, that's
algorithmic AI (meaning someone has programmed the specific rules or algorithm) figuring out which elevator it
should be.

Most recently, we embedded generative AI-the technology behind ChatGPT-into our health care applications.
Generative AI is very clever. It looks at gazillions of similar situations and figures out what to say or do next. For
example, to help physicians be efficient, generative AI drafts responses to patients' MyChart messages for the
clinician to review and edit as needed. Feedback has been that the patients and clinicians really like the AI-created
replies because they often are friendlier than the busy clinician's responses.

In the exam room, as the patient and clinician discuss the patient's care, AI can-with patient approval-listen and
create a draft note for the clinician's documentation. This allows the clinician to concentrate on communicating with
the patient and saves a lot of time.

                                                                                                      Page 2 of 2
                                      Adding Up AI's Impact on Health Care

With many new use cases under development, AI will help make everything from scheduling appointments to office
workflows more efficient. Even more exciting is how AI can help us all stay healthier-for example, by showing you
and your clinician the results of the medications thousands of patients who are similar to you have taken, so you
can make the best choice.

Epic turned 45 years old in March, and we helped health care move from paper charts-often barely legible, dense
and easily misplaced-to electronic health records. In addition, now health systems can start using the data in these
records to solve the mysteries of disease and help people stay healthier.

It's exciting new technology, and there is a lot more to come. Even as things change, I'm grateful for the
mathematics foundation I received at Dickinson. It helped define who I am, and I think it's the best major there is.

Judith Faulkner '65 was named one of the "most powerful women in healthcare" by Forbes. She founded Epic, a
privately owned health care software company and the leading medical-records software company in the U.S., in
1979. She and her family established the Roots & Wings Foundation to provide vital support to low-income children
and families at pivotal times.

Read more from the spring 2024 issue of Dickinson Magazine.

TAKE THE NEXT STEPS?


Load-Date: June 9, 2024


  End of Document

                                                                                                     Page 1 of 2
        Panel discusses implementation of AI into healthcare for underserved communities - The Daily Texan




      Panel discusses implementation of AI into healthcare for underserved
                        communities - The Daily Texan
                                        The Daily Texan: University of Texas - Austin
                                                      April 8, 2024 Monday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 477 words

Body


The IC² Institute, a hub for interdisciplinary research and economic development at UT, hosted the AI Health for All
conference on April 4 to discuss the implications of incorporating AI into healthcare.

The conference gathered researchers, health professionals and community leaders. It also featured a panel called
"Designing an Inclusive Health AI for All" which explored the barriers to AI that underserved communities may face.

"If we, together, can understand the problems and the barriers, then together, we can then start doing something
about it and actually helping make sure that AI is integrated in a way that really advances health equity," said
Zainab Garba-Sani, one of the panelists at the event.

Garba-Sani is a Stanford researcher who specializes in health AI policy and implementation in the United Kingdom.
During the panel, Garba-Sani said her research explores the way certain demographic populations perceive AI.

"I'm leading an international interdisciplinary initiative that really tries to make sure that AI is implemented in a
community-centered way, so no one's left behind," Garba-Sani said. "Actually, you really understand the hopes and
fears of our most underserved communities when it comes to AI."

Garba-Sani said her research sheds light on why people from certain ethnic backgrounds perceive AI more
negatively. Garba-Sani said representation in health data sets may be impacted because they don't take into
account the hesitation underserved communities have towards AI. This discrepancy in data may mean underserved
communities do not get full access to the benefits of AI in healthcare.

"The most underserved and underprivileged get even worse health outcomes because of bias and the fact that
they are underrepresented in the data set," Garba-Sani said. "Therefore, we're actually perpetuating all these
disparities."

Jo Carcedo, former philanthropy leader for the Episcopal Health Foundation, said AI presents an opportunity for
researchers to be intentional about who is included in data sets used in healthcare research. This helps to ensure
different communities are being represented, Carcedo said.

                                                                                                    Page 2 of 2
       Panel discusses implementation of AI into healthcare for underserved communities - The Daily Texan

"If we aren't careful, we're repeating narratives that are not beneficial to the work that we're trying to achieve,"
Carcedo said. "We have a story to tell that is reflective of the people that we really want to see participate in this."

Meme Styles is the founder and president of Measure, a research and data activism organization based in Texas,
and serves as the vice president of responsible and ethical AI with the Austin AI Alliance. Styles said her
organization joins community members to provide information about AI as a health tool for underrepresented
communities.

"We are sharing with our community ways to lean in," Styles said. "The thing is, if we don't lean in now, it's going to
be designed without us."


Load-Date: April 8, 2024


  End of Document

                                                                                                     Page 1 of 4
                                Slowing down AI for the health of the planet - The DePaulia




                  Slowing down AI for the health of the planet - The DePaulia
                                                The Depaulia: DePaul University
                                                  September 30, 2024 Monday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: OPINIONS; Pg. 1
Length: 967 words
Byline: Connor Upshaw

Body

Artificial intelligence has completely rewired how many of us accomplish things, from drafting ideas to creating
artwork. While there may be positives to using AI, there is growing concern about some negative impacts, including
our overreliance on technology and the overlooked effect on the environment, because of the large amount of
energy it takes to run AI software.

When someone says AI, most people will think of language models like ChatGPT, Google Gemini or Microsoft
Copilot. These forms of AI respond and complete the user's tasks in a conversational and organized structure.

Need to send a memo to your employees? AI can draft it. Need a recipe for brownies? AI can give you one. Need
to finish your final paper for your ethics class? Check your school's policy on AI usage, but it sure can write the
whole thing for you.

There are genuine productive uses for this software, but we do not know the long term risks of using it. Like with
any new technology, testing is important and it seems as though companies are throwing this out for the public to
use and basing all of their updates and tweaks off of user experience.

PauseAI is a non-profit community organization that aims to convince governments to halt AI software
advancement.

Joep Meindertsma, a Dutch software engineer who founded the organization, said he started the project because
he is worried about the development of frontier AI models.

"It's absolutely ludicrous that we're allowing companies to run these dangerous experiments, and we all are just
sitting ducks while it's happening," Meindertsma said.

Amy Merrick, a journalism instructor at DePaul, has been exploring artificial intelligence and is working on her
master's degree in computer science to study the implementation of AI. Merrick believes that AI will greatly impact
work, education and communication.

"Some of the positives that we've seen in recent AI usage are happening in science and technology," Merrick said.
"For example, learning about the structure of proteins which could lead to the treatment of diseases."

                                                                                                      Page 2 of 4
                             Slowing down AI for the health of the planet - The DePaulia

But the impact on the environment has serious implications for the future.

"The amount of energy that is needed to build and run these programs is making it difficult for big tech companies
to reach zero emissions," Merrick said.

That goal of reducing carbon emissions would only be harder to reach from this point forward as the demand for
research and development grows.

NPR found that the number of data centers that house servers for AI has risen from 3,600 in 2015 to over 7,000
worldwide today. That 94% increase in data centers also comes with increases in emissions, according to the
report. Google alone has reported a 48% increase in emissions since 2019.

Even with growing awareness, Meindertsma fears AI's unchecked growth will cause huge problems.

"We are now getting into territory where the environmental impact is about to get serious, but if we allow it to
continue, it will be 10 times worse," Meindertsma said.

We do not know what AI will look like in the future. It could remain an instrumental tool yet also be detrimental to
our thought processes, making us too reliant on its existence. From science fiction films that prophesize androids
ruling the world to the current state of automation in many different industries that may put thousands of peoples'
jobs at risk, these fears about an AI takeover can be both exaggerated and plausible.

To me, it's worth slowing down AI development to make sure we are prepared if things go wrong. If we treat AI the
same way we treat all other things that harm the environment, then there will be no real change in its production. I
don't think anyone will stop using something until they can see the damage. Even then, they'll still make an
argument that it isn't a problem, just like people have done with climate change.

Regulating AI lies in the hands of lawmakers and politicians, and that might make change seem insurmountable for
the average person. With that, we could be looking at safer AI and a smaller harmful impact on our environment.

 "Our politicians are completely sucked into this technological race dynamic ... and they are not trying to work
together," Meindertsma said. "Working together is possible. We just need one country to start."

I like certain aspects of AI but I think the consumer version that everyone's mom, brother and dog are using is not
something to blindly trust as it's no secret it can be unsafe. Meindertsma even mentioned how some AI systems are
able to hack other websites and steal data.

Do I think we'll be enslaved by robots in 10 years? Probably not. What I do know is that when AI companies start
having a bigger impact on our planet and it takes peoples' jobs, everyone is going to start moaning that we should
have done something about it when we could.

Let's not get to that point. The time to do something is now.

Stay informed with The DePaulia's top stories,

delivered to your inbox every Monday.

View Story Comments

0

Like This Story

Share on Facebook

Share on X

Email this Story

                                                                                                  Page 3 of 4
                                    Slowing down AI for the health of the planet - The DePaulia

Print this Story

Leave a Comment

Tags:
      •   artificial intelligence
      •   environmental issues

Facebook

Instagram

X

Spotify

YouTube

Email Signup

Open Search Bar

Search this site

Submit Search
      •   Sections News La DePaulia Arts/Life Sports
      •   Sections Opinions Nation & World Focus
      •   Follow X Instagram Facebook Newsletter Spotify YouTube
      •   About Contact The DePaulia Staff Advertise The DePaulia Code of Ethics Get Involved

© 2024 · FLEX Pro WordPress Theme by SNO · Log in

Comments (0)

Share your thoughts...

All

The DePaulia Picks

Reader Picks

Sort: Newest

Cancel reply

Your email address will not be published. Required fields are marked *

Comment * Spam Control Field.Verification Field.

Name *

Email *

Sign me up for the weekly DePaulia newsletter and breaking news alerts.

                                                                                      Page 4 of 4
                        Slowing down AI for the health of the planet - The DePaulia

?

Close

Close Modal Window

Close


Load-Date: September 30, 2024


    End of Document

                                                                                                Page 1 of 11
    AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                       doctor may use an algorithm before deciding on your treat....




   AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to
    transform health care, soon your doctor may use an algorithm before
                         deciding on your treatment
                                          Spokesman Review (Spokane, WA)
                                             February 27, 2024 Tuesday
                                                   MAIN Edition



Copyright 2024 Spokane Spokesman-Review

Section: A; Pg. 001
Length: 1575 words
Byline: Amanda Sullender The Spokesman-Review

Body


When doctors decide on a

course of treatment, they have

a lot of data to inform their decision-

making. But they do not

always have the time to interpret

that data.

University of Washington

Chair of Radiology Dushyant Sahani

believes physicians are only

able to process about 5% of the

data available to them before deciding

on a particular treatment.

"Physicians are overwhelmed

with managing the data. And we

                                                                                                 Page 2 of 11
     AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                        doctor may use an algorithm before deciding on your treat....

want the physician to focus more

time with the patient and provide

them the best experience,"

he said. "Health care is one of the

best human endeavors, but it's

also a journey of data. And in the

modern world, we have so much

data, but we need a better way of

using this data for appropriate

decision-making."

Sahani is a co-founder of UW's

Institute of Medical Data Science,

which supports health care-related

artificial intelligence initiatives.

Founded last year in Seattle,

the institute hopes to provide

research, education and funding

to get AI into hospitals to provide

better patient outcomes.

The technology promises to

transform health care by synthesizing

millions of pieces of data

in nanoseconds - informing how

a physician treats their patients

and how care is prioritized. But

as AI becomes permanently enmeshed

in the process of healing, an

algorithm working as intended can

become a life and death proposition.

Appropriately used, an AI algorithm

                                                                                                Page 3 of 11
    AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                       doctor may use an algorithm before deciding on your treat....

helps medical professionals

sift through large amounts of data in

a short time. Sahani pointed to the

determination of whether a lesion

in the body is potentially cancerous.

Based on the risk profile of the lesion,

a physician could decide to wait

to see if the legion grows, or test it

through an invasive procedure that

carries a small amount of risk.

An AI algorithm could be trained

on many images of the same type

of legion and a host of other data.

Through this, the AI would determine

whether that legion carries

enough risk to merit further testing,

which would inform the doctor's observations.

AI also can help triage and prioritize

care. Often, medicine's role is

to decide how to prioritize patients

who need care first or need more

care. Sahani said these AI tools can

interpret patient data and "pick selective

patients who might benefit

most appropriately for early interventions."

More mundane uses of AI in

health care are the use of large language

models - in the vein of Chat-

GPT - that can assist medical providers

with administrative tasks like

                                                                                                Page 4 of 11
    AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                       doctor may use an algorithm before deciding on your treat....

writing notes following a doctor visit

or helping patients schedule their

appointments.

"AI is collecting and integrating

that information for us, which is

very difficult for humans to manually

apply. We need many staff and

other resources to meaningfully apply

data. AI can often make a more

precise diagnosis quicker," Sahani

said. "With AI, we might be able to

integrate clinical information with

lab imaging and other information to

come up with more personalized diagnostics

that will help us with more

appropriate decision-making for that

patient."

Though he believes AI is "not a

panacea," Sahani and his collaborators

at the Institute of Medical Data

Science hope the technology will improve

the patient experience.

Despite the optimism, many of the

issues plaguing AI in other sectors

have much higher stakes in health

care. An algorithm that does not

work correctly could lead a doctor to

misdiagnose their patient or incorrectly

prioritize care.

DOES AI CREATE BIAS IN HEALTH CARE?

                                                                                                 Page 5 of 11
     AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                        doctor may use an algorithm before deciding on your treat....

A 2019 study conducted by the by

University of California, Berkeley

found an algorithm used to triage

care among 200 million patients a

year was racially biased.

The AI analyzed in the study was

used by hospitals to identify patients

with complex health needs who may

need specialized care. But researchers

found the algorithm predicted

health care costs rather than the severity

of illness.

Because of existing racial disparities

in health care, less money is

spent on Black patients than white

patients. As a result, the algorithm

assumed Black patients were less in

need of specialized care than white

patients, even though that is not the

case.

If corrected, the algorithm would

predict 46.5% of Black patients

would need this additional help,

compared to the 17.7% of Black patients

the algorithm actually predicted

would need it.

"Less money is spent on Black

patients who have the same level of

need, and the algorithm thus falsely

concludes that Black patients are

                                                                                                 Page 6 of 11
     AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                        doctor may use an algorithm before deciding on your treat....

healthier than equally sick White patients,"

the study reads.

In a U.S. Senate hearing on the

use of artificial intelligence in health

care earlier this month, study author

Ziad Obermeyer said his research

showed how easily human bias could

unintentionally find its way into AI

and then be legitimized by the supposed

impartiality of the technology.

"(AI) predicted - accurately - that

Black patients would generate lower

costs, and thus deprioritized them

for access to help with their health.

The result was racial bias that affected

important decisions for hundreds

of million patients every year," he

said in remarks to the Senate.

Though not analyzed in his study,

Obermeyer noted AI algorithms can

also create bias outside of race, such

as gender, socioeconomic status or

disability.

Obermeyer also said that many of

these algorithms are still in use following

his 2019 study, and that regulators

should not "take algorithm developers'

word that it's performing

correctly." Despite these criticisms,

Obermeyer also stated AI has the

                                                                                                Page 7 of 11
    AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                       doctor may use an algorithm before deciding on your treat....

potential to both improve health and

reduce costs.

Speaking at a Senate Finance

Committee hearing, committee

Chair Sen. Ron Wyden, D-Ore., said

that while AI is making health care

more efficient, the technology is also

"riddled with bias that discriminates

against patients based on race, gender,

sexual orientation and disability."

In his efforts to spread AI in health

care, Sahani hopes the technology

can reduce disparity. But he acknowledged

it can exacerbate bias

as well.

"Clearly, bias is an important concern.

I don't think we have addressed

that fully. We need to keep an open

mind and constantly evaluate our algorithms

to validate if they are true,"

he said.

Sahani also noted it is incredibly

important to be upfront with the

public and patients about how AI is

being utilized in their health care.

WHAT ABOUT IN SPOKANE?

Artificial intelligence tools are already

in use in Spokane hospitals,

although they may not yet be used

in some of the expansive ways envisioned

                                                                                                 Page 8 of 11
     AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                        doctor may use an algorithm before deciding on your treat....

by AI's champions.

Providence, the largest health system

in Spokane, uses AI to complete

administrative tasks, assist medical

professionals in diagnosis and in

"other innovative methods" in Sacred

Heart Medical Center and other

facilities.

"Providence is always exploring

ways to improve the patient experience.

For the last several years, Providence

has invested in technological

advancements, including artificial

intelligence, that allow us to pioneer

new ways of delivering high-quality,

compassionate care safely and

responsibly," Providence said in a

statement.

At the beginning of this year, Providence

CEO Rod Hochman said AI

would be "one of the major drivers of

transformation" for the health system

in 2024.

"Having significantly invested in

IT infrastructure, digital and cloud

technology in recent years, health

systems have laid the foundation for

rapid AI innovation in 2024. Generative

AI will fuel advances leading

to personalized patient experiences,

                                                                                                Page 9 of 11
    AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                       doctor may use an algorithm before deciding on your treat....

improved patient outcomes and

clinical breakthroughs," he said in

January.

"Grace" is an AI-powered chatbot

on the Providence website. Powered

by large language models similar to

those used in ChatGPT, Grace helps

patients to "determine what level of

care they needed" and "triage a high

volume of patient calls."

Providence also has partnered

with Microsoft and AI company Nuance

to implement an AI tool that

assists physicians with data entry,

which Providence said will allow

more time with patients.

MultiCare, Spokane's other large

health system, also has implemented

AI tools in recent years. The technology

is used in the organization's

planning tool and Electronic Medical

Record to add "more patient

time." AI also is used for "inventory

management, reducing waste and

detecting anomalies," according to a

statement from MultiCare Chief Information

Officer Bradd Busick.

The hospital system has launched

an "ambient listening platform" that

uses AI to automate the creation of

                                                                                              Page 10 of 11
    AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                       doctor may use an algorithm before deciding on your treat....

clinical notes and medical charts.

MultiCare facilities also use AI to

refill patient prescriptions over the

phone.

MultiCare Deaconess Hospital introduced

several autonomous robots

that use AI to traverse the hospital

and deliver supplies and complete

menial tasks. According to Multi-

Care's statement, the four Moxi robots

have completed 35,000 deliveries

of items, traveled 7,000 miles and

saved over 23,000 staff hours.

Both hospital systems said only

internal data is used to train their AI

programs and that all private data is

protected.

"MultiCare's utilization of AI is

trained on our own curated data. We

do not use open source/off the shelf

platforms but rather apply strict governance

and provisions about the

types of investments we make in AI,"

Busick said in a statement.

Providence signed the "Rome Call

to AI Ethics," a 2020 document that

hopes to create a framework around

the ethical development of AI. Also

signed by IBM and Microsoft, the

letter states AI must be developed

                                                                                              Page 11 of 11
    AI IN HEALTH CARE AND IN OUR LIVES As artificial intelligence aims to transform health care, soon your
                       doctor may use an algorithm before deciding on your treat....

"with a focus not on technology, but

rather for the good of humanity and

of the environment."

"Providence proactively set up

an AI governance structure to align

priorities and strategy, safeguard

patient data and privacy, prevent

bias and ensure access to promising

innovations for all, especially under

served populations," the hospital system

said in a statement.



Notes

Amanda Sullender can be reached at (509) 459-5455 or by email at amandas@spokesman.com


Load-Date: February 29, 2024


  End of Document

                                                                                                         Page 1 of 2
                   Student-led Bruincare initiative uses AI to enhance mental health support services




   Student-led Bruincare initiative uses AI to enhance mental health support
                                     services
                                      Daily Bruin: University of California - Los Angeles
                                                      April 5, 2024 Friday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 710 words
Byline: Catherine Hamilton

Body


This post was updated April 4 at 9:01 p.m.

Anish Dulla wanted to make mental health services on campus more accessible - so the fourth-year statistics and
data science student turned to artificial intelligence.

The Bruincare server allows for 24/7 access to immediate mental health support and helps UCLA Counseling and
Psychological Services with triage and patient support, Dulla said. The server, which is currently in a study phase,
was developed in part by the statistics and data science department - including Dulla's advisor, senior continuing
lecturer Vivian Lew. The student-led Bruin Mental Health Advisory Committee led its outreach, along with students
June Park and Kai Alcayde.

Dulla said he launched the platform after hearing the experiences his friends had while accessing CAPS services
during mental health crises. One of his friends had to wait three to four weeks for an initial consultation, Dulla said,
leading him to start planning in September.

The program will allow students to seek mental health care without the potential barrier of having to speak with
someone they do not know, he said.

"A lot of students feel like they're not ready to speak to a person. ... People aren't willing to speak to their family,
their friends, so speaking to a stranger or a counselor is also very daunting," Dulla said. "This is a way for people to
get some immediate support without having to feel the burden of judgment."

The Bruincare server begins by asking the student to share about their mental health and then offers coping
suggestions and available services if the student grants permission. After the student finishes using the platform, it
provides a report that summarizes the student's concerns and rates the severity of their symptoms from one to four.

A rating of one indicates more generalized anxiety, and a rating of four indicates the need for serious, immediate
care, Dulla said. He added that the score can help providers prioritize triage patients' care.

                                                                                                        Page 2 of 2
                 Student-led Bruincare initiative uses AI to enhance mental health support services

In its current stage, the platform allows students to remain anonymous and sends the report back to the student.
However, the Bruincare report will only be accessible by a CAPS provider to help them prepare for an initial
consultation after the platform officially launches, Dulla said.

Lew said in an emailed statement that she became interested in the platform when Dulla told her about it, adding
that she believes it would grant students quicker access to mental health services.

Elena Chan, a co-chair of BMHAC and a third-year psychobiology student, said CAPS reached out to the
committee for student input on the idea, specifically as to how to introduce AI into the mental health space. She
and her co-chair, doctoral student in nursing Cristina Cabrera-Mino, liked Bruincare as a way to assist clinicians
with triage and provide students after-hours care, she said.

Chan added that many graduate students have had difficulties accessing CAPS services during the center's current
business hours, which tend to range between 8 a.m. and 6 p.m. on weekdays. CAPS currently does not operate on
the weekends.

"Introducing this would honestly increase the exposure and the availability (of campus mental health resources)
because I myself understand that it's not easy to go on a triage call for a set amount of time during certain hours of
the day," Chan said. "I was really excited about the potential of this AI service created by our own students."

Despite wariness surrounding the use of generative AI, especially in an area as sensitive as mental health care,
Dulla said the platform and information provided to it are secure and private. Chan said Bruincare can be bolstered
by complex IT services that ensure information submitted through the platform is protected and encrypted to only go
to CAPS providers.

One of the main areas of improvement moving forward will be incorporating UCLA-specific resources and
information in the platform's database, which at the moment mostly relies on open AI services, Chan said.

Dulla said he hopes Bruincare will ultimately ensure Bruins get adequate, timely access to mental health care.

"We're not intending to replace CAPS or replace any current service. We're just intending to aid CAPS, provide
another tool in the tool belt," Dulla said.


Load-Date: April 8, 2024


  End of Document

                                                                                                         Page 1 of 2
                                   Campus community uses AI to address mental health




                    Campus community uses AI to address mental health
                                       The Technician: North Carolina State University
                                                  March 20, 2024 Wednesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 927 words
Byline: Kate Denning, News Editor

Body


Editor's Note: This article is part of a collaborative project between nine North Carolina college newsrooms to cover
mental health in their communities. To explore the interactive project developed specifically for this collaborative,
visit the mental health edition website.

An NC State professor is using artificial intelligence to flag keywords on X, the platform formerly known as Twitter,
in posts containing content that may indicate mental health concerns.

Ana-Maria Staicu, a professor in the department of statistics, is conducting this research, funded by a state grant.
Staicu said she decided to look into if violent events could be predicted by an individual's social media activity after
the August shooting at UNC-Chapel Hill. The research also considers trends in shootings since COVID-19 by
comparing social media activity before and after the onset of the pandemic.

"We're looking at how the mental health trends have been impacted by COVID lockdown," Staicu said. "This has
been triggered by the fact that a lot of these violent events have happened, have intensified, after COVID. So we
wanted to see people who had some mental health issues before, how is their activity after COVID-19."

Staicu said the research utilizes AI to analyze what she called the arousal of a post - whether the post is positive,
negative or shows any strong emotion at all. Through this function and the use of keywords, AI is able to flag posts
containing potentially concerning messages.

After the post is flagged, Staicu said a potential intervention process is contingent on having a control group.

"We need to have a sense of what is a normal tweeting behavior, and to define that normal, it's important to have
an age group, right?," Staicu said. "Because an adult on social media wouldn't necessarily tweet as a young adult.
Then we need to define what is abnormal."

Sripad Ganti, a first-year studying statistics, has assisted Staicu in the research. After seeing how data could be
used for a good cause, Ganti started the Dreamers and Data Club with the purpose of using statistics to promote
social change.

                                                                                                         Page 2 of 2
                                Campus community uses AI to address mental health

While jump-starting the club, Ganti had the idea to create YUNO, an AI chatbot specifically designed to address a
user's mental health concerns and distribute resources.

Ganti said he has witnessed students experience long wait times at the Counseling Center, and felt as though a
chatbot like YUNO, an acronym for "Your Understanding Nurturing Observer," could be a resource during those
periods.

"I have friends who sometimes try to book appointments to the counseling sessions, and that takes forever; it's like
a week, two weeks sometimes," Ganti said. "So it was then I decided let's maybe create some sort of chatbot or
something where, I guess it can kinda bridge the gap between the time it takes to get an appointment and just be a
helpful resource."

YUNO is similar to AI models like ChatGPT, but Ganti has been able to train the data in a way that tunes the
responses to be mental health-oriented.

"What really, I think, sets it apart a little bit is that you can fine tune whatever the ChatGPT API is to specifically
focus on mental health resources," Ganti said. "I can put in mental health resources that I find on the web, or I can
put in how you respond to certain things."

While he hopes YUNO can offer resources to users, Ganti said YUNO should never be used as a replacement for
therapy. Instead, he sees it functioning as an on-the-go way to access resources quickly, or simply being a place for
users to vent.

"You want to talk to an actual person," Ganti said. "But sometimes an actual person is not available right away. And
in that time, if you really need some sort of resources, or if you're looking for resources, or even if you know
someone who is struggling, and you want to find resources for them, that's the goal of the chatbot."

Ganti and Staicu said mental health issues are particularly of concern amongst teenagers and young adults. While
Staicu said the pandemic is a contributor to mental health issues amongst the younger generation, Ganti said the
shock of being thrust into a new, high-pressure environment and the expectations that go along with that is a key
factor.

"You're expected to, all of a sudden, be an adult right away," Ganti said. "You're also working with so many
students that you feel the need to perform and do well. ... Because of that, sometimes people put a lot of
expectations on themselves, and that can often sometimes result in problems and unneeded stress."

Staicu said doing research like this at NC State is beneficial because of students like Ganti who realize the need
that exists and take advantage of the resources NC State has in order to find a solution.

"Not only are they strong students, but they're able to take advantage of the classes that we offer, and sometimes
really teach themselves to learn how to scrape data, how to write codes to automatically download data," Staicu
said. "We're talking about thousands of and hundreds of users, right? You can't do that manually because it takes
hours, so being able to have access to coding and improving the skills, I think that's very helpful."

Staicu said the issue of mental health is everyone's responsibility to understand and involve themselves in.

"I feel that there's a lot of focus nowadays on mental health, but I think we're just scratching the surface," Staicu
said. "I think there's more to learn, and I think we have a responsibility to the young people to help them get the life
that they deserve and they were meant to have."


Load-Date: March 20, 2024


  End of Document

                                                                                                            Page 1 of 4
                 AI technologies are giving some doctors more time for patients, improving health care




  AI technologies are giving some doctors more time for patients, improving
                                 health care
                                               Tribune-Review (Greensburg, PA)
                                                  September 9, 2024 Monday



Copyright 2024 Tribune Review Publishing Company All Rights Reserved

Section: Tribune-Review Valley News Dispatch
Length: 1339 words
Byline: by MEGAN TROTTER and HALEY MORELAND

Body


Emily Schneider uses artificial intelligence at work for six hours a day, twice a week.

As a physician assistant at West Penn Hospital, it's her job to operate Vectra, a 3D imaging system intended to
capture signs of skin disease. The algorithm the machine uses is an example of artificial intelligence at work. It uses
a vast database of information and applies it to each photograph, identifying potential problems far faster than any
human could.

It's one of the many ways AI is being used in medicine to improve patient care. According to a 2023 report by
Morgan Stanley, 94% of hospitals nationwide were implementing or planning to implement AI technologies.

West Penn Hospital is the only hospital in Pittsburgh using AI technology like Vectra.

While the patient plants their feet at the center of the machine, Vectra takes images using 92 cameras installed in
the various pods that make up its curving structure.

Those images are then transferred to a computer and analyzed by an algorithm that scores each spot's risk on a
scale of zero to 10. This scale is called the Dermoscopy Explainable Intelligence Score, or DEXI score.

After the photos have been analyzed and the patient's records are sent to a specialist, Schneider's work is done.
Each scan takes about an hour, so she can do up to 12 scans a week.

Not only is the process quick, Schneider said, but it also is more effective for identifying changes in skin condition
over time.

"I think it's definitely making an improvement," Schneider said. "I think it's just adding to the patient experience."

Katrina Barger, 38, of Churchill was the first person to step inside the machine. She was diagnosed with melanoma
in 2011, at age 26.

                                                                                                       Page 2 of 4
               AI technologies are giving some doctors more time for patients, improving health care

"It was definitely shocking," Barger said of the cancer diagnosis. "When you're young, you never really think you're
going to get cancer."

She had been able to manage her melanoma by attending regular doctor and dermatologist appointments, keeping
out of the sun and protecting her skin with sunscreen, but Vectra took her health care a step further.

"I was very impressed because it was able to locate every mole on my body," Barger said.

Barger has had 30 melanoma spots removed -- one of them was detected by Vectra. Vectra also found three other
atypical cells on Barger's skin. She has been inside the Vectra machine twice, once in October and again in June.

"It's available to anyone who wants to use it and make an appointment," Barger said.

The machine isn't covered by insurance. A scan costs $250.

New tech in the health industry

At Allegheny Health Network, new technologies are being developed and implemented daily. More than 300
providers at AHN have started using AI.

Ashis Barad, a physician who serves as AHN's chief digital information officer, said the health system started using
AI to record and summarize health visits. This new technology, called ambient listening, is intended to shorten the
time it takes to file medical records.

Ambient listening uses an audio recording from the health visit and transcribes it in real time before transforming
the recording into a summary. This summary is then edited and approved by a physician before being stored.

Barad said it takes doctors 16 minutes, on average, to file medical records after a health visit. Ambient listening
technology can dramatically reduce that time and gives doctors more time for other things, such as spending time
with patients.

"We hope that doctors also get to take time where they say ... I want a refreshment break (or) I need to use the
bathroom," Barad said. "You think these are simple things, but sometimes when you're in the throes of (the) clinic, I
know plenty of doctors that have waited hours to just go get a drink because they just have so many patients
waiting for them."

Other hospital systems, such as Penn Medicine and UPMC, also have begun using ambient listening in their
buildings to help doctors focus on face-to-face interactions with patients.

"A lot of doctors are feeling a sense of burnout, and it's because of the work that needs to be done ... (and) the
increasing demands of us to correspond with patients," said William Hanson, chief medical information officer for
Penn Medicine.

Chris Carmody, chief technology officer and senior vice president of UPMC, said system hospitals have
implemented nine electronic health record systems.

"It's shifting our nurses, our doctors away from doing the documentation, having it automatically done so they can
focus on a patient," Carmody said.

While AI has been cutting down on doctors' time charting, it also has begun to help predict patient behavior and risk
factors.

Researchers at Penn Medicine at the University of Pennsylvania Medical System and Penn State University are
implementing AI programs that predict people's risk of infection and disease.

Dr. Liu Dajiang, a health sciences professor and director of artificial intelligence and medical informatics at Penn
State College of Medicine, said doctors are using AI to determine someone's genetic risk score.

                                                                                                            Page 3 of 4
                AI technologies are giving some doctors more time for patients, improving health care

"A lot of people are lucky to be born with some genetic mutations that protect them from developing disease,
regardless of their lifestyle," Dajiang said. "The idea for these algorithms is to figure out what are the protective
variants and how they function, so that we can develop a drug that mimics those."

With AI, Dajiang said, it will become possible to use medical records to quickly conduct DNA sequencing, a practice
that can pinpoint genetic disorders. DNA sequencing cost billions of dollars at the beginning of the 21st century, but,
with AI technologies, prices could drop to a few hundred dollars per patient.

AI also can cut the time between diagnosis and treatment in some cases.

UPMC Enterprises recently created Realyze Intelligence to match cancer patients with clinical trials at their first
visit, helping patients to start treatment sooner, Carmody said.

Patient consent and stigmas around AI

AHN doctors and patients are free to opt out of using ambient listening during health visits. Barad said the health
system is working to understand what makes patients uncomfortable with the implementation of AI in their health
services.

"We're spending a whole lot of time to understand how our community feels about AI," Barad said. "Do they want to
know every time AI is used in their health care decisions, or is it one of those things where I expect you to use it?"

At AHN hospitals where AI is used, Barad said, consent forms are given out at the front desk. Verbal consent is
sought throughout health care visits where AI technology is being used.

"We're still at a handful of patients that say no," Barad said. "Based on data in our communities, most patients are
saying, 'Hey, if that makes you be a better doctor and you spend more time with me and I get to see you, talk to
you, then I get it.' "

Schneider said her patients have had no issues with Vectra's image processing algorithm.

"A lot of people have really embraced it," she said.

Future impact on health care

At Independence Health, Chief Information Officer Roger Lutz said the system is cautiously introducing AI into its
network to streamline the process of submitting claims to insurance companies.

"Not a very exciting area of health care, but ... it is complex," Lutz said. "With the right technologies, it becomes
more effective."

Still, while Lutz noted there are benefits to incorporating AI into medicine, he said Independence Health is holding
off for now from using more AI technologies.

"It holds a lot of promise, and, for us, it's just the offerings that are on market right now aren't a good fit for us just
yet," Lutz said.

Despite some hesitation, others are looking forward to see how AI technologies may impact health care.

"I don't think AI is going to replace people by any means. I think we see it as a very opportunistic way to help and
create efficiencies in health care," Carmody said. "We can improve upon the quality of care that we deliver to our
patients. That's the ultimate goal."


Load-Date: September 11, 2024

                                                                                                    Page 4 of 4
            AI technologies are giving some doctors more time for patients, improving health care


End of Document

                                                                                                     Page 1 of 2
                              Report: Few health care systems have formal policies on AI use




           Report: Few health care systems have formal policies on AI use
                                                       Lehigh Valley Business
                                                  February 15, 2024 Thursday



Copyright 2024 BridgeTower Media All Rights Reserved




Section: NEWS
Length: 521 words
Byline: Cris Collingwood

Body


A survey by the Center for Connected Medicine (CCM) at UPMC shows very few health systems have written
formal policies addressing the use of artificial intelligence.

In its report, “How Health Systems are Navigating the Complexities of AI,” CCM said even fewer have policies
specific to generative AI, reflecting the rapid advances the solutions have made in health care.

The research comes as AI is drawing greater interest from health systems looking to help reduce the burden of
documentation on clinicians and add automation to administrative functions, among other potential benefits, CCM
said. At the same time, vendors increasingly are touting AI in their products.

CCM partnered with KLAS Research to survey nearly three dozen health system executives about how they are
navigating both the promise of AI and the possible risk to patient data and privacy that could accompany the use of
AI in health care without appropriate safeguards.

While only 16% of survey respondents said their organizations had a system-wide governance policy in place,
many said their health systems have formed governance committees of senior executives from

multiple departments to oversee AI, which CCM said underscores the seriousness being placed on AI.

“There are many ways health care can and will benefit from AI, including freeing up our clinicians to focus more on
caring for patients and helping systems more efficiently process a range of tasks,” said Dr. Robert Bart, chief
medical information officer for UPMC, which is a founding partner of the CCM. “But it is essential that health care
executives also take seriously the responsibility to protect our patients’ privacy and health data. At UPMC, we
uphold the highest standards of security and privacy for all our data. ”

In addition to surveying health system leaders on their approaches to overseeing AI, CCM said the research also
addressed the promise of generative AI, which has gained prominence over the past year.

                                                                                                       Page 2 of 2
                          Report: Few health care systems have formal policies on AI use

CCM said executives responding to the survey identified improving efficiency, bringing more visibility to clinical
decisions and automating repetitive tasks as the top three ways they expect generative AI to enhance health care.

Generative AI is making its way into health care settings, including as integrated solutions within electronic health
record systems (EHRs). Of the executives surveyed, 70% said they have or plan to adopt AI solutions via EHR
vendors due to the easy integration.

“Before adopting generative AI technologies in health care, it’s crucial for executives to clearly define their
objectives and establish measurable benchmarks,” said Jeffrey Jones, senior vice president of product
development at UPMC Enterprises, the innovation, commercialization and venture capital arm of UPMC. “Regular
evaluations are essential to adjust strategies as necessary. Generative AI is not a one-time fix, but a dynamic tool
that requires attention and calibration. ”

The research was conducted in October and November 2023 and surveyed executives and other leaders at U.S.
hospitals and health systems.

Copyright © 2024 BridgeTower Media. All Rights Reserved.


Load-Date: February 21, 2024


  End of Document

                                                                                                     Page 1 of 2
                              Report: Few health care systems have formal policies on AI use




           Report: Few health care systems have formal policies on AI use
                                             Central Penn Business Journal 2016
                                                  February 15, 2024 Thursday



Copyright 2024 BridgeTower Media All Rights Reserved




Section: NEWS
Length: 521 words
Byline: Cris Collingwood

Body


A survey by the Center for Connected Medicine (CCM) at UPMC shows very few health systems have written
formal policies addressing the use of artificial intelligence.

In its report, “How Health Systems are Navigating the Complexities of AI,” CCM said even fewer have policies
specific to generative AI, reflecting the rapid advances the solutions have made in health care.

The research comes as AI is drawing greater interest from health systems looking to help reduce the burden of
documentation on clinicians and add automation to administrative functions, among other potential benefits, CCM
said. At the same time, vendors increasingly are touting AI in their products.

CCM partnered with KLAS Research to survey nearly three dozen health system executives about how they are
navigating both the promise of AI and the possible risk to patient data and privacy that could accompany the use of
AI in health care without appropriate safeguards.

While only 16% of survey respondents said their organizations had a system-wide governance policy in place,
many said their health systems have formed governance committees of senior executives from multiple
departments to oversee AI, which CCM said underscores the seriousness being placed on AI.

“There are many ways health care can and will benefit from AI, including freeing up our clinicians to focus more on
caring for patients and helping systems more efficiently process a range of tasks,” said Dr. Robert Bart, chief
medical information officer for UPMC, which is a founding partner of the CCM. “But it is essential that health care
executives also take seriously the

responsibility to protect our patients’ privacy and health data. At UPMC, we uphold the highest standards of
security and privacy for all our data. ”

                                                                                                       Page 2 of 2
                          Report: Few health care systems have formal policies on AI use

In addition to surveying health system leaders on their approaches to overseeing AI, CCM said the research also
addressed the promise of generative AI, which has gained prominence over the past year.

CCM said executives responding to the survey identified improving efficiency, bringing more visibility to clinical
decisions and automating repetitive tasks as the top three ways they expect generative AI to enhance health care.

Generative AI is making its way into health care settings, including as integrated solutions within electronic health
record systems (EHRs). Of the executives surveyed, 70% said they have or plan to adopt AI solutions via EHR
vendors due to the easy integration.

“Before adopting generative AI technologies in health care, it’s crucial for executives to clearly define their
objectives and establish measurable benchmarks,” said Jeffrey Jones, senior vice president of product
development at UPMC Enterprises, the innovation, commercialization and venture capital arm of UPMC. “Regular
evaluations are essential to adjust strategies as necessary. Generative AI is not a one-time fix, but a dynamic tool
that requires attention and calibration. ”

The research was conducted in October and November 2023 and surveyed executives and other leaders at U.S.
hospitals and health systems.

Copyright © 2024 BridgeTower Media. All Rights Reserved.


Load-Date: February 21, 2024


  End of Document

                                                                                                        Page 1 of 2
                      Opinion: AI has a home in Utah , and it's creating newfound prosperity for all




Opinion: AI has a home in Utah, and it's creating newfound prosperity for all
                                                        The Deseret News
                                                    October 13, 2024 Sunday



Copyright 2024 The Deseret News Publishing Co. All Rights Reserved

Length: 710 words
Byline: Bill Rappleye

Body


Scott G Winterton, Deseret News Posed photo of iPhone displaying ChatBox in Salt Lake City on Tuesday, March
19, 2024. 1

Across Utah, people are using AI to transform the world around them for the better, and as is frequently the case,
our small businesses are leading the way. Innovators and technology-leading business leaders across our state are
incorporating AI tools in aspects of everyday life as common as going to the grocery store or as critical as providing
mental health services to students. With AI advancements and Utah's ambitious and renowned private sector, our
state is on the cusp of unprecedented levels of prosperity and a robust economy that benefits every Utah resident.

Utah grocery store Davis Food &amp; Drug, for example, recently launched a new program to introduce Caper
Carts at its stores, smart grocery carts equipped with AI. These Caper Carts not only allow customers to track
spending and access coupons but also to check off items in their cart and get personalized recommendations. It
improves the shopping experience for customers, making them more efficient and faster in finding the items that
they and their families require.

AI is also helping solve staffing shortages in key services here in Utah, like mental health providers. While AI is not
a substitute for a trained customer service representative or mental health professional, it can make trained
professionals' knowledge and expertise more accessible. One Utah company is doing just that: creating an AI
chatbot (ElizaCHAT) to help students experiencing mental health issues. ElizaCHAT's approach uses AI to
disseminate advice and guidance from clinically trained psychiatrists and experts to students, when it would
otherwise be impossible for every student to meet with a professional one-on-one.

Even in our state's classrooms, where the next generation of business leaders are honing their skills and
entrepreneurial spirits, AI is being utilized to improve outcomes. For example, Utah teachers are beginning to use
AI to create tailored and interactive learning plans for their students. At East Midvale Elementary, fifth-grade
teacher Laura Bettison has seen remarkable results when asking AI to generate lesson plans and content for her
class. She utilizes AI to help with many of the menial aspects of making a lesson plan, like updating lesson plan
language and strategies to make ideas and concepts more accessible to students' unique learning levels. This
allows Bettison to spend more time on her relationships with her students, cultivating their growth and desire to
learn, instead of working on paperwork that used to take hours.

                                                                                                      Page 2 of 2
                    Opinion: AI has a home in Utah , and it's creating newfound prosperity for all

All these developments in AI in Utah have happened just in the past few months. AI is thriving in Utah thanks in
large part to our hard work and commitment to going above and beyond, but also due to smart policies set by our
lawmakers. They have recognized the risks of AI and addressed them responsibly, all while encouraging and
fostering an environment where AI can innovate and thrive. Like in May of this year, when our legislature passed
legislation that ensured that people who commit crimes using AI can still be prosecuted under existing anti-fraud
legal frameworks. This is an important step that every state should take, as it crucially remedies some of the most
pressing concerns around the abuse of AI tools, without creating sweeping new and untested regulations that often
fail to address the underlying and legitimate issues.

AI has enormous potential for every Utahn, across economic sectors, government agencies and education. We
simply cannot afford to miss out on the benefits of this new technology due to misconceptions or overregulation.
Businesses, large and small, here in Salt Lake City and across our state, are already utilizing AI tools to improve
nearly every aspect of their businesses. Both their workers and customers are benefiting immeasurably, whether
from improved services, lower costs or increased access. Utah must continue to be a leader in AI, and that starts in
Salt Lake City with policymakers who both understand the potential of AI and are willing to create an environment
for AI to succeed.

Bill Rappleye is president of WER Enterprises and two-term Draper City council member.


Load-Date: October 13, 2024


  End of Document

                                                                                                        Page 1 of 3
    The doctor will see you now, and the robot is listening The prospect of AI freeing physicians and nurses from
                               the need to manually document everything has clini....




  The doctor will see you now, and the robot is listening; The prospect of AI
    freeing physicians and nurses from the need to manually document
   everything has clinical executives at UChicago and Rush envisioning a
                       return to 'real-time' patient care
                                                    Crain's Chicago Business
                                                         June 3, 2024
                                                         Print Version



Copyright 2024 Crain Communication All Rights Reserved




Section: Pg. 3; Vol. 47
Length: 1022 words
Byline: Jon Asplund

Body


Two Chicago health systems will soon test artificial intelligence tools that promise to make patient visit
documentation much less burdensome and more patient-focused.

"I remember as a child going to a doctor who would look you in the eyes and ask you how you were doing," said Dr.
Bina Desai, chief medical informatics officer at Rush. "But for the last 10 years or so, the majority of us are typing
away on a laptop while talking to patients. It's almost like there's this wall" between the patient and the doctor or
advanced practice nurse.

With an accurate record of the visit translated into an electronic health record, or EHR, AI can "help bring us back
to that earlier time, when the full attention is on you," she said.

Rush University System for Health has already been working with the ambient AI product Dax Copilot from Nuance
Communications, one of the most established players in the sector, and will soon add a pilot program with voice AI
documentation software from a company called Suki. At the University of Chicago, a small group of physicians will
launch a study of documentation technology from Abridge.

Dr. Sachin Shah, chief medical information officer at UChicago Medicine, wants a doctor-led development of these
AI tools that capture clinician-patient interactions to fix the problems caused by the EHR.

"There wasn't a lot of provider input at the advent of the EHR era, and it causes a lot of problems," Shah said. "So
this time we need to be on the ground floor."

                                                                                                       Page 2 of 3
   The doctor will see you now, and the robot is listening The prospect of AI freeing physicians and nurses from
                              the need to manually document everything has clini....

"Documentation burden is one of the biggest parts of burnout among clinicians," Shah said. An AI tool "can just put
time back in our day and allow me to turn my chair back toward the patient."

Both Desai and Shah referred to how hours of writing up EHR documentation, referring to incomplete notes and
memories, wears on doctors and nurses, adding it often ends up being done long after the patient has been seen,
during "pajama time."

Ambient AI works through doctor-patient conversations recorded on devices or smartphones, which are then run
through generative AI to produce a transcript of the visit.

Far from perfect

As Crain's sister site Modern Healthcare points out, so far ambient AI is far from perfect. Kaiser Permanente and
Permanente Medical Group researchers, for example, were unable to verify edits the AI made to the doctor-patient
conversation such as when it omitted parts of the conversation that the model deemed unrelated to patient care.

It is also not available for all specialties and languages, Modern Healthcare reported.

At Rush and UChicago, the AI systems would work to write up documentation for EHR systems from electronic
records leader Epic.

Even though physicians must review and edit the recorded and transcribed patient visits, the technology can
revolutionize what the EHR can be, Shah said.

It lets doctors see details that could be lost in the conversation, helps with decision support and can help better
capture a natural doctor-patient discussion of the determinants of health the patient experiences, UChicago's Shah
said. And with those full conversations treated like a dataset, clinicians can analyze them more efficiently and in
more detail, he said.

At Rush, once systems are vetted and an AI vendor is chosen, Desai says the plan would be to offer it to all
clinicians who see patients regularly, "especially our learners." She hopes the technology can be standard by the
time a new medical student is through with residency.

Eventually, Desai envisions generative AI technology will be available and effective throughout a health system, in
nursing stations, in-patient settings, even the operating room.

Before that happens, she said, hospital informatics experts need to work on two things: privacy concerns and cost.

"This isn't going to be cheap," she said. "It's not free. Although a lot of people think, 'I've got it on my phone for free,'
the health care system will use something very different."

Affordability challenge

The challenge will be to figure out how to make it affordable at scale, Desai said, and to have it make sense to
install.

Health systems' AI must be very protected, both secure and private in a way that makes patients and doctors
comfortable around it, she said.

Patients, and some clinicians, will be skeptical of their conversations being recorded, Desai said, so this will be
another outlet that providers have to be extremely careful about and educate the patient and themselves.

"It is going to be up to us in health care to be out in front on this, fully vetting these systems," Shah said. The
process must be transparent, patient consent forms need to be clear and patients need to understand that
"recordings will be kept, and used, only as long as the note is finalized, then deleted."

                                                                                                       Page 3 of 3
   The doctor will see you now, and the robot is listening The prospect of AI freeing physicians and nurses from
                              the need to manually document everything has clini....

Patient privacy concerns often involve regulations like the federal privacy law HIPAA and Business Associate
Agreements among health care providers and their third-party vendors.

However in recent months, a new priority, cybersecurity, has gained urgency, following cyberattacks like those
recently experienced by health care companies and providers such as Change Healthcare, Lurie Children's
Hospital and Ascension.

While privacy regulations "continue to be critical priorities, the cyberattacks on (health care providers) in 2023 call
into focus a different priority: ensuring access to care and availability of systems in the face of cyberattacks,"
according to a recent white paper on cybersecurity and health care by Zip Security and Ambience Healthcare.

Zip Security is a venture-backed cyber startup, and Ambience Healthcare is a company that provides an AI
operating system for health care.

"We are seeing the benefit in both quality and efficiency of delivering care through the utilization of third-party
technologies - particularly in the space of generative AI, and how this can improve (physicians') workflows," the
white paper said. "These applications and technologies are contributing to the general increase of hosted services
by vendors. While their impact and benefit are overall very positive, they do pose an additional consideration in the
cybersecurity conversation."


Load-Date: June 6, 2024


  End of Document

                                                                                                         Page 1 of 3
                                            AI research could personalize disease care




                               AI research could personalize disease care
                                                  The Atlanta Journal-Constitution
                                                      August 4, 2024 Sunday
                                                           Main Edition



Copyright 2024 The Atlanta Journal-Constitution




Section: MAIN; Pg. 15A
Length: 1129 words
Byline: Roni Robbins For the AJC


For the AJC
Highlight: Emory scientist pioneers less invasive treatment for diseases.

Body


At the helm of Emory University’s research using artificial intelligence to pinpoint treatments for the nation’s largest
healthcare concerns is a biomedical engineer on a personal mission.

Anant Madabhushi, director of the year-old Emory Empathetic AI for Health Institute, recently published research
on how artificial intelligence could be used to manage treatments for two major health concerns — breast cancer
and age-related macular degeneration (AMD) of the eye. Both are issues that have impacted his family: His aunt
died from breast cancer and his father suffers from the eye disorder.

AI programs paired with medical scans and other existing diagnostic tools can help doctors propose more
personalized treatments and predict potential problems resulting from treatment.

Madabhushi’s research found that combining AI with medical images to find non-invasive and economic treatments
for major cancers and diseases could detect such issues earlier and help clinicians better manage treatment
decisions.

More clinical testing is needed before doctors can use AI to change their treatment strategies. But early results
show its potential for reducing overtreatment.

“AI is on everyone’s lips right now,” he said. Researchers used AI computer programming to gather detailed
information about disease treatment in the past, but they lacked medical data doctors could understand to prove

                                                                                                           Page 2 of 3
                                      AI research could personalize disease care

AI’s veracity. “The skepticism is real. It’s not misplaced, but a large part of it is the lack of real understanding about
AI.” If doctors don’t understand how AI works, they can’t trust its predictions, he said.

Madabhushi led one study, published July 9 in The Lancet Digital Health, that showed how AI could be used to
better manage treatment for patients with early-stage breast cancer known as ductal carcinoma in situ, also
considered stage 0 breast cancer. It accounts for about 20% of all new cancer diagnoses each year affecting more
than 55,000 women.

The data for the study was pulled from a clinical trial conducted in the United Kingdom, Australia and New Zealand
from 1990 to 1998 to determine the effect of tamoxifen, a breast cancer drug, and radiotherapy on 755 patients with
DCIS.

About 30 years later, in 2020, AI was used to analyze the data and identified with 95% accuracy which patients had
a higher risk of disease progression and could benefit most from radiation therapy. Medical records of the patients
from the ‘90s confirmed the AI predictions of how their cancer would progress.

Though the analysis was based on 30-year-old data, Madabhushi explained that the management of women with
DCIS hasn’t changed much in that time despite the arrival of newer cancer treatments. Clinicians still have to
decide between surgery or surgery plus another treatment such as a drug or other therapy, said Madabhushi, who
is also a cancer immunology researcher with Emory’s Winship Cancer Institute.

Using the old data to confirm the new technology’s predictions is “like the Lazarus Effect,” Madabhushi said,
referring to the medical phenomenon where someone declared dead comes back to life. “We can learn and discern
new information from [data gathered] so long ago in a different country that could benefit patients today.”

More discoveries to come

In the next year, Madabhushi expects to seek approval from the U.S. Food and Drug Administration to use AI as a
medical device and conduct clinical testing that will monitor AI’s impact on patient health. He predicts that within
two years doctors will be able to use AI to take some of the guesswork out of their decisions by helping them
pinpoint the most effective treatment for their patients.

Madabhushi and a team of researchers also used AI to detect eye inflammation that is a serious side effect caused
by drugs to treat a common eye disease.

AMD is the leading cause of vision loss for older adults affecting 11 million Americans. A specific type of AMD,
neovascular age-related macular degeneration, is associated with abnormal blood vessel growth under the retina.
The treatment involves injecting medication into the eye, but inflammation can be a serious side effect.

Using a machine learning model developed by Emory AI.Health, researchers identified patterns seen in eye scans
that signaled inflammation even before it was visible to doctors. The study was published in June in the Cell Press
journal Heliyon.

Another Madabhushi-led study used AI to analyze the lung damage caused by COVID-19. Using CT scans from
more than 3,400 patients and three continents. The study showed that patients with severe COVID-19 experienced
significant deformities to the surfaces of the lungs, according to the research published in May in the Journal of
Computers in Medicine and Biology.

“As we are thinking about long COVID, we still try to understand its impact long-term,” Madabhushi said. “We can
quantify the impact the disease has to the extent of lung injury, the quantitative impacts on lung function.”

‘Revolutionizing’ medical care

Madabhushi is considered one of the global pioneers in combining AI with high-resolution medical images for
diagnosing diseases and predicting the results of patient treatment, according to Dr. Jacob “Jake” Scott, a radiation
oncologist who conducts AI research through the Cleveland Clinic and Case Western Reserve University. They

                                                                                                     Page 3 of 3
                                    AI research could personalize disease care

supervised students at the latter when Madabhushi was a professor of biomedical engineering and director of the
Center for Computational Imaging and Personalized Diagnostics before joining Emory.

Several Cleveland researchers co-authored recent AI studies with Madabhushi.

“Anant is leading the charge in redefining the medicine patients need,” said Scott, co-director of Case Western’s
Center for AI Enabling Discovery in Disease Biology. “It’s a newer field that allows a deeper level of intuition.”

Scott added that Madabhushi and his team are “pushing the limits … taking a new and powerful tool and
revolutionizing how we understand disease.”

Madabhushi and his team are now trying to apply what they learned from their AI research to other cancers,
including those impacting the prostate and lungs. “Cancer is not necessarily a death sentence,” he said.

In September, Madabhushi plans to present new research on hormonal therapy for DCIS and breast cancer
patients at the European Society of Medical Oncology. Building off research on the use of radiation, researchers
were able to use AI to identify which stage 0 breast cancer patients would benefit from hormonal therapy and which
should avoid it, he said.

“It’s fulfilling to see my work come out,” he said of the recently published research. “The breast cancer work has
been near and dear to me for over 20 years. … This particular journey I have been on to find a cure for the disease
that killed my aunt.”


Load-Date: August 4, 2024


  End of Document

                                                                                                    Page 1 of 4
           Researchers receive funding to improve trustworthiness of AI - The GW Hatchet Donation Button




     Researchers receive funding to improve trustworthiness of AI - The GW
                           Hatchet Donation Button
                                         The Hatchet: George Washington University
                                                  September 23, 2024 Monday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1260 words

Body

content"class="skip-to-content">Skip to Content
     •    Advertise
     •    Donate
     •    Contact
     •    About
     •    Join
     •    More

Facebook

Instagram

X

YouTube

The GW Hatchet

Open Search Bar

Search this site

Submit Search

AN INDEPENDENT STUDENT NEWSPAPER SERVING THE GW COMMUNITY SINCE 1904
     •    News Administration Academics Events Health & Research Metro Student Government Student Life
     •    Culture Ask Annie Features Reviews

                                                                                                  Page 2 of 4
         Researchers receive funding to improve trustworthiness of AI - The GW Hatchet Donation Button

    •   Sports Courtside Features
    •   Opinions Columns Perspectives Editorial Board Letters to the Editor Op-eds Quick Takes
    •   Multimedia Photo Video
    •   Podcasts Getting to the Bottom of It
    •   More

Open Navigation Menu

The GW Hatchet
    •   Advertise
    •   Donate
    •   Contact
    •   About
    •   Join
    •   More

The GW Hatchet

Open Search Bar

Search this site

Submit Search

Open Navigation Menu
    •   News Administration Academics Events Health & Research Metro Student Life Student Government
    •   Opinions Columns Perspectives Op-eds Editorial Board Letters to the Editor Quick Takes
    •   Culture Ask Annie Features Reviews
    •   Sports Courtside Features
    •   Podcasts Getting to the Bottom of It
    •   Photo
    •   Video
    •   About Us Contact Us Join The Hatchet
    •   Donate
    •   More

The GW Hatchet

Open Search Bar

Search this site

Submit Search

DC Law Fair

Donation Button

                                                                                                  Page 3 of 4
         Researchers receive funding to improve trustworthiness of AI - The GW Hatchet Donation Button

The Hatchet is celebrating its 120th birthday

DONATE TODAY

NEWSLETTER

Sign up for our twice-weekly newsletter!

Are you human?

Yes!

Email address: Leave this field empty if you're human:

LATEST NEWS

Crime log: Thurston Hall resident reports stolen birthday balloonsBy Ella Mitchell, Contributing News Editor ·
September 23, 2024Sociology experts talk prevalence of racism 'denial' in AsiaBy Phillip Castro, Reporter ·
September 23, 2024Students revive independent publication reporting on GW Law, SBABy Molly St. Clair,
Assistant News Editor · September 23, 2024CCAS reinstates tenured faculty travel reimbursements, but uncertainty
remains over graduate fundingBy Tyler Iglesias, Assistant News Editor · September 23, 2024Faculty suggestions
not 'recognized' after delayed diversity action plan debutBy Sachini Adikari, Contributing News Editor · September
23, 2024

Researchers receive funding to improve trustworthiness of AI

By Jenna Lee and Caitlin Jacob

September 23, 2024

Sage Russell | Senior Photo Editor Pedestrians pass the Science and Engineering Hall in April.

A multi-university initiative including GW announced new funding for research to improve the trustworthiness of
artificial intelligence earlier this month.

The initiative, the Institute for Trustworthy AI in Law and Society - which launched in May 2023 and involves four
universities including GW - announced five new grants, totaling $685,000, to fund research into the ethical use of
AI. Valerie Reyna, a researcher with the School of Engineering & Applied Sciences and a project lead for Cornell
University on the initiative, said her work will train medical AI to use more logical principles in their decision-making
to improve patient outcomes and increase trustworthiness.

"We want to, on the one hand, make sure that society is able to take advantage of these remarkable technological
achievements," Reyna said. "But on the other hand, we want to make sure that there are appropriate protections
and safety elements in this."

The initiative is made up of four universities, the University of Maryland, GW and Cornell and Morgan State
universities. The five new grants are funding projects to improve the quality of AI in health, autonomous vehicle
safety, social media platforms, academia and educational settings, according to a release announcing the funding.

Reyna said a key part of how researchers determine the trustworthiness of AI is by applying human psychological
principles to analyze the decision-making processes of AI models. She said researchers look for psychological
principles in AI decision-making to see if the technology is making consistent decisions based on logic, which can
be applied to a range of AI forms from chatbots like ChatGPT and Gemini to AI medical technology.

"If I ask you a bunch of choices and your decisions contradict themselves, then you're not really making sense,"
Reyna said. "And then we can say we worry that that's not a rational decision process. If decisions are inconsistent
with one another, it's kind of a minimum condition."

                                                                                                  Page 4 of 4
         Researchers receive funding to improve trustworthiness of AI - The GW Hatchet Donation Button

She said her research studies physician decision-making to understand how people make decisions in health care
and will use that to train the AI health models to ensure they are based on real perspectives.

Reyna said a common problem in medical research is the lack of diversity among participants and scientists, which
she said this project aims to change by relyingon community participation to inform their results. She said most
medical research focuses on expert opinions.

"We're very much dedicated to the importance of community participation and active participation in research,"
Reyna said. "And that's extremely important to diverse communities and people from different backgrounds and
people with different needs and bringing them into this discussion and in an active way in terms of helping shape
the research."

Experts in AI said the lack of trustworthiness is a problem in the AI field because of how popular its usage has
become and the number of people making AI programs in recent years - many of whom have not properly trained
their models, leading them to provide inaccurate information and decrease users' trust.

Janusz Wojtusiak, professor of health informatics at George Mason University, said the biggest issue in AI right
now is distinguishing the "good stuff from the not so good stuff." Wojtusiak said because AI has gotten so popular,
the market has become saturated with newer programs that have not been tested.

"It needs to do what it's supposed to do," Wojtusiak said. "It needs to be extremely well tested, so we know it
actually does that thing."

Wojtusiak said a lot of AI programs can be what he calls a "black box" where users feed it information and it gives
them a result, but they don't know how it got to that answer. Wojtusiak said research into the decisions of AI can
increase user trust, and experiences with AI providing inaccurate information and a lack of information can cause
people to distrust.

"All you have is an app that does something, maybe correct or maybe not," Wojtusiak said. "But we just don't know
what it is. So it's all about the transparency on what the thing is doing, how well it's doing, and what's been trained
on."

Peter Szolovits, a professor of computer science and engineering at the Massachusetts Institute of Technology,
said the trustworthiness of chatbots like ChatGPT has improved since they first launched. He said about two years
ago, he asked ChatGPT to write a synopsis of his career, and it got most of the facts wrong, but now, the model will
tell you if it does not have enough information to give you an accurate answer.

"That's one thing that has actually helped, and empirically, that does seem to reduce the amount of hallucination
done by systems, although not to zero," Szolovits said.

Szolovits said in the medical field, AI models succeed at making broad generalizations from large data sets that are
mostly accurate. He said AI models run into problems with specific case studies, where it is more likely to miss key
information.

"If you're going to make clinical decisions about an individual patient, then I'm much more nervous about models,"
Szolovits said. "Because basically if it misses some important thing in my medical record or if it makes up some
important thing in my medical record, that could kill me, and I'm not interested in having that happen."

Jennifer Igbonoba contributed reporting.


Load-Date: September 23, 2024


  End of Document

                                                                                                           Page 1 of 2
                                           Does AI have a place in the classroom?




                                Does AI have a place in the classroom?
                                               The Delphian: Adelphi University
                                                      October 11, 2024 Friday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 867 words

Body


Higher education has historically contended with a number of disruptors, from recessions to the COVID-19
pandemic, for example. Now there's a new existential challenge on the block: generative AI (artificial intelligence),¹
a phenomenon that's poised to reshape the future of learning, for better or worse. For students, AI offers an
irresistible cheat code. For faculty, it could invite the nightmare scenario of large-scale plagiarism.

But there's no turning back the tide on this new technology. A. Hasan Sapci, MD, associate professor in the College
of Nursing and Public Health and program director of health informatics, is leading the charge to ensure that
Adelphi can stay ahead of the latest advances in generative AI technology. As the chair of Adelphi's
multidisciplinary Artificial Intelligence Committee, Dr. Sapci is working with faculty to integrate AI into the curriculum
and research, enhance teaching methods across disciplines, and promote ethical use of AI. While the sudden
release of powerful AI text-generation tools powered by LLMs (large language models) took most universities by
surprise, Adelphi's task force, now a committee, met the challenge head-on, quickly instituting a plan to navigate
the impending changes. "I can proudly say that Adelphi was one of the first academic institutions that recognized
the transformative potential of technology," Dr. Sapci noted.

Previously a task force, it is now a committee that includes representatives from the Academic Standards
Committee, the Faculty Senate Committee on Academic Information and Technology , and the Committee on
Academic Integrity. It conducted a variety of University-wide surveys, then incorporated feedback into an evolving
set of standards and best practices.

Dr. Sapci presented the task force's AI road map at the CAHIIM (Commission on Accreditation for Health
Informatics and Information Management Education) 2023 Summit on Higher Education, which includes the
important statement that Adelphi does not approve of stopping people from using generative AI. Instead of building
restrictive policies, the task force strives to incorporate AI tools into teaching and research strategies. Though Dr.
Sapci and his colleagues caution that unacknowledged use constitutes plagiarism (which instructors should
communicate through a template provided by the task force), they ultimately embrace AI's value.

"By incorporating AI tools into the curriculum, students can be exposed to cutting-edge technology and use [it] as a
research tool to enhance their learning experiences," he told Adelphi last year. "This is an excellent strategy to
equip them with valuable skills for the future."

                                                                                                        Page 2 of 2
                                      Does AI have a place in the classroom?

Nevertheless, the possibility of academic dishonesty looms large. Because there is no foolproof way to detect AI-
written student material, Dr. Sapci is taking inspiration from his background in the medical field to counter cheating
and plagiarism. "Due to the complex nature of human health, there is no perfect treatment for several diseases," he
explained. "However, there are always best practices, such as early detection strategies, regular screenings and
personalized treatment plans, combined with several methods to prevent complications. We need to adopt a similar
approach."

Under Dr. Sapci's guidance, the task force has developed digital resources for students and instructors, including a
rubric designed to assist instructors in evaluating the AI content of student work alongside input from originality
checking and plagiarism detection service Turnitin, LLC. The student rubric for AI use, available on the Adelphi
website, aims to make students aware of the limitations of generative AI tools, such as its tendencies toward bias
and misinformation. It also outlines a process for responsible use of AI in coursework, which entails obtaining
permission, ensuring proper attribution and avoiding academic dishonesty.

Far from fearing or attempting to obstruct the oncoming changes wrought by AI, Dr. Sapci welcomes adaptation. As
businesses around the globe have learned, it's a crucial survival mechanism in the face of disruption. "We need to
stay current with changing trends, learn this technology's limitations and adapt our teaching practices as faculty
members," he said. "It is up to us to determine new skills, track the latest trends and provide future-proof skills to
our students."

Biography

A. Hasan Sapci, MD

A. Hasan Sapci, MD

A. Hasan Sapci, MD, associate professor and program director in the Department of Health Informatics, holds
several certifications in artificial intelligence and AI in medicine. His research interests include AI in healthcare,
connected health, telemedicine and remote patient monitoring, innovative clinical informatics and data analytics
applications for patient care, clinical support systems, and modeling complex medical decision-making.

¹Sapci, A. H. (2022)."The Development of AI-Proof Teaching Strategies for Health Informatics Education"
[Conference presentation]. CAHIIM 2023 Summit on Higher Education, Virtual. https://www.cahiim.org/docs/default-
source/resources/events/cahiim-summit-on-higher-education-2023/2023-cahiim-summit-on-higher-
education.pdf?sfvrsn=316e9078_6


Load-Date: October 11, 2024


  End of Document

                                                                                                        Page 1 of 3
                                Guardians of the Grid: AI's Cyber Shield for Homeland Security




            Guardians of the Grid: AI's Cyber Shield for Homeland Security
                                                             R Street Institute
                                                    September 10, 2024 Tuesday



Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 R Street Institute, USA All Rights Reserved

Length: 1303 words

Body



Artificial intelligence (AI) has emerged as a pivotal force in modern national defense, impacting how nations
approach cybersecurity-particularly within the realm of critical infrastructure. AI has been used in cybersecurity for
years, but the recent focus on generative AI has spurred further innovation and emphasized its security
applications. The integration of AI into defense strategies is not only a technological enhancement, but also a
necessity to protect critical infrastructure and national security from evolving threats.

Although concerns exist about how AI could be exploited to carry out cyber incidents, these risks underscore the
importance of leveraging AI for its security benefits. This exploration focuses on AI's key role as a cybersecurity
tool, with critical infrastructure as a prominent example of its application. While significant progress has been made,
more work is required to fully harness AI's potential in securing national defense and critical infrastructure.

AI as a Cybersecurity Tool in National Defense

AI has impacted cybersecurity in national defense by enhancing threat detection, automating responses, and
enabling predictive capabilities. Its continuous learning allows defense systems to evolve with emerging threats
while adapting algorithms to counteract new attack vectors. One of AI's key strengths is its ability to assess and
prioritize threats based on severity, which helps defense teams effectively allocate resources.

To further illustrate AI's role, consider two concrete examples: AI-powered threat intelligence-sharing platforms that
enable faster, more effective responses, and AI's integration into critical infrastructure security management. Both
underscore AI's importance in creating a dynamic and resilient defense posture, driving innovation, and
strengthening homeland security.

Threat Detection and Analysis in Networks

AI algorithms excel at identifying patterns and anomalies within vast amounts of data, making them ideal for
detecting cyber threats in real time. By continuously analyzing network traffic, AI can pinpoint malicious activities
that might go unnoticed by human analysts (or at least take up valuable human time), including zero-day
vulnerabilities. This capability is crucial in defending against sophisticated and constantly evolving cyberattacks.

                                                                                                        Page 2 of 3
                          Guardians of the Grid: AI's Cyber Shield for Homeland Security

Automated Response and Mitigation for Systems

AI-driven systems can minimize damage and reduce response times by autonomously responding to detected
threats. Automated responses include isolating compromised systems, blocking suspicious IP addresses, and
applying patches to vulnerable systems. This automation is crucial in national defense scenarios, where every
second counts. By reducing the need for human intervention, AI allows for faster and more efficient handling of
threats-essential in high-stakes environments.

Behavior Analytics and Anomaly Detection

AI systems use machine learning to understand typical behavior within networks and identify deviations that may
indicate a cyber threat. This capability is particularly useful in military contexts, where quickly detecting unusual
activities can prevent insider threats and other significant security breaches. AI's ability to analyze and learn from
large datasets means it can adapt to new threats and continuously improve its detection capabilities.

AI in Critical Infrastructure

Critical infrastructure encompasses energy, water, transportation, and communications-all of which are vital to
national security and public safety. Protecting these sectors from cyber threats is crucial, as disruptions can have
widespread impact. AI is increasingly leveraged across various sectors of critical infrastructure, with some
applications directly focused on cybersecurity and others not specifically related to cyber threats but with the
potential to be leveraged for security purposes. This is particularly important since most critical infrastructure is
privately owned, limiting direct government implementation of the technology. Selected examples of AI use in these
sectors offer best practices that can be adopted more broadly for cybersecurity enhancement.

Energy

AI-driven predictive maintenance systems in the energy sector have prevented outages by addressing potential
issues before they escalate. For instance, the Tennessee Valley Authority has deployed AI systems that monitor
equipment health and predict failures, which facilitates timely maintenance and prevents costly power outages.

Water

In the water sector, AI technology has proven valuable for monitoring and securing water distribution networks. For
instance, the City of Atlanta implemented an AI-based system that analyzes data from sensors placed throughout
the water network to detect leaks and potential contamination. This proactive approach ensures a safe and reliable
water supply by identifying issues before they escalate.

Additionally, researchers at Florida A&M University and Florida State University are exploring AI's potential to
enhance water quality in the state. Their work involves developing AI models that can predict harmful algal blooms,
monitor water quality, and optimize the use of resources. These initiatives aim to provide more accurate and timely
information, ultimately leading to better management of water resources and protection against contaminants.

Transportation

AI is making significant strides in the transportation sector, particularly in enhancing cybersecurity and operational
efficiency at critical infrastructure sites. For example, the Port of Los Angeles has implemented AI to bolster its
cybersecurity posture. By analyzing network traffic and identifying anomalies, AI helps protect the port's critical
infrastructure from cyber threats, ensuring the smooth operation of this vital hub for international trade.

Moreover, GridMatrix has deployed AI software to enhance operational efficiency and security at the Port Newark-
Elizabeth Marine Terminal in New Jersey. This AI-driven system analyzes traffic patterns, optimizes vehicle
movements, and reduces congestion, all while maintaining a focus on cybersecurity. The integration of AI at these
ports underscores its essential role in safeguarding critical infrastructure and improving the flow of goods and
services.

                                                                                                        Page 3 of 3
                           Guardians of the Grid: AI's Cyber Shield for Homeland Security

Health Care

In the health care sector, AI plays a crucial role in safeguarding sensitive patient data and ensuring the integrity of
medical devices-especially in light of recent widespread cyber incidents targeting health care systems. For
example, the Mayo Clinic employs AI-driven systems to monitor network traffic for signs of cyber threats, effectively
protecting both patient data and critical health care infrastructure. By detecting and responding to emerging threats,
these systems help mitigate the risks associated with sophisticated cyberattacks on health care organizations.

Conclusion

The integration of AI into cybersecurity efforts has profoundly impacted critical infrastructure protection. Joint
initiatives between the public and private sectors, such as AI-powered threat intelligence sharing platforms, have
enabled faster and more effective responses to cyber threats, demonstrating AI's role in enhancing national
defense. And programs like the Federal Communications Commission's U.S. Cyber Trust Mark aim to certify
products that meet cybersecurity standards, thereby contributing to a safer technology landscape. With its
continued ability to further strengthen cybersecurity, AI remains crucial in addressing future challenges. Ongoing
research, development, and strategic collaborations will be key to harnessing AI's full potential in safeguarding
critical infrastructure and national security. The future holds promising opportunities for continued AI innovation and
improvement in cybersecurity.




Load-Date: September 11, 2024


  End of Document

                                                                                                     Page 1 of 3
                                                  Health leaders gather for dialogue




                                       Health leaders gather for dialogue
                                                  The Atlanta Journal-Constitution
                                                     September 20, 2024 Friday
                                                            Main Edition



Copyright 2024 The Atlanta Journal-Constitution




Section: MAIN; Pg. 16A
Length: 1275 words

Byline: Michael Scaturro and Roni Robbins For the AJC and Ariel Hart , ariel.hart@ajc.com


Staff
Highlight: Presentations cover major topics, from AI tech to mental health.

Body


A former Biden administration official who is a DeKalb County health adviser said Wednesday that artificial
intelligence in medical spaces should be subjected to bias audits.

“When I hear ‘AI-based medicine,’ I think the evidence might not be sound,” Dr. Sandra Elizabeth Ford said
Wednesday at the Health Connect South conference in Atlanta, which drew about 1,100 participants, including
doctors, researchers and students, to network and share ideas on a range of pressing public health issues. Ford
said the assumptions on which many AI models are based could be flawed, and this can impact care for patients in
the U.S. from minority backgrounds.

Ford was special assistant to the president for public health and science in the Biden Administration, and is now a
DeKalb health adviser.

Though she thinks AI tools in medical settings could reduce paperwork for hospital employees and ultimately be
useful, she told an audience at the annual health care conference at the Georgia Aquarium in downtown Atlanta
that not all patients will know how to interact with AI platforms in medical settings.

She also flagged the potential bias of programmers and AI trainers as an area of concern.

“We need to make sure that the people who are programming AI respect diversity. We need to make sure that AI
trainers are as diverse as the population they are serving,” she said.

                                                                                                        Page 2 of 3
                                         Health leaders gather for dialogue

AI medical biases also crosses over into gender, Ford noted.

Women comprise 28.2% of the STEM workforce, according to the World Economic Forum, compared to 47.3% in
non-STEM sectors.

While 73% of business leaders believe having more women in leadership is important for mitigating gender bias in
AI, only 33% have a woman in charge of decision-making for AI strategy, according to IBM.

A federal rule issued in July aims to protect consumers from discrimination when artificial intelligence tools are used
in health care, but it could be reversed by future administrations, according to KFF Health News. Dr. Rowland
Illing, chief medical officer and director for Global Healthcare & Nonprofits Amazon Web Services, said at the
conference the industry should strive to “plug gaps” around privacy and diversity concerns to head off further
regulation.

But the U.S. needs to overcome a history of building biases into new health systems, cardiologist Dr. Jayne
Morgan told The Atlanta Journal-Constitution.

“AI can end up being a tool of othering,” Morgan said. She added that AI would be useful in a medical setting if “it
were neutral and factual and clean, and the biases we have now in the medical system weren’t built into it.”

Dr. Anne Dunlop, a gynecologist and professor at Emory University, said AI holds the potential to free up doctors’
resources to focus on other aspects of the care experience. But as of now, she is using it only as a means of
capturing notes.

She echoed Ford’s concerns, saying doctors can pick up body language or speech patterns, while that instinct
might elude AI systems.

“We as clinicians pick up how a patient is feeling when we are in the room,” she said. “People express pain with
different words and expressions. AI, to be helpful in addressing complex medical issues, will need to reflect this
diversity.”

Health care worker shortage continues

The CEOs of three major Georgia health systems were unanimous during a conference panel that the shortage of
health care workers remains a huge problem.

To address it, they’ve each invested in educational institutions to train more people, hoping they’ll stay in Georgia
and come to work at their companies.

“We always have a deficit of nurses and other clinicians,” said Scott Steiner, CEO of Phoebe

Putney Health System of southwest Georgia.

“We turn down patients each and every day,” said Neil Pruitt, CEO of the skilled nursing and senior living company
Pruitt Health. “Not because we don’t have open beds. But because we don’t have the staff available.”

As a result, Steiner, Pruitt and Candice Saunders, CEO of Wellstar Health System, have each overseen major
investments in colleges and technical schools.

Phoebe Putney’s investment in a local nursing program reached $45 million.

One issue worsening the shortage, Saunders said, is the disturbing trend of violence against health care workers
— it began during the COVID-19 pandemic and has increased.

“It’s a major threat to the workforce, and it’s something that we’re focused on every day,”&Saunders said. Wellstar
learned from a comprehensive assessment of the safety threat that “Yes, the ERs are high risk in our care settings,
but so are doctor’s offices, so are urgent care, so are home care settings.”

                                                                                                      Page 3 of 3
                                         Health leaders gather for dialogue

As a result, Wellstar has begun implementing security measures, which patients and visitors will see. Those include
armed guards in Wellstar locations, visitors no longer being able to enter freely and wander and the installation of
panic buttons. For workers who see patients remotely, Wellstar is investigating solutions such as remote
monitoring, and even predictive AI.

“It’s been a huge investment,”&Saunders said. “But then if there is an event, then we have a very, very rapid
response, like we do for a heart attack in the hospital.

“But I can’t emphasize enough how this is affecting the health and well-being of our health care workers today, and
is something that all of us need to be aware of.”

Public health partnerships needed

At another panel discussion focusing on public health partnerships, health leaders said hospitals and health
systems need to give more than lip service in their efforts to partner with public health organizations to improve
health care.

“I want public health to be recognized” on par with for-profit health care, said Dr. Kathleen Toomey, commissioner
of the Georgia Department of Public Health. She said public health is often overlooked in health care because “it’s
not where the money is at.”

“We have the worst PR about ourselves,” she said. “We have to show our value to the health system.”

Toomey pointed to how public health gained more attention during 9/11 and the COVID-19 pandemic, when a wide
range of partnerships were formed that included hospitals and the businesses community. But she believes public
health emergencies should not be the only impetus to strengthen those partnerships.

Chelsea Cipriano, managing director of the Common Health Coalition, agreed: “We can’t wait for a public health
emergency.”

Last year, four major health care organizations, including the American Medical Association and the American
Hospital Association, formed the coalition, which focuses on using lessons learned during the pandemic to
strengthen partnerships between health care and public health systems.

“We should have agreements in place and not just for emergencies.”

One such partnership, More in Common Alliance, links Morehouse School of Medicine and CommonSpirit Health,
which provides health care to underserved communities. The goal of the partnership, formed in 2020, is to increase
medical education opportunities for more people of color in the hopes of better diversifying the medical workforce
and improving patient care.

The alliance believes patients fare better when treated by clinicians of similar backgrounds.

The partnership is also trying to address a shortage of clinicians from diverse backgrounds and the need for more
equitable health care.

In 2020, Morehouse School of Medicine teamed up with CommonSpirit Health in a 10-year, $100 million
partnership to provide new training opportunities for Morehouse School of Medicine students in Chattanooga,
Lexington and Seattle, along with postgraduate residencies and fellowships in California in Bakersfield, Los
Angeles, Santa Cruz and Ventura County.


Load-Date: September 20, 2024


  End of Document

                                                                                                            Page 1 of 4
                                   How AI helps hospitals keep a watchful eye on patients




                   How AI helps hospitals keep a watchful eye on patients
                                                       LNP (Lancaster, PA)
                                                      March 3, 2024 Sunday



Copyright 2024 LNP Media Group, Inc. All Rights Reserved

Length: 1251 words
Byline: CAROLE DECK FOR LNP, LANCASTERONLINE

Body


While many businesses embrace the advantages of AI to streamline processes, some question the disadvantage of
AI lacking human emotion.

However, the health care field is seeing success with AI-generated technology for patient monitoring without
limiting care or humanity.

WellSpan Health discovered a way to use AI to improve patient safety and address nurse burnout. The health
system collaborated with Artisight Inc. in Northfield, Illinois, to use its Smart Hospital Platform powered by AI for a
pilot patient monitoring and virtual nursing program.

The program has been used at WellSpan Surgery and Rehabilitation Hospital in York since mid-August.

Patients at high risk for falls are monitored 24/7 using patient-room audio and video connections by a virtual nurse
tele-sitting in a designated control space to monitor behavior in each room. The virtual staff can interact with
patients and ask assistance from an onsite clinician as necessary.

“The virtual nurse can monitor more patients at a time and is an extension of a registered nurse with the two
working as a team,” says Kasey Paulus, senior vice president and chief nursing executive at WellSpan York
Hospital.

READ: Full coverage of Progress 2024 [roundup]

She explains the camera uses AI to monitor normal movement and gives a visual color cue that shows on a
computer screen, such as when a patient gets out of bed or is at risk for a fall. Such cues put into motion immediate
safety precautions.

WellSpan continues to gather data, but Paulus says results show the program to be a success.

“It’s very exciting and has proven to be positive for patients and staff, along with a reduction in falls,” she says.

In November and December of 2023, the pilot program expanded with the addition of a mobile observation cart to
monitor patients in the medical/surgical units at WellSpan York, WellSpan Gettysburg and WellSpan Good
Samaritan in Lebanon.

                                                                                                        Page 2 of 4
                               How AI helps hospitals keep a watchful eye on patients

“The mobile cart made it faster for us to implement the program in other hospitals,” Paulus says.

By June 2024, all WellSpan hospitals will have the program hardwired including WellSpan Ephrata Community,
WellSpan Chambersburg, WellSpan PhilHaven and WellSpan Waynesboro.

‘Caring for many with few’

Penn State Health began using AI to monitor ICU patients in September 2022 in its medical centers in Hershey,
Reading and Lancaster.

The virtual intensive care units (vICU), use Wilmington, Delaware-based CLEW Medical’s AI-powered virtual IU
platform.

Specially trained critical care nurses do around-the-clock monitoring using high-resolution audio and visual
telehealth equipment to communicate with a patient and bedside staff. Physicians and other clinicians also are able
to monitor patients.

Bedside visitors and staff are notified when cameras are in use with a doorbell chime. The cameras are not on 24
hours a day, but data is recorded on a continual basis.

“The technology affords caring for many with few,” says Chris LaCoe, vice president of Penn State Health Virtual
Health.

He says the telehealth software uses sophisticated algorithms to notify staff about the patient’s health to expand
existing critical care and support the bedside clinical team. It’s helped to improve patient outcomes and overall
quality of care, he says.

READ: Lancaster AI founder: 2024 will be transformative year

The virtual ICU nurses provide assistance with a variety of tasks such as new admissions, patient transfers and
pain reassessments, and they serve as a resource and mentor for new hires and nurse graduates.

“Along with being able to track real time patient health in ICU rooms, the virtual ICU staff can monitor those waiting
for a room, which reduces demand on the emergency department,” LaCoe says.

In May 2023, respiratory therapy was added to the virtual intensive care services at Milton S. Hershey and
Lancaster.

While the technology and virtual nursing can never replace human touch, LaCoe says it’s another way to deliver
care.

“It not only benefits patients as seen with lifesaving success stories, it also benefits staff and helps with the staff
shortage experienced by all health care systems today,” LaCoe says.

The AI-generated technology will also soon be put into operation at Penn State Health Holy Spirit Medical Center,
Camp Hill, and Penn State Health Hamden Medical Center, Enola.

‘A game-changer’

Penn Medicine Lancaster General Health uses AI-driven technology to optimize patient care by continually
monitoring patients’ health and providing real-time data to providers.

The Phillips Healthcare Smart Alert technology tele-ICU program is in a centralized location for nurses and
providers to extend monitoring of ICU beds by using sophisticated alarming algorithms with multiple data sources to
help alert clinicians when something happens.

                                                                                                            Page 3 of 4
                                How AI helps hospitals keep a watchful eye on patients

Monitoring is done through a multidisciplinary team of health care professionals. Once alerted, the team contacts
the attending physician if needed.

“Penn Medicine is using Rapid AI in emergency rooms,” says Michele Sellers, director of the NeuroRescue
Program at Penn Medicine, University of Pennsylvania Health System.

READ: How PCA&D's faculty, students are navigating AI's creative, legal challenges

The program, developed by a San Mateo, California, company, uses an AI-based platform designed to identify
patients who could benefit from brain-saving procedures.

The sophisticated software tool helps physicians identify more accurate diagnosis for faster care.

“It’s a game-changer for stroke care,” Sellers says, explaining the program can interpret CT scans within minutes,
speeding emergency care for the patient.

The technology tool speeds up assessment and care for stroke patients when time is critical.

Penn Medicine has been using the program for the past five years with significant success at all five hospitals in the
Penn Medicine Health System: Lancaster General Health, Chester County Hospital, West Chester; and
Pennsylvania Hospital, Hospital of the University of Pennsylvania and Penn Presbyterian Medical Center, all in
Philadelphia.

“We believe AI will change health care significantly over time, touching all areas of the service delivery model,”
says Allen Cubell, Penn Medicine Lancaster General Health’s executive director of innovation, Center for Health
Care Innovation.

Cubell says LG Health is continually exploring new systems to improve quality and safety for patients.

Improving efficiency

The UPMC health care system is using AI technologies to increase efficiency of health care practices.

Chris Camody, UPMC chief technology officer, explains the health care system isn’t quite there yet to use AI for
patient monitoring.

“We’re taking a very thoughtful approach to ensure the integrity, reliability, security and privacy of patients is first in
place,” Camody says.

He says he sees tremendous value in the AI technology currently in use at UPMC for documentation and predictive
analysis, noting it saves time for clinicians.

The technology proved to be especially helpful in addressing pandemic-related challenges that impacted
efficiencies, he says.

Camody agrees the technology is getting smarter and can help with staff shortages and contribute to better patient
outcomes.

Before UPMC puts AI technology in place to monitor patients, the process will undergo rigorous due diligence, he
says.

“It’s unlikely AI will replace a clinical staff, but could become a care team copilot to alert them to take action,”
Camody says. “And (it) will make us more effective in care and treatment.”

It’s a goal, he says, we all want for our patients.

                                                                                    Page 4 of 4
                           How AI helps hospitals keep a watchful eye on patients


Load-Date: March 3, 2024


  End of Document

                                                                                                         Page 1 of 2
                    Byte-sized Care: Is AI the key to cracking the mental health crisis? - The Tribune




    Byte-sized Care: Is AI the key to cracking the mental health crisis? - The
                                     Tribune
                                             The McGill Tribune: McGill University
                                                 September 17, 2024 Tuesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: SCI-TECH; Pg. 1
Length: 699 words
Byline: Russel Ismael

Body


Across Canada, 1.6 million children face mental health issues in an ongoing crisis which is exacerbated by a
shortage of mental healthcare professionals. Given the potential benefits of artificial intelligence in diagnosing,
preventing, and treating mental illnesses, some people are turning to AI for solutions. But should the future of
mental healthcare go digital?

Professors in McGill's Department of Family Medicine, Samira Abbasgholizadeh-Rahimi and Mark Yaffe, along with
Master's student Pooria Ghadiri, explored this question by consulting with some of Montreal's primary-care
physicians (PCPs).

According to Rahimi, investigating how AI affects adolescent mental health is an important but under-researched
topic.

"I believe adolescent mental health is a very important issue that's not properly studied, specifically when it comes
to the intersection of adolescent mental health and the use of advanced technologies like [AI]," Rahimi explained in
an interview with The Tribune. "There are different areas that we can look into [regarding AI] in terms of prevention,
[...] in terms of identification, or high-risk populations."

Before beginning their research process, Rahimi inquired with the Jewish General Hospital about implementing AI
in mental healthcare. She wanted to determine if AI could improve treatment plans for adolescents by addressing
the challenges clinicians face when treating them.

"We discussed a lot about the no-shows of adolescents, difficulty of building trust [with patients] to share [medical]
information, helping young adults [stick with] their treatment, as [...] there is low adherence to these medications
sometimes," Rahimi explained.

Yet despite AI's promises of a novel solution, PCPs are largely uncertain about the idea.

"I think it's important to recognize that in healthcare, things tend to be very much oriented to evidence-based
practices and evidence-based outcomes," Yaffe said in an interview with The Tribune. "There is still a lot of concern

                                                                                                         Page 2 of 2
                    Byte-sized Care: Is AI the key to cracking the mental health crisis? - The Tribune

about the ability of AI to deliver the goods in a way that is acceptable to doctors, patients, society, and our
regulatory bodies."

He punctuated his point by stating that there is no research that identifies "the single best" AI that can diagnose a
patient.

"Remember that mental health is an extremely broad area for diagnosis, and we're dealing with depression,
anxiety, psychosis, drug abuse, suicidality, and the list goes on," Yaffe said.

Rahimi also stated that current data laws limit AI capabilities in healthcare. However, she is hopeful for a paradigm
shift as public education about AI potential increases.

"I've been presenting [AI in healthcare] in different seminars and webinars in terms of its potential, and in a majority
of my presentations, I get at least one question in terms of how dangerous these devices are, if there are going to
be killer robots in the future," Rahimi said. "I think there is a lot of need for increasing awareness among the
population [...] so they can have a better understanding of what AI is."

There are also restrictions found at the clinical level, as Yaffe explained that Canadian medical colleges, like the
Collège des médecins du Québec, set standards of care by looking at physician practices to assess their validity.

"[Medical colleges] look at what outcomes the physicians get from whatever it is that they're doing. They seek
feedback from society at large about acceptability." Yaffe said. "I think that one has to ask, before saying 'Let's put
this into action,' 'What are the concerns?'"

By holding healthcare to high standards, physicians can maintain public trust in their work. While AI shows promise,
both Rahimi and Yaffe conclude that more research and education must be done before it can be accepted by not
only the public but also medical regulatory bodies.

"Our research was an attempt to learn more about what Montreal [PCPs] understood about the potential use of AI
in the assessment of adolescents' mental health care," Yaffe explained. "Varied expressions of both enthusiasm
and caution suggest these physicians will approach AI with the same responsibility they employ with constantly
evolving technologies and treatments."

Share this:


Load-Date: September 18, 2024


  End of Document

                                                                                                    Page 1 of 3
                   AI CHATBOTS WORK TO WIDEN ACCESS TO CARE TECHNOLOGY | HEALTH




      AI CHATBOTS WORK TO WIDEN ACCESS TO CARE; TECHNOLOGY |
                             HEALTH
                                        Wisconsin State Journal (Madison, Wisconsin)
                                                       March 1, 2024 Friday
                                                              ALL EDITION



Copyright 2024 Madison Newspapers, Inc. All Rights Reserved

Section: LOCAL; Pg. A9
Length: 862 words
Byline: THALIA BEATY Associated Press

Body


NEW YORK - Komal Vilas Thatkare says she doesn't have anyone to ask about her most private health questions.

"There are only men in my home - no ladies," said the 32-year-old mother and housewife in Mumbai. "I don't speak
to anyone here. So I used this app as it helps me in my personal problems."

The app she uses is powered by artificial intelligence running on OpenAI's ChatGPT model, that Myna Mahila
Foundation, a local women's organization, is developing. Thatkare asks the Myna Bolo chatbot questions and it
offers answers. Through those interactions, Thatkare learned about a contraceptive pill and how to take it.

Thatkare is one of 80 test users the foundation recruited to help train the chatbot. It draws on a customized
database of medical information about sexual health, but the chatbot's potential success relies on test users like
Thatkare to train it.

The chatbot, currently a pilot project, represents what many hope will be part of the impact of AI on health care
around the globe: to deliver accurate medical information in personalized responses that can reach many more
people than in-person clinics or trained medical workers. In this case, the chatbot's focus on reproductive health
also offers vital information that - because of social norms - is difficult to access elsewhere.

"If this actually could provide this nonjudgmental, private advice to women, then it could really be a gamechanger
when it comes to accessing information about sexual reproductive health," said Suhani Jalota, founder and CEO of
the Myna Mahila Foundation, which received a $100,000 grant from the Bill & Melinda Gates Foundation last
summer to develop the chatbot, as part of a cohort of organizations in low- and middle-income countries trying to
use AI to solve problems in their communities.

Building the 'missing middle'

Funders like the Gates Foundation, the Patrick J. McGovern Foundation and Data.org, are seeking to build up this
"missing middle" in AI development, especially in areas like health and education. These philanthropic initiatives

                                                                                                         Page 2 of 3
                 AI CHATBOTS WORK TO WIDEN ACCESS TO CARE TECHNOLOGY | HEALTH

offer developers access to AI tools they otherwise could not afford so they can solve problems that are a low priority
for corporations and researchers - if they are on their radars at all - because they don't have high profit potential.

"No longer can the global north and high-income countries drive the agenda and decide what does and does not
need to be addressed in local communities in the global south," wrote Trevor Mundel, president for global health at
the Gates Foundation in an October online post, adding, "We cannot risk creating another chasm of inequity when it
comes to AI."

The Associated Press receives financial support for news coverage in Africa from the Bill & Melinda Gates
Foundation.

The Myna Mahila Foundation recruited test users like Thatkare to write real questions they have. For example,
"Does using a condom cause HIV?" or "Can I have sex during periods?" The foundation's staff then closely monitor
the chatbot's responses, developing a customized database of verified questions and answers along the way that
helps improve future responses.

Work in progress

The chatbot is not yet ready for wider release. The accuracy of its responses is not good enough and there are
issues with translation, Jalota said. Users often write questions in a mix of languages and may not provide the
chatbot with enough information for it to offer a relevant response.

"We are not yet fully sure on whether or not women can understand everything clearly and whether or not it's fully
medically accurate all of the information that we're sending out," Jalota said. They are considering training some
women to help ask the chatbot prompts on behalf of someone else, though still aim to improve the chatbot so it can
be released on its own.

Dr. Christopher Longhurst, chief medical officer at the UC San Diego Health, has led the implementation of AI tools
in health care settings and said it is important to test and measure the impact of these new tools on patient health
outcomes.

"We can't just assume or trust or hope that these things are going to be good. You actually have to test it,"
Longhurst said. He thinks the promise of AI in health care is overestimated in the next two to three years, "But I
think long term, over the next decade, AI is going to be as impactful as the introduction of penicillin in health care."

Shoring up privacy

Jalota's team consulted with other projects funded by the Gates Foundation that were designing chatbots for health
care settings so they could solve similar problems together, said Zameer Brey, interim deputy director for
technology diffusion for the Gates Foundation.

The Myna Mahila Foundation is also partnering with another Gates grantee to propose developing privacy
standards for handling data for reproductive health. The foundation, which is working with an outside technology
firm to develop the chatbot, is also considering other steps to help ensure the privacy of users.

"We've been discussing whether we should delete messages within a certain time frame of women sending it to add
to this privacy," Jalota said, as some women share phones with family members.



Graphic


Rafiq Maqbool, Associated Press Komal Vilas Thatkare, 32, right, learns to use a chatbot powered by artificial
intelligence Feb. 1 at her home in Mumbai, India. "There are only men in my home - no ladies," she said. "I don't

                                                                                                   Page 3 of 3
                AI CHATBOTS WORK TO WIDEN ACCESS TO CARE TECHNOLOGY | HEALTH

speak to anyone here. So I used this app as it helps me in my personal problems." Rafiq Maqbool, Associated
Press The Myna Bolo chatbot pilot project represents what many hope will be part of the impact of AI on health
care around the globe: to deliver accurate medical information in personalized responses that can reach many more
people than in-person clinics or trained medical workers. Rafiq Maqbool, Associated Press Women learn to use an
AI-powered chatbot Feb. 1 in Mumbai, India. Rafiq Maqbool, Associated Press Women learn to use a chatbot
powered by artificial intelligence developed by Myna Mahila Foundation on Feb. 1 in Mumbai, India. The chatbot,
currently a pilot project, represents what many hope will be part of the impact of AI on health care around the
globe.


Load-Date: March 1, 2024


  End of Document

                                                                                                             Page 1 of 4
                    Young Utahns struggle with their mental health. Is a new A.I. chatbot the answer?




    Young Utahns struggle with their mental health. Is a new A.I. chatbot the
                                  answer?
                                                       The Salt Lake Tribune
                                                   September 23, 2024 Monday



Copyright 2024 The Salt Lake Tribune All Rights Reserved

Length: 2071 words
Byline: Jessica Schreifels

Body


The founders of ElizaChat hope that Utah students will soon be talking to their artificial intelligence chatbot, to test
whether the app can help improve teenagers' mental health. And by next year, they want school districts
throughout Utah - and across the country - using taxpayer dollars to pay for the chatbot.

Yet in the rapidly evolving landscape of artificial intelligence, businesses like ElizaChat are finding themselves in a
gray area of what their generative A.I. can do legally and ethically.

Does a chatbot - or the company selling it - need to be licensed like a human therapist if it gives mental health
advice? Is it required to report suspected child abuse or neglect to authorities, like mental health professionals are
required to do? Should it adhere to medical privacy laws?

And who's responsible if the chatbot's responses harm a young person, or if it doesn't recognize serious signs of
self-harm or other mental health struggles that endanger their safety?

The answers to these questions aren't found in Utah's current policies and laws, which were written in an era long
before AI text chatbots infiltrated our lives after ChatGPT launched in 2022. But it's these unknowns that have
caused worry among Utah mental health professionals, who have questioned in public meetings whether ElizaChat
is safe or effective for children who are struggling.

There is a critical need for mental health help for young Utahns. According to a recent report from the Utah
Behavioral Health Coalition, children and teenagers here have not been able to receive treatment despite being
diagnosed with mental or behavioral health conditions, largely due to a shortage of available therapists.

ElizaChat CEO Dave Barney said he believes his product, designed with therapists, is safe for kids - and that it's
more dangerous to do nothing while the mental health crisis deepens.

"It's unsafe to not bring solutions to the market," he said. "By not doing anything, we're not keeping our kids safe."

[Tell The Tribune Have you struggled to get mental health help for a child?]

Barney hopes to offer his product inside Utah schools soon, and is working with a new state government agency,
the Office of Artificial Intelligence Policy, to get there. Partially a learning lab, its staff will suggest to policymakers

                                                                                                       Page 2 of 4
                 Young Utahns struggle with their mental health. Is a new A.I. chatbot the answer?

what guardrails should be in place for companies like ElizaChat whose AI products are pushing the boundaries of
current laws.

But it also has another critical and powerful role It can offer ElizaChat and other tech companies what's called a
mitigation agreement. These contracts can exempt companies from laws, put caps on any state penalties or give
them other accommodations if they are trying to do something innovative that may run afoul of laws written before
AI existed.

People are already starting to use these types of AI-driven chatbots, Greg Whisenant - who is the AI's office policy
advisor - told Utah's Behavioral Mental Health Board at a recent meeting.

"The need is real. These products are coming either way," Whisenant said. "The issues facing our youth are
overwhelming resources available at this time."

"This is our chance," he added, "to achieve policy before these products take hold."

ElizaChat's beginnings

ElizaChat's founders have spent their careers in the tech field working with artificial intelligence. They started
thinking about how they might integrate AI into the mental health world about three years ago, said Luke Olson,
one of the Utah-based company's three cofounders.

The men - Olson, Barney and Jaren Lamprecht - had been working for a tech company that used AI in marketing,
and one of their clients was a large addiction center.

Patients could use an AI bot they called "Christina" to schedule appointments at the addiction center, Olson said,
and they got feedback that some patients were asking if they could continue talking to Christina after they got into
treatment because they felt the bot had helped them during a difficult time in their lives.

"That was kind of a light bulb moment of like, whoa. We can create human-like conversations with AI," he said. "We
can also do this for a greater purpose than just marketing, that can help people in their lives."

Barney said that while they knew they wanted to explore creating a company that focused on the intersection of
artificial intelligence and mental health, they didn't settle right away on a chatbot for struggling kids. They also
looked in other areas, like adult addiction and recovery or postpartum depression.

"And I think where we kind of landed on teens is that just seems to be the biggest problem where we can make the
most impact," he said.

That approach also has the potential for lucrative contracts Rather than relying on individual downloads in the App
Store, they are targeting deals that draw on government funding via entire school districts that would make
ElizaChat available to students.

The founders said they've designed ElizaChat alongside their board of trained psychologists and licensed
physicians who helped guide them on the best practices to use when giving advice to young people.

Since registering as a business in March, the company has been moving quickly. In May, Barney started reaching
out to school districts like Salt Lake City, according to emails obtained via a records request. The company
announced a month after that it had received $1.5 million in pre-seed funding from an angel investor. And by July, it
was officially working with the Office of Artificial Intelligence Policy.

Unlike other mental health bots available, Barney said their product isn't just a new interface placed over ChatGPT
- which relies on technology known as a large language model. These models mimic human writing by processing
large swaths of information available online. ElizaChat, Barney said, relies on more limited scripts that are guided
by the mental health professionals on their board.

                                                                                                         Page 3 of 4
                 Young Utahns struggle with their mental health. Is a new A.I. chatbot the answer?

Barney and Olson emphasized that, for now, they don't intend for ElizaChat to be a replacement for human
therapists, particularly in cases where young people are struggling with suicidal thoughts or other acute mental
health issues. The chatbot won't give mental health diagnoses, Olson said, and will act more as a life coach,
talking students through their struggles with their parents or their friends.

If Eliza detects a teenager is expressing suicidality or wanting to hurt someone, that's when real humans are
brought in The founders say ElizaChat will automatically notify the student's school and likely their parents. (The
involvement of parents will vary depending on medical and privacy consent laws in each state, Olson said.)

Barney said he is confident that the involvement of mental health professionals means that ElizaChat is safe.
Whether the product actually helps kids will be tested during a pilot program with a handful of school districts, he
said, through assessments before and after using the app.

The assessments haven't been designed yet, Barney said, and no districts have signed a contract yet to purchase
access to ElizaChat.

Risks in AI and mental health

The American Psychiatric Association advises clinicians to be cautious if they want to integrate artificial intelligence
into their work, citing a lack of evidence around quality, safety and effectiveness. The organization also expressed
concern for potential harm, pointing to one example where an eating disorder chatbot offered harmful dieting
advice.

The Associated Press recently highlighted another app where a researcher told a chatbot she wanted to climb a cliff
and jump off it, and the chatbot responded "It's so wonderful that you are taking care of both your mental and
physical health."

These types of apps aren't regulated by the U.S. Food and Drug Administration, which ensures safety of medical
devices, including software. That's because many of the apps, like ElizaChat, don't specifically claim to treat
medical conditions.

Concerns about safety were top of mind for therapists who are part of Utah's Behavioral Health Board, a group of
licensed mental health workers who advises state licensors on policy and disciplinary action. Zach Boyd, who is the
director of Utah's Office of Artificial Intelligence Policy, has twice met with the board to get their feedback on
ElizaChat and how artificial intelligence should be used to help improve mental health.

He was met with apprehension at both meetings. Board member Verl Pope said he was concerned about an AI bot
possibly misdiagnosing an eating disorder or someone's suicidality.

"There's some real concerns about using AI," he said, "and those concerns have not been alleviated in my mind."

Others were concerned about whether asking teenagers to interact with a computer program instead of a human
will exacerbate feelings of loneliness, or that the program will not understand vague messages - like a teen
struggling with suicidal feelings who may tell the bot he or she wants to "end it."

Another board member, Jared Ferguson, questioned whether a chatbot should be licensed - like a human therapist
is - if it will be providing mental health services.

"It stands to reason that licensing should be heavily considered with a chatbot that is looking to serve the residents
of Utah," he said. "And that somebody should have some recourse in filing a complaint that's outside of the App
Store."

'Serious outcomes are at stake'

                                                                                                           Page 4 of 4
                  Young Utahns struggle with their mental health. Is a new A.I. chatbot the answer?

Earlier this year, Utah legislators passed a bill which set up two guardrails for artificial intelligence companies in an
effort to protect consumers. First, the bill clarified that if an AI product harms someone, the company is responsible
- it can't blame computer error and skirt consumer laws or other liability.

The bill also requires that licensed professionals, such as health care workers, disclose to clients when they are
interacting with generative artificial intelligence. But for companies using AI, the law requires that the chatbot
disclose to a consumer that they are chatting with a computer program if the customer asks if they are talking to a
real person.

This legislation also established the Office of Artificial Intelligence Policy. Boyd, who's been on the job for about four
months, said its goal is to craft a space which allows the companies it partners with to drive innovation with artificial
intelligence while protecting Utahns from potential harm.

"There is this kind of move fast and break things mentality in the tech world," he said. "I really think that AI and
mental health care is probably not the right place to be doing 'move fast and break things' as a philosophy."

Boyd's office hasn't yet finalized its mitigation agreement with ElizaChat, so it's not publicly known what rules or
laws will be relaxed for the company as it works to start its initial rollout in a handful of Utah school districts. Boyd
said that generally, they can agree that a certain law may not apply to a company, monetary fines could be capped,
or a company could get 30 days to solve a problem before the Division of Consumer Protection steps in.

In exchange for that agreement, a company agrees to share information with Boyd's office so that he can then
suggest permanent regulatory solutions to state lawmakers.

But Boyd emphasized that AI companies are not exempt from all laws. If, for example, his office decided to relax
licensing requirements for an AI chatbot working in mental health, it doesn't mean consumer deception laws can't
be used if the company harms or misleads its customers.

"Serious outcomes are at stake," he said, "and we want to make sure that we've got enough guardrails."

Barney, with ElizaChat, said regulatory laws are ambiguous. So for now, they're toeing the line and acting as if
ElizaChat was a person - so it won't diagnose people like a therapist does, or do anything else that only licensed
professionals can. It will act more as a support for someone and an advice giver, he said, and alert school
counselors when a teen needs more care or attention.

But he acknowledged that they'll continue to push where that line is - and that's one of the reasons why they are
working with regulatory bodies, to decide whether AI can be in spaces where only licensed professionals can
currently work.

"Is there a place for AI to do more than coaches can do today?" Barney asked. "But probably never everything that
a therapist can. We're hoping that line moves - but we're always going to stay on that legal side."


Load-Date: October 8, 2024


  End of Document

                                                                                                    Page 1 of 2
    How can generative AI impact students' learning? Four student panelists weigh in. - The Brown Daily Herald




   How can generative AI impact students' learning? Four student panelists
                     weigh in. - The Brown Daily Herald
                                          The Brown Daily Herald: Brown University
                                                 October 23, 2024 Wednesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 553 words
Byline: Ian Ritter

Body


Students and faculty gathered Wednesday to discuss how generative AI can impact learning in an event hosted by
the Sheridan Center for Teaching and Learning. Moderated by Mary Wright, the center's executive director, the
event included a panel featuring four students, followed by a Q&A.

The panel began by discussing how generative AI can be used to supplement learning within their fields. All four
panelists are writing fellows and associates at the Sheridan Center.

Prudence Ross GS, a fifth-year English PhD candidate, noted that while AI can help organize ideas and edit writing,
its contents need to be double-checked and scrutinized.

When using AI, Ross said that students should ask themselves questions to ensure that any AI-generated content
accurately reflects their intentions. "Is this word choice actually what I want to say? Is this organization that it's given
me for an outline really emphasizing the thing I want to emphasize?" she asked.

ADVERTISEMENT

Ross also noted how generative AI struggles with close reading assignments, as it regurgitates facts instead of
breaking down and analyzing text.

Angela Lian '26 agreed with Ross, noting that tools such as Grammarly can be particularly useful for improving
students' writing. But she emphasized that the use of AI to generate entire assignments - which she said is
uncommon - is detrimental to students' skill development.

Abby Katz GS, a 3rd year PhD student at the School of Public Health, noted that AI is becoming "ubiquitous" within
society and stressed the importance of getting familiar with its benefits and limitations. To emphasize the
technology's fault, she cited a viral example in which AI failed to correctly identify how many r's are in the word
strawberry.

                                                                                                   Page 2 of 2
   How can generative AI impact students' learning? Four student panelists weigh in. - The Brown Daily Herald

Da-Young Kim '25 highlighted the importance of gaining a fundamental understanding of a field before trying to use
AI to aid with comprehension and problem-solving.

Kim noted that AI simply doesn't have the fundamentals of critical thinking to solve mathematical proofs and write
code. "It just doesn't have the capabilities to weave together such complex ideas," Kim said.

Next, the panel turned to policies in the classroom, stating that professors need to make their AI usage regulations
clearer to students to avoid academic misconduct. Before the panel, the four students agreed not to mention their
personal usage of AI to avoid any potential consequences from the University.

Katz noted that some assignments flagged as being generated by AI are actually products of the students' original
work. To combat these false positives, she suggested that professors require students to turn in drafts of their work
as they complete the assignment.

To ensure that students properly cite AI-generated content within their work, Kim suggested that instructors require
students to indicate how they used AI to complete the assignment, whether to generate ideas, edit text or organize
their thoughts.

Students ended the panel by discussing the need for stricter restrictions on AI and technology usage for younger
students.

"The pervasiveness of technology and AI is dissuading people from developing critical skills like social interaction
and critical thinking because that stuff is hard and uncomfortable," Kim said. "You get a lot of good things out of
being in discomfort."

ADVERTISEMENT


Load-Date: October 24, 2024


  End of Document

                                                                                                        Page 1 of 3
                                ADVANCING CANCER DIAGNOSIS, TREATMENT WITH AI




                 ADVANCING CANCER DIAGNOSIS, TREATMENT WITH AI
                                               Pittsburgh Post-Gazette
                                            September 15, 2024 Sunday
                                                   EAST EDITION



Copyright 2024 P.G. Publishing Co.

Section: BUSINESS; Pg. E-1
Length: 749 words
Byline: Evan Robinson-Johnson Pittsburgh Post-Gazette

Body


When people think about the greatest potential for artificial intelligence, many cite curing cancer and other health
care breakthroughs.

In Pittsburgh, the promise of diagnosing just one cancer - pancreatic - with AI was enough to convince Logan Nye
to abandon his plans of becoming a surgeon. He's now using coding and math to build Galen Health, in partnership
with the city's top universities and medical centers.

"We're slated to get access to [UPMC's] patient data in the next couple weeks," he told me.

Others like Shiv Rao, a practicing cardiologist at the University of Pittsburgh Medical Center, are building AI
transcription tools to give doctors more time with their families. Mr. Rao was recognized last week by Time
Magazine, which named the Abridge founder one of the 100 most influential people in AI.

Just a few years ago, researchers were skeptical about how much AI would transform health care.

"Despite more than a decade of significant focus, the use and adoption of AI in clinical practice remains limited, with
many AI products for healthcare still at the design and develop stage," a 2021 article in Future Healthcare Journal
noted.

But that appears to be shifting.

According to the National Cancer Institute, AI is already improving the speed, accuracy and reliability of some
cancer screening and detection. Using digital images, computers have been able to find evidence of prostate,
breast and cervical cancers, research cited by the institute found.

In Pittsburgh, West Penn Hospital is creating its own array of images using Vectra, a full body scan that uses AI to
detect skin cancer.

"AI is ultimately going to come down to the data that we have," said Megan Shaw, who leads the Pittsburgh Life
Sciences Alliance. And with two major hospital systems here, she said the region is "exceptionally well positioned."

                                                                                                       Page 2 of 3
                           ADVANCING CANCER DIAGNOSIS, TREATMENT WITH AI

Some of the limitations and fears that have plagued consumer AI tools like ChatGPT have larger ramifications in
the clinical setting - think sensitive patient data, biased training, or hallucinations. "These models can perpetuate
medical bias" if the data used to train them are not diverse and representative, the National Cancer Institute notes.

But the gains appear to be greater, too.

Well-informed chatbots could give patients tailored information on their diagnosis, like a personalized WebMD.
More sophisticated tools could parse data across populations to find trends that aren't evident to human
researchers. It also appears to be helping researchers find new drugs.

"I'm reticent to say that it's making new drugs, because we're not there yet," said Jonathan Steckbeck, chief
executive of South Side-based Peptilogics. "But we are becoming much more efficient at finding unique chemical
matter that may one day turn into drugs. And that is a win in and of itself."

The cancer institute has called for a set of standards for the development of medical AI - a pursuit it says will
ultimately "accelerate the effort to end cancer."

At UPMC, that chase will be tempered by the need to protect patient privacy, chief medical information officer Dr.
Robert Bart said in a statement last month.

"Health system leaders are understandably excited about the potential for AI â€¦ but the excitement also must be
balanced with a commitment to high-quality care for patients and protections of their data and privacy," he said.

Last year, UPMC trained an AI algorithm on over 1.25 million surgical patients to predict which people were at high
risk for complications after surgery. The system would flag people scheduled on a given day, allowing clinical teams
to "better coordinate care and institute some prehabilitation," the hospital said.

NOMA AI, a local startup that partners with the hospital, is using a similar approach to predict hemorrhages in
childbirth.

"We want to make sure the algorithm works for everyone, including minorities," said chief medical officer Dr. Gilles
Clermont.

The hardest step, he said, remains to be securing an approval from the Food and Drug Administration. But the
nation's top health regulator is at least helping startups chase that potential.

"They are definitely on board" with AI, said Mr. Clermont, who was part of an FDA meeting with startups and other
academics last week. "Their guidance is becoming more precise as of last year, and a lot more helpful for those of
us that are trying to develop AI solutions."

Have an AI question? Contact tech reporter Evan Robinson-Johnson at ejohnson@post-gazette.com or on X
@sightsonwheels.



Graphic


PHOTO: Pittsburgh Post-Gazette: An aerial view of UPMC Mercy in Uptown. The city's top universities and medical
centers, including UPMC and AHN, are using AI more frequently to provide better health care.


Load-Date: September 15, 2024

                                                                  Page 3 of 3
                  ADVANCING CANCER DIAGNOSIS, TREATMENT WITH AI


End of Document

                                                                                                             Page 1 of 3
                                      AI and imaging: 'It takes radiology to the next level'




                      AI and imaging: 'It takes radiology to the next level'
                                                       LNP (Lancaster, PA)
                                                    April 10, 2024 Wednesday



Copyright 2024 LNP Media Group, Inc. All Rights Reserved

Length: 1018 words
Byline: ROCHELLE A. SHENK FOR LNP, LANCASTERONLINE

Body


Artificial intelligence has become part of our daily lives, whether it’s navigating our surroundings with Google Maps
or using digital voice assistants such as Siri and Alexa.

It is also being deployed by health care systems as a tool to aid in analyzing results generated by scans.

“We work with people’s lives, so we do trials of a number of AI systems to find what works best for us,” says Dr.
Heidi Beilis, vice president and chief medical officer of WellSpan Health’s diagnostic service line. “We want to use
the technology responsibly.”

In fact, she says, WellSpan is one of 20 health systems that have pledged to use AI responsibly.

“I think we’re in the very early stages of using AI in health care, and radiology is on the cutting edge of using this
technology,” says Dr. Timothy Mosher, Penn State Health physician lead for radiology.

READ: Full coverage of Progress 2024 [roundup]

Beilis says AI is not “emerging” technology. “It’s here and it’s not new to us; it’s integrated into patient care.”

WellSpan uses the Aidoc system, launched in February 2022, to flag patient CT scan results for abnormalities that
might otherwise not be noticed by the human eye and prioritize these urgent findings for radiologists to review.

Last year, 152,000 cases were analyzed relating to pulmonary artery embolism assessment, cervical-spine fracture
and intracranial hemorrhage, Beilis says, and 7,780 were flagged.

“It takes radiology to the next level,” she says.

WellSpan is “dipping our toe in the water with using AI in conjunction with digital mammograms,” she says,
explaining that if AI flags an area for further study, the algorithm retrieves previous mammograms, compares them
to determine if it’s a real issue and prioritizes a scan that may have a real issue.

“The goal is to expedite patient care,” Beilis says. “AI can flag areas and pull up previous imaging quickly. If there’s
an issue that requires a closer look, we’d like to have that information before the patient leaves the facility.”

                                                                                                        Page 2 of 3
                                  AI and imaging: 'It takes radiology to the next level'

This new use of AI is being rolled out gradually, she says. So far, it’s being used in 110 practices throughout
WellSpan’s system.

There’s also a trial project this year using AI in conjunction with lung imaging.

Dr. Beilis says various technologies are merging in WellSpan’s Gene Health project. According to information
provided by WellSpan, the research project is a partnership with Helix, and it helps identify and study how genetic
factors may influence a person’s health while also supporting new research discoveries across the community.

“We want to take care of the whole patient,” she says. “But people also need to be engaged in their care by getting
routine exams and/or scans.”

‘A silent partner’

Mosher says Penn State Health is doing a fair amount of research about AI tools.

“We look at various AI packages, and before we roll out AI technology in any type of imaging, we look at the quality
of the images and the issues flagged by AI,” he says. “AI has continuously gotten better and has become more
accurate, but it’s a tool and we have to develop the structure to deploy it properly. AI and the radiologist work
together — it’s a ‘silent partner’ for the radiologist; it flags areas where the radiologist should take a closer look.
What used to be a very manual process has been enhanced.”

The oldest use of AI for imaging at Penn State Health is in relation to mammograms — the AI algorithms review
images after they’re taken. More recently, Penn State Health has deployed AI in other imaging areas, including
chest X-rays to detect lung cancer. Another area being considered for AI is heart imaging.

“Chest X-rays isn’t as far along as mammography because there are a lot of variables that could point to possible
lung cancer,” Mosher says. “One of the things AI is good at is spotting the difference between two sets of scans. It’s
a bit more complicated when there are more variables involved.”

READ: App fine-tuned at Lancaster innovation lab uses AI to spot skin cancer

Saving time

Dr. Danielle Brewington Cross, stroke medical director for Penn Medicine Lancaster General Health, says the
health care system began using AI technology about five years ago and currently uses an AI brand called Rapid for
CT scans in its stroke program.

“The software analyzes the imaging and creates a report within minutes that can be used in clinical situations to
help the physician determine the patient’s treatment plan,” Cross says. “The main benefit of using AI with CAT
scans occurs in stroke patients with a large vessel occlusion (LVO) in need of a thrombectomy. The AI software can
identify a LVO and show the affected territory, allowing the multidisciplinary team to start from the same baseline
when deciding to move forward. While the team has access to the raw images in the Epic digital system, those
images can take time to be visible. A perk of the AI software is that it also gives the team faster access to the
patient’s scans/images.”

Cross says Penn Medicine Lancaster General Health is exploring mammography systems that would improve
breast cancer screening. Penn Medicine researchers have developed an AI tool/imaging technique that’s still being
tested that provides highly detailed views of cells and how patients’ genes operate, allowing doctors and
researchers to see cancer cells that may have been virtually invisible.

Proceeding with care

Chris Carmody, senior vice president of the UPMC information technology division, says AI is currently used in the
ophthalmology department to evaluate images of the retina to look for signs of macular degeneration.

                                                                                                      Page 3 of 3
                                AI and imaging: 'It takes radiology to the next level'

For patients with acute stroke symptoms, UPMC uses AI to review CT scans and flag areas for a radiologist to
examine closer.

Moving forward, AI will be used in other areas, he says.

“We’re on this journey, and we’re diligent in our testing and evaluation of this technology,” Carmody says. “We want
to be sure it meets the high standards we’re looking for. In evaluating the various AI imaging packages, we’re also
concerned with the cybersecurity of our patient’s data. We continually evolve our practices to protect our patient’s
data.”


Load-Date: April 11, 2024


  End of Document

                                                                                                        Page 1 of 1
                             S. Korean science ministry opens joint AI research lab with NYU




          S. Korean science ministry opens joint AI research lab with NYU


                                                         ASEAN Tribune
                                                   September 24, 2024 Tuesday



Copyright 2024 ASEAN Tribune All Rights Reserved




Length: 229 words

Body


 24 Sep 2024 (Yonhap News Agency) South Korea's science ministry said Tuesday it has opened a joint artificial
intelligence (AI) research lab in collaboration with New York University (NYU) as part of efforts to lead global-level
AI research projects.

The new Global AI Frontier Lab at NYU aims to become a global AI joint research hub for researchers from South
Korea and the United States, as well as many other countries, according to the Ministry of Science and ICT.

The lab will be co-led by two distinguished computer scientists -- Cho Kyung-hyun and Yann LeCun -- who are both
professors at NYU.

Cho is currently a board member of the South Korean AI startup Upstage, while LeCun is the chief AI scientist at
Meta Platforms Inc., the operator of Facebook and Instagram.

The science ministry has set aside 45 billion won (US$33.8 million) to fund the lab over the next five years, and
NYU plans to contribute $31.5 million.

At the lab, experts from Seoul and Washington will focus on fundamental research in AI, and study trust and
responsible AI, as well as AI for medical and health care, according to the ministry.

"This is a critical moment of change for the AI partnership between South Korea and the U.S.," Science Minister
Yoo Sang-im said during the lab's opening ceremony in New York, calling for further expansion of the bilateral
partnership in science and technology.


Load-Date: September 25, 2024


  End of Document

                                                                                                        Page 1 of 2
                             Will Tufts follow in other universities' footsteps with an AI major?




          Will Tufts follow in other universities' footsteps with an AI major?
                                                  Tufts Daily: Tufts University
                                                      May 15, 2024 Wednesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 611 words
Byline: Maggie Monahan

Body


In February, the University of Pennsylvania announced it will begin offering an artificial intelligence major, open for
enrollment in fall 2024. The major will be offered through Penn's School of Engineering. Several other universities
have announced AI-specific degree programs in recent years; MIT began offering one in fall 2022 and Carnegie
Mellon has had one since fall 2018. Although Tufts computer science students have the option of focusing their
studies on AI, Tufts currently does not offer an AI-specific degree program, but that could change in the future,
according to Kyongbum Lee, dean of the School of Engineering. When developing new AI-based courses, he
hopes to focus on ethics in computing and "how to make AI curriculum more accessible" to all students, rather than
just those pursuing math-based degrees.

There is definite interest in an AI degree program among current Tufts students. Computer science major Sammy
Kao said that he would absolutely have pursued an AI major alongside his current degree if possible, because "AI
and computer science are pretty intertwined. ... So I think the AI degree program would be a mix of both, with a few
more theoretical classes."

AI has become increasingly relevant in nearly every industry, not just computer science and engineering. Computer
science professor Matthias Scheutz, who focuses on artificial intelligence, believes that "being at AI savvy has
become a necessary part of any education."

"I would think that anybody who comes out of school with a college degree needs to have some sort of AI
proficiency, at least at the conceptual level," Scheutz said.

The use of AI has recently been a hot-button issue in many fields. AI played a major role in the Writers Guild of
America's strike, which ultimately ended in a contract ensuring that studios cannot use AI to write scripts or
generate "source material" for a project.

However, AI has also been praised for its uses in other fields, such as medicine. Seema Kumar, CEO of healthcare
innovation campus Cure, highlighted a slew of AI health solutions under exploration by entrepreneurs - including "a
robotic arm that can produce and send ultrasound images to specialists anywhere in the world," "a service that
provides AI social workers that can simplify scheduling wellness visits and health screenings for low-income

                                                                                                       Page 2 of 2
                          Will Tufts follow in other universities' footsteps with an AI major?

families while enrolling them in assistance programs" and "AI-facilitated cardiovascular health screenings in trusted
community spaces for Black patients," among others.

The field of artificial intelligence is rapidly evolving, which means AI education does not end with an undergraduate
degree, regardless of the degree program.

"Tufts tries to teach the foundational work," Kao said. "Once you graduate you're going to have to learn a lot of new
things on your own, just because the field is rapidly evolving and these companies are coming out with new
techniques by the week."

The engineering school has introduced several new AI-focused courses in recent years and hopes to introduce
more in the future.

"One course that we don't have right now, that we would really like to have, is a course on large language models
that specifically focuses on the technical aspects of large language, or foundation models, as they're called,"
Scheutz said.

Large language models can understand and generate natural language - ChatGPT is a popular example.

Kao agreed that he would like to see a large language model class at Tufts.

"They definitely should offer a generative AI class, or something with large language models or transformers," Kao
said. "If Tufts ever did have a class like that, it'd be a pretty big pull within the program."


Load-Date: May 15, 2024


  End of Document

                                                                                                      Page 1 of 1
         Emmes Group partners with Miimansa AI to accelerate adoption of generative AI in clinical research




         Emmes Group partners with Miimansa AI to accelerate adoption of
                       generative AI in clinical research
                                               Daily Record, The (Baltimore, MD)
                                                       July 23, 2024 Tuesday



Copyright 2024 BridgeTower Media All Rights Reserved

Section: NEWS
Length: 287 words
Byline: Daily Record Staff

Body


Emmes Group, a Rockville-based global contract research organization, Tuesday announced a multi-year
partnership with health tech startup Miimansa AI to acquire use of its Clinical Entity Modeling tools based on
advanced large language modeling (LLM) techniques and generative AI.

Emmes Group is rapidly maturing its technology platform, Veridix AI, and Miimansa's Clinical Entity Modeling
technology will serve as a building block to accelerate the development of state-of-the-art automated text
processing solutions tailored for clinical research.
The partnership will focus on creating capabilities for quickly and accurately processing vast amounts of clinical
data and enabling text to text transformations such as protocol authoring and medical writing, reducing the time and
cost associated with manual data handling and analysis.
Emmes Group is a privately held contract research organization (CRO), wholly owned by New Mountain Capital. It
was founded as Emmes more than 47 years ago, becoming one of the primary clinical research providers to the
U.S. government before expanding into public-private partnerships and commercial biopharma.

Emmes Group has built industry leading capabilities in cell and gene therapy, vaccines and infectious diseases,
ophthalmology, rare diseases and neuroscience. Today, the company is creating the industry's first native digital
and AI based CRO optimized to deliver programs faster, better and more efficiently. Where human intelligence
meets artificial intelligence.

Miimansa AI is led by former faculty and alumni from IIT Kanpur andStanford University and specializes in clinical
data management and biomedical research.

Copyright © 2024 BridgeTower Media. All Rights Reserved.


Load-Date: July 29, 2024


  End of Document

                                                                                                        Page 1 of 3
                   Dr. David C. Miller announced to be the new EVP and CEO of Michigan Medicine




      Dr. David C. Miller announced to be the new EVP and CEO of Michigan
                                    Medicine
                                      Michigan Daily: University of Michigan-Ann Arbor
                                                  October 17, 2024 Thursday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS-; Pg. 1
Length: 938 words
Byline: Emma Lapp

Body


The University Insider is The Daily's first faculty and staff-oriented newsletter. This weekly newsletter will give U-
M faculty and staff the ability to see the most important issues on campus and in Ann Arbor - particularly those
related to administrative decisions - from the perspective of an independent news organization. It will also provide a
better understanding of student perspectives.

Subscribe

Processing...

Success! You're on the list.

Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.

Dr. David C. Miller, a urologist and surgeon, will be the new University of Michigan executive vice president for
medical affairs and CEO of Michigan Medicine starting July 2025. The announcement came in September after
Marschall S. Runge, who has served as the EVP and CEO of Michigan Medicine since March 2015, announced his
retirement. Miller is the current executive vice dean for clinical affairs for the Medical School and president of
Michigan Medicine.

In a letter to the U-M community, University President Santa Ono wrote that Miller's skills and career experience will
serve the Michigan Medicine and Ann Arbor communities well.

"Dr. Miller is an extraordinary leader, a brilliant researcher and the kind of doctor we all hope for when we need
exemplary care," Ono wrote. "His robust clinical background, his collaborative and empathic approach, his
understanding of the intricacies of patient care, and his strong strategic vision make him the clear choice for this
important leadership role."

Miller told The Michigan Daily that he appreciates everything Runge has done in the position, and feels proud to
continue his work.

                                                                                                            Page 2 of 3
                  Dr. David C. Miller announced to be the new EVP and CEO of Michigan Medicine

"I'm very grateful, humbled and honored by this opportunity," Miller said. "I have a lot of gratitude for Runge, who's
been our current CEO, for his leadership and mentorship and support for our doctors, our nurses, staff, students,
our entire community, including our patients. I'm deeply grateful for the opportunity to keep working with our
extraordinary team members."

Miller said that some of his overarching goals for Michigan Medicine as CEO are to continue supporting clinical
research and to build upon existing excellence.

"To start with, we have an amazing medical school with extraordinary students who are advancing learning
methods and research that are leading the next generation of innovations in clinical care," Miller said. "An important
goal is to continue our initiatives across all of our missions, so in clinical care, as I mentioned, our continuous efforts
to be the safest, highest quality health care delivery system with improved access and a great experience for our
patients and our team members."

Miller also hopes to continue integrating artificial intelligence into Michigan Medicine care. The use of AI in health
care has been generally increasing in recent years, and Miller hopes to take advantage of technology to improve
patient care. Miller explained that Michigan Medicine currently uses AI to determine the best location, inpatient or
outpatient, for patients undergoing different medical procedures.

"We're starting to see some momentum in that area that I'm hopeful we can continue to advance," Miller said.
"We've been able to use AI to help us identify the best and safest locations for patients who need surgical
procedures."

LSA senior Zoe Walters is considering applying to the Medical School, and told The Daily that she believes the rise
of AI in health care represents a major change to the industry.

"The biggest thing that is changing the health care field is the influence of technology," Walters said. "The most
recent thing that has been implemented is using AI to write all of the charting notes. It records it and stores it in a
database just for the time being and it saves the doctors a lot of time after they see the patient."

Miller said that the changing nature of the medical field requires creative solutions.

"Broadly speaking, with Michigan Medicine as a leading health care organization, the field of health care itself is
ever-changing," Miller said. "There are different dynamics that might be financial or regulatory or even issues and
challenges related to our workforce. Making sure that we're supporting and developing our workforce. I think we will
have to be creative and wise across all those areas to make sure that our clinical enterprise continues to serve as
an important foundation for all that we're trying to accomplish."

Discussion of sustainability in hospital settings has also been growing in the last decade. Sustainability initiatives in
these settings can include reducing medical waste, switching to renewable energy, being conscious of energy
usage and reducing toxic chemical use. Miller said that, in his tenure, he hopes to continue the sustainability
initiatives that Michigan Medicine is already implementing.

"We have great initiatives in our operating rooms that are actually separating materials that used to go into landfills
that are now being recycled," Miller said. "(Sustainability) is an ongoing area of prioritization for us, all the way to
where we have a subcommittee of our board focused on issues including environmental sustainability."

Ono wrote that he believes in Miller's ability to move Michigan Medicine forward in research innovation, training and
patient care.

"I am confident he will continue to drive innovation and improvements to ensure (Michigan Medicine) and the U-M
Medical School continue to be beacons of teaching, learning and healing far into the future."

Daily Staff Reporter Emma Lapp can be reached at emmalapp@umich.edu

                                                                                               Page 3 of 3
                Dr. David C. Miller announced to be the new EVP and CEO of Michigan Medicine


Load-Date: October 18, 2024


  End of Document

                                                                                                   Page 1 of 2
    Penn addresses technology's future UPenn med school names first vice dean of AI, senior VP for data, tech
                                                 solutions.




   Penn addresses technology's future; UPenn med school names first vice
               dean of AI, senior VP for data, tech solutions.
                                                    The Philadelphia Inquirer
                                                      April 14, 2024 Sunday



Copyright 2024 Philadelphia Newspapers, LLC All Rights Reserved

Section: HEALTH; Pg. G2
Length: 539 words
Byline: Sarah Gantz (Staff Writer)

Body


ABSTRACT

University of Pennsylvania wants to establish a strategy for using and teaching artificial intelligence, as the
technology becomes more common in medicine and everyday life.

The Perelman School of Medicine named Marylyn Ritchie the first vice dean of artificial intelligence and computing.
Ritchie, who also works as the director of Penn's Institute for Biomedical Informatics, will be responsible for
developing a plan to incorporate AI into medical school education.

Mitchell Schnall, Penn's former chief of radiology, has been named the first senior vice president for data and
technology solutions at University of Pennsylvania Health System. He will work to expand AI's use across Penn
Medicine's hospitals and physician groups.

AI tools - such as the popular chatbot ChatGPT, which can draft resumes and write computer code - are
increasingly popular and accessible. But these tools also make mistakes, and must be used carefully in medicine.

The health system and medical school want to establish a cohesive approach to using AI and establish best
practices for vetting new AI tools.

"We know AI is becoming part of the fabric of society and likely to be there in clinical care," Ritchie said. "It's really
important that providers can use it to their advantage."

AI in medical school

Ritchie will oversee a committee tasked with making recommendations for how to incorporate AI into Penn's
medical training programs.

Doctors-in-training need to learn what AI is good for - and what it's not good for, Ritchie said. She wants medical
students to learn how to be skeptical of new AI tools and gauge whether they will be useful.

                                                                                                   Page 2 of 2
    Penn addresses technology's future UPenn med school names first vice dean of AI, senior VP for data, tech
                                                 solutions.

She will also help decide which medical research specialties are most promising for Penn's investment in AI.

For instance, Ritchie sees potential for Penn to advance AI research in immune health.

Ritchie thinks researchers could use AI to analyze the health records of patients with autoimmune diseases to find
patterns, such as common lab results or secondary illnesses. The information could help doctors predict patients at
risk for developing an autoimmune disease.

Scaling AI tools across Penn Medicine

AI is already being used in some parts of Penn.

      Every Cure, a nonprofit organization co-founded by a Penn immunologist, uses AI to identify existing
medications that could be used to treat rare diseases, for which there are few or no treatment options.

Radiologists use AI tools to help search for abnormalities in CT scans and other imaging tests.

Schnall will help identify the AI tools with the greatest potential and ways to scale them across the health system.

For instance, Schnall is interested in exploring how AI could help doctors more quickly digest patients' medical
history.

Electronic medical records are troves of information, but they're poorly organized. Doctors may spend hours
combing through a patient's past test results and doctors' notes for clues about their current condition.

An AI tool might be able to read patient records and create what Schnall called a "clinical context," a summary or
digest of the patient's medical history that's easier to search.

"There's going to be a huge impact on the way we practice medicine," Schnall said.

sgantz@inquirer.com

SarahGantz


Load-Date: April 14, 2024


  End of Document

                                                                                                         Page 1 of 2
                            Cleveland Clinic explores using AI in patient-caregiver interactions




        Cleveland Clinic explores using AI in patient-caregiver interactions
                                                   Crain's Cleveland Business
                                                          January 29, 2024
                                                            Print Version



Copyright 2024 Crain Communications All Rights Reserved




Section: Pg. 4; Vol. 45
Length: 757 words
Byline: Paige Bennett

Body


Cleveland Clinic is exploring the use of artificial intelligence in patient-caregiver interactions as buzz around the
technology continues to grow in health care.

AI was one of the topics Cleveland Clinic CEO and president Dr. Tom Mihaljevic discussed during this year's State
of the Clinic Address, which is given annually by the CEO to the Clinic's 81,000 caregivers.

The Clinic is piloting an AI scribe powered by computer software company Nuance that will capture conversations
between a patient and a provider and summarize them in a digital medical note. Providers will then be able to
review the summary before placing it in the patient's electronic medical record.

"That will allow for a much more meaningful interaction between a patient and a provider," Dr. Mihaljevic said in a
recent interview with reporters ahead of his annual address. "It will take up to one-third of the time that's currently
being spent entering and typing and retrieving data and will give that time back to providers to really take care of the
patients."

The health system is also piloting an AI interface that will answer questions for patients rather than a provider. In
particular, it will focus on patients with chronic diseases.

Mihaljevic said the Clinic has already started testing the AI companion with a certain segment of patients. In blind
surveys, patients have often said they found the AI-generated responses more compassionate, detailed and timely
than those written by caregivers, Mihaljevic said.

AI is being used by the Clinic as a business tool as well. The system has partnered with software company Palantir
to create a "digital twin" of the system's main campus and is using AI to predict the number of surgeries performed
and patients entering the hospital to determine the best ways to utilize staff and physical resources.

                                                                                                           Page 2 of 2
                          Cleveland Clinic explores using AI in patient-caregiver interactions

At this stage, the Clinic is being very careful about bringing clinical applications of AI into practice, Mihaljevic said,
and there is always a person monitoring AI's output. Still, the Clinic is "very optimistic" about the future of AI in
health care.

Here are a few other takeaways from the address and Dr. Mihaljevic's interview with reporters.

Cleveland Clinic isn't immune to financial difficulties affecting U.S. hospitals.

The Clinic generated more than $14 billion in revenue last year. It resulted in an operating margin of 0.4%, which is
an increase from 2022. Still, the system has not been immune to the financial challenges plaguing U.S. hospitals.

Mihaljevic said margins are "severely compressed" as a result of the rising costs of wages, supplies and
pharmaceuticals, and inflation has outpaced increases in reimbursement.

Year-over-year, the Clinic saw a 10% increase in labor costs and a 20% increase in the price of pharmaceuticals
while reimbursements from the Centers for Medicare and Medicaid Services, the Clinic's largest payer, grew by
only 2.5%, Mihaljevic said.

Despite the financial difficulties of the times, the health system has seen increase in patient encounters, Mihaljevic
said, and services to patients have increased by 53% since 2018.

The system is focused on caregiver retention amid global workforce shortages.

Workforce shortages are a lingering problem that will continue to affect health systems in the coming years,
Mihaljevic said.

Shortages existed before the pandemic, he noted, and the industry will need to adjust to living with them for many
more years. The Clinic has been focused on retaining its existing workforce and using technology to redesign
health care delivery processes in the face of these shortages.

Incidents of violence against health care workers went up in 2023.

Last year, the health system's caregivers reported 3,800 incidents of physical or verbal violence. That's over 1,000
more reports than 2022 (2,761). Mihaljevic called violence against caregivers a "silent epidemic.

The Clinic has continued to enhance its police and security presence, he said, and has installed in every
emergency department. It confiscated 30,000 weapons brought in by patients and visitors in 2023.

Telehealth is a necessity for the system.

Continuing with the theme of technology, Mihaljevic said telehealth is now a well-established part of the Clinic's
offerings. More than 10% of visits take place remotely, he said.

As an example, every room at Cleveland Clinic Mentor Hospital, which opened to patients last summer, is equipped
so patients can interact with caregivers virtually. Telehealth allows patients to gain quicker access to specialized
health care services, he said.


Load-Date: February 1, 2024


  End of Document

                                                                                                        Page 1 of 2
                  Southeast's first graduate degree program focused on AI in medicine launched at UAB




       Southeast's first graduate degree program focused on AI in medicine
                                 launched at UAB
                                  The Kaleidoscope: University of Alabama at Birmingham
                                                      June 17, 2024 Monday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 786 words

Body


UAB now enrolling students in the Master of Science degree in artificial intelligence in medicine.The University of
Alabama at Birmingham is now offering a Master of Science degree in artificial intelligence in medicine following
recent approval from the University of Alabama System Board of Trustees. The new graduate degree program
through the UAB Marnix E. Heersink School of Medicine is the first of its kind in the Southeast that is designed to
provide a dynamic educational degree experience that equips students with the knowledge and skills required to
excel in the evolving intersection of medicine and artificial intelligence.

"This is a unique degree program in the Birmingham medical community that will enable engineers, computer
scientists and future clinical practitioners to adopt an integrated approach to improving human health that leverages
artificial intelligence," said Anupam Agarwal, M.D., senior vice president of Medicine and dean of the Heersink
School of Medicine. "We are meeting the growing demand for professional education and technical expertise at the
graduate level for training in artificial intelligence in medicine. Our goal is to provide graduate-level professionals
with AI application skill sets from various backgrounds to adopt an integrated approach to improving human health
and patient outcomes."

The M.S. degree in AIM, established collaboratively by the Marnix E. Heersink Institute for Biomedical Innovation
and the Heersink School of Medicine, is designed to equip graduate students with the specialized technical skills
necessary for managing extensive large medical datasets for AI development. This degree program focuses on the
development of sophisticated AI-driven applications for medical imaging and signal processing, as well as the
creation of large language models to aid in clinical decision-making. The curriculum is structured to provide
essential technical training for students who have completed the Graduate Certificate in AI in Medicine.

"As part of graduate dissertation research, students will engage in cutting-edge research at UAB, collaborate with
faculty experts and utilize state-of-the-art AI labs across UAB to gain a comprehensive understanding of AI's
practical applications in medicine," said Sandeep Bodduluri, Ph.D., director of AI in the MHIBI and the M.S. degree
in AIM program director. "Our mission is to produce graduates who are prepared for the workforce with graduate-
level expertise in AI with specialized knowledge in medical applications."

                                                                                                        Page 2 of 2
               Southeast's first graduate degree program focused on AI in medicine launched at UAB

The M.S. degree in AIM will focus on comprehensive graduate training in four key areas including foundations,
applications, integration and design of AI application through dissertation research. The integrated curriculum is
developed in collaboration with the UAB schools of Engineering, Business and Health Professions and the College
of Arts and Sciences.

Learn more about UAB's newest AI graduate degree program.

Graduates will serve as critical accelerators in translation and adoption of medical AI technologies. The M.S.
degree in AIM program combines academic rigor with real-world applications, offering students a strong foundation
in AI while providing opportunities for practical experience in clinical settings.

"At UAB's Heersink School of Medicine and the Heersink Institute for Biomedical Innovation, we recognize the
immense responsibility that preeminent academic institutions have in shaping the future of AI in health care," said
Rubin Pillay, Ph.D., M.D., assistant dean in the Heersink School of Medicine and executive director in the Heersink
Institute for Biomedical Innovation. "Our AI programs are committed to training a diverse group of designers and
developers to create responsible, ethical solutions. We also empower users to make informed decisions about
leveraging AI and ensure that individuals, whose data and care are managed by AI, can ask the right questions.
Our suite of programming at MHIBI reflects our mission to democratize AI literacy and make AI accessible and
beneficial for all."

The graduate degree meets the needs of the growing population of health care-related technological companies in
Birmingham and the state of Alabama, as well as UAB students who will join the Birmingham and Alabama health
care workforce, including physicians and nurses. It will aid UAB students and faculty who plan to launch their own
health care ventures and those in other clinically related fields who desire specific knowledge and technical skills in
advanced AI techniques.

To apply for the new M.S. degree in AIM program, visit www.uab.edu/apply. For further details on the curriculum
and degree objectives, please contact Bodduluri at sbodduluri@uabmc.edu


Load-Date: June 17, 2024


  End of Document

                                                                                                            Page 1 of 2
            Opinion: Artificial intelligence will radically improve health care, but only if managed carefully




 Opinion: Artificial intelligence will radically improve health care, but only if
                                managed carefully
                                                        TheHill.com
                                                 March 19, 2024 Tuesday



Copyright 2024 NEXSTAR MEDIA INC. All Rights Reserved




Section: HEALTH CARE INDUSTRY NEWS, Healthcare management news & ROBOTICS NEWS
Length: 839 words
Byline: Rep. Gregory F. Murphy (R-N.C.) and Michael Pencina, opinion contributors

Body


More important than the speed of bringing artificial intelligence (AI) into widespread use in American health care, is
ensuring we do it correctly. To unlock the innovation’s greatest positive impact, assurance of integrity and
transparency must take the highest priority. This can be accomplished by applying the principles that guide clinical
research, including the respect for the human person, maximization of benefits and avoidance of harms to patients,
just distribution of benefits, meaningful informed consent and protection of patient confidential information.

The emergence of artificial intelligence is reminiscent of the great Gold Rush, a frenzied time bursting with unlimited
potential yet filled with uncertainty, speculation and unforeseen consequences. The advancement of AI brings
medicine to the precipice of truly transformational change that can help reduce existing burdens and inefficiencies
while at the same time improve patient care and experience. Examples range from ambient voice transcription tools
that enable doctors or nurses to spend more time with their patients to diagnostic devices that detect diabetic
retinopathy or colon polyps, with the list growing daily. Its applications are nearly limitless; a new revolution has
arrived.

This technology has galvanized the field of health care, but its broad implementation is a road yet to be traveled. It
remains to be seen how medical professionals and patients will interact with and utilize artificial intelligence.
Unfortunately, the potential for harm has already been demonstrated with examples of substantial algorithmic bias
and the use of AI to deny patient care authorizations. Experts use the term human-in-the-loop (HITL) to describe
requisite human involvement within the system of automated processes. However, this is inadequate as we must
not merely be one dimension of the progressive machine learning system, but atop the hierarchy. The last line
bears repeating: Humans must remain atop the hierarchy. We need to control AI, not the other way around.

The complexity of artificial intelligence will require significant bandwidth to properly oversee its application and erect
sensible guardrails that enable innovation and at the same protect patients and other key stakeholders. The size

                                                                                                            Page 2 of 2
            Opinion: Artificial intelligence will radically improve health care, but only if managed carefully

and scope of this undertaking far exceeds what can be accomplished by the federal government alone. Unlike the
top-down approaches pursued in other parts of the world, we must utilize public-private partnerships to develop
these guidelines and guardrails and validate that what is produced is trustworthy and of value. This can be
achieved, in part, by creating independent assurance laboratories that evaluate AI models and their applications
using commonly accepted principles. We need more than one hen guarding the chicken house.

Avoiding similar missteps that hindered the integration of now mature technologies, such as Electronic Health
Records, is paramount. National standards are critical to establish health AI best practices for the use of emerging
innovations, and adoption of these benchmarks should be as close to the end beneficiaries as possible. Federal
authority has an important role to play here, that of a convener and enabler of creation of these standards.
However, their implementation should be deferred as much as possible to the local governance at the health
system level with federal authorities intervening only when necessary. Progress will not be free, but we must learn
from past mistakes.

In our pursuit of bringing artificial intelligence into mainstream medicine, ethical considerations must maintain
supremacy. Patients in rural or low-income communities must have access to the benefits of this technology.
Further, it is imperative AI used on or by these communities is as trustworthy as those used by premier health
systems. Just as access to health care is not a guarantee of quality, access to artificial intelligence systems will not
certify the capacity or reliability of what is available.

Reducing clinician burden, improving patient health and experience, and introducing new, life-saving technologies
to the burgeoning world of health care is an exciting endeavor. Traversing these unknowns in a way that
circumvents avoidable hazards will allow human intelligence to harness the power of unlimited computations to
create better and more affordable care. Practitioners and patients alike eagerly anticipate the powerful capabilities
and practical benefits of artificial intelligence in the delivery of health care. It is essential to ensure that its imminent
and explosive entrance into care settings is executed judiciously and strategically to maximize its positive impact for
all.

Greg Murphy, MD, a practicing urologist, represents North Carolina’s 3rd District. Michael Pencina, PhD, serves as
chief data scientist in Duke Health and professor of biostatistics and bioinformatics in the Duke University School of
Medicine.

For the latest news, weather, sports, and streaming video, head to The Hill.


Load-Date: March 19, 2024


  End of Document

                                                                                                         Page 1 of 3
    The computer will see you now: Artificial intelligence usage grows at Central Florida hospitals A lot of people
                               are alarmed by the prospect of AI being used in ....




The computer will see you now: Artificial intelligence usage grows at Central
  Florida hospitals; A lot of people are alarmed by the prospect of AI being
   used in their health care, according to a 2023 Pew Research poll, which
             found 60% of Americans are uncomfortable with it.
                                                        Tampa Bay Times
                                                      March 1, 2024 Friday



Copyright 2024 Times Publishing Company All Rights Reserved

Section: NEWS; Health
Length: 1206 words
Byline: Caroline Catherman|Orlando Sentinel (TNS)

Body


Central Florida's two major health systems, Orlando Health and AdventHealth Central Florida, are widely using
artificial intelligence for administrative work and, increasingly, to sound early alarms about potential illnesses,
including deadly pancreatic cancer and sepsis.

Eventually, some experts think AI could even be used to diagnose patients and make treatment decisions.

On one hand, a growing body of research suggests this could make patients safer because the computer software
that generates AI doesn't get tired or make mistakes like overworked medical staff.

But a lot of people are alarmed by the prospect. A 2023 Pew Research poll found 60% of Americans are
uncomfortable with AI being used in their health care. The U.S. Department of Health and Human Services has
warned AI can still be prone to human bias.

For those concerned, health-care leaders emphasize that doctors are still making care decisions, every step of the
way.

"We are not trying to replace people's thinking. We're just trying to enhance it," said Dr. Victor Herrera, who in
September was appointed the chief clinical officer for AdventHealth's Central Florida Division - South Region.
"There is always a physician, a nurse, a licensed professional that is qualified ultimately making the decision."

Nearly 700 applications so far

The U.S. Food and Drug Administration has approved 692 artificial intelligence and machine-learning enabled
medical devices as of December.

                                                                                                        Page 2 of 3
   The computer will see you now: Artificial intelligence usage grows at Central Florida hospitals A lot of people
                              are alarmed by the prospect of AI being used in ....

AdventHealth Central Florida uses AI in more than 40 ways. An AI Advisory Board meets monthly to vet potential
new technology.

Most AI-assisted tasks involve administrative work, like recording and transcribing appointments, then generating
clinical notes and summaries. This saves much-needed time for providers amid Florida's chronic staffing shortage.

It's also used in limited scope to solve specific problems and provide a safety net. For instance, AdventHealth
integrated AI into its imaging department in 2020 to flag early signs of potential strokes. The system has X-rays with
AI that screen for osteoporosis.

AI also monitors patient vitals and alerts providers for signs of sepsis, a potentially deadly immune response and a
leading cause of U.S. hospital deaths.

"Most of the things that we have incorporated here at AdventHealth are on the early recognition side of things, not
yet [treatment or diagnosis], but I think that's the future," Herrera said.

At Orlando Health, AI helps identify candidates for its hospital-at-home program. It's for people who need hospital-
level care but are independent and stable enough to live at home with daily visits and remote monitoring.

AI also helps remotely monitor these patients' vitals and alerts nurses - who watch these patients 24/7 at a patient
care hub - when a patient may be in trouble.

"Could you do [hospital at home] without AI? Probably could, but I think you might not quite get the same scope and
traction," said Dr. Siddharaj Shah, senior medical director for Orlando Health's hospital care at home program.

At both AdventHealth and Orlando Health, alerts are ultimately reviewed by medical professionals who can choose
to agree or disagree with the AI's conclusion.

"I think [replacement of human decision makers] is probably well in the future, if ever," Shah said.

Safeguards are needed

Mary Mayhew, president and CEO of the Florida Hospital Association, said AI is reducing burnout by shrinking
administrative busy work. She hopes for a future where AI can do even more. But, she added, appropriate
safeguards need to remain in place.

"AI is only as good as the information and data it has," Mayhew said. "We have to be aware of potential bias in how
that data is being developed and analyzed through AI. That's where human beings and judgment and critical
decision making has to remain at the forefront."

These AI technologies still make mistakes. A 2023 study of more than 11,000 patients found that AI sepsis
technology was associated with a 44% reduction in sepsis deaths. But a February study from the University of
Michigan analyzed the same AI sepsis technology used on more than 77,000 patients and found it only predicted
sepsis in half the patients who eventually contracted it and couldn't be reliably counted on to diagnose sepsis faster
than medical professionals.

A 2023 study by Stanford researchers tested whether doctors could rely on plugging in patient clinical scenarios to
Chat GPT-4 and asking the technology to give advice. The researchers found that the software answered correctly
only 41% of the time. About 6% of the time, the answer included a fake citation, a phenomenon dubbed
"hallucinating" that creators haven't yet been able to fix.

Orlando connections

AI is not only being used in Central Florida, it's being invented here.

                                                                                                         Page 3 of 3
    The computer will see you now: Artificial intelligence usage grows at Central Florida hospitals A lot of people
                               are alarmed by the prospect of AI being used in ....

Dr. Shyam Varadarajulu, Orlando Health's Digestive Health Institute president, is working on a prototype of AI tech
to help doctors diagnosis pancreatic cancer. It is projected to kill more than 50,000 Americans this year and is set to
become America's second-deadliest by 2030, according to the American Cancer Society.

The biggest issue is timely diagnosis: Only about 20% of people are diagnosed when the cancer is still operable.
Most people don't have symptoms and don't get tested until it's too late. For those who are lucky enough to receive
early testing, pancreatic tumors are tiny and easy to miss in their early stages, particularly for less experienced
doctors.

Varadarajulu, in collaboration with experts from across the globe, has built AI-guided endoscopic ultrasound
technology. It's a computer program that will analyze images from endoscopic ultrasounds and highlight potentially
abnormal areas of the pancreas for doctors to look closely at.

His technology is still in its early stages and will need to be trained on millions of images, but eventually,
Varadarajulu hopes to test it in a clinical trial and submit it for FDA approval.

"Our job is to pioneer artificial intelligence so that the person doing this procedure in any part of the United States
will have an outcome comparable to us," he said.

For patients scared off by the prospect of AI, Varadarajulu also has reassurances.

"The AI component does not control anything during the procedure, nothing," he said. "All the technology will do,
eventually, is to point out certain areas that can be missed by a less experienced endoscopist."

Even more ambitious efforts are taking place at the University of Central Florida.

Roger Azevedo, a professor in the School of Modeling Simulation and Training at UCF with a Ph.D. in educational
psychology, is working to create a human digital twin - a digital replica of a person - that potentially could be used in
patient care or clinician training.

UCF has received millions of dollars in federal funding for this effort.

He's also collaborating with other researchers to use AI to monitor and improve clinician performance using eye-
tracking and other sensors. He sees a future where such technology is employed to monitor team dynamics in an
operating room.

"AI ...could indicate 'Hey, you're not looking at the right anatomical region, or you're not looking at the right team
member who can actually support you, given what you're doing right now,'" Azevedo said.



Graphic


See image link

Dr. Shyam Varadarajulu, president of Orlando Health Digestive Health Institute, demonstrates endoscopic
ultrasound technology, on Wednesday.


Load-Date: March 3, 2024


  End of Document

                                                                                                           Page 1 of 3
                     Opinion: ASU should not be the testing ground for teaching counselors with AI




Opinion: ASU should not be the testing ground for teaching counselors with
                                    AI
                                          The State Press: Arizona State University
                                                  March 27, 2024 Wednesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: SCIENCE-AND-TECH; Pg. 1
Length: 892 words
Byline: Dimitra Manatou

Body


Opinion, Business & Tech

Opinion: ASU should not be the testing ground for teaching counselors with AI

One of a few projects featured during the OpenAI Innovation Challenge was BehavioralSim, an AI bot intended to
help teach counselors in the College of Health Solutions

"If it doesn't solve the problem better, enhance the outcome better, help the student better, we're not going to do it."

Lavanya Paliwal

By Dimitra Manatou

|

March 26, 2024 | 8:18pm MST

As artificial intelligence spreads to new fields, not all of them are quite ready to embrace it. They need more time for
security measures to be implemented, comprehensive ethical guidelines to be developed and regulatory
frameworks to be put in place.

On Feb. 1, following their partnership with OpenAI, ASU began accepting proposals for potential applications of the
program. One such proposal showcased in their Innovation Challenge update is intended for the College of Health
Solutions, called BehavioralSim.

The initiative's goal with AI is to simulate counseling scenarios for students to practice their skills on, including
person-centered techniques and practical skills. This raises serious questions about replacing human teachers and
their professional experience with AI.

While utilizing this tool or similar AI bots, it's important to acknowledge the inherent limitations of such technology.

                                                                                                           Page 2 of 3
                   Opinion: ASU should not be the testing ground for teaching counselors with AI

"They have a lot of flaws," ASU President Michael Crow said in a meeting with The State Press. "I've asked them
really complicated social questions or cultural questions that I had one of them lying to me, you know, along the
way."

Despite its ability to offer guidance and information, an AI bot cannot fully replace the expertise and nuanced
understanding provided by human counselors. In times of heightened stress or when faced with psychologically
intense questions, the efficacy of AI may be questionable.

Andy Woochan Kwon is a Licensed Associate Counselor and graduate of the Masters of Counseling program at
ASU.

"A lot of your prognosis and counseling as a patient is dependent on the relationship that you formed with your
therapist," Kwon said. "I believe the research shows us about (25)% of that prognosis can be attributed to the
relationship that you have with the therapist."

The complexities of human emotions and experiences often require the empathetic support and personalized
approach that only a trained counselor can offer. Furthermore, the dynamic nature of counseling necessitates the
ability to adapt and respond in real time, a capability that may be lacking in AI-driven interactions.

"AI is a great tool, but it's not yet a replacement for how complex humans can be," Kwon said.

Additionally, it's essential to recognize that AI, like humans, possesses biases and limitations.

These biases may inadvertently influence the responses provided by AI bots, potentially impacting the quality and
accuracy of the information offered. In situations requiring sensitivity and nuanced understanding, the reliance
solely on AI may fall short of meeting the diverse needs of individuals seeking mental health guidance.

Until the risk of bias and false information is proven to be minimally impactful and mechanisms are in place to verify
the diagnoses that AI replicates, it should not utilized in the mental health field.

Protecting patient privacy and ensuring data security are critical considerations in the integration of AI into
counseling. However, an ethical dilemma arises when attempting to utilize patient data to enhance AI models
without compromising confidentiality.

"The ethical code about confidentiality is there to ensure that clients feel safe in the therapy setting," Kwon said.

Currently, ASU's proposal guidelines state that ChatGPT Enterprise, the AI engine behind these projects, is not
approved for FERPA-protected or other sensitive data.

This creates a paradox, where in order to improve itself, the BehavioralSim must access data it is currently not
secure enough for. Crow was asked in a meeting with The State Press about how the success of OpenAI
partnership programs, such as BehavioralSim, will be evaluated.

"If it doesn't solve the problem better, enhance the outcome better, help the student better, we're not going to do it,"
Crow said in the meeting. "So if it doesn't have the ability to be of any value at all, then it's not going to be doing
so."

While this approach might be suitable for other fields, the consequences of mishandling mental health are too
serious to risk. Is the mental health of students worth being an experiment for AI?

Navigating the complex terrain between data-driven insights and high ethical standards is essential for fostering
trust and confidence in the use of AI technology in mental health and beyond. AI has not proven that it can hold up
to the standards that are required for mental healthcare, and so it should be prohibited until it is improved.

Edited by River Graziano, Alysa Horton and Grace Copperthite.

Reach the columnist at dmanatou@asu.edu

                                                                                                    Page 3 of 3
                    Opinion: ASU should not be the testing ground for teaching counselors with AI

Editor's note: The opinions presented in this column are the author's and do not imply any endorsement from The
State Press or its editors.

Want to join the conversation? Send an email to editor.statepress@gmail.com Keep letters under 500 words, and
include your university affiliation. Anonymity will not be granted.

Like The State Press on Facebook and follow @statepress on X.


Load-Date: March 27, 2024


  End of Document

                                                                                                        Page 1 of 2
                                        Is AI Ready to Replace Human Policy Advisers?




                          Is AI Ready to Replace Human Policy Advisers?
                                                  Government TechNology
                                                     April 5, 2024 Friday



Copyright 2024 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 468 words
Byline: Paul W. Taylor, Government Technology

Body


Apr. 5—Listen to this episode on the player below or subscribe for free on YouTube or the podcast app of your
choice — Apple Podcasts, Spotify, Audacy and Audible.

Government Technology Data Reporter Nikki Davidson tasked Google's AI tool Gemini (formerly Bard) to explore
AI's perspective on government technology use. Davidson's innovative approach involved treating AI as a
collaborative partner to generate insights on AI's potential applications in government. Despite Gemini's occasional
inaccuracies and deviations from instructions, Davidson's project yielded diverse and unexpected use cases across
different areas, such as mental health, opioid use and climate change.

Gemini's recommendations extended to climate challenges and infrastructure needs, reflecting a surprisingly deep
understanding of regional concerns. Gemini itself suggested it would be five to 10 years before AI is fully integrated
in government operations, emphasizing that it is inevitable for government.

Believing turnabout is fair play, Davidson asked Gemini for feedback on her work. It gave the article a strong
numerical grade on a scale of 1 to 10 but did have suggestions on how to make it better. Human reviewers,
including Benjamin Palacio, a senior IT analyst with Placer County, Calif., highlighted both the promise and
challenges of AI applications, particularly in sensitive areas like mental health support. Davidson views AI as a
valuable tool but underscores the necessity of human oversight and awareness of its limitations.

SHOW NOTES

Takeaways:

* AI can be used as a tool to explore the best uses of technology in government.

* Surprising use cases of AI in government include mental health and opioid abuse awareness.

* Ethical concerns arise when AI suggests analyzing sensitive data like social media and medical records.

* Human intervention is necessary to ensure the accuracy of AI.

                                                                                               Page 2 of 2
                                 Is AI Ready to Replace Human Policy Advisers?

Chapters:

00:00 Introduction: AI as a Policy Advisor

01:14 Exploring the 50-State Experiment

05:52 The Limitations and Tendencies of AI Tools

08:18 Addressing Societal Issues with AI

10:40 AI Solutions for Infrastructure and Climate Challenges

12:31. Realistic Timelines for AI Implementation

14:26. The Challenges of Working with AI

16:23. Human Reviewers' Perspectives

17:00 Conclusion and Future Possibilities

Related Links to items referenced in the episode:

* How Does AI Predict Governments Will Use AI? It Depends Where You Live

* Center for Public Sector AI, a division of e.Republic, the parent company of Government Technology and
Governing.

Our editors used ChatGPT 4.0 to summarize the episode in bullet form to help create the show notes. The main
image for this story was created using DALL-E 3.

___ (c)2024 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: April 6, 2024


  End of Document

                                                                                                        Page 1 of 2
                                    What should we fear with AI in medicine? Commentary




                               What should we fear with AI in medicine?
                                            Commentary
                                                          The Morning Call
                                                      May 30, 2024 Thursday
                                                            FIRST Edition



Copyright 2024 Capital Gazette Communications, Inc. All Rights Reserved

Section: MAIN; A; Pg. 8
Length: 903 words
Byline: Sheldon H. Jacobson and Dr. Janet A. Jokela Chicago Tribune
Highlight: A family physician in Hermitage, Mercer County, uses artificial intelligence to produce a summary of a
patient visit. Maddie McGarvey/The New York Times

Body


Will the threats associated with artificial intelligence be as bad as some fear? Or will AI be relatively benign? Could
the answer be somewhere in between?

Perspectives on AI abound. Whether it be in medicine, security or education, new applications in search of an AI
advantage continue to grow. This has prompted calls for well-intentioned restraint and regulation or, at the very
least, slower growth and proliferation.

To alleviate some of that fear, we should consider one area in which AI is proving to offer significant benefits and
potential: medicine and the delivery of health care. A recent article in Medscape Medical News highlights studies
that give AI the advantage in delivering more precise and reliable medical care. Eric Topol, founder and director of
the Scripps Research Translational Institute, has argued that the future of medicine lies with AI, with benefits such
as a reduction in medical errors and delivery of more robust diagnoses and treatment plans.

Some will argue that AI has no feelings and therefore cannot replace functions that demand human interactions,
empathy and sensitivity. While it is true that AI has no feelings or ethics, AI medical systems do not need to feel;
their patients do. And what patients want and certainly need from their physicians is their time and their attention,
which demands patience, something that AI systems have in abundance. Indeed, patience may be construed by
some as a surrogate for human empathy and sensitivity, while impatience may be interpreted as the antithesis of
such human characteristics.

As corporations buy medical practices, ultimately influencing the practice of medicine and the delivery of health
care services, physicians and health care providers are pushed to squeeze more health care dollars into tighter
time windows. This provides an opening for more misdiagnosis and poor health care delivery.

AI medical systems can process information infinitely more quickly than any human clinician. AI medical systems
also have access to and can digest many times more medical data and knowledge than human physicians and

                                                                                                          Page 2 of 2
                               What should we fear with AI in medicine? Commentary

clinical providers. This means that an AI medical system may spot an unusual condition that could expedite a
diagnosis, identify an appropriate treatment plan and save lives - all at a lower cost. They may even identify a novel
condition by exhaustively eliminating the possibility of all possible known diseases, effectively creating new
knowledge by a process of elimination.

Yet AI medical systems have their limitations and risks.

The plethora of data being used to train AI medical systems has come from physicians and human-centric health
care delivery. If such sources of data are overwhelmed by AI-generated data, at some point, AI medical systems
will be primarily relying upon data generated from AI medical care. Will this compromise the quality of care that AI
medical systems deliver?

Then there is the fundamental understanding of how AI medical systems work. Much of the output is observational
based on complex statistical associations. Few, if any, medical personnel understand such models, how these
models use data and how their outputs are obtained. Of course, much of clinical medicine is evidence-based, which
in turn is based on clinical trials or extended observational experience. When viewed in this context, AI medical
systems are taking a similar approach, with the time window to glean insights infinitesimally compressed.

Then there are the issues of data bias and privacy.

Medical data is inherently biased since it comes from a biased world. To cleanse such data would change the data,
with unexpected consequences that may bias AI medical systems in unexpected ways. It may even compromise
the efficacy of such systems. In the short term, if data bias issues are to be addressed, they should be managed at
the back end, much like how human systems manage them today. The long-term objective is more complex, to
have the AI systems themselves prune such biases in, shall we say, an unbiased manner.

The other issue of concern is data privacy, which appears overstated and often amplified, stoking fear. Privacy
safeguards should always be considered, yet there are no foolproof ways to guarantee complete and total privacy.
Many people inadvertently sacrifice personal privacy for personal convenience often unthinkingly.

People often confuse personal privacy with personal control of their data. Yet permitting our personal data to be
accessed with our blessing, such as we do when using social media, does not keep us any safer than if our data is
accessed unknowingly by others.

AI medical systems need anonymized data as inputs. Protecting the integrity of the anonymization process is what
we can reasonably expect.

Anything that cannot be easily understood may elicit fear. AI certainly qualifies. In a world filled with uncertainty and
risk, AI systems of all kinds offer tremendous benefits. Yet the uncertainty and risk that surround us will not
miraculously go away with AI. There are no free lunches in this regard. Prudence and caution are reasonable.
Efforts to stop or even slow AI advances are what we should really fear.

Sheldon H. Jacobson is a professor of computer science at the University of Illinois at Urbana-Champaign. Dr.
Janet A. Jokela is the senior associate dean of engagement for the Carle Illinois College of Medicine at the
University of Illinois at Urbana-Champaign.


Load-Date: May 30, 2024


  End of Document

                                                                                                           Page 1 of 2
                  USA doctor addresses students at University of Science and Technology , Meghalaya




   USA doctor addresses students at University of Science and Technology,
                                Meghalaya
                                                              The Sentinel
                                                      August 22, 2024 Thursday



Copyright 2024 Omega Printers & Publishers Pvt Ltd, distributed by Contify.com All Rights Reserved




Length: 337 words
Byline: Sentinel Digital Desk

Body


Guwahati : The Associate Director of Medical Education, USA, Dr. Vijay K Mittal, has delivered an insightful talk on
"Simulation for Health Care Workers including AI" at a workshop organized by IQAC, USTM at the NKC Auditorium
of the University on Wednesday.

The session began with a warm welcome by Pro Vice Chancellor of USTM , Dr. Sarbeswar Sahariah, in the
presence of Advisor USTM, Dr. R.K. Sharma, and Pro Vice Chancellor USTM, Dr. B.K. Das, among others.

Speaking on the occasion, Dr. Sarbeswar Sahariah said that the introduction of simulation is a great achievement in
medical science. "A simulation-trained medical professional is very important nowadays. Diagnosis is the most
difficult part of medical science, after which appropriate treatment can follow. AI will play a very important role in the
coming days in diagnosing patients," he added.

Addressing the students, Associate Director of Medical Education, USA, Dr. Vijay K. Mittal, said that simulation is a
technique, not a technology, to replace or amplify real experiences with guided experiences that evoke or replicate
substantial aspects of the real world in a fully interactive manner. In the non-medical community, simulation training
is well established in the military, aviation, nuclear power, NASA, gaming industry, etc.

According to him, healthcare simulations can be said to have four main purposes: education, assessment,
research, and health system integration in facilitating patient safety. "Simulation technology can be used to improve
individual and team performance through interdisciplinary team training. For medical students, simulation makes a
paradigm shift in teaching. It is largely used for educational purposes across medical knowledge, patient care,
psychomotor tasks, critical thinking, and decision-making.

The workshop ended with an enthusiastic interactive session between the resource person and the students, and
the workshop was attended by over 250 students from USTM, along with staff from PIMC USTM, stated a press
release.

                                                                                                  Page 2 of 2
              USA doctor addresses students at University of Science and Technology , Meghalaya


Load-Date: August 22, 2024


  End of Document

                                                                                               Page 1 of 2
         CHI Saint Joseph Health named among Nation's 15 Top Health Systems by Fortune and PINC AI™




  CHI Saint Joseph Health named among Nation's 15 Top Health Systems by
                           Fortune and PINC AI™
                                                 The Sentinel Echo, London, Ky.
                                                   January 23, 2024 Tuesday



Copyright 2024 The Sentinel Echo (London, Ky.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 521 words
Byline: Janie Slaven, The Sentinel Echo, London, Ky.

Body


Jan. 23—LONDON — CHI Saint Joseph Health has been recognized as one of the nation's 15 Top Health
Systems according to an independent quality analysis based on a scorecard provided by PINC AI, the technology
and services brand of Premier, Inc. (NASDAQ: PINC), and reported by Fortune. By category, the Lexington-based
system is recognized in the top five medium-sized health systems in the nation; due to a tie, there are six systems
in this category.

To create the list, PINC AI conducted an objective, quantitative analysis of publicly available data to identify the top
health systems in the U.S. The primary purpose of the PINC AI 15 Top Health Systems study is to inspire hospital
and health system leaders to pursue higher performance and deliver added value to their patients and
communities. The quantitative study is based on a balanced scorecard which consists of a variety of measurements
distributed across four pillars: clinical, financial, operational and patient experience.

"This recognition among the nation's 15 Top Health Systems, and among the six best medium-sized systems in the
country, is a testament to our unwavering commitment to excellence in providing health care services," said
Anthony Houston, Ed.D., FACHE, market president, CHI Saint Joseph Health. "This honor is a reflection of the
dedication to excellence and humankindness of our exceptional caregivers across Kentucky. Each and every day,
they are fulfilling our mission, living our values and achieving excellence. We are honored to be recognized as one
of the top six medium-sized health systems in the country as part of the nation's PINC AI 15 Top Health Systems."

15 Top Health Systems program performance

This year, based on comparisons between the study winners and a peer group of similar health systems, the
analysis found that the winners of the 15 Top Health Systems program delivered better outcomes while operating
more efficiently and at a lower cost. Compared to non-winning health systems, this year's winners had:

—21 percent fewer deaths.

—5 percent fewer patients with complications.

                                                                                              Page 2 of 2
        CHI Saint Joseph Health named among Nation's 15 Top Health Systems by Fortune and PINC AI™

—21 percent fewer health care-associated infections (HAIs).

—0.5-day shorter average length of stay.

Better reported patient experience scores, with a top-box Hospital Consumer Assessment of Healthcare Providers
and Systems (HCAHPS) score of 74 percent versus 69.6 percent for non-winning hospitals.

"Health system leaders are continuously focused on quality, excellence and patient-centered care," said Leigh
Anderson, Premier's chief operating officer and the leader of PINC AI. "A selection as one of the 15 Top Health
Systems is a great honor and demonstrates the importance of health system leadership and proven strategies for
improvement. As one of the 15 Top Health Systems, CHI Saint Joseph Health has achieved high-quality health
care and the implementation of key strategies that have directly led to significantly improved patient outcomes, with
fewer readmissions and complications."

___ (c)2024 The Sentinel Echo (London, Ky.) Visit The Sentinel Echo (London, Ky.) at www.sentinel-echo.com
Distributed by Tribune Content Agency, LLC.


Load-Date: January 25, 2024


  End of Document

                                                                                                        Page 1 of 2
      Report: Area lacks skilled workers, training St. Louis area companies need skilled workers. But they don't
                                            spend on training, report says.




  Report: Area lacks skilled workers, training St. Louis area companies need
        skilled workers. But they don't spend on training, report says.
                                                  St. Louis Post-Dispatch (Missouri)
                                                       August 8, 2024 Thursday
                                                               01 EDITION



Copyright 2024 St. Louis Post-Dispatch, Inc. All Rights Reserved

Section: A; Pg. 6
Length: 707 words
Byline: By Serina DeSalvio St. Louis Post-Dispatch

Body


KIRKWOOD - St. Louis may miss out on the opportunity to spearhead the AI in health care movement as
companies say they struggle to find skilled workers - but don't spend money to provide training to meet their needs.

The disconnect was highlighted in the 16th annual State of St. Louis Workforce Report, released Thursday, that
also heralded the largest workforce - 1,495,200 people - the St. Louis area has ever seen.

"This workforce puts us in the top 10 cities in the nation for growth," said Phyllis Ellison, associate vice chancellor of
St. Louis Community College's Workforce Solutions Group. "It's nice to be in the top 10 for growth, for a change."

Despite having the largest workforce in the region's history to pull from, the 600 companies surveyed for the report
listed several barriers to recruiting new talent.

Top on the list is a shortage of workers with industry-relevant knowledge or skills. Some 74% of surveyed
companies said their applicant pool lacks experience in patient care, followed by shortages in skilled trades (54%)
and manufacturing and maintenance (41%).

The report sheds light on where this problem may come from: 24% of surveyed companies reported spending no
money on employee training in the past year. And 42% spent $500 or less.

"If that 24% and 42% is really representative of our region, I'm concerned," said Ellison.

She said over 60% of workers, nationally, live paycheck to paycheck; 30% of workers have less than $1,000 in
savings.

"They can't afford to step away from their jobs, get more training, then find their next job," Ellison said. "It's a
disconnect that needs to be addressed."

                                                                                                       Page 2 of 2
     Report: Area lacks skilled workers, training St. Louis area companies need skilled workers. But they don't
                                           spend on training, report says.

The training in question isn't a four-year college degree. Report results indicate that across sectors, "middle-skill"
workers are the most desired group, with 53% of firms seeking employees with more than a high school diploma but
less than a four-year degree.

In 2023, the number of employers with middle-skill positions available was 40%. This year, it was 49%.

St. Louis Community College is working to address these needs, in part with six new buildings being constructed
across STLCC campuses, said Jeff Pittman, the college system's chancellor.

"All of these buildings are related to workforce sectors," he said. Three will be dedicated to addressing needs of
health care employers, the highest employer category in the St. Louis area.

Currently, working in health care is a challenge, and it has been since the start of the pandemic. AI could help,
experts said.

"Doctors are just not okay," said Dr. Danish Nagda, founder of Rezilient Health, in a panel discussion Thursday for
the report release. Between a high volume of patients and short turn-around times between patients, many doctors
and nurses across the country are experiencing burnout, he said.

Artificial intelligence may help alleviate challenges associated with complex, multi-variable tasks in health care - the
ones that most often start to slip when providers experience burnout, said Dr. Philip R. O. Payne, associate dean
for health information and data science at Washington University.

Examples include predicting patient outcomes for highly complex diseases, or double-checking that patients'
prescription medications won't react with one another.

St. Louis has several large hospital systems, and a business environment that fosters startup development. It's
home to 5,653 new startups this year alone.

Payne said St. Louis is "the ideal testbed for the AI revolution," as the region has university researchers and
entrepreneurs to develop AI tools, large patient datasets to train and test them on, and the workforce to deploy
them once they are ready for use.

Payne added, however, that AI is only as good as the way its trained, and the people that use it. It is not about
replacing people.

"It's about enhancing what people can do," he said.

Some hospitals in the region are already taking advantage of AI to avoid nurse and doctor burnout, said Jill
Williams, vice president of workforce development at the Missouri Hospital Association.

"We want to try to bring back the joy of working at bedsides, and take away the administrative burden, and I think
we can do that with AI," she said.

Serina DeSalvio - 314-340-8091sdesalvio@post-dispatch.com


Load-Date: August 8, 2024


  End of Document

                                                                                                        Page 1 of 7
                                                     Dr. AI will see you now




                                               Dr. AI will see you now
                                                        The Deseret News
                                                    May 8, 2024 Wednesday



Copyright 2024 The Deseret News Publishing Co. All Rights Reserved

Length: 4143 words
Byline: Lois M. Collins

Body


Eliza Anderson, Deseret News 1

Dr. AI is setting up practice in a medical setting near you. And experts say your health care is likely to improve in
multiple ways with that new attention to detail. But in some areas, you might want to steer clear.

Artificial intelligence is quickly becoming a staple in growing segments of health care, but it's not ready in others.
Still, experts say you need not worry that you'll lose the personal touch if you've been getting that from a medical
provider: Humans are as important as ever in the practice of medicine. You might even find care providers have
more time to address your needs.

The National Institutes of Health notes artificial intelligence tools are driving widespread change across medical
disciplines including research, diagnosis and treatment. Concurrent advancements in computing power and the
proliferation of massive, health-related data sets are setting the stage for new approaches in the research field as
scientists increasingly employ AI software and its powerful information processing capabilities to advance their work
at an increasingly rapid pace.

"I am excited about the technology," said attorney Daniel J. Gilman, senior scholar at the International Center for
Law and Economics, a nonpartisan, nonprofit research center based in Portland, Oregon. "I think we've seen that
as long as it is introduced and used in a careful and responsible fashion, AI seems to have tremendous promise."

From experiment to problem solver

Dr. Yves Lussier is both physician and engineer - and an unabashed AI enthusiast. At the University of Utah School
of Medicine, he's department chair of biomedical informatics - the founding department of that field in the U.S. and
maybe the world, dating from the late 1950s, he said.

Lussier traces the roots of AI to the 1940s, when neural networks were developed to "reason with uncertainty."
Later, AI advanced to reason with certainty. The pace of each AI breakthrough has been faster than the one before.
By the mid-1970s, software from Stanford could reason with both certainty and uncertainty - "expert systems," he
said. Since, Depp learning (15 years ago) and "transformers" (seven years ago) have led to the emerging
conversational AIs called "generative AI," such as ChatGPT.

                                                                                                           Page 2 of 7
                                                Dr. AI will see you now

AI types abound. Most people don't realize the voice recognition that's an open sesame to your bank account is AI.
What Lussier calls the "game changer" came seven years ago with generative AI, which can be prompted to create
texts, images, videos and other data. You can push a transcript into a generative AI and retrieve plainspoken words
or technical terms depending on your audience.

The biggest impact, perhaps, is helping solve problems that have been largely intractable.

Dr. Nathan Blue is an obstetrician and assistant professor at the University of Utah School of Medicine's
Department of Obstetrics and Gynecology. Blue has been involved with research efforts for over a decade, working
to develop new clinical diagnostic strategies that can identify early signs of pregnancy complications that arise from
deficiencies in placental material.

Those deficiencies, Blue said, can lead to fetal growth restrictions, complications involving bleeding, preeclampsia
and stillbirths. The traditional research strategies to quantify risk associated with placental deficiencies have a lot of
pitfalls, he said, and can be crude and inflexible.

New research techniques that incorporate AI systems are showing promise for overcoming some of the
inefficiencies of previous strategies and could lead to new clinical practices that will, Blue said, lower stress for
expectant mothers, help reduce uncertainty about medical intervention decisions and lead to better use of
resources.

"In the last couple of years, we've started working with the bioinformatics and genomics group here at the U.," Blue
said. "These senior thought leaders and investigators have helped us leverage more computationally advanced
approaches, including artificial intelligence, to better quantify risk."

Part of the research work includes applying AI tools to large data troves, including anonymized genomic profiles of
more than 10,000 obstetrics patients, and zeroing in on diagnostic markers that may become part of new clinical
applications to help more accurately predict future at-risk pregnancies.

"On the research and investigation side, what is really exciting about what the AI-based tools and approach can
offer is, until now, we've been trying different versions of the same thing," Blue said. "Using pretty old-fashioned
tools to find factors, but really we're mucking about in the same sandbox, so to speak.

"What I'm super excited about in the AI-based strategy is it's helping us bypass a lot of the pitfalls to analysis but
boosting how we conceptualize how we use information. In that sense, the progress is really accelerating risk for
pregnancy work and the application and accuracy of those tools is better than what we were getting before."

Professor Xiaondong Ma from the University of Utah School of Medicine's Department of Radiology and Imaging
Sciences is a member of the Medical Imaging and Computational Analysis Lab, a research team working to develop
advanced techniques, including AI in image acquisition, analysis and quantification for clinical and research
applications.

Among other projects, he and his team are investigating vascular issues - particularly how abnormalities in the
carotid artery could serve as indicators of more serious vascular pathologies.

Ma said analyzing images captured by MRI and/or CT scans has traditionally been a manual, time-consuming
process. Thanks to an AI-powered, semiautomatic image analysis technique being developed by the MICA lab, the
work to develop new diagnostic strategies has accelerated.

Another MICA project that's leveraging AI-based image analysis tools is looking at the connection between
calcification that occurs in the brain and its relationship to the ravages of aging, he said.

"We have the potential to predict vascular disease and diseases associated with aging, like Alzheimer's," Ma said.
"Our hope is that AI can help us screen these images and define which patients may be of high risk."

Workload triage

                                                                                                            Page 3 of 7
                                                 Dr. AI will see you now

Women who've had a pap smear are already part of AI's story in medicine. AI has been used for 30 years to sort
through millions of exams annually to determine which need special attention, proving its worth as triage there and
in radiology, among others. AI may spot the earliest signs of unhealthy tissue change that the naked eye could
miss, saving time, money and suffering.

The AI is designed to have many false positives and no false negatives. "It doesn't make an error of forgetting a
cancer. But it claims 10 times more often that there's cancer when there is none," which a pathology expert sorts
out, Lussier said. But how fast AI runs through images makes cervical cancer screening manageable and
affordable.

Lussier said it took a decade or more to design that kind of artificial intelligence long years ago. Now, given the
pace of advances, such a program could probably be created in weeks or months.

Would a redesign improve results? "No, it's highly accurate. But it would cost a lot less now because it would take
less time and be done with better tools. That's the game changer," said Lussier. Faster design using fewer
resources means lower costs, accessible for more users within industries like health care, providing greater benefit
for consumers.

AI takes a star turn

AI shines especially bright finding abnormalities in radiology images.

Gilman said AI imaging refinements now do a more sophisticated job than human eyes alone to discern noise in an
image without introducing artifacts or losing information. Another strength is "signal detection - finding things with
better images that a time-pressed radiologist might miss with a quick scan and the naked eye."

But while AI can call something to an expert's attention, it cannot diagnose. Radiologists check AI results because
they have the experience and knowledge.

It's hard to overestimate the value, though, of AI trained on millions of images to free up the physician's time by
going through the entire image workload to flag those needing attention. And AI can regularly review to see what
might have been missed. "The radiologist, the physician, the oncologist is not eliminated. What's eliminated is a big
pile of time they spend staring at these things. They're still going to stare at images, but they're going to stare at the
ones that really need attention," Gilman said. "A considerable amount of the workload is shifted so the practitioner's
involvement is much more efficient."

Dr. Christoph Wald, an American College of Radiology spokesman, believes AI and radiology are especially
compatible because radiology is digital from image through answer. "We're the first digital specialty that exists."

But perhaps the greatest benefit for patients is making good images with less information, which means lower-dose
radiation or shorter tests without sacrificing quality.

The FDA has approved AI in radiology for triage. What AI can say amounts to, "'I am reasonably certain this case is
positive for the finding that I was trained on,'" said Wald. "It doesn't say the disease is present, but it flags it so the
human expert can make the call."

AI is trained to find a little black line, for instance, not diagnose a broken neck. Other things can create that line,
including "things on the image that aren't real. The radiologist will say, 'I know why you're saying that. But that's not
a break.' It's really important to understand that distinction because AI doesn't try to diagnose."

Quantitative AI is another bit of magic in radiology. On the lung CT of a longtime smoker with emphysema,
quantitative AI measures what portion of the lung is diseased. A human cannot do that. That information helps
decide how intensive therapy should be, said Wald, so AI impacts treatment. Differently trained AIs can quantify fat,
muscle mass, calcium in arteries, even brain thickness for patients with neurodegenerative disease. AI's measuring
capacity keeps growing.

                                                                                                         Page 4 of 7
                                                Dr. AI will see you now

Certain patterns - lots of fat, little muscle, bone calcium that's not dense - could signal a patient at great risk for
metabolic disease, creating opportunistic screening that improves care. It's not feasible to have a human do that,
but when AI can - quickly, at scale - it becomes feasible, said Wald.

AI can also help a radiologist by zipping through the electronic health record to see what's known about the patient,
summarizing large chunks of information to help physicians reach correct conclusions.

Couldn't insurance companies use the same tools to exclude people from coverage? Probably, he said. But they
already analyze data to risk-stratify premiums. "They know a lot of that already. The fact we're using AI inside the
electronic health record does not mean we're revealing more about you to the outer world. It's a processing tool,"
Wald said.

AI gets an enthusiastic high-five from care providers for summarizing the latest from ever-growing knowledge in
medical subspecialties. "We're hopeful with AI it will become easier to discover relevant developments that no
single human can possibly constantly monitor," Wald said.

Radiology AI is narrowly focused, so multiple products may be strung together. His department has AI that looks for
pulmonary embolism and another scanning for preincidental pulmonary embolism. Yet another AI looks for rib
fractures. "That's three AIs we have to license to get a not even comprehensive assessment of a chest CT for a
couple of important findings." Looking for other things requires differently trained AI.

More time for you

Helping care providers manage a time crunch is a major expected AI benefit in health care, experts told Deseret
News. Electronic health records have made it easy to share medical information with other professionals, but
building those records takes a couple of hours a day writing notes, leading to an "epidemic of burnout among
nurses and physicians because it adds too much of a burden on every (patient) visit," said Lussier.

"We're gonna hope (AI) will reduce that."

Fortunately, many of AI's advantages reduce both time drag and administrative costs, "which have become
staggering in health care," per Gilman.

Some AI applications figure out complicated scheduling. Since most imaging providers are overloaded with patients
- Wald's practice has a six-week wait for a non-urgent MRI - AI can help make use of the machine's every moment.
Duration for exams varies: A cardiac MRI could take two hours, a knee MRI 15 minutes. The variety makes it tough
to efficiently slot everyone in. AI is unfazed. "It can put these complex requests in a pattern shown to work well,"
Wald said.

AI could figure out how long operations take and whether some surgeons are faster on average to schedule assets
like operating rooms efficiently. It could reduce time waiting for an appointment as well as waits at the clinic.

Lussier said if AI improves scheduling or otherwise frees up time, it could be used for patient care.

Scott G Winterton, Deseret News A.I. Med_SGW_00300.jpg A.I. Med_SGW_00300.jpg 1

An elusive diagnosis

When a patient has a complaint, the option is some combination of a physical exam, lab work or imaging. AI can
help the doctor figure out what kind of imaging to order. It helps patients, too. "If you were to go to Bing, Copilot or
ChatGPT and say, 'I've had a big headache for four weeks, what's the best test to do?' you'd get a pretty good
answer," said Wald. You could see if your doctor agreed.

"AI is really good at navigating a large body of insight and distilling it down to a reasonable recommendation," he
said.

                                                                                                        Page 5 of 7
                                               Dr. AI will see you now

Lussier tells the story of a mom who took her young son to 17 doctors in three years seeking the cause of his
constant pain. She told Today that each specialist would address symptoms within their own area of expertise, but
no true answer emerged. Frustrated, the mom typed his symptoms and every bit of his MRI notes into ChatGPT,
which suggested tethered cord syndrome, an invisible condition associated with spina bifida. She'd never heard of it
in all those doctor visits, but the AI suggested consulting a neurosurgeon. Her son was finally helped.

But AI doesn't always get it right. Washington State University reported in the journal PLOS ONE recently that in a
study with thousands of simulated cases of patients who had chest pain, ChatGPT's suggestions were inconsistent.
It came up with drastically different heart risk assessment levels when it was given the same patient information. In
a news release, researchers said that's "likely due to the level of randomness built into the current version of the
software, ChatGPT4, which helps it vary its responses to simulate natural language. This same randomness,
however, does not work well for health care uses that require a single, consistent answer," per the lead researcher.

Gentle communicator

Lussier's half joking when he notes that a kind, detailed missive from a physician was likely crafted by AI. There's
truth to it, because AI can be taught to send a detailed and humane message with information and
recommendations that not all physicians have time to craft for every case.

"It generates notes that are, strangely enough, more compassionate to the patient, because physicians and nurses
are under duress and on a very tight schedule," said Lussier.

Those missives give patients basic information, answer common questions about diseases and procedures, and
provide clear instructions. They don't require a separate writing session for each patient, yet don't read like a form
letter. The tone is designed to be warm and reassure patients about whatever medical journey they're on.

Humans vet the letters and brochures. AI just makes it easier. Lussier said that a blinded group of physicians
compared letters made by ChatGPT and those by peers and could not tell the difference, though, exposed to the
letters often enough, they began to spot AI.

AI can generate reports on the same case for two target readers: a technical one for medical staff and another for
the patient, said Wald. AI can easily embed definitions, hyperlinks and other aids.

When it comes to language barriers, Wald said, "Seamless term translation; just absolutely fabulous."

Scott G Winterton, Deseret News A.I. Med_SGW_00184.jpg A.I. Med_SGW_00184.jpg 1

Peering into the future

Among AI's promising areas is disease surveillance: spotting trends in public health. AI's great at mining large
datasets to find patterns, as it did during COVID-19, Lussier said. Researchers used a massive U.K. database to
see if COVID-19 made people with certain cancers more likely to die, finding it severely complicated melanoma, but
not breast cancer.

That's not just for public health, but in ways that could change individual outcomes. Lussier said AI helps untangle
health interplay, like whether using a drug to treat high cholesterol might prevent or delay Alzheimer's or another
drug might increase risk. Findings must be confirmed by clinical studies, but AI can help spot connections that
elude clinicians. Ensuring it's not "purely a spurious association" is vital.

Drug discovery is promising with AI. So is designing tests. AI helped Co-Diagnostics, a Salt Lake-based company
that makes polymerase chain reaction, or PCR, diagnostic tests for conditions ranging from COVID-19 to
tuberculosis, flu, strep and others. PCR makes a high number of copies of specific segments of DNA.

Dwight Egan, CEO, said AI sped and improved the tests' development, proving invaluable in medical tool
innovation, including for making a small testing unit called Co-Dx PCR Pro to enable home or clinical testing. You
add a swabbed sample to a test-specific cartridge in the unit. The results come back in half an hour.

                                                                                                          Page 6 of 7
                                                Dr. AI will see you now

While they're hoping for U.S. regulatory approval this year, the goal is to make the low-cost diagnostic tool available
in countries where diagnoses are challenging, like India and Africa. Fifteen tests have been cleared by India's
government, where getting a speedy result is crucial, because people often travel far to see a clinician but can't wait
long for test results.

"We leverage AI daily in our toolsets," Egan said.

Chris Thurston, Co-Diagnostics' chief technology officer, hopes AI advances to the point one could feed it
geographic prevalence of an illness and patient data like viral load to predict whether someone who tests positive is
likely contagious. Right now, a specialist might say you're positive but don't seem too sick; you're probably not
contagious. "He makes the prediction. But I do see that in the near future the decision will be data driven."

Check the work

Gilman warned it's important to have a system on the back end in health care for "evaluation and scrutiny, to make
sure things are going as they should and that there are ways to intervene if you're getting anomalous results. I don't
think there's anything fundamentally strange about that; you're always balancing," he added, noting that with drug
approval, for instance, there's a terrific amount of testing beforehand, but also ongoing surveillance so problems
can be reported if they arise after a drug is approved.

"You want real and serious checks on the quality of the tools you're using, whether those are medical devices or
drugs or software," said Gilman. "By the same token, you don't want to be so careful you impede patient access to
care. You have to balance being high quality and efficient."

Spurious associations dot AI's journey. Lussier smiles when he tells how good AI was at spotting the difference
between dogs and wolves. It wasn't flawless, but seemed to do pretty well until someone tested whether it was
crying wolf based on background scenery. Turns out "it knew the one in snow was more likely to be a wolf."

AI's not good at explaining its findings and it can be overwhelmed. AI must do things systematically and if there's a
lot to consider - "like how 12 medications and 12 diseases interact with each other, for example - it just stops. It will
find three or four of them. It doesn't have the grit to go through them all," Lussier said. AI thrives on short, simple
commands.

You could ask AI to look at each of the pairs separately, with different prompts for each. That's not very efficient.

Scott G Winterton, Deseret News A.I. Med_SGW_00081.jpg A.I. Med_SGW_00081.jpg 1

AI 'hallucinations'

Ma and Blue both note that their respective research work relies on a hybrid approach that pairs high-powered AI
tools with the expertise of scientists. While AI tools are accelerating scientific data processing and analysis, both
researchers said AI-generated output comes with flaws that may include issues like bias and random conclusion
errors, sometimes referred to as "hallucinations."

AI hallucinations occur when the systems perceive patterns that don't really exist and lead to nonsensical or
inaccurate outputs. Bias can arise from the datasets used to train AI systems. If the underlying data is skewed,
analysis and conclusions that arise from that data can reflect the same inaccuracies.

Ma said AI-generated data is scrutinized by scientists before being incorporated into research.

"We are very careful about how we process this kind of output because of the nature of our work: health care," Ma
said. "We need to ensure output is accurate and reliable."

Still, experts who use AI see more benefits than problems. Gilman thinks "some of the dire worries that people talk
about outside the health care sector seem to flirt with science fiction." Inside the realm of health care, though, he
has two concerns: quality control and data security. Being able to transmit data ever further offers advantages like

                                                                                                           Page 7 of 7
                                                Dr. AI will see you now

connecting a physician in a very small town with a network of specialists at a big medical center. But that comes
with security risks.

"To me, risks are risks to manage; they're not big. I don't have any grand science fiction fears for AI in health care.
But that doesn't mean I know what the future will look like in 20 years. Thus far, I can see some very useful
applications," he said.

Lussier thinks AI could pose problems if tasked with jobs for which it's not fit. "I would reconsider using imaging in
clinical care right now from generative AI, especially if there's writing in it. I would be concerned having generative
AI try to explain to a patient with multiple diseases and drugs that interact with one another. It's not there yet."

Generative AI doesn't draw pictures, either, so it can't illustrate that brochure it worded so beautifully to explain
mechanics of a heart valve. It could create a conceptual illustration for the cover, probably. But a technically correct
picture to explain anatomical anomaly? Nope.

AI's red hot right now and there's a temptation to use it everywhere, Thurston said. Sometimes it doesn't add value
to a traditional algorithmic approach, which they learned when they tried it for certain tasks. He said it hasn't made
its way into mechanical or engineering sides of his company, though the software team has adopted AI for many
uses.

Where does Wald think AI should not go? "I think we must be very careful when we use AI on our individual patient
populations. AI is typically trained on a relatively small number of patients. We absolutely need to make sure as
local practitioners we validate that the technology is working as promised on our own patients. That's currently not
the case. Most practices do not have the wherewithal to actually monitor how well that stuff's working. That's a gap
we need to close."

He adds, "If you decide to use AI, make sure it works on your patients all the time and over time."

Wald also strongly opposes autonomous AI, meaning AI that makes decisions without human oversight or
validation. And he warns most AI in the U.S. is being trained on datasets from big academic medical centers,
whose patient populations "are not necessarily representative of the population in the rest of the country," which
could build in bias unintentionally.

It's vital to remember that AI makes mistakes in medicine, as it does in other realms. And if AI becomes an excuse
to reduce staff, that's no win for health providers or patients.

Blue said in spite of the fast-evolving usefulness of AI tools, he doesn't foresee any near-term future where AI
wholly replaces the work being done by medical researchers or health care clinicians.

"There's a role for efficient processing and analysis of information but the end goal of both researchers and
clinicians is to provide the best patient care attainable," Blue said. "And that is work that requires the human traits of
empathy, insight and perspective."

Scott G Winterton, Deseret News A.I. Med_SGW_00267.jpg A.I. Med_SGW_00267.jpg 1


Load-Date: May 8, 2024


  End of Document

                                                                                                         Page 1 of 3
                 Skeptical about AI in healthcare? Here's how some doctors and hospitals are using it




   Skeptical about AI in healthcare? Here's how some doctors and hospitals
                                  are using it
                                                        USA Today Online
                                                        January 10, 2024



Copyright 2024 Gannett Media Corp All Rights Reserved

Section: HEALTH CARE INDUSTRY NEWS, HEALTH CARE INDUSTRY NEWS & CINCINNATI NEWS
Length: 1126 words
Byline: Elizabeth B. Kim, Cincinnati Enquirer

Body


All of Cincinnati’s major hospital systems are using artificial intelligence, technology that most Americans are wary
of.

Cincinnati’s TriHealth uses artificial intelligence, or AI, to help diagnose pulmonary embolism, stroke and breast
cancer – conditions for which early detection can be lifesaving.

UC Health and St. Elizabeth Healthcare are using AI for detection and diagnosis. Christ Hospital uses AI to
automate insurance and claims billing, while Bon Secours Mercy Health relies on AI to recruit and hire nurses.

Despite its widespread rollout in hospital systems, most Americans don’t trust this technology, according to a 2023
Pew Research survey. Less than 40% of Americans expected AI to improve patient health outcomes, the survey
said.

Nationwide, insurance companies have been sued over faulty and allegedly discriminatory algorithms. Doctors have
been criticized for using ChatGPT to write up medical records and potentially exposing sensitive patient information
by doing so.

Hospital executives say that hospitals are using artificial intelligence, which the National Institutes of Health define
as machines learning to perform tasks, to increase efficiency and elevate the standard of care provided to patients.

More drone deliveries, new AI tech: Here's a guide to what Walmart unveiled at CES 2024

“What people don't realize is AI has been around for a very long time, starting back in the 1950s," said Paul Grone,
chief information officer of Christ Hospital. "It’s evolved from many years ago. Health care has been using AI in the
back office for quite some time.”

Cincinnati hospitals say AI can help doctors

Link to Image

                                                                                                        Page 2 of 3
                Skeptical about AI in healthcare? Here's how some doctors and hospitals are using it

Christ Hospital is partnering with Microsoft and Epic Systems, the medical records software company that runs
MyChart, to develop AI that helps doctors respond to patient emails.

Grone said he doesn’t think AI will result in less face-to-face time between patients and doctors, citing AI
technology that records medical notes during appointments.

“Normally in the appointment, the provider would be on the computer the whole time as he or she’s talking to you,”
he said. “Now, they’re facing you ... and the system is capturing the conversation. So, actually, it improves the face
time with the patient.”

He said Christ Hospital aims to pilot the technology starting in February.

TriHealth’s Chief Operating Officer Terri Hanlon-Bremer shared similar sentiments about AI improving the patient
experience. “It helps us pinpoint where that doctor should focus ... in an effective and efficient manner,” she said.

Hanlon-Bremer said the AI would be an aid, rather than a substitute, for doctors. “AI is not replacing the role of the
physician or the clinical decision-making that a physician brings to the table,” she said.

TriHealth’s four-hospital system is also considering implementing a ChatGPT-like system that will help doctors
respond to patient questions, according to John Ward, TriHealth’s senior vice president of regional operations.

“One of the tough things for physicians today with electronic medical records and with patient portals is that they get
bombarded with a ton of messages,” Ward said. "So being able to process those and respond to those is difficult. It
ends up taking hours at night.”

He said AI can help doctors prioritize those messages to save time.

Unlike ChatGPT, however, which was briefly banned in Italy for collecting data without consent, any data collected
by hospitals is subject to HIPAA, the federal law that prohibits healthcare providers from sharing or selling a
patient’s health information.

“If you're going to share data of any kind, it has to be totally de-identified,” Ward said.

Part of the task that hospitals face is properly vetting AI vendors. As TriHealth’s Hanlon-Bremer remarked, “The
challenge we have is how to find a company that is credible, that has technology that is going to better our clinical
outcomes, and that isn’t going to go away overnight.”

Meanwhile, Columbus-based AI startup Olive shut down suddenly in November 2023, after promising to use AI to
increase efficiency in 600+ hospitals across the US. TriHealth had previously partnered with the now-defunct
startup to automate medical billing and process denials.

Link to Image

Most Americans skeptical about AI’s benefits

Most Americans do not share hospital executives’ enthusiasm about the potential of AI.

In the Pew Research Survey, 75% thought healthcare providers would adopt AI technologies too quickly, before
fully accounting for the risks to patients, and 79% of Americans said they did not want an AI chatbot to respond if
they needed mental health support.

In May 2023, reports emerged that an AI-driven chatbot designed to help those struggling with eating disorders
ended up offering users tips on dieting instead. The chatbot’s host, the National Eating Disorders Association, took
it down shortly thereafter.

Implementing AI into medical billing has also met its challenges.

                                                                                                        Page 3 of 3
               Skeptical about AI in healthcare? Here's how some doctors and hospitals are using it

Insurance company Cigna was sued twice in 2023 over allegations that it relied on AI to deny thousands of pre-
approved medical claims at a time. With the help of algorithms, Cigna employees took 1.2 seconds on average to
reject each claim, according to a class action suit. Plaintiffs said that Cigna violated a California law that obliges
insurers to evaluate claims in a “thorough, fair, and objective” manner.

Similarly, UnitedHealth Group was hit with a proposed class action lawsuit arguing that its AI algorithm methodically
rejected elderly patients’ claims for care, such as stays in nursing facilities.

Biden, doctors call for more AI regulation

The privacy and ethics concerns that come with algorithms trained on large swaths of personal data have doctors
and elected officials alike calling for more patient protections.

In an October executive order, President Joe Biden called on Congress to pass data privacy legislation, referring to
AI as holding “extraordinary potential for both promise and peril.”

Earlier in the year, the American Psychiatric Association issued a statement strongly opposing doctors entering
patient data into generative AI tools like ChatGPT, citing probable violations of HIPAA.

Generative AI tools for healthcare have not yet been approved by the Food and Drug Administration. However, Dr.
Douglas Flora, the executive medical director of oncology services at St. Elizabeth Healthcare, thinks it’s only a
matter of time.

“Looking three to five years down the road, I don’t think that a health care system that hasn’t employed generative
AI is going to be able to compete with those that have," Flora said.

This article originally appeared on Cincinnati Enquirer: Skeptical about AI in healthcare? Here's how some doctors
and hospitals are using it


Load-Date: January 10, 2024


  End of Document

                                                                                                            Page 1 of 2
                                                Stay human as AI joins humanity




                                      Stay human as AI joins humanity
                                           The Columbian (Vancouver, Washington)
                                                     August 3, 2024 Saturday



Copyright 2024 The Columbian Publishing Co. All Rights Reserved

Section: OPINION-COLUMNS; Pg. A12
Length: 715 words
Byline: Joseph Vukov
Highlight: The first time I used generative artificial intelligence, I felt like a kid at an amateur magic show. Is the
card really floating in midair? The parents at this kind of show, of course, are less dumbstruck than the kids: The
card is not floating but instead swinging on some string. It's not magic. You simply have to know where to look.

The same goes for artificial intelligence. Once you know where to look, even the most powerful AI stops looking like
magic. No string here - instead, look at the AI's training data.

Body

The first time I used generative artificial intelligence, I felt like a kid at an amateur magic show. Is
the card really floating in midair? The parents at this kind of show, of course, are less dumbstruck than
the kids: The card is not floating but instead swinging on some string. It's not magic. You simply have to
know where to look.

The same goes for artificial intelligence. Once you know where to look, even the most powerful AI stops
looking like magic. No string here - instead, look at the AI's training data.

Training data is the information used to construct an AI. After programmers feed an AI a massive diet of
training data, the AI learns to identify patterns in it and then generates output.

In all the hubbub around AI, it can be tempting to think that it will eclipse us; that it will expand
infinitely, until it can do all that a college-educated human can do - and more; that it will take over
not only the jobs of data crunchers and coders and copy editors, but also poets and artists and high-level
managers.

We are probably right to worry about some of our jobs. But many predictions about AI are overblown. The
technology faces crucial limitations.

First: AI is limited by the data on which it is trained. Even if you were to train an AI on the entire
internet, it would miss out on a lot: thoughts jotted down on a napkin; late-night conversations with a
college roommate; that week in 2018 you spent camping in the Rockies; and the feeling of seeing your
grandma after a long time apart. None of that is part of the AI's world.

Second: AI lacks critical thinking. Can an image-generating AI churn out several versions of a cat in a
fedora painted in the style of Rembrandt? Yup. But can it discern which of the paintings is better than
the others? No.

                                                                                             Page 2 of 2
                                     Stay human as AI joins humanity

As a writer, I believe AI can be a helpful tool. It can generate ideas, word choices and metaphors. But
for an undergraduate churning out a last-minute essay, AI will be far less useful. The essay won't come
together without someone to form it.

Since I started writing about AI, I get asked a lot about the Terminator. Are cyborgs going to take over?
No. Yet we should still worry about AI. It is poised to take over large swaths of human activity and, in
doing so, erode our individual and shared humanity.

The truth is that generative AI is only the tip of the iceberg. The influence and potential dangers of the
AI revolution go far beyond the flashy, generative versions.

For example, AI has been making a splash in health care. Applications can discern subtle differences in
radiology scans and can be used to triage patients and complete physicians' notes. They can be used to
craft care plans for patients upon discharge. Used correctly, AI could deliver more effective health care.
But used improperly, AI-powered health care could exacerbate problems in delivery, rob medicine of the
human element and reduce our view of a person to a collection of data.

AI is also in Big Retail. You've likely bought a book on the recommendation of Amazon's algorithm, viewed
videos based on YouTube's suggestions and clicked on an ad for a product you never would have looked up on
your own. In all these instances, AI predicts your preferences. Scarier still, it helps shape your
preferences in the first place.
We become, in a phrase, less human.

AI does, indeed, threaten our humanity - not in the form of a cyborg, but with the promise of a funny
YouTube video or a new pair of jeans.
In the early days of the internet, when it was slow-moving and quirky, we couldn't have imagined
smartphones, streaming platforms and online banking becoming part of our daily lives.

Similarly, AI is finding its legs. Like the internet, it is poised to infiltrate our lives in myriad
unexpected ways. We cannot predict precisely how or where AI will take up residence in 50 years.

How to prepare for this kind of infiltration? By reflecting carefully on AI now. By identifying those
areas of lives we want to retain as human spaces and those we are comfortable ceding to the algorithms. By
reflecting on what it means to be human in the first place.

AI is here to stay. We need to ensure that humanity as we know it is here to stay as well.
Joseph Vukov is a philosophy professor at Loyola University Chicago. He wrote this for the Chicago
Tribune.



Load-Date: September 16, 2024


  End of Document

                                                                                                      Page 1 of 3
                                        Absence of AI hospital rules worries nurses




                               Absence of AI hospital rules worries nurses
                                                       Stateline.org
                                                 March 5, 2024 Tuesday



Copyright 2024 Stateline.org

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 1310 words
Byline: Madyson Fitzgerald, Stateline.org

Body


Mar. 5—For nurse Judy Schmidt, the beeping monitors hooked up to critical patients at the Community Medical
Center in Toms River, New Jersey, were just a normal part of the whirlwind of activity in the intensive care unit.

But looking back on her work about a decade ago, Schmidt said she realizes those machines were using early
versions of artificial intelligence to help analyze and track the patients' health.

Artificial intelligence has been used in health care settings for years, even before the public became familiar with
the technology, said Schmidt, CEO of the New Jersey State Nurses Association, a professional organization.

Today, some electronic health records are programmed to alert providers when patients could be having symptoms
of a major illness. And in medical education, professors are depending more on simulations using mannequins,
such as those programmed to mimic a birth, she said.

But the fast-paced development of these systems — to the point where robotics are being used in surgery — raises
practical and ethical questions for the providers who work with that technology, Schmidt said.

Some experts say AI technology can improve the health care industry by automating administrative work, offering
virtual nursing assistance and more. AI systems can predict whether a patient is likely to get sicker while in the
hospital. Virtual assistant chatbots in telehealth services enable remote consultations. And more health care
providers could start using robotics in the examination room.

But some nurses are concerned that the scarcity of laws regarding AI's use in hospitals and beyond means a lack
of protections for individuals who could suffer from the technology's mistakes.

"In the long run, whatever artificial intelligence we use, it's still the human — the person — that has to take that
data, and the interpretation of that data in some respects, and apply it to the real person that's in the bed, the
nursing home or the home of that person," Schmidt said.

                                                                                                             Page 2 of 3
                                      Absence of AI hospital rules worries nurses

State legislators are lagging on creating regulations for the use of AI, said Richard Ridge, an assistant professor of
nursing at the University of Virginia. As the technology becomes more advanced, most health care workers are
relying on policies set by their own hospital or practice, which can vary.

Legislators not only need to educate themselves about AI but also consider protections for patients within systems
that use the technology, said Ridge, who added that nurses should be a part of those conversations.

"The value nurses bring to the table in any health care discussion is helping policymakers and decision-makers see
things from the patient's point of view and the patient's perspective," Ridge said.

"I wouldn't want to read something [policy] about AI in health care and it not have anything to say about nurses,"
added Ridge, who also heads a panel on workforce issues for the professional group the Virginia Nurses
Association.

Lawmakers in several states have introduced bills on artificial intelligence in health care, but a Stateline survey
found only one that has been enacted: a Georgia law that allows the use of artificial intelligence devices in eye
exams.

One Pennsylvania bill that's sitting in a House committee would require insurers to disclose whether they are using
AI-based algorithms when reviewing claims to determine whether medical procedures are necessary.

Pennsylvania state Rep. Arvind Venkat, a Democrat sponsoring the bill and a physician, said the growth of artificial
intelligence means it can be used to determine whether treatments or medications aren't covered by a patient's
insurance.

"One of the problems we've seen with AI is that the data goes into the AI platform, it makes a decision, and it gets
spit out, but that decision is only as good as the data being used to train the platform," Venkat said. "Existing biases
are being reinforced by the use of artificial intelligence, and especially in the area of health insurance."

An Illinois bill would set the maximum number of patients that may be assigned to a registered nurse in specified
situations. For health care facilities that use AI, nurses could override the technology's recommendations if they
deem it in the patient's best interest.

In the long run, whatever artificial intelligence we use, it's still the human — the person — that has to take that data,
and the interpretation of that data in some respects, and apply it to the real person that's in the bed, the nursing
home the home of that person. — Judy Schmidt, CEO of the New Jersey State Nurses Association

The American Nurses Association's code of ethics, followed by all nurses in the country, states that advanced
technologies, including AI, do not replace nursing skills or judgement.

In a position statement, the organization said nurses "are responsible for being informed about and ensuring the
appropriate use of AI" for their patients. It also said it's essential for nurses to be a part of efforts to advocate for an
AI governance framework that holds technology developers accountable.

Dan Weberg, the vice president of the American Nurses Association\California and an expert in the connection
between technology and nursing, said rapid advances in AI are making the issues more complicated.

"We've been using algorithms and machine-generated insights for a number of years," Weberg said, "but now, it's
sort of getting more pressing with the complexity. It's getting more refined with more tools and that kind of stuff."

Albert Fox Cahn, the executive director of the Surveillance Technology Oversight Project, a nonprofit organization
that advocates for privacy rights in the use of new technologies, said that in the absence of federal rules, he hopes
state and local policymakers will begin to create policies modeled after that of the European Union.

                                                                                                           Page 3 of 3
                                      Absence of AI hospital rules worries nurses

The EU AI Act, which is set to become the world's first set of laws to govern artificial intelligence, could become the
global standard for AI governance. It attempts to define artificial intelligence and would set rules for regulating the
technology across the EU, including prohibited AI practices.

While acknowledging that the technology has major benefits, the legislation establishes rules for public and private
entities — including the health care sector — to use risk assessments, testing and more to ensure AI systems are
working properly and protecting the rights of its users.

The EU's artificial intelligence liability directive, which was proposed in September 2022, would ease the burden of
proof for victims to show damage caused by an AI system.

It's a really alarming moment for people in technology policy, Cahn said. There are new AI systems being deployed
across industries, including health care, but without the laws in place to protect individuals in case something goes
wrong, he said.

That doesn't mean AI systems should be scrapped, Cahn said, but ignoring the dangers of these systems would be
a mistake. Policymakers should look at the impact of AI from every standpoint, he added, including the datasets
used to train artificial intelligence that could hold implicit biases and lead to discrimination.

One challenge as AI advances is maintaining trust between providers and patients. Many patients fear that they're
dealing with a robot rather than their practitioner, said Jennifer Shepherd, vice president of the Virginia Nurses
Association. Providers must work with AI systems from a human-centered perspective, she added.

"One of the things we've thought about and what a lot of our focus is on is instead of just calling it 'AI in health care'
or 'evidence-based AI,' what if we start using the term 'human-centered AI'?" said Shepherd. "Focusing in on that,
it's not so scary."

SUPPORT NEWS YOU TRUST.

___ (c)2024 Stateline.org Visit Stateline.org at www.stateline.org Distributed by Tribune Content Agency, LLC.


Load-Date: March 12, 2024


  End of Document

                                                                                                        Page 1 of 2
                                        AI pilot aims to widen health access




                                AI pilot aims to widen health access
                                       The Pantagraph (Bloomington, Illinois)
                                               March 01, 2024 Friday



Copyright 2024 The Pantagraph

Section: A; Pg. A6
Length: 782 words
Byline: THALIA BEATY Associated Press

Body


NEW YORK - Komal Vilas Thatkare says she doesn't have anyone to ask about her most private health questions.

"There are only men in my home - no ladies," said the 32-year-old mother and housewife in Mumbai. "I don't speak
to anyone here. So I used this app as it helps me in my personal problems."

The app she uses is powered by artificial intelligence running on OpenAI's ChatGPT model, that Myna Mahila
Foundation, a local women's organization, is developing. Thatkare asks the Myna Bolo chatbot questions and it
offers answers. Through those interactions, Thatkare learned about a contraceptive pill and how to take it.

Thatkare is one of 80 test users the foundation recruited to help train the chatbot. It draws on a customized
database of medical information about sexual health, but the chatbot's potential success relies on test users like
Thatkare to train it.

"If this actually could provide this nonjudgmental, private advice to women, then it could really be a gamechanger
when it comes to accessing information about sexual reproductive health," said Suhani Jalota, founder and CEO of
the Myna Mahila Foundation, which received a $100,000 grant from the Bill & Melinda Gates Foundation last
summer to develop the chatbot, as part of a cohort of organizations in low- and middle-income countries trying to
use AI to solve problems in their communities.

Funders like the Gates Foundation, the Patrick J. McGovern Foundation and Data.org, are seeking to build up this
"missing middle" in AI development, especially in areas like health and education. These philanthropic initiatives
offer developers access to AI tools they otherwise could not afford so they can solve problems that are a low priority
for corporations and researchers - if they are on their radars at all - because they don't have high profit potential.

"No longer can the global north and high-income countries drive the agenda and decide what does and does not
need to be addressed in local communities in the global south," wrote Trevor Mundel, president for global health at
the Gates Foundation in an October online post, adding, "We cannot risk creating another chasm of inequity when it
comes to AI."

The Associated Press receives financial support for news coverage in Africa from the Bill & Melinda Gates
Foundation.

                                                                                                         Page 2 of 2
                                         AI pilot aims to widen health access

The Myna Mahila Foundation recruited test users like Thatkare to write real questions they have. For example,
"Does using a condom cause HIV?" or "Can I have sex during periods?" The foundation's staff then closely monitor
the chatbot's responses, developing a customized database of verified questions and answers along the way that
helps improve future responses.

The chatbot is not yet ready for wider release. The accuracy of its responses is not good enough and there are
issues with translation, Jalota said. Users often write questions in a mix of languages and may not provide the
chatbot with enough information for it to offer a relevant response.

"We are not yet fully sure on whether or not women can understand everything clearly and whether or not it's fully
medically accurate all of the information that we're sending out," Jalota said. They are considering training some
women to help ask the chatbot prompts on behalf of someone else, though still aim to improve the chatbot so it can
be released on its own.

Dr. Christopher Longhurst, chief medical officer at the UC San Diego Health, has led the implementation of AI tools
in health care settings and said it is important to test and measure the impact of these new tools on patient health
outcomes.

"We can't just assume or trust or hope that these things are going to be good. You actually have to test it,"
Longhurst said. He thinks the promise of AI in health care is overestimated in the next two to three years, "But I
think long term, over the next decade, AI is going to be as impactful as the introduction of penicillin in health care."

Jalota's team consulted with other projects funded by the Gates Foundation that were designing chatbots for health
care settings so they could solve similar problems together, said Zameer Brey, interim deputy director for
technology diffusion for the Gates Foundation.

The Myna Mahila Foundation is also partnering with another Gates grantee to propose developing privacy
standards for handling data for reproductive health. The foundation, which is working with an outside technology
firm to develop the chatbot, is also considering other steps to help ensure the privacy of users.

"We've been discussing whether we should delete messages within a certain time frame of women sending it to add
to this privacy," Jalota said, as some women share phones with family members.


Load-Date: March 1, 2024


  End of Document

                                                                                   Page 1 of 2
          MEET THE MUSCLE BEHIND PITTSBURGH'S AI STEEL CITY INNOVATION IS BUILT ON ONE
                                  CHIPMAKER'S POPULAR TOOL




 MEET THE MUSCLE BEHIND PITTSBURGH'S AI; STEEL CITY INNOVATION
           IS BUILT ON ONE CHIPMAKER'S POPULAR TOOL
                                              Pittsburgh Post-Gazette
                                               April 14, 2024 Sunday
                                                  EAST EDITION



Copyright 2024 P.G. Publishing Co.

Section: BUSINESS; Pg. E-3
Length: 543 words
Byline: Evan Robinson-Johnson Pittsburgh Post-Gazette

Body


While Pittsburgh and Carnegie Mellon University have long touted themselves as pioneers of artificial intelligence,
much of the power behind that innovation has been driven by one company: Nvidia.

The trillion-dollar chipmaker that got its start in gaming has long propped up the city's autonomous vehicle
development. It is now partnering with or directly powering a slew of Pittsburgh AI projects, including Abridge's
notation platform for doctors, Ansys' simulation software and Agility Robotics' friendly warehouse humanoids.

"Any company in Pittsburgh that is using big data, AI or training AI models is going to be relying on Nvidia chips,"
Marc Swinnen, Ansys' director of product marketing, told me in a recent interview.

He said the technology differs from other industries like steel in its growth rate. As soon as one chip is released, a
new one that's "twice as big" is already in the works.

Competitors are only just now catching up, with Google, Intel and Meta all announcing new versions of their own AI
chips this week. (At least one Pittsburgh startup is also trying to carve out its own chip profits by focusing on
efficiency.)

Meanwhile, Nvidia, which has an estimated 80% of the AI chip market, is looking to take on the world of humanoid
robotics, with Pittsburgh's own two-legged Digit leading the way.

Digit joined a lineup of other human-like bots at Nvidia's recent summit in California, where it unveiled Project
Gr00t, a "comprehensive AI platform for leading humanoid robot companies" including Boston Dynamics and Digit's
maker, Agility Robotics, which designs and tests the robots in Lawrenceville.

"Our collaboration with Nvidia augments our existing computing and simulation tools, and essentially gives us a
force multiplier on our ability to do the kind of model building and training that we need to accelerate Digit's
commercial capabilities," Agility told me by email.

                                                                                  Page 2 of 2
         MEET THE MUSCLE BEHIND PITTSBURGH'S AI STEEL CITY INNOVATION IS BUILT ON ONE
                                 CHIPMAKER'S POPULAR TOOL

Nvidia has said the focus will help robots understand human speech and "emulate movements by observing human
actions," making it easier for them to move around our world.

Beyond its hardware, Nvidia also is training the Pittsburgh talent behind AI.

The company is supporting Carnegie Mellon University students through its fellowship program and is backing
startups like Downtown-based Preamble AI with development expertise.

Abridge, the startup using AI to help doctors process notes, said its investment from Nvidia - part of a recently
closed $150 million funding round - is also a "strategic collaboration around health care AI." The two are working
on research efforts that could expand Abridge's product to other health care applications.

Chris Paxton, an AI and robotics research scientist based in Pittsburgh who has worked for Nvidia and Meta, said
the chips became ubiquitous in part because their software capabilities made them so easy to pair.

"Everyone is using Nvidia, absolutely everyone," he said. "I would be shocked if you could find a single robotics
company in Pittsburgh that does not rely on those cards."

He noted that between games and AI, there was another big use case for Nvidia's powerful processors: mining
cryptocurrency.

Have an AI question? Contact tech reporter Evan Robinson-Johnson at ejohnson@post-gazette.com or on X
@sightsonwheels.



Graphic


PHOTO: Philip Pacheco/Bloomberg: Nvidia headquarters in Santa Clara, Calif. The trillion-dollar chipmaker is now
partnering with, or directly powering, a slew of Pittsburgh AI projects, including Abridge's notation platform for
doctors, Ansys' simulation software and Agility Robotics' friendly warehouse humanoids.


Load-Date: April 14, 2024


  End of Document

                                                                                                        Page 1 of 2
                   Research Roundup: Searching the stars and the brain Login or create an account




   Research Roundup: Searching the stars and the brain Login or create an
                                account
                                            The Stanford Daily: Stanford University
                                                      April 22, 2024 Monday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 774 words
Byline: Jack Quach

Body


By Jack Quach

Published April 22, 2024, 1:43 a.m., last updated April 22, 2024, 1:43 a.m.

The academics desk gathers a weekly digest with impactful and interesting research publications and
developments at Stanford. Read the latest in this week's Research Roundup.

SLAC builds largest digital camera for astronomy

Engineers at Stanford's SLAC National Accelerator Laboratory finished the construction of the Legacy Survey of
Space and Time Camera this month, a 3,200 megapixel digital camera. The milestone completes nearly two
decades of research and development on a key observational tool.

The research team will place the record-setting camera atop a telescope at Rubin Observatory in Chile. Once the
camera gains full functionality, it will guide researchers to explore dark energy and matter, aspects of the universe
fundamental to the workings of physics and astronomy, yet those that scientists have yet to gain much foothold on
understanding.

According to SLAC, the camera weighs over three tons and carries a front camera lens five feet across - a record
for a camera of its type and purpose. Each one of its 3.2 billion pixels go toward making the definition of its images
immensely sharp.

 The camera "could resolve a golf ball from around 15 miles away, while covering a swath of the sky seven times
wider than the full moon," said Aaron Roodman, a particle physics and astrophysics professor at SLAC. "These
images with billions of stars and galaxies will help unlock the secrets of the universe," Roodman said.

The camera, a core piece of the Rubin Observatory, will allow scientists to track the weak bending of light by gravity
with precision. In addition, astronomers plan to dive into the secrets of our galaxy, the Milky Way, with newfound
detail.

                                                                                                        Page 2 of 2
                 Research Roundup: Searching the stars and the brain Login or create an account

For now, the LSST Camera will take the nearly 6,000-mile journey to Chile and be brought 8,900 feet above the
ground to prepare to document the universe, nestled in the Andes mountains.

Stanford Medicine finds potential new epilepsy treatment

Researchers found, in a April 17 Nature Medicine study, that investigating a specific region of the brain before
surgery could lead to improved surgical outcomes for patients with epilepsy.

Currently, the only effective treatment for epileptic seizures that cannot be solved through medications involves
performing surgery on the temporal lobe of the brain. According to Stanford Medicine, , this approach fails to relieve
patients of seizures one-third of the time. Researchers discovered that mapping the fasciola cinereum, a small
region of the hippocampus, for seizure activity can help doctors tailor their surgical approach to better suit each
patient and deliver more consistent and effective outcomes.

Surgeons can use stereoelectroencephalography, or sEEG, electrodes to map areas of the brain. The researchers
found that documenting brain activity from the fasciola cinereum can lead to better understanding of what causes a
patient's seizures and how to solve them through surgery.

"Our findings suggest that all patients with drug-resistant temporal lobe epilepsy should have depth electrodes
placed in the fasciola cinereum as part of the surgery planning process," said professor of neurosurgery and
neurosciences Ivan Soltesz.

AI improves nurse-doctor teamwork

A new artificial intelligence model developed by Stanford Med aims to support doctors and nurses in monitoring
patient information and health statuses.

The AI model analyzes vital patient metrics and decides whether the patient is likely to suffer a health decline. If
one is likely, the program alerts the health care workers so they can act accordingly.

Nurses and doctors often need to trade off patient information and updates. However, Ron Li, the study's senior
author and a Stanford Medicine associate professor, explained that key patient needs may be lost in the bustle of
day-to-day operations at the hospital. Stanford Medicine physicians hope the implementation of AI tools can alert
health care workers when they miss certain aspects about patient health trajectories.

"This model is powered by AI, but the action it triggers, the intervention, is basically a conversation that otherwise
may not have happened," Li said.

The medical researchers behind the model will examine refining the AI to improve its accuracy in reading changes
to patient health.

Jack Quach '27 is a beat reporter, covering research and awards, and staff writer for News. He is from San
Francisco, CA, and in his free time loves cheering for his hometown sports teams, exploring the outdoors, learning
new recipes and being the official(TM) S.F. expert/tour guide for his friends.

Print Article


Load-Date: April 22, 2024


  End of Document

                                                                                                             Page 1 of 2
                              AI shows promise but remains limited for heart and stroke care




            AI shows promise but remains limited for heart and stroke care
                                                       Idaho Business Review
                                                 February 28, 2024 Wednesday



Copyright 2024 BridgeTower Media All Rights Reserved




Section: NEWS
Length: 637 words
Byline: Marc Lutz

Body


Artificial intelligence has the potential to change many aspects of cardiovascular care, but not right away, a new
report says.

Existing AI and machine-learning digital tools are promising, according to the scientific statement from the American
Heart Association. Such tools already have shown they can help screen patients and guide researchers in
developing new treatments. The report was published Wednesday in the journal Circulation.

But, the authors said, research hasn’t shown that AI-based tools improve care enough to justify their widespread
use.

“There is an urgent need to develop programs that will accelerate the education of the science behind AI/machine
learning tools, thus accelerating the adoption and creation of manageable, cost-effective, automated processes,”
Dr. Antonis Armoundas, who led the statement writing committee, said in a news release. He is a principal
investigator at the Cardiovascular Research Center at Boston’s Massachusetts General Hospital.

“We need more AI/machine learning-based precision medicine tools to help address core unmet needs in medicine
that can subsequently be tested in robust clinical trials,” said Armoundas, who also is an associate professor of
medicine at Harvard Medical School.

The report is the AHA’s first scientific statement on artificial intelligence. It looks at the state of research into AI and
machine learning in cardiovascular medicine and suggests what may be needed for safe, effective widescale use.

“Here, we present the state of the art, including the latest science regarding specific AI uses from imaging and
wearables to electrocardiography and genetics,” Armoundas said.

AI can analyze data and make predictions, typically for narrowly defined tasks. Machine learning uses mathematical
models and algorithms to detect patterns in large datasets that may not be evident to human observers alone. Deep
learning, a subfield of machine learning, is used in image recognition and interpretation.

                                                                                                      Page 2 of 2
                          AI shows promise but remains limited for heart and stroke care

Researchers have used such technologies to analyze electronic health records to compare the effectiveness of
tests and treatments, and, more recently, to create models that inform care decisions.
The report notes several ways digital tools might help cardiovascular patients.

Imaging, for example, is important for diagnosing heart attacks and strokes. AI and machine-learning tools could
address inconsistencies in human interpretation and relieve overburdened experts.

AI has helped automate analysis of electrocardiograms, which measure the heart’s electrical activity, by identifying
subtle results that human experts might not see.

And with implantable and wearable technologies providing steady streams of health information, AI could help
remotely monitor patients and spot when something is amiss.
But the report also spells out many challenges and limits.

With imaging, for example, broad use of AI and machine learning for interpreting tests is challenging because the
data available to study is limited. Researchers also need to prove AI technology works in each area where it will be
used.

With implantable and wearable tech, the research gaps include ways to identify which patients and conditions may
be best for AI- and machine learning-enabled remote monitoring. Other issues include how to address cost-
effectiveness, privacy, safety and equitable access.
More broadly, protocols on how information is organized and shared are critical, the report says, and potential
ethical, legal and regulatory issues need to be addressed.

And while AI algorithms have enhanced the ability to interpret genetic variants and abnormalities, the writing
committee warned of limits. Such algorithms, the committee wrote, still require training on human-derived data that
can be error-prone and inaccurate.

Copyright © 2024 BridgeTower Media. All Rights Reserved.


Load-Date: March 5, 2024


  End of Document

                                                                                                         Page 1 of 3
                            Your doctor might not be listening to you. AI can help change that.




        Your doctor might not be listening to you. AI can help change that.
                                                        USA Today Online
                                                         March 27, 2024



Copyright 2024 Gannett Media Corp All Rights Reserved

Length: 1196 words
Byline: Rotimi Kukoyi, Victor Agbafe and Dr. Joan Perry

Body


Are you tired of feeling like just another number at the doctor’s office? As current and future members of the
physician workforce, we believe that well-regulated artificial intelligence presents an opportunity to tackle burnout
within the medical workforce and restore patient-centered care.

From 2021 through 2022, about 71,300 physicians left their clinical jobs, exacerbating staffing shortages. Even
more troubling, the Association of American Medical Colleges projects a shortage of up to 124,000 physicians by
2034.

A major factor driving this shortage is the overwhelming and increasing administrative burden associated with care
delivery. These burdens leave physicians, who train to connect with their patients face-to-face, spending more time
with their eyes glued to their electronic health records.

Dr. Christine Sinsky, a vice president at the American Medical Association, explains, “Physicians don't leave their
careers. They are leaving their inbox.”

Link to Image

'The doctor is not really listening to me'

It's not just doctors feeling the strain, either. When a doctor spends half their time typing away at their computer, it
is no surprise that patients feel neglected. Many patients resent the resulting decline in face-to-face time with their
doctors, frustrated as they slip through the cracks of what many increasingly describe as a corporatized health care
system.

One of us, Victor Agbafe, learned this firsthand from his frustrated neighbor who after an encounter with his primary
care provider told him, “The doctor is not really listening to me – they’re too focused on their pre-set agenda.”

Yes, urgent care is convenient. But seeing your doctor may save your life.

And it's not just a one-off complaint.

                                                                                                      Page 2 of 3
                        Your doctor might not be listening to you. AI can help change that.

A study from the Mayo Clinic showed that doctors often interrupt their patients within just 11 seconds of them
talking. The patients in the study who did voice concerns about the history and physical aspects of their patient
encounter cited being interrupted a few seconds into their encounter as their chief complaint.

Fortunately, this is exactly where generative AI can make a remarkable difference. AI tools can reduce the
physician’s administrative workload, freeing up more time to spend with patients.

Opinion alerts: Get columns from your favorite columnists + expert analysis on top issues, delivered straight to
your device through the USA TODAY app. Don't have the app? Download it for free from your app store.

How AI can help doctors treat patients better

For example, in Tennessee, Dr. Matthew Hitchcock is using an AI tool that drafts his medical notes, turning two
hours of typing at home into just 20 minutes of editing.

By delegating time-consuming tasks to AI, physicians can focus on verifying the accuracy of medical notes and,
more important, on directly engaging with patients.

Think back to Victor’s neighbor, whose appointments were depersonalized by doctors typing notes into electronic
medical records, dividing their attention between their screens and patients. With AI-assisted appointments, doctors
can spend their limited time forming genuine connections with patients and asking important follow-up questions.

Link to Image

Minimizing keyboard clicking and computer screen barriers creates more space for doctors and patients to build the
trust and mutual understanding necessary to maximize the doctor-patient relationship. This shows the positive
potential of AI making inroads in health care: It can enhance rather than replace human connection.

Beyond easing administrative tasks, AI's integration into health care can benefit diagnostics and treatment planning
– particularly through the integration of retrieval-augmented generation techniques (RAG), which enhance the
accuracy and reliability of AI models.

America needs diverse medical workforce: Racial disparities in health care cost lives. Medical school needs
race-conscious admissions.

Imagine the models as standard GPS systems, which navigate using preloaded maps based on vast collections of
old data. The models generate outputs that mirror natural language, much like a GPS guides you based on existing
road layouts.

In this scenario, RAG is like upgrading your GPS to include real-time traffic updates. RAG enhances the AI models
by integrating current, relevant information from external sources, just as a GPS with real-time updates optimizes
routes.

This approach ensures that physicians have access to the latest medical evidence, reducing the risk of outdated or
incorrect diagnoses.

Link to Image

For instance, when a physician evaluates a patient, RAG-enabled AI systems can sift through vast databases of
medical literature and clinical guidelines in real time. They can offer additional diagnoses or remind physicians of
rare conditions, ensuring a more thorough consideration of all possibilities. They can even flag potentially
dangerous drug interactions that might be overlooked in a busy clinical setting, protecting vulnerable populations
like older patients.

                                                                                                        Page 3 of 3
                         Your doctor might not be listening to you. AI can help change that.

As health care evolves from volume-based to value-based care and we increasingly integrate population health
within the context of the individual patient, AI will remain a valuable tool. It enables our doctors, nurses and other
clinical providers to tailor insights gleaned from large-scale population data to the individual needs of each patient.

Even so, let us be clear: AI will not and should not replace our doctors. Medicine is both an art and a science that
requires human intuition and judgment that AI cannot replicate.

Link to Image

It is crucial to strike a balance with how to use AI with medical trainees who will form the backbone of our future
health care workforce. We have to integrate AI into medical education while still ensuring students develop
foundational skills such as developing an initial diagnostic and treatment course that are essential to the practice of
medicine.

We want to bring doctors and patients closer. If implemented responsibly, AI promises to help return medicine to its
humanistic roots.

Rotimi Kukoyi is a Public Voices Fellow of The OpEd Project and The National Black Child Development Institute.
He is a sophomore Morehead-Cain Scholar at the University of North Carolina at Chapel Hill, where he studies
health policy and management, biology and chemistry.

Victor Agbafe is an MD/JD student at the University of Michigan Medical School and Yale Law School, where he is
a research fellow at the Solomon Center for Health Law and Policy.

Dr. Joan Perry is a pediatrician and the chairwoman of the department of pediatrics at Lenoir Memorial Hospital in
Kinston, North Carolina. She is also an adjunct assistant clinical professor of pediatrics at East Coastal University
(ECU) and the University of North Carolina School of Medicine, and a former member of the North Carolina 7th
Congressional District Advisory Committee on Medical and Health Affairs.

You can read diverse opinions from our Board of Contributors and other writers on the Opinion front page, on
Twitter @usatodayopinion and in our daily Opinion newsletter.

This article originally appeared on USA TODAY: Your doctor might not be listening to you. AI can help change that.


Load-Date: March 27, 2024


  End of Document

                                                                                                       Page 1 of 3
   AI devices connect patients, care team Forget ringing the button for the nurse. Patients now stay connected by
                                                    wearing one




    AI devices connect patients, care team; Forget ringing the button for the
              nurse. Patients now stay connected by wearing one
                                                Richmond Times Dispatch (Virginia)
                                                       May 20, 2024 Monday
                                                            01 Edition



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2024 Richmond Times-Dispatch, Richmond, VA

Section: HEALTH; Pg. 16D
Length: 869 words
Byline: PHIL GALEWITZ KFF Health News

Body


Patients admitted to Houston Methodist Hospital get a monitoring device about the size of a half-dollar affixed to
their chest - and an unwitting role in the expanding use of artificial intelligence in health care.

The slender, battery-powered gadget, called a BioButton, records vital signs including heart and breathing rates,
then wirelessly sends the readings to nurses sitting in a 24-hour control room elsewhere in the hospital or in their
homes. The device's software uses AI to analyze the voluminous data and detect signs a patient's condition is
deteriorating.

Hospital officials say the BioButton has improved care and reduced the workload of bedside nurses since its rollout
last year.

"Because we catch things earlier, patients are doing better, as we don't have to wait for the bedside team to notice
if something is going wrong," said Sarah Pletcher, system vice president at Houston Methodist.

But some nurses fear the technology could wind up replacing them rather than supporting them - and harming
patients. Houston Methodist, one of dozens of U.S. hospitals to employ the device, is the first to use the BioButton
to monitor all patients except those in intensive care, Pletcher said.

"The hype around a lot of these devices is they provide care at scale for less labor costs," said Michelle Mahon, a
registered nurse and an assistant director of National Nurses United, the profession's largest U.S. union. "This is a
trend that we find disturbing," she said.

The rollout of BioButton is among the latest examples of hospitals deploying technology to improve efficiency and
address a decades-old nursing shortage. But that transition has raised its own concerns, including about the
device's use of AI; polls show the public is wary of health providers relying on it for patient care.

                                                                                                      Page 2 of 3
  AI devices connect patients, care team Forget ringing the button for the nurse. Patients now stay connected by
                                                   wearing one

In December 2022, the FDA cleared the BioButton for use in adult patients who are not in critical care. It is one of
many AI tools now used by hospitals for tasks like reading diagnostic imaging results.

In 2023, President Joe Biden directed the Department of Health and Human Services to develop a plan to regulate
AI in hospitals, including by collecting reports of patients harmed by its use.

The leader of BioIntelliSense, which developed the BioButton, said its device is a huge advance compared with
nurses walking into a room every few hours to measure vital signs. "With AI, you now move from 'I wonder why this
patient crashed' to 'I can see this crash coming before it happens and intervene appropriately,'" said James Mault,
CEO of the Golden, a Colorado-based company.

The BioButton stays on the skin with an adhesive, is waterproof, and has up to a 30-day battery life. The company
says the device - which allows providers to quickly notice deteriorating health by recording more than 1,000
measurements a day per patient - has been used on more than 80,000 hospital patients nationwide in the past
year.

Hospitals pay BioIntelliSense an annual subscription fee for the devices and software.

Houston Methodist officials would not reveal how much the hospital pays for the technology, though Pletcher said it
equates to less than a cup of coffee a day per patient.

For a hospital system that treats thousands of patients at a time - Houston Methodist has 2,653 non-ICU beds at its
eight Houston-area hospitals - such an investment could still translate to millions of dollars a year.

Hospital officials say they have not made any changes in nurse staffing and have no plans to because of
implementing the BioButton.

Inside the hospital's control center for virtual monitoring on a recent morning, about 15 nurses and technicians
dressed in scrubs sat in front of large monitors showing the health status of hundreds of patients they were
assigned to monitor.

A red check mark next to a patient's name signaled the AI software had found readings trending outside normal.
Staff members could click into a patient's medical record, showing patients' vital signs over time and other medical
history. These virtual nurses, if you will, could contact nurses on the floor by phone or email, or even dial directly
into the patient's room via video call.

Nutanben Gandhi, a technician who was watching 446 patients on her monitor that morning, said that when she
gets an alert, she looks at the patient's health record to see if the anomaly can be easily explained by something in
the patient's condition or if she needs to contact nurses on the patient's floor.

The hospital has placed small cameras and microphones inside all patient rooms enabling nurses outside to
communicate with patients and perform tasks such as helping with patient admissions and discharge instructions.
Patients can include family members on the remote calls with nurses or a doctor, she said.

Virtual technology frees up on-duty nurses to provide more hands-on help, such as starting an intravenous line,
Pletcher said.

Sheeba Roy, a nurse manager at Houston Methodist, said some members of the nursing staff were nervous about
relying on the device and not checking patients' vital signs as often themselves. But testing has shown the device
provides accurate information.

"After we implemented it, the staff loves it," Roy said.

                                                                                                      Page 3 of 3
  AI devices connect patients, care team Forget ringing the button for the nurse. Patients now stay connected by
                                                   wearing one



Graphic


The BioButton, a monitoring device, is being used in dozens of hospitals employing artificial intelligence to analyze
patients' vital signs. Phil Galewitz, KFF Health News The BioButton, a monitoring device, is being used in dozens
of hospitals employing artificial intelligence to analyze patients' vital signs. Phil Galewitz, KFF Health News A nurse
inside Houston Methodist Hospital's virtual care unit monitors patients from afar. Nurses can track dozens of
patients using technology that helps them supplement bedside care. Phil Galewitz, KFF Health News A nurse
inside Houston Methodist Hospital's virtual care unit monitors patients from afar. Nurses can track dozens of
patients using technology that helps them supplement bedside care. Phil Galewitz, KFF Health News A nurse
speaks virtually to a patient at Houston Methodist Hospital from the facility's virtual care center. Phil Galewitz, KFF
Health News A nurse speaks virtually to a patient at Houston Methodist Hospital from the facility's virtual care
center. Phil Galewitz, KFF Health News Sarah Pletcher, system vice president at Houston Methodist, stands inside
the hospital's 24-hour virtual intensive care unit where patients are monitored by nurses and technicians. Phil
Galewitz, KFF Health News Sarah Pletcher, system vice president at Houston Methodist, stands inside the
hospital's 24-hour virtual intensive care unit where patients are monitored by nurses and technicians. Phil Galewitz,
KFF Health News


Load-Date: June 24, 2024


  End of Document

                                                                                                               Page 1 of 2
                      Unleash the power of our 'super region' Unleash the power of our 'super region'




   Unleash the power of our 'super region'; Unleash the power of our 'super
                                   region'
                                                Richmond Times Dispatch (Virginia)
                                                    October 15, 2024 Tuesday
                                                            01 Edition



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2024 Richmond Times-Dispatch, Richmond, VA

Section: MAIN; Pg. 5A
Length: 852 words

Body


CLOSE THE SKILLS GAP

Our region, which spans the corridor through Baltimore, Washington, D.C., and Richmond, is a vibrant economic
hub in an enviable position. From 2020-2023, we witnessed the creation of 300,000 new jobs, a testament to our
region's resilience. According to recent data, projections show that this figure could double by 2030, further
strengthening our status as a leading economic engine.

There is one pressing challenge on this current trajectory: the skills gap. Our region's leading employers face a
critical shortfall of skilled workers capable of filling future job opportunities. Without strategic intervention to cultivate
essential skillsets within our local workforce, these positions risk going to other regions.

This skills shortage is particularly acute in three sectors with strong demand growth: health care, tech and AI; and
advanced industries, like manufacturing and green jobs. In 2023, many key growth occupations in these sectors -
such as health care practitioners, computer/tech professionals and engineers/architects - had more than 70% of job
ads unfilled each month.

How do we find a solution to fill these open jobs? Our region already has higher-than-average levels of labor force
participation (approximately 70% vs. 63% nationally). We could try to attract more people to work here, and we are.
But higher levels of outmigration since the pandemic have kept our population growth essentially flat. Even if we
could retain all those people, that alone likely wouldn't solve the talent shortage.

The missing ingredient is skills - specifically, ensuring that job seekers possess the necessary skills for our fastest-
growing occupations. They may be "hard" skills like specialized training and technical expertise, or so-called "cross-
cutting skills" that are widely applicable like interpersonal, leadership or critical thinking skills.

Unlocking the next level of regional growth hinges on closing these key skills gaps.

Take the health care sector, which is one of the top growth engines of our local economy. In 2023, 29% of regional
health care roles (50,000 postings) required nursing and patient care skills - such as home care, patient counseling

                                                                                                         Page 2 of 2
                    Unleash the power of our 'super region' Unleash the power of our 'super region'

and care coordination. However, only 8% (40,000) of online health care profiles in the region listed these skills, and
most of those individuals are already employed.

Across the region, we observe a similar dynamic in other high-demand sectors. For instance, in the tech and AI
space, there are notable gaps in fundamental computer science and cybersecurity skills. Furthermore, advanced
industries also face significant skills gaps, particularly in logistics, manufacturing technology, and specialized
construction trades.

Demand for AI and machine learning skills in our region doubled over the last four years with more than 15,000 job
postings requiring these skills today but fewer than 13,000 people who have the required skills. This becomes an
even more difficult obstacle if a security clearance is necessary or if a federal contract mandates that individuals
must hold a bachelor's degree.

Unlocking further growth will require a sharper understanding of the skill gaps in our region and a plan to engage a
wide range of influential stakeholders. We recommend a few steps to get started.

First, employers need to continue investing in transparent and universal methods to forecast and share the specific
skills they need with educators and other training providers. This includes collaborating across sectors to support
programs that equip learners with these skills. The Greater Washington Partnership is working to solve these
challenges with our Employer Signaling System, which creates an efficient way for employers to call out the skills
they need before wide gaps emerge and help close gaps that do exist.

Second, more employers need to take a skills-based mindset when hiring and developing talent. This means not
only hiring for actual skills rather than just standard credentials (like a postsecondary degree) - but also promoting
skills-based education, reskilling, and ongoing learning. Removing some of these artificial barriers should also
increase racial equity and access to in-demand jobs, which expands the talent pipeline.

Third, we need to raise awareness of formal skills training options for both industry-specific and cross-cutting skills.
Students need early exposure to technical roles - why not start in middle school? Mid-career and older workers
need more help identifying the training and credentials that will lead to good jobs. Improving and funding
internships, apprenticeships, and other work-based learning would greatly support this effort.

To sustain and enhance our region's economic growth, we must invest in our most valuable asset - our people. By
focusing on skill development and creating opportunities for lifelong learning, we can unlock the full potential of the
super region.

Kathy Hollinger is CEO of the Greater Washington Partnership and Nora Gardner is a senior partner at McKinsey &
Company. Contact both authors at tshaw@greaterwashingtonpartnership.com


Load-Date: October 15, 2024


  End of Document

                                                                                                        Page 1 of 2
                          Amid collaboration with Northwell, Aegis Ventures launches new effort




     Amid collaboration with Northwell, Aegis Ventures launches new effort
                                                   Long Island Business News
                                                       April 4, 2024 Thursday



Copyright 2024 BridgeTower Media All Rights Reserved




Section: NEWS
Length: 513 words
Byline: Adina Genn

Body


Three years into a collaboration with Northwell Health, New York-based Aegis Ventures has announced a new
initiative, the Digital Consortium.

In this effort, nine health systems, including Northwell, are serving as its founding members. The health systems
will collaborate with Aegis, which partners with industry leaders and entrepreneurs to create, launch, and scale
transformative companies. Specifically through the Digital Consortium, the health systems will work with Aegis with
the aim to codevelop and deploy health-tech applications that address pressing needs, generating diversified
revenue sources.

Dr. John Noseworthy, emeritus president and CEO of Mayo Clinic, will serve as the Digital Consortium’s chairman.

In addition to Northwell, the eight other participating health systems include Endeavor Health, Indiana University
Health, Memorial Hermann Health System, Novant Health, Ochsner Health, The Ohio State University Wexner
Medical Center, Sharp HealthCare and Stanford Health Care. These organizations were selected through a
“rigorous evaluation process for their demonstrated track records of leadership and innovation in care delivery and
quality,” according to a news release about the new effort.

"Health systems must play a central role in designing the next generation of healthtech innovation, and I am
honored to serve at the helm of this initiative," Noseworthy said in a news release.
"As we embark on this endeavor, our focus is clear to address the fundamental challenges in healthcare through a
unified, innovative approach, and accelerate the translation of ideas into tangible solutions that put patients at the
center and address growing burnout among healthcare workers," Noseworthy added.

For the last three years, Northwell has worked with Aegis, partnering in the building and growth of four companies,
addressing such areas as patient engagement, women's health, AI-enabled diagnostics, workflow automation, and
emotion analytics.

                                                                                                  Page 2 of 2
                      Amid collaboration with Northwell, Aegis Ventures launches new effort

"Our collaboration with Aegis Ventures has exemplified what's possible when you combine leading clinical,
technology, and business resources to advance healthcare innovation,” Michael Dowling, president and CEO of
Northwell Health said in the news release.

“Together we've fast-tracked the creation of cost-effective, validated solutions that solve important challenges
across our enterprise and can now be replicated with health systems across the country,” Dowling added. “The
Digital Consortium harnesses health systems' collective expertise to foster groundbreaking solutions, redefining
healthcare delivery for the better. ”

"The partnership between Aegis Ventures and Northwell Health epitomizes the transformative impact that new
technologies can have on health system patients and employees," Aegis Ventures Co-Founder and Managing
Partner John Beadle said in the news release. "At a time of seismic change across the healthtech landscape, we
are poised to expand this successful playbook on a larger scale, catalyzing innovation across the nation."

Copyright © 2024 BridgeTower Media. All Rights Reserved.


Load-Date: April 10, 2024


  End of Document

                                                                                                               Page 1 of 2
                        Joseph Vukov: Worried about AI? Here are things you need to know (copy)




 Joseph Vukov: Worried about AI? Here are things you need to know (copy)
                                                         The Bismarck Tribune
                                                         August 2, 2024 Friday



Copyright 2024 The Bismarck Tribune, a division of Lee Enterprises All Rights Reserved

Section: A; Pg. 009
Length: 944 words

Body


The first time I used generative artificial intelligence, I felt like a kid at an amateur magic show. Is the card really
floating in midair? The parents at this kind of show, of course, are less dumbstruck than the kids: The card is not
floating but instead swinging on some string. It’s not magic. Not even a particularly good illusion. You simply have to
know where to look.

The same goes for generative artificial intelligence. Once you know where to look, even the most powerful AI stops
looking like magic. No string here — instead, look at the AI’s training data.

Training data is the information used to construct an AI. After programmers feed an AI a massive diet of training
data, the AI learns to identify patterns in it and then generates output. The more data you feed an AI, the more
subtle the patterns it can recognize and generate. That’s why ChatGPT can churn out travel itineraries, B-level
college essays and social media marketing campaigns.

In all the hubbub around AI, it can be tempting to think that AI will eclipse us. That it will expand infinitely, until it can
do all that a college-educated human can do — and more. That it will take over not only the jobs of data crunchers
and coders and copy editors, but also poets and artists and high-level managers.

We are probably right to worry about some of our jobs. But many predictions about AI are overblown. The
technology faces crucial limitations.

AI is limited by the data on which it is trained. Even if you were to train an AI on the entire internet, the AI would
miss out on a lot: thoughts jotted down on a napkin; late-night conversations with a college roommate; that week in
2018 you spent camping in the Rockies; and the feeling of seeing your grandma after a long time apart. None of
that is part of the AI’s world.

AI lacks critical thinking. Can an image-generating AI churn out several versions of a cat in a fedora painted in the
style of Rembrandt? Yup. But can an AI discern which of the paintings is better than the others? No.

Yes, AI can generate incredible content. But it cannot evaluate the content it creates. At least not in the way you
and I can.

Many new AI users make a mistake. They assume it can simply replace entire swaths of human expertise — such
as creating art, writing code or penning essays. This is a misguided assumption. Will AI streamline tasks and

                                                                                                         Page 2 of 2
                     Joseph Vukov: Worried about AI? Here are things you need to know (copy)

eliminate some jobs? Likely, yes. Yet the most effective users of AI are those who are already experts in the
relevant task.

In other words, AI can write code, craft text and generate images, but it is most effective if you already know what
you are doing. For example, I have friends who write code, and they tell me that the code AI writes is good but
needs to be consolidated and cleaned up by a human.

Likewise, as a writer, I believe AI can be a helpful tool. It can generate ideas, word choices and metaphors. But for
an undergraduate churning out a last-minute essay, AI will be far less useful. The essay won’t come together
without someone to form it.

Since I started writing about AI, I get asked a lot about "The Terminator." Are cyborgs going to take over? No. Yet
we should still worry about AI. It is poised to take over large swaths of human activity and, in doing so, erode our
individual and shared humanity.

The truth is that generative AI is only the tip of the iceberg. The influence and potential dangers of the AI revolution
go far beyond the flashy, generative versions.

For example, AI has been making a splash in health care. Applications can discern subtle differences in radiology
scans and can be used to triage patients and complete physician’s notes. They can be used to craft care plans for
patients upon discharge. Used correctly, AI could deliver more effective health care. But used improperly, AI-
powered health care could exacerbate problems in delivery, rob medicine of the human element and reduce our
view of a person to a collection of data.

AI is also in Big Retail. You’ve likely bought a book on the recommendation of Amazon’s algorithm, viewed videos
based on YouTube’s suggestions and clicked on an ad for a product you never would have looked up on your own.
In all these instances, AI predicts your preferences. Scarier still, the AI helps shape your preferences in the first
place, creating a desire and then immediately offering the opportunity to satisfy it. In each of these interactions, we
lose a sliver of our humanity. We cede our desires to the algorithms. We become more materialistic and less free.

We become, in a word, less human.

AI does, indeed, threaten our humanity. Not in the form of a cyborg but with the promise of a funny YouTube video
or a new pair of jeans.

In the early days of the internet, when it was slow-moving and quirky, we couldn’t have imagined smartphones,
streaming platforms and online banking becoming part of our daily lives.

Similarly, AI is finding its legs. Like the internet, AI is poised to infiltrate our lives in myriad and unexpected
ways. We cannot predict precisely how or where AI will take up residence in 50 years.

How to prepare for this kind of infiltration? By reflecting carefully on AI now. By identifying those areas of lives we
want to retain as human spaces and those we are comfortable ceding to the AI algorithms. By reflecting carefully on
our values, and what it means to be human in the first place.

AI is here to stay. We need to ensure that humanity as we know it is here to stay as well.

Vukov is a philosophy professor and associate director of the Hank Center for the Catholic Intellectual Heritage at
Loyola University Chicago. He is the author of "Staying human in an era of artificial intelligence."


Load-Date: August 2, 2024


  End of Document

                                                                                                      Page 1 of 4
                                 AI interviews are changing the job search - The DePaulia




                  AI interviews are changing the job search - The DePaulia
                                                The Depaulia: DePaul University
                                                      October 21, 2024 Monday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: ARTSLIFE; Pg. 1
Length: 992 words
Byline: Sam Mroz

Body

When DePaul junior Ishan Shah decided to apply for a summer internship in banking at Deloitte, one of the largest
professional service firms in the world, he had a rough idea of what the interview process would entail.

But upon receiving a request to move forward in the application process, he was alarmed by a new interviewing
system. Instead of a human resources representative, he would answer questions from an artificial intelligence
forum designed to record, analyze and ultimately determine his value as a job candidate.

"At first, I thought the idea of it was cool," Shah said. "As someone who did not have much interview experience, it
made me feel more comfortable just talking to a camera and answering questions."

After about one or two rounds, the questions began to feel monotonous, Shah said. He began to miss the
interpersonal aspect of interviews.

In Shah's case, his AI interviewer belonged to a recruitment solutions company known as Hirevue, one of the most
popular human resource management companies that specializes in machine processing. Increasingly, large and
small companies are using AI in various aspects of their businesses.

Although not as overt, even certain networking sites including LinkedIn or Glassdoor have incorporated AI systems
into application review and profile management.

As more AI-driven companies help screen candidates, some businesses are cutting their own internal human
resources and recruiter positions.

But even as these new interview practices make their way into corporate settings, not all participants or spectators
favor the methods used in this new age of hiring.

Tim Cole, an associate professor of Communication and Media in DePaul's College of Communication, specializes
in the studies of deceptive communication, romantic relationships, attachment and relational communication.

                                                                                                         Page 2 of 4
                                AI interviews are changing the job search - The DePaulia

"When we interact with others, it sparks emotions like empathy, happiness and even love," Cole said. "Whether it's
a chat with a friend or working together on a project, these interactions are what make us feel connected to the
world."

Although Cole's work prioritizes a more human touch over a tech-driven approach, he finds that these days the two
are often intertwined.

"Technology opens conversations by making it easier to connect ... but at the same time, it can be detrimental,"
Cole said. "Quick texts or posts can lack depth, and people sometimes avoid real conversations by relying too
much on digital tools."

Despite offering companies a way to cut costs, AI interviews can also dissuade applicants who see it as an
impersonal barrier.

Shah wonders if that means companies will miss out on unique and qualified employees, simply because they don't
match the AI specifications.

After going through this processed system, Shah said the applicant may question the values of the companies.

"As an applicant, applying for a role and then instantly receiving a 'Hirevue' just elongated the application process
and made me feel like more of a cog in the wheel," Shah said.

For human hiring professionals, AI interviews often go against their own training and values, even if enticing from a
streamlining stance.

David Avdul, interim vice president of human resources at DePaul and a part-time faculty member in the School of
Business, wrestles with this conflict as a former corporate HR professional. Before joining DePaul in 2016, he spent
nearly a decade in compensation and benefits management. Now he works to balance both perspectives in the
face of AI.

"We've seen in research that most job interviewers prefer unstructured interviews because they believe it will allow
them to gather richer information about candidates," Avdul said. "However, AI can be extremely powerful and
beneficial in helping to streamline much of the heavy lifting that goes into sourcing and finding qualified candidates."

Avdul sees the value in AI's ability to conserve time, review large sets of data and even to curb potential bias and
errors brought about by human instinct. But he understands that it could also portray a cold and inhumane
demeanor.

But in certain industries, such as the financial sector, Shah has realized it's simply something he must do. In the
past year, he has done over six Hirevue interviews for placement across various financial brands, including EY,
KPMG and JPMorgan Chase & Co.

Avdul agrees it's inevitable.

"Going forward, it will be essential for jobs to adapt their processes, toolkits and mindset with the understanding that
many organizations are going to deploy AI technology for talent acquisition," Avdul said. "I think that's the reality."

Related Stories:
    •    Bring a gun on the CTA? AI might know
    •    Slowing down AI for the health of the planet
    •    AI, democracy and disinformation: How to stay informed without being influenced by fake news

Stay informed with The DePaulia's top stories,

delivered to your inbox every Monday.

                                                                                                Page 3 of 4
                                    AI interviews are changing the job search - The DePaulia

View Story Comments

0

Like This Story

Share on Facebook

Share on X

Email this Story

Print this Story

Leave a Comment

Tags:
    •     AI
    •     artificial intelligence
    •     internships

About the Contributor

Sam Mroz, Arts & Life Editor

Sam is a sophomore pursuing a major in journalism and a minor in media and cinema studies. He enjoys watching
movies (in the theater), cooking and cleaning up after his dirty roommate.

Facebook

Instagram

X

Spotify

YouTube

Email Signup

RSS Feed

Open Search Bar

Search this site

Submit Search
    •     Sections News La DePaulia Arts/Life Sports
    •     Sections Opinions Nation & World Focus
    •     Follow X Instagram Facebook Newsletter Spotify YouTube
    •     About Contact The DePaulia Staff Advertise The DePaulia Code of Ethics Get Involved

The DePaulia

Donate

                                                                                        Page 4 of 4
                             AI interviews are changing the job search - The DePaulia

Have a tip?

Facebook

Instagram

X

Spotify

YouTube

Email Signup

RSS Feed

© 2024 · FLEX Pro WordPress Theme by SNO · Log in

Comments (0)

Share your thoughts...

All

The DePaulia Picks

Reader Picks

Sort: Newest

Cancel reply

Your email address will not be published. Required fields are marked *

Comment * Spam Control Field.Verification Field.

Name *

Email *

Close

Close Modal Window

Close


Load-Date: October 21, 2024


    End of Document

                                                                                                  Page 1 of 2
                              What jobs are safe from AI? Here are 4 career fields to consider




           What jobs are safe from AI? Here are 4 career fields to consider
                                                        The Deseret News
                                                     April 23, 2024 Tuesday



Copyright 2024 The Deseret News Publishing Co. All Rights Reserved

Length: 657 words
Byline: Paul Hoskin

Body


Kristin Murphy, Deseret News Third grade teacher Nereida Lopez talks to one of her students before The Great
Utah ShakeOut earthquake drill at Heartland Elementary School in West Jordan on Thursday, April 18, 2024. 1

We now live in an age of artificial intelligence and robot automation. And while that comes with creative and
educational benefits, some are concerned about AI's potential to disrupt some career fields, per the U.S. Career
Institute.

AI is estimated to play a growing role in the U.S. economy in the years ahead. A 2023 report by the McKinsey
Global Institute found that up to 30% of current working hours in the U.S. economy could become AI-automated by
2030.

And a recent Pew Research analysis covered by CNBC found that roughly 1 in 5 workers in the U.S. could have
"high exposure" to AI - which could either play a beneficial role in the job or lead to job displacement.

AI interference is already common in some industries. In a recent survey by Resume Builder, 37% of business
leaders claimed their companies replaced employees with AI in 2023, and 44% claimed that AI will lead to layoffs
this year.

So what jobs could be safe from AI's grasp?

1. Health care

Forbes argued that jobs associated with mental health in health care require "a significant social or emotional
component," which makes them less susceptible to AI interference.

Additionally, the U.S. Career Institute analyzed 65 occupations with an "automation risk probability of 0%" and
found that nurse practitioners had the highest projected growth by 2031 - out of all applicable occupations.
Physician assistants, mental health counselors and post-secondary nursing instructors ranked among the top five
in projected growth.

                                                                                                         Page 2 of 2
                          What jobs are safe from AI? Here are 4 career fields to consider

However, AI can provide some benefit to the health care system. The California Health Care Foundation wrote that
it could be used to "explore insurance coverage options, predict hospital admission rates, or enhance culturally
concordant care."

2. Education

Peter Stone, a professor of computer science at the University of Texas at Austin, told Education Week that
teachers' jobs will be "transformed" but are "not going to disappear." He highlighted a teacher's ability to "watch the
student" and "adjust the curriculum" when students aren't adjusting.

"Did a calculator replace the role of human teachers in math classrooms? No. The teacher now has to teach how to
do arithmetic without a calculator and then how to use the calculator appropriately," Stone told Education Week.

NASDAQ reported that a teacher's role - outside of conveying information - includes mentoring and "shaping young
minds," and that these personal touches that allow teachers to "remain indispensable."

3. Law

While AI can be used to review legal documents - and can reduce human error - it may not replace actual lawyers
and attorneys, according to Forbes.

Kirsten Whitfield, a privacy specialist at Fieldfisher Law, told Forbes that legal work generally still requires a human
touch.

"Lawyers don't just help navigate the law, they help clients make risk-based judgment calls in complex
circumstances. Those judgment calls are guided by life and professional experience that AI cannot recreate," she
said.

Paul Britton, CEO of legal firm Britton &amp; Time, told Forms that AI is not very good at nuance. "You can only
program AI to do certain things dependent on input," he said.

4. Creative professionals

Writers, artists and other creatives develop a "unique blend of cultural understanding, personal expression, and
emotional resonance" that "remains elusive to algorithms," according to NASDAQ.

In an interview with Fortune that was later highlighted by Business Insider, Adobe's senior vice president of digital
media, Ashley Still, claimed AI won't end graphic design jobs.

"Think about the invention of the camera," Still said, according to Business Insider. "People thought painting was
going to go away, and it didn't. It's just that a new type of content emerged."


Load-Date: April 22, 2024


  End of Document

                                                                                                          Page 1 of 2
                                  University of Dayton to present 3 learning events this week




                University of Dayton to present 3 learning events this week
                                                    Dayton Daily News (Ohio)
                                                    April 11, 2024 Thursday



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2024 Cox Ohio Publishing.

Section: LOCAL
Length: 357 words
Byline: Daniel Susco

Body


The University of Dayton will present three learning events this week on digital learning, health and environmental
justice and AI in healthcare.

Local snake slithers into national 'Wacky Pet Names' contest and needs your vote

Health and environmental justice symposium

The first of the three events is the third annual Imagining Community Symposium on Thursday and Friday at the
Hub Powered by PNC Bank in the Dayton Arcade.

This free event features more than 80 presenters focusing on "solutions that move toward a more just, equitable
and flourishing Dayton," and this year will address health and environmental justice.

The symposium will feature keynote speaker Monica Unseld, Until Justice Data Partners founder and executive
director, along with a screening of "Birthing Justice", which focuses on the experiences of Black women during
pregnancy, delivery and postpartum.

Registration is requested on the university website.

Digital learning day

From 10 a.m. to 2 p.m. Saturday at the Greater Dayton Recreation Center, there will be a digital learning day, with
lessons like finding and applying for jobs online, managing finances through mobile banking apps, using a Gmail
account and others.

The event is free and includes free pizza, raffles, giveaways and more. It is being hosted by the University of
Dayton, CareSource Foundation, City of Dayton, SICSA and Greater Dayton Premier Management.

The Premier Mobile Clinic will also be onsite for health screenings and health and lifestyle education.

AI in healthcare symposium

                                                                                                     Page 2 of 2
                            University of Dayton to present 3 learning events this week

Also on Saturday, the 14th annual University of Dayton and Miami Valley Hospital symposium will take place from 9
a.m. to 1:30 p.m. at Kennedy Union.

The symposium will discuss artificial intelligence and its effects of patient care, medical research and healthcare
systems, including a keynote address by Dr. Sameer Badlani, a panel discussion on the ethical considerations,
small group discussions, poster presentations from UD students and more.

Registration is available on the university website. The symposium is $50 for community members and free for
students, medical residents and UD faculty and staff.


Load-Date: April 11, 2024


  End of Document

                                                                                                        Page 1 of 3
                             Mammography AI can cost patients extra. Is it worth the money?




          Mammography AI can cost patients extra. Is it worth the money?
                                                    The Philadelphia Inquirer
                                                    January 14, 2024 Sunday



Copyright 2024 Philadelphia Newspapers, LLC All Rights Reserved

Section: HEALTH; Pg. G1
Length: 1354 words
Byline: Michelle Andrews (KFF Health News)

Body


As I checked in at a Manhattan radiology clinic for my annual mammogram in November, the front desk staffer
reviewing my paperwork asked an unexpected question: Would I like to spend $40 for an artificial intelligence
analysis of my mammogram? It's not covered by insurance, she added.

I had no idea how to evaluate that offer. Feeling upsold, I said no. But it got me thinking: Is this something I should
add to my regular screening routine? Is my regular mammogram not accurate enough? If this AI analysis is so
great, why doesn't insurance cover it?

I'm not the only person posing such questions. The mother of a colleague had a similar experience when she went
for a mammogram recently at a suburban Baltimore clinic. She was given a pink pamphlet that said: "You Deserve
More. More Accuracy. More Confidence. More power with artificial intelligence behind your mammogram." The
price tag was the same: $40. She also declined.

In recent years, AI software that helps radiologists detect problems or diagnose cancer using mammography has
been moving into clinical use. The software can store and evaluate large datasets of images and identify patterns
and abnormalities that human radiologists might miss. It typically highlights potential problem areas in an image and
assesses any likely malignancies. This extra review has enormous potential to improve the detection of suspicious
breast masses and lead to earlier diagnoses of breast cancer.

While studies showing better detection rates are extremely encouraging, some radiologists say, more research and
evaluation are needed before drawing conclusions about the value of the routine use of these tools in regular
clinical practice.

"I see the promise and I hope it will help us," said Etta Pisano, a radiologist who is chief research officer at the
American College of Radiology, a professional group for radiologists. However, "it really is ambiguous at this point
whether it will benefit an individual woman," she said. "We do need more information."

The radiology clinics that my colleague's mother and I visited are both part of RadNet, a company with a network of
more than 350 imaging centers around the country. RadNet introduced its AI product for mammography in New
York and New Jersey last February and has since rolled it out in several other states, according to Gregory
Sorensen, the company's chief science officer.

                                                                                                          Page 2 of 3
                          Mammography AI can cost patients extra. Is it worth the money?

Sorensen pointed to research the company conducted with 18 radiologists, some of whom were specialists in
breast mammography and some of whom were generalists who spent less than 75% of their time reading
mammograms. The doctors were asked to find the cancers in 240 images, with and without AI. Every doctor's
performance improved using AI, Sorensen said.

Among all radiologists, "not every doctor is equally good," Sorensen said. With RadNet's AI tool, "it's as if all
patients get the benefit of our very top performer."

But is the tech analysis worth the extra cost to patients? There's no easy answer.

"Some people are always going to be more anxious about their mammograms, and using AI may give them more
reassurance," said Laura Heacock, a breast imaging specialist at NYU Langone Health's Perlmutter Cancer Center
in New York. The health system has developed AI models and is testing the technology with mammograms but
doesn't yet offer it to patients, she said.

Still, Heacock said, women shouldn't worry that they need to get an additional AI analysis if it's offered.

"At the end of the day, you still have an expert breast imager interpreting your mammogram, and that is the
standard of care," she said.

About 1 in 8 women will be diagnosed with breast cancer during their lifetime, and regular screening mammograms
are recommended to help identify cancerous tumors early. But mammograms are hardly foolproof: They miss about
20% of breast cancers, according to the National Cancer Institute.

The FDA has authorized roughly two dozen AI products to help detect and diagnose cancer from mammograms.
However, there are currently no billing codes radiologists can use to charge health plans for the use of AI to
interpret mammograms. Typically, the federal Centers for Medicare & Medicaid Services would introduce new
billing codes and private health plans would follow their lead for payment. But that hasn't happened in this field yet
and it's unclear when or if it will.

CMS didn't respond to requests for comment.

Thirty-five percent of women who visit a RadNet facility for mammograms pay for the additional AI review,
Sorensen said.

Radiology practices don't handle payment for AI mammography all in the same way.

The practices affiliated with Boston-based Massachusetts General Hospital don't charge patients for the AI
analysis, said Constance Lehman, a professor of radiology at Harvard Medical School who is co-director of the
Breast Imaging Research Center at Mass General.

Asking patients to pay "isn't a model that will support equity," Lehman said, since only patients who can afford the
extra charge will get the enhanced analysis. She said she believes many radiologists would never agree to post a
sign listing a charge for AI analysis because it would be off-putting to low-income patients.

Sorensen said RadNet's goal is to stop charging patients once health plans realize the value of the screening and
start paying for it.

Some large trials are underway in the United States, though much of the published research on AI and
mammography to date has been done in Europe. There, the standard practice is for two radiologists to read a
mammogram, whereas in the States only one radiologist typically evaluates a screening test.

Interim results from the highly regarded MASAI randomized controlled trial of 80,000 women in Sweden found that
cancer detection rates were 20% higher in women whose mammograms were read by a radiologist using AI
compared with women whose mammograms were read by two radiologists without any AI intervention, which is the
standard of care there.

                                                                                                              Page 3 of 3
                           Mammography AI can cost patients extra. Is it worth the money?

"The MASAI trial was great, but will that generalize to the U.S.? We can't say," Lehman said.

In addition, there is a need for "more diverse training and testing sets for AI algorithm development and refinement"
across different races and ethnicities, said Christoph Lee, director of the Northwest Screening and Cancer
Outcomes Research Enterprise at the University of Washington School of Medicine.

The long shadow of an earlier and largely unsuccessful type of computer-assisted mammography hangs over the
adoption of newer AI tools. In the late 1980s and early 1990s, "computer-assisted detection" software promised to
improve breast cancer detection. Then the studies started coming in, and the results were often far from
encouraging. Using CAD at best provided no benefit, and at worst reduced the accuracy of radiologists'
interpretations, resulting in higher rates of recalls and biopsies.

"CAD was not that sophisticated," said Robert Smith, senior vice president of early cancer detection science at the
American Cancer Society. Artificial intelligence tools today are a whole different ballgame, he said. "You can train
the algorithm to pick up things, or it learns on its own."

Smith said he found it "troubling" that radiologists would charge for the AI analysis.

"There are too many women who can't afford any out-of-pocket cost" for a mammogram, Smith said. "If we're not
going to increase the number of radiologists we use for mammograms, then these new AI tools are going to be very
useful, and I don't think we can defend charging women extra for them."

                KFF Health News                   is a national newsroom that produces in-depth journalism about
health issues and is one of the core operating programs at KFF-an independent source of health policy research,
polling, and journalism. Learn more about               KFF              .

I I see the promise and I hope it will help us. ...It really is ambiguous at this point whether it will benefit an individual
woman. We do need more information.

Etta Pisano, a radiologist who is chief research officer at the American College of Radiology


Load-Date: January 14, 2024


  End of Document

                                                                                                       Page 1 of 2
                                              UHG 's trade secret lawsuit dismissed




                                   UHG's trade secret lawsuit dismissed
                                                  Star Tribune (Minneapolis, MN)
                                                     June 18, 2024 Tuesday
                                                        METRO EDITION



Copyright 2024 Star Tribune All Rights Reserved

Section: BUSINESS; Pg. 1D
Length: 734 words
Byline: NICK WILLIAMS; STAFF WRITER, STAR TRIBUNE (Mpls.-St. Paul)
Highlight: Company accused former execs of stealing information to form rival Minnesota firms.

Body


A federal lawsuit filed by UnitedHealth Group against two of its former executives alleging they stole confidential
company information to create new companies has been dismissed.

Minnetonka-based UHG alleged Ken Ehlert and Mark Pollman used trade secrets to start up several competing
companies, including Sequelae Inc. and Lore Health.

Lore Health recently launched an AI-driven social network called Lore designed to support people trying to
overcome challenges affecting their health and wellness.

The lawsuit aimed to stop Lore Health from "irreparably harming" UnitedHealth and to pay for damages caused or
profits Lore received by allegedly using the trade secrets.

Following arbitration this spring - a binding procedure for settling disputes privately - a judge dismissed the case
May 21.

In separate but identical statements to the Star Tribune, UnitedHealth Group and Lore Health said: "The parties to
the arbitration and the federal lawsuit have settled all claims on mutually agreeable terms. Neither side
acknowledges fault. The parties have released their claims and agreed to go their separate ways."

Minneapolis-based Sequelae Inc., which fully owns Lore, has so far raised $100 million from private investors,
making it one of the heaviest venture-backed

companies in Minnesota. Lore operates remotely with employees in 27 states, the company stated.

Soured relationship

In 2017, Ehlert and Pollman sold their health care research and development firm, Savvysherpa, to UnitedHealth
for $46.8 million. As part of the deal, Ehlert became UnitedHealth's chief scientific officer and CEO of UnitedHealth
Group R & D, which later became Optum Labs, and Pollman joined as chief technology officer of the R & D unit.

                                                                                                          Page 2 of 2
                                        UHG 's trade secret lawsuit dismissed

Savvysherpa, founded in 2009, was developing a Type 2 diabetes management tool called Level2 centered on real-
time glucose monitoring. The acquisition led to the commercial launch of Level2 in early 2021. The relationship
between UnitedHealth and Ehlert and Pollman soured, however, and the two left the company that year.

Ehlert and Pollman said in a separate filing that they were terminated as part of a UnitedHealth restructuring aimed
at exerting total control over the Level2 business.

The pair sued UnitedHealth for allegedly reneging on compensation for Level2, a dispute that eventually went to
arbitration that closed in December 2022.

They claimed the Level2 business was worth between $1.5 billion and $2 billion.

Alleged hard drive exchange

UnitedHealth claimed Ehlert and Pollman were in possession of highly confidential information after they left the
company in July 2021.

Three months after they left, UHG claimed Pollman made a "lunch date" with a former subordinate. He left the lunch
with a hard drive containing nearly 500,000 files from UnitedHealth, including highly sensitive business documents
and emails, some relating to the company's diabetes management programs and other confidential and information
and trade secrets, the lawsuit said.

Shortly after the alleged hard drive exchange, Ehlert and Pollman set up several companies, including Sequelae
Inc. and Lore Health, United claimed.

"These companies were designed to profit off United's confidential information and trade secrets," UHG's complaint
reads. Specifically, UnitedHealth claimed Lore Health's business model closely followed that of Level2.

UnitedHealth also alleged Ehlert and Pollman tried to "cover their tracks" over the course of 2023 by erasing
incriminating information from a previous website for Lore Health and disabling the Sequelae website. The
company also claimed they recruited several doctors to be "the face of the organization."

Lore's ownership said the resolved litigation will not affect business operations, its technology or users.

Lore's technology includes a generative AI large language model called LoreBot that asks questions "to help users
think deeply about what's making them unwell or unhappy and how they can change course," according to a May
news release. "Lore's AI does not give advice, but instead can highlight public conversations by other Lore users
who have found ways to cope with similar circumstances."

Lore is provided by invitation only through employers, health plans and health care systems. The company is
compensated based on the health care savings of its users.

Upon launch, more than 4,000 people were using the Lore platform.

Nick Williams · 612-673-4021


Load-Date: June 18, 2024


  End of Document

                                                                                                        Page 1 of 2
                  House lawmakers warn VA officials about data privacy risks for veterans posed by AI




   House lawmakers warn VA officials about data privacy risks for veterans
                               posed by AI
                                                    Dayton Daily News (Ohio)
                                                    February 1, 2024 Thursday



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2024 Cox Ohio Publishing.

Section: LOCAL
Length: 671 words
Byline: Linda F. Hersey

Body


House lawmakers on Monday grilled officials from the Department of Veterans Affairs over how they plan to protect
millions of veterans' medical records from data breaches as the VA increasingly uses artificial intelligence in health
care.

Rep. Keith Self, R-Texas, questioned the VA's ability to safeguard patient privacy as AI systems require a massive
amount of data for decision-making processes to perform clinical and administrative tasks at the VA.

"How will you protect against the cascading release [of patient data] across the commercial sector?" Self, a member
of the technology modernization subpanel of the House Committee on Veterans' Affairs, asked at a hearing that
looked at the rise of AI at the VA and steps underway to secure data.

Rep. Matt Rosendale, R-Mont., who is the chairman of the subcommittee, said the VA has a history of problems
keeping the health, financial and personal information of veterans secure.

"Data breaches happen every few months, and they have taken many different forms," he said, noting private
patient information has been disclosed from errors in mass postal mailings and employee error and theft.

But those data breaches "represent the Stone Age compared to the privacy risks posed by artificial intelligence,"
Rosendale said. "The VA has thousands of contractors and partner companies that access veterans' health and
personal data today. Controlling how they apply AI will be extremely difficult."

Gil Alterovitz, director of the VA's National Artificial Intelligence Institute, responded the VA can cancel contracts
with commercial vendors that improperly share or "release" private patient data to individuals or parties that do not
have the legal right to see or use the information.

The Office of Inspector General is notified to investigate cases of "egregious activity" that involve major breaches of
"sensitive patient information" improperly accessed, viewed or extracted by a contractor in the course of performing
work for the VA.

                                                                                                          Page 2 of 2
                House lawmakers warn VA officials about data privacy risks for veterans posed by AI

The VA prioritizes patient privacy when developing and analyzing AI programs internally and when contracting with
vendors for AI services, said Charles Worthington, the VA's chief technology officer.

Worthington described the VA's processes for continually monitoring, detecting and responding to online intrusions
and cyber threats. They include "identity management" with a tiered system for user permissions to access data
resources.

He said the VA has implemented what is known as the National Institute of Standards and Technology risk
management framework. The process enables the VA to manage privacy and security.

The VA also is organizing a governance council to provide strategic direction in the development and deployment of
AI in the health care setting, Worthington said. The committee is being formed at the request of the Office of
Management and Budget.

Oversight committees also are being piloted at VA hospitals, he said.

"You've got to have sanctions in place that are fairly severe, and they've got to be clarified in policies upfront," Self
said.

The VA employs AI to scan patients for cancer and to identify words associated with suicidal behavioral risks in
patients' medical records, Rosendale said. AI is used to "extract signals of suicide risk from clinical progress notes
and other medical records."

Rosendale warned about the accuracy of computer software and the potential impacts of wrongly identifying a
veteran as a suicide risk.

"We need to do whatever we can to prevent veteran suicide," he said. "But I'm concerned that this could lead to
violation of veterans rights, limiting personal freedoms and gun ownership."

Rosendale asked whether veterans know that the VA is using the AI technology.

"Shouldn't this be disclosed to the patients so they understand who is performing this analysis?" he asked.

Alterovitz acknowledged there is not a consistent policy across the VA for informing veterans about the use of AI in
their health care.

"That has to be elevated to a top priority," Rosendale said.



Graphic


Rep. Keith Self, R-Texas, and members of the conservative House Freedom Caucus denounce the fiscal year 2024
appropriations process as they decry so-called "woke" spending by Democrats and President Joe Biden, at the
Capitol in Washington, Tuesday, July 25, 2023. (AP Photo/J. Scott Applewhite)


Load-Date: February 1, 2024


  End of Document

                                                                                                        Page 1 of 2
                  House lawmakers warn VA officials about data privacy risks for veterans posed by AI




   House lawmakers warn VA officials about data privacy risks for veterans
                               posed by AI
                                                   Stars and Stripes
                                             January 31, 2024 Wednesday



Copyright 2024 The Stars and Stripes

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 692 words
Byline: Linda F. Hersey, Stars and Stripes

Body


Jan. 31—WASHINGTON — House lawmakers on Monday grilled officials from the Department of Veterans Affairs
over how they plan to protect millions of veterans' medical records from data breaches as the VA increasingly uses
artificial intelligence in health care.

Rep. Keith Self, R-Texas, questioned the VA's ability to safeguard patient privacy as AI systems require a massive
amount of data for decision-making processes to perform clinical and administrative tasks at the VA.

"How will you protect against the cascading release [of patient data] across the commercial sector?" Self, a member
of the technology modernization subpanel of the House Committee on Veterans' Affairs, asked at a hearing that
looked at the rise of AI at the VA and steps underway to secure data.

Rep. Matt Rosendale, R-Mont., who is the chairman of the subcommittee, said the VA has a history of problems
keeping the health, financial and personal information of veterans secure.

"Data breaches happen every few months, and they have taken many different forms," he said, noting private
patient information has been disclosed from errors in mass postal mailings and employee error and theft.

But those data breaches "represent the Stone Age compared to the privacy risks posed by artificial intelligence,"
Rosendale said. "The VA has thousands of contractors and partner companies that access veterans' health and
personal data today. Controlling how they apply AI will be extremely difficult."

Gil Alterovitz, director of the VA's National Artificial Intelligence Institute, responded the VA can cancel contracts
with commercial vendors that improperly share or "release" private patient data to individuals or parties that do not
have the legal right to see or use the information.

The Office of Inspector General is notified to investigate cases of "egregious activity" that involve major breaches of
"sensitive patient information" improperly accessed, viewed or extracted by a contractor in the course of performing
work for the VA.

                                                                                                          Page 2 of 2
                House lawmakers warn VA officials about data privacy risks for veterans posed by AI

The VA prioritizes patient privacy when developing and analyzing AI programs internally and when contracting with
vendors for AI services, said Charles Worthington, the VA's chief technology officer.

Worthington described the VA's processes for continually monitoring, detecting and responding to online intrusions
and cyber threats. They include "identity management" with a tiered system for user permissions to access data
resources.

He said the VA has implemented what is known as the National Institute of Standards and Technology risk
management framework. The process enables the VA to manage privacy and security.

The VA also is organizing a governance council to provide strategic direction in the development and deployment of
AI in the health care setting, Worthington said. The committee is being formed at the request of the Office of
Management and Budget.

Oversight committees also are being piloted at VA hospitals, he said.

"You've got to have sanctions in place that are fairly severe, and they've got to be clarified in policies upfront," Self
said.

The VA employs AI to scan patients for cancer and to identify words associated with suicidal behavioral risks in
patients' medical records, Rosendale said. AI is used to "extract signals of suicide risk from clinical progress notes
and other medical records."

Rosendale warned about the accuracy of computer software and the potential impacts of wrongly identifying a
veteran as a suicide risk.

"We need to do whatever we can to prevent veteran suicide," he said. "But I'm concerned that this could lead to
violation of veterans rights, limiting personal freedoms and gun ownership."

Rosendale asked whether veterans know that the VA is using the AI technology.

"Shouldn't this be disclosed to the patients so they understand who is performing this analysis?" he asked.

Alterovitz acknowledged there is not a consistent policy across the VA for informing veterans about the use of AI in
their health care.

"That has to be elevated to a top priority," Rosendale said.

___ (c)2024 the Stars and Stripes Visit the Stars and Stripes at www.stripes.com Distributed by Tribune Content
Agency, LLC.


Load-Date: February 1, 2024


  End of Document

                                                                                                          Page 1 of 2
                 Opinion: AI already plays a vital role in medical imaging and is effectively regulated




  Opinion: AI already plays a vital role in medical imaging and is effectively
                                   regulated
                                                        TheHill.com
                                               February 24, 2024 Saturday



Copyright 2024 NEXSTAR MEDIA INC. All Rights Reserved




Section: IMAGING EQUIPMENT NEWS
Length: 799 words
Byline: Henry I. Miller, opinion contributor

Body


Artificial intelligence (AI) is all the rage in many aspects of our lives, from composing students’ essays to designing
new fashions. Its use in medicine has enabled physicians and other trained health professionals to make more
timely, accurate diagnoses and guide effective treatment plans, from patient triage to detecting abnormalities during
diagnostic procedures. It is especially good at analyzing X-rays, for example, and has long been used in medical
imaging, leading to greater accuracy and improved patient outcomes.

However, there’s a significant difference between using AI in a highly regulated sector like medical imaging and in
other, unregulated applications of the technology, like ChatGPT, other recent open AI models, or other services that
do not involve a health care professional.

Therefore, public policy should not paint all AI applications with the same broad brush. Congress should recognize,
and leave alone, regulatory oversight that is working well to balance safety, security, and innovation, and instead
focus on creating any needed oversight where AI applications are creating new, unmitigated risks.

Radiologists and other trained health care providers use advanced AI-enabled medical imaging devices to quickly
analyze vast amounts of data, more effectively detect abnormalities, and interpret complex patterns to help inform
their decision-making for patients. The belief that “AI will replace radiologists” is a myth. In fact, radiologists who
utilize regulated AI applications are transforming radiology and harnessing this technology to both make their jobs
easier and improve patient care and outcomes.

During my last colonoscopy, for example, the gastroenterologist used a new AI tool called “GI Genius” to help
detect abnormalities such as polyps or adenomas (precancerous lesions) in the colon in real-time. The FDA
approved it in 2021 based on a trial in 700 subjects undergoing a colonoscopy for colorectal cancer screening.

                                                                                                         Page 2 of 2
                Opinion: AI already plays a vital role in medical imaging and is effectively regulated

Colonoscopy plus GI Genius was able to identify lab-confirmed adenomas or carcinomas in 55.1 percent of patients
compared to 42.0 percent of patients with standard colonoscopy.

My gastroenterologist said that he occasionally found polyps that GI Genius missed, and vice versa, and that the
module is getting smarter and more accurate as more examples of colonoscopies are being fed into its database.

Such tools are a win for everyone.

For years, the Food & Drug Administration (FDA) has exercised regulatory authority over AI medical imaging
devices, ensuring they are held to the same rigorous, stringent level of regulation as the rest of the medical device
landscape. FDA’s oversight of AI medical imaging devices includes both a pre-market review process to assess
safety and effectiveness as well as robust post-market monitoring that ensures ongoing performance of devices
after they’ve been approved for use. Before approval, all AI medical imaging devices must be reviewed for safety
and effectiveness by the FDA, and the agency’s strict labeling requirements help ensure proper use by providing
detailed information for the intended user. Manufacturers of AI-enabled medical imaging devices must also maintain
a quality-management system that meets FDA requirements.

To date, the FDA has authorized more than 500 AI medical imaging devices, helping to revolutionize clinical
radiology while greatly improving patient care and outcomes. Having served at the Agency for 15 years and studied
it for another 30, I am confident in the FDA’s ability to continue playing a strong regulatory role in overseeing AI in
health care and medical imaging.

As policy debates over regulating AI continue in Washington, it is vital that policymakers clearly distinguish between
the regulated use of AI in medical imaging from other AI applications that may or may not need regulatory
guardrails. Adding additional regulation to the use of AI in medical imaging and health care — where effective
regulation already exists — runs the risk of slowing innovation and undermining patient care.

The FDA has done an exemplary job regulating the application of AI in medical imaging, carefully balancing the
need for innovation with oversight to deliver safety and improved care for patients. The FDA should continue to be
responsible for the oversight of AI in medical imaging while Congress, regulators, and product developers in other
industries address the range of regulatory concerns in other forms and applications of AI.

Henry I. Miller, a physician and molecular biologist, is the Glenn Swogger Distinguished Fellow at the American
Council on Science and Health. He was the founding director of the FDA’s Office of Biotechnology. Find Dr. Miller
on X @HenryIMiller

For the latest news, weather, sports, and streaming video, head to The Hill.


Load-Date: February 23, 2024


  End of Document

                                                                                                            Page 1 of 3
                       Opinion: Don't hate artificial intelligence. Enlist AI to support victims of hate.




Opinion: Don't hate artificial intelligence. Enlist AI to support victims of hate.
                                                        USA Today Online
                                                 October 8, 2024 9:05 AM EST



Copyright 2024 Gannett Media Corp All Rights Reserved

Length: 1175 words

Body


The most recent hate against Haitian Americans feels depressingly familiar: rumors and lies, amplified online and
by prominent leaders, invoke racist tropes and incite violence. Already, bomb threats in Springfield, Ohio, have
forced schools and city buildings to close. An entire community fears that its most vulnerable members ‒
immigrants and children ‒ will fall victim.

As researchers who study the effects of anti-Asian hate, we’ve seen this all before. The challenge remains the
same: how to support community members facing hate and discrimination.

When anti-AAPI hate incidents, fueled by xenophobic rhetoric, surged during the COVID-19 pandemic, the sudden
urge to aid Asian Americans and Pacific Islanders ‒ too often dismissed as monolithic or as model minorities ‒ was
a welcome change. Community-based organizations provided legal services, case management, mental health
services and community gatherings to the elderly, recent immigrants and those with limited English, living in
enclaves such as Chinatown.

But Asian Americans and Pacific Islanders still need more support.

A troubling paradox between older and younger immigrants

Link to Image

Anti-Asian hate didn’t start with the pandemic, and it certainly didn’t end there. A new report by Stop AAPI Hate and
the National Opinion Research Center at the University of Chicago found that last year, 49% of Asian Americans
and Pacific Islanders were victims of a hate act in the United States.

Our own research uncovered a troubling paradox within this trend. Surveying 835 Asian Americans in Los Angeles
and New York City about their experiences with hate and community services, we found ‒ to our surprise ‒ that
U.S.-born or early-immigrant Asians, and who were financially better off, were more likely to report hate incidents
than older, first-generation immigrants.

Even as they were more likely to have reported hate, they found it harder to get help. Some of these younger, U.S.-
born Asian Americans told us they didn’t seek help because they had more pressing concerns or doubted things
would change by reporting an incident.

                                                                                                         Page 2 of 3
                    Opinion: Don't hate artificial intelligence. Enlist AI to support victims of hate.

Opinion: Hate against Haitian immigrants ignores how US politics pushed them here

These findings point to a larger disconnect.

Community-based organizations, while providing crucial services, can zero in on specific groups ‒ the elderly or
non-English speaking immigrants who might live nearby ‒ which often means that they inadvertently overlook other
AAPIs who might blend in but, it turns out, are equally in need.

Opinion alerts: Get columns from your favorite columnists + expert analysis on top issues, delivered straight to
your device through the USA TODAY app. Don't have the app? Download it for free from your app store.

As a result, despite reporting more discrimination at a higher rate than older, first-generation immigrants, these
younger, more assimilated AAPIs weren’t able to get services from community-based organizations and didn’t feel
they had anywhere else to turn.

That makes it imperative to help community organizations reach and support more Asian Americans and Pacific
Islanders. And that’s where increasingly available technologies, such as artificial intelligence, could help.

How a chatbot could help victims of hate

Busy AAPI parents and professionals, like a lot of us, might be most easily reached on their smartphones, where
AI-powered mental health apps already provide help, when and where people need it.

For AAPIs not served by community-based organizations, such AI tools could be a game changer. That is if one-
size-fits-all apps evolved into culturally attuned resources, designed to support the well-being of specific
communities.

Imagine a victim-service chatbot, armed with a community-based organization’s deep knowledge of localized
information and obtuse regulations, that can talk fluently to young AAPI professionals and their elderly relatives.
Following a hate incident, the victim could, say, describe that incident, and the chatbot could suggest how to report
it, confirm its entry into hate incident databases, describe help they could seek, contact a caseworker and perhaps
even assess whether the incident could be prosecuted as a hate crime.

Opinion: AI conspiracy theories are here. Don't believe everything you read.

There are reasons to be skeptical of enlisting AI to fight hate. After all, hate proliferates on AI-powered social
media.

Chatbots and image generators produce racial stereotypes. And many Americans are wary of AI in daily life.

However, a chatbot dedicated to assisting victims of hate might help address such concerns. Mental health
chatbots have their problems but they also have advantages, such as providing answers in the language people
prefer.

Link to Image

To be sure, much work lies ahead to develop such a chatbot. For one, chatbots would need to be culturally tailored,
as many existing ones do not adequately capture cultural nuance and thus risk worsening bias.

For instance, Black AI founders have launched their own chatbots to address what they see as shortcomings in
how well ChatGPT and other AI tools understand Black history and culture.

                                                                                                         Page 3 of 3
                    Opinion: Don't hate artificial intelligence. Enlist AI to support victims of hate.

Likewise, cultural identities influence how AAPIs experience stress and distress, access services and seek help.
Chatbots would need to recognize lesser-known challenges ‒ like the fact that income inequality is greatest among
Asian Americans, and that Chinese Americans have the highest income inequality among Asian Americans.

Link to Image

Tech developers and founders could seize this opportunity to build artificial intelligence tools that resonate with and
support the diverse needs of Asian Americans, Haitian Americans or others affected by hate. AI companies could
bolster language and cultural capabilities. With adequate resources, community-based organizations could adapt
their services to be inclusive of all generations and provide the evidence-based guidance needed to develop such
chatbots.

Much of the recent excitement around AI hinges on its potential to upend society ‒ for both good and ill. But
meaningful change often starts within a community. California, as one example, has initiated an array of efforts to
attack hate against Americans who are Black, transgender or Muslim, among others.

Supporting Asian Americans and others who experience hate could be just one way to harness AI technology for
good. Done right, it could transform the healing capacity of communities still grappling with widespread hate,
ensuring that no one is left unseen or left behind.

Douglas Yeung is a senior behavioral scientist at RAND and a professor of policy analysis at the Pardee RAND
Graduate School. Lu Dong is a behavioral scientist at RAND and a professor of policy analysis at the Pardee RAND
Graduate School.

You can read diverse opinions from our USA TODAY columnists and other writers on the Opinion front page, on X,
formerly Twitter, @usatodayopinion and in our Opinion newsletter.

This article originally appeared on USA TODAY: Opinion: Don't hate artificial intelligence. Enlist AI to support
victims of hate.


Load-Date: October 8, 2024


  End of Document

                                                                                                         Page 1 of 4
                                 AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS




                  AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS
                                               Pittsburgh Post-Gazette
                                               March 26, 2024 Tuesday
                                                 SOONER EDITION



Copyright 2024 P.G. Publishing Co.

Section: ASECTION; Pg. A-1
Length: 1363 words
Byline: Kris B. Mamula Pittsburgh Post-Gazette

Body


Artificial intelligence is making its way into medical offices throughout Pennsylvania, including those in Pittsburgh,
with the tantalizing promise of fewer administrative headaches for doctors and better care for patients.

The transition could be bumpy: Among obstacles to widespread adoption of tech that instantly taps vast stores of
information will be doctors' resistance to change how they've practiced medicine, experts say. For patients, the
selling point could be more eye contact and better communication during office visits, if doctors aren't tied up with a
computer screen, typing notes into a medical record.

But that's just the start.

Google, Microsoft and Nvidia are among the tech giants plowing money into medicine. For the 12 months ending
July 30, 2023, the Food and Drug Administration approved 171 AI or machine learning devices for use in medicine,
a number that was expected to increase 30% for the year compared to 2022.

Nearly 700 AI-like devices have been approved by the FDA since 1995.

Up for grabs is a market expected to reach $51.3 billion by 2030 from just $2.9 billion in 2022, according to India-
based market research firm Insights 10.

In the coming weeks, artificial intelligence will be introduced at the 14-hospital Allegheny Health Network - first with
the goal of chipping away at the administrative workload of doctors, nurses and others, and later to take on some
far less mundane tasks including monitoring high-risk patients.

AHN rival UPMC has also been adding AI tools in the clinician's office, with the same early goal of freeing doctors
from medical record documentation through what's called "ambient listening."

With patients' permission, AI software will "listen" to the physician-patient conversation in the office, then organize
the notes into the written medical record. The doctor's role will be reduced to simply editing the software's notes for
final entry.

                                                                                                        Page 2 of 4
                              AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS

And other, more ambitious, ways to tap the capabilities of artificial intelligence will find their way into the local
health care workforce soon.

AHN's 22,000 employees will soon get access to Google's Vertex AI Search and Sidekick software that can, for
instance, draft letters to health insurers on behalf of patients who need specialty medications, medical equipment
or other care that's not standard in their insurance benefits. The program will be "trained" on internal Highmark
Health data rather than publicly available information sources, like ChatGPT and similar tools.

"It's paradoxical, but AI is going to humanize health care," said Ashis Barad, a pediatrician and AHN chief digital
and information officer. "It will not replace anybody."

Ford, Seagate, Wayfair and Lowe's are among other corporate users of Vertex AI, a cloud-based platform Google
developed in 2021, according to San Francisco online newspaper TechCrunch. Mayo Clinic and HCA Healthcare,
which operates more than 2,000 hospitals in the U.S. and Britain, are also Google AI customers.

Highmark and UPMC have long been rivals, so it isn't surprising the two Pittsburgh health care giants have chosen
different paths to the world of artificial intelligence.

UPMC has partnered with Google rival Microsoft, subsidiary Nuance Communications and Pittsburgh startup
Abridge AI Inc. to allow doctors and other care providers to use Nuance's DAX Copilot ambient listening software to
organize and write patient exam narratives for medical records.

Privately held Abridge was founded in 2018 and automates clinical notes. The startup has offices in Lawrenceville
and elsewhere.

Microsoft acquired Nuance for $19.7 billion in 2021. Microsoft is also a major investor in OpenAI, the for-profit arm
of the San Francisco company founded in 2021 that created all the buzz a year later around generative AI models
like ChatGPT.

"Operational efficiency has the potential of being greatly aided by AI," said Robert Bart, a UPMC pediatric
intensivist and system chief medical information officer. "It can listen, then create the document for the workflow,
creating a much more natural, caring interaction to occur between the doctor and patient."

Figuring out what AI can do

Throughout the U.S., the industry is going big for artificial intelligence, with academic medical centers tapping AI's
vast reserves of information to do things like better identify pre-diabetes, perform retinal exams for early signs of
disease and detect an array of cancers as well or better than humans.

Eventually, doctors at both AHN and UPMC envision a far bigger role for AI than the initial documentation tasks,
with some of the possibilities growing out of evolving partnerships between Epic Systems and AI vendors. Both
health systems use the Verona, Wis., company's services to store patient medical records.

Tasks that artificial intelligence tools could pick up include writing patient progress notes, responding to emailed
questions from patients and suggesting medical coding, which is the basis of billing.

Dr. Bart envisions the day when such a tool might note a change in the seriousness of a medical problem based on
the doctor's conversation with the patient, alert the physician that a certain prescription drug is not covered by the
patient's health insurance or even suggest a diagnosis.

"AI is not going to replace who I am as a physician, but I believe physicians who adopt AI will be better prepared to
deliver high-quality care into their practice," Dr. Bart said.

Separately, AHN is preparing to introduce a smart patient room and a digital nursing program at its Forbes Hospital
in the coming weeks.

                                                                                                           Page 3 of 4
                             AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS

A 47-bed unit of the Monroeville hospital is being equipped with monitors that will allow a seasoned nurse at a North
Shore office - or even at home - to brief new patients in a live chat on what to expect during their stay and also
provide discharge instructions before they go home.

Permission from the patient will be required. A doorbell chime will mark the start of the session.

Admissions' briefings typically take 45 minutes and discharge instructions last 20-30 minutes, Forbes Hospital Chief
Nursing Officer Lynn Kosar said. That's time that floor nurses could be spending instead with patients, she said.

"These things really help our nursing staff focus more on patients, getting them their meds, making sure patients
are getting the best care we can," Ms. Kosar said. "Nurses see the value in it. They're really excited."

AHN nurses spend two hours of every typical 12-hour shift recording test results and other information in patient
medical records, according to an internal study, Dr. Barad said. Only 45% of their time is spent on direct patient
care, compromising the reason many nurses choose the vocation.

Partnering with Orlando, Fla.-based care.ai, a company specializing in virtual medical care systems, AHN is
preparing for the day when AI will monitor hospital patients with dementia or who risk falling because of dizziness or
other issues. Today, these patients may require someone to be in the room with them at all times, but AHN
anticipates high-risk patients could eventually be monitored remotely by AI and sensors on their bed.

Starting at Forbes, smart patient rooms are slated to be rolled out throughout AHN's hospital system.

Change is hard

A 2023 survey by the American Medical Association found that 65% of more than 1,000 doctors surveyed saw
advantages to what the medical organization called "augmented intelligence." But doctors also worried about data
privacy issues and legal liability for AI-generated medical errors.

For some doctors, change is just hard, AHN's Dr. Barad said, especially older physicians who've been practicing for
years. It's his job to make the case for embracing AI to the health system's medical staff.

Dr. Barad was reminded of a 2014 study at the University of Bristol that found most ants instinctively turn left when
entering unfamiliar places.

Part of the reason may be in seeking strength in numbers since other ants exhibit similar behavior, an analogy that
can be extended to seasoned doctors, he said.

"It's easier to go through the inefficiencies they know," Dr. Barad said. "I'm the left-turn guy. My job is empathy."

Kris B. Mamula: kmamula@post-gazette.com



Graphic


PHOTO: care.ai: Orlando, Fla.-based care.ai is partnering with Allegheny Health Network in installing cameras and
screens in patient rooms to allow remote nurses to talk with patients. The video link is expected to allow floor
nurses to spend more time with patients.


Load-Date: March 27, 2024

                                                                   Page 4 of 4
                  AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS


End of Document

                                                                                                         Page 1 of 4
                                 AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS




                  AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS
                                               Pittsburgh Post-Gazette
                                               March 26, 2024 Tuesday
                                                 SOONER EDITION



Copyright 2024 P.G. Publishing Co.

Section: ASECTION; Pg. A-1
Length: 1363 words
Byline: Kris B. Mamula Pittsburgh Post-Gazette

Body


Artificial intelligence is making its way into medical offices throughout Pennsylvania, including those in Pittsburgh,
with the tantalizing promise of fewer administrative headaches for doctors and better care for patients.

The transition could be bumpy: Among obstacles to widespread adoption of tech that instantly taps vast stores of
information will be doctors' resistance to change how they've practiced medicine, experts say. For patients, the
selling point could be more eye contact and better communication during office visits, if doctors aren't tied up with a
computer screen, typing notes into a medical record.

But that's just the start.

Google, Microsoft and Nvidia are among the tech giants plowing money into medicine. For the 12 months ending
July 30, 2023, the Food and Drug Administration approved 171 AI or machine learning devices for use in medicine,
a number that was expected to increase 30% for the year compared to 2022.

Nearly 700 AI-like devices have been approved by the FDA since 1995.

Up for grabs is a market expected to reach $51.3 billion by 2030 from just $2.9 billion in 2022, according to India-
based market research firm Insights 10.

In the coming weeks, artificial intelligence will be introduced at the 14-hospital Allegheny Health Network - first with
the goal of chipping away at the administrative workload of doctors, nurses and others, and later to take on some
far less mundane tasks including monitoring high-risk patients.

AHN rival UPMC has also been adding AI tools in the clinician's office, with the same early goal of freeing doctors
from medical record documentation through what's called "ambient listening."

With patients' permission, AI software will "listen" to the physician-patient conversation in the office, then organize
the notes into the written medical record. The doctor's role will be reduced to simply editing the software's notes for
final entry.

                                                                                                        Page 2 of 4
                              AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS

And other, more ambitious, ways to tap the capabilities of artificial intelligence will find their way into the local
health care workforce soon.

AHN's 22,000 employees will soon get access to Google's Vertex AI Search and Sidekick software that can, for
instance, draft letters to health insurers on behalf of patients who need specialty medications, medical equipment
or other care that's not standard in their insurance benefits. The program will be "trained" on internal Highmark
Health data rather than publicly available information sources, like ChatGPT and similar tools.

"It's paradoxical, but AI is going to humanize health care," said Ashis Barad, a pediatrician and AHN chief digital
and information officer. "It will not replace anybody."

Ford, Seagate, Wayfair and Lowe's are among other corporate users of Vertex AI, a cloud-based platform Google
developed in 2021, according to San Francisco online newspaper TechCrunch. Mayo Clinic and HCA Healthcare,
which operates more than 2,000 hospitals in the U.S. and Britain, are also Google AI customers.

Highmark and UPMC have long been rivals, so it isn't surprising the two Pittsburgh health care giants have chosen
different paths to the world of artificial intelligence.

UPMC has partnered with Google rival Microsoft, subsidiary Nuance Communications and Pittsburgh startup
Abridge AI Inc. to allow doctors and other care providers to use Nuance's DAX Copilot ambient listening software to
organize and write patient exam narratives for medical records.

Privately held Abridge was founded in 2018 and automates clinical notes. The startup has offices in Lawrenceville
and elsewhere.

Microsoft acquired Nuance for $19.7 billion in 2021. Microsoft is also a major investor in OpenAI, the for-profit arm
of the San Francisco company founded in 2021 that created all the buzz a year later around generative AI models
like ChatGPT.

"Operational efficiency has the potential of being greatly aided by AI," said Robert Bart, a UPMC pediatric
intensivist and system chief medical information officer. "It can listen, then create the document for the workflow,
creating a much more natural, caring interaction to occur between the doctor and patient."

Figuring out what AI can do

Throughout the U.S., the industry is going big for artificial intelligence, with academic medical centers tapping AI's
vast reserves of information to do things like better identify pre-diabetes, perform retinal exams for early signs of
disease and detect an array of cancers as well or better than humans.

Eventually, doctors at both AHN and UPMC envision a far bigger role for AI than the initial documentation tasks,
with some of the possibilities growing out of evolving partnerships between Epic Systems and AI vendors. Both
health systems use the Verona, Wis., company's services to store patient medical records.

Tasks that artificial intelligence tools could pick up include writing patient progress notes, responding to emailed
questions from patients and suggesting medical coding, which is the basis of billing.

Dr. Bart envisions the day when such a tool might note a change in the seriousness of a medical problem based on
the doctor's conversation with the patient, alert the physician that a certain prescription drug is not covered by the
patient's health insurance or even suggest a diagnosis.

"AI is not going to replace who I am as a physician, but I believe physicians who adopt AI will be better prepared to
deliver high-quality care into their practice," Dr. Bart said.

Separately, AHN is preparing to introduce a smart patient room and a digital nursing program at its Forbes Hospital
in the coming weeks.

                                                                                                           Page 3 of 4
                             AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS

A 47-bed unit of the Monroeville hospital is being equipped with monitors that will allow a seasoned nurse at a North
Shore office - or even at home - to brief new patients in a live chat on what to expect during their stay and also
provide discharge instructions before they go home.

Permission from the patient will be required. A doorbell chime will mark the start of the session.

Admissions' briefings typically take 45 minutes and discharge instructions last 20-30 minutes, Forbes Hospital Chief
Nursing Officer Lynn Kosar said. That's time that floor nurses could be spending instead with patients, she said.

"These things really help our nursing staff focus more on patients, getting them their meds, making sure patients
are getting the best care we can," Ms. Kosar said. "Nurses see the value in it. They're really excited."

AHN nurses spend two hours of every typical 12-hour shift recording test results and other information in patient
medical records, according to an internal study, Dr. Barad said. Only 45% of their time is spent on direct patient
care, compromising the reason many nurses choose the vocation.

Partnering with Orlando, Fla.-based care.ai, a company specializing in virtual medical care systems, AHN is
preparing for the day when AI will monitor hospital patients with dementia or who risk falling because of dizziness or
other issues. Today, these patients may require someone to be in the room with them at all times, but AHN
anticipates high-risk patients could eventually be monitored remotely by AI and sensors on their bed.

Starting at Forbes, smart patient rooms are slated to be rolled out throughout AHN's hospital system.

Change is hard

A 2023 survey by the American Medical Association found that 65% of more than 1,000 doctors surveyed saw
advantages to what the medical organization called "augmented intelligence." But doctors also worried about data
privacy issues and legal liability for AI-generated medical errors.

For some doctors, change is just hard, AHN's Dr. Barad said, especially older physicians who've been practicing for
years. It's his job to make the case for embracing AI to the health system's medical staff.

Dr. Barad was reminded of a 2014 study at the University of Bristol that found most ants instinctively turn left when
entering unfamiliar places.

Part of the reason may be in seeking strength in numbers since other ants exhibit similar behavior, an analogy that
can be extended to seasoned doctors, he said.

"It's easier to go through the inefficiencies they know," Dr. Barad said. "I'm the left-turn guy. My job is empathy."

Kris B. Mamula: kmamula@post-gazette.com



Graphic


PHOTO: care.ai: Orlando, Fla.-based care.ai is partnering with Allegheny Health Network in installing cameras and
screens in patient rooms to allow remote nurses to talk with patients. The video link is expected to allow floor
nurses to spend more time with patients.


Load-Date: March 26, 2024

                                                                   Page 4 of 4
                  AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS


End of Document

                                                                                                    Page 1 of 2
                                                Reforming Federal Health Care




                                        Reforming Federal Health Care
                                                        Economic Thinking
                                                        July 5, 2024 Friday



Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 Economic Thinking, USA All Rights Reserved

Length: 538 words
Byline: Gregory Rehmke

Body

Past Economic Thinking posts have reviewed health care policies and ideas for reform. The 2024 Stoa policy topic
is:
Resolved: The United States Federal Government should substantially reform its policy on healthcare.

Though many critics think the US has a "free market" or market-based health care system, it is a heavily regulated
and federally subsidized system. The Peter G. Peterson foundation notes:

Link to Image
    •     Government insurance programs, such as Medicare and Medicaid, made up 45 percent, or $1.9 trillion, of
          national healthcare spending.
    •     Private insurance programs, including employer-provided health insurance as well as plans purchased
          through the Affordable Care Act, accounted for 30 percent, or about $1.3 trillion.

The Cato Institute's Michael F. Cannon, author of Recovery: A Guide to Reforming the U.S. Health Sector
(October, 2023) (PDF here)
Cannon give an overview in this June 17, 2024 discussion at the Institute for Economic Affairs in London: The Myth
of America's Free Market Healthcare | IEA Book Club

There is of course much more to say about federal health care reform, but students (and parents) shouldn't feel
overwhelmed by the topic. Most health care services are local and most health care regulations and programs are
local and state. State level policies and programs likely should be reformed, but the Stoa topic calls for USFG to
"substantially reform its policy on healthcare."

Homeschool debate alumni now reforming federal health care policies

A number of today's health care policy experts were homeschooled debaters (and many attended FEE or
Economic Thinking workshops).
    •     Lawson Mansell, Niskanen Center
    •     Jonathan Wolfson, Cicero Institute

                                                                                                         Page 2 of 2
                                           Reforming Federal Health Care

    •   Jonathan Williamson, ALEC
    •   Maxford Nelson, Freedom Foundation
    •   Andrew Trask, Deep Mind, OpenMined

1. Lawson Mansell, former NCFCA debater, now Health Policy Analyst at the Niskanen Center. Lawson worked at
the Milken Institute on health care issues. I've emailed Lawson and he is interested in participating and has case
ideas.
2. Jonathan Wolfson at Cicero Institute I haven't contacted Jonathan yet. Jonathan is Diana Wolfson's son. And
Cicero Institute is sponsor of State Policy Network August annual meeting in Arizona.
3. Jonathan Williams, ALEC. Jonathan was homeschool debater in Michigan and attended an early FEE or
Economic Thinking workshop. Now he is with the American Legislative Exchange. They work to network pro-market
state legislators. Here Jonathan is with Medicaid expansion video.

4, Maxford Nelson, former Seattle debater. I earlier read Max's work on resisting state mandates to push homecare
workers (federally funded) to join labor union. I don't know the latest on this. But for all federal and state funded or
assisted health care, there is push to unionize everyone as condition of state or federal funds. Here are other
Freedom Fd. health care posts

5. Andrew Trask, Deep Mind and Openmined. Andrew was a homeschool debater in Memphis and I was in touch
with him for the AI topic. He has videos and articles on his privacy preserving AI for health care. Most medical
records are protected by federal regulations so can't be shared without security. But that limit research that could
discover possible causes for illnesses.


Load-Date: July 6, 2024


  End of Document

                                                                                                         Page 1 of 2
                             Is Your Government AI-Ready? An Interactive Tracker of AI Action




         Is Your Government AI-Ready? An Interactive Tracker of AI Action
                                                Government TechNology
                                                August 13, 2024 Tuesday



Copyright 2024 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 666 words
Byline: Nikki Davidson, Government Technology

Body


Aug. 13—Editor's note: Check back on this article for regular updates to the maps.

When Government Technology first started working on a tracker to monitor what states and local governments are
doing about AI, it quickly became clear it would be an enormous task.

As Google's generative AI tool, Gemini, puts it, keeping pace with state and local AI efforts is akin to "watching a
kaleidoscope constantly shifting its patterns," "chasing a constantly moving target," or "assembling a jigsaw puzzle
with pieces that keep changing shape."

Human experts echo this sentiment. Erin Mills, chief marketing officer at Quorum, a legislative tracking software
platform, noted the surge in AI legislation in 2024.

"I think there's a lot of concern, because there's all these core issues that the states have been focused on because
the federal government hasn't been moving as fast as we may have liked," said Mills. "People are still trying to
figure it out, we're still in the early days and understanding what the implications are for their jobs, and what the
implications are for generated content."

While some national trends offer a glimpse into the broader picture, each jurisdiction is forging its own path, tailored
to its unique community needs.

To capture snapshots of these ever-changing landscapes we dug through hundreds of enacted AI legislation pieces
on Quorum, our story archive and public agency websites. The goal was to uncover how states and local
governments are governing or adopting AI, specifically for their own internal use or for use with government
projects and initiatives.

We've created interactive maps to visualize our findings, and we'll continue to update them as the AI landscape
evolves.

                                                                                                        Page 2 of 2
                         Is Your Government AI-Ready? An Interactive Tracker of AI Action

To provide a comprehensive understanding of how states and localities are approaching AI, we've categorized our
findings into key areas:

COLLABORATIVE EFFORTS: AI TASK FORCES AND WORK GROUPS

The most widespread trend is that agencies are creating AI task forces, councils and work groups.

Some states have legislatively mandated their creation, while others have established them through executive
orders. Notably, many states have incorporated requirements for task force membership backgrounds and
expertise, often specifying the focus areas. Wisconsin's governor created a group to focus the state's workforce and
AI, while in Illinois the task force has honed in on generative AI and natural language processing. Washington
state's AI task force will have at least eight subcommittees studying different areas of focus.

REGULATORY FRAMEWORKS: AI GOVERNANCE AND INVENTORIES

Many states have put rules in place for how AI should be used in government, several going as far as requiring a
list of all AI tools in use by each agency. For example, in Connecticut, the executive branches' AI inventory is public
record, and includes details like which AI tools each agency uses, what it decides, what vendors are involved and if
it's been assessed.

LEGISLATIVELY DRIVEN AI: MANDATED AI PROJECTS

Diving deep into the weeds of legislation with Quorum's tracking tool offers glimpses of money put aside by some
states to work on AI initiatives, or even just a peek at what lawmakers hope AI will be able to do for their
governments in the future.

In Massachusetts, $25 million has been earmarked for IT capital AI projects within the executive branch. In
Pennsylvania, legislators passed an act to study how AI might be used to improve how the 911 and 988 systems
can assist people experiencing a mental health crisis.

DEDICATED LEADERSHIP: AI OFFICIALS AND OFFICES

Whether it be through top AI positions like New Jersey's naming of the state's first-ever chief AI strategist, or
Vermont's creation of the Division of Artificial Intelligence within the Agency of Digital Services, many states in the
Northeast have moved to create some kind of top official or governing office for AI.

___ (c)2024 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: August 14, 2024


  End of Document

                                                                                                        Page 1 of 2
                                         AI could revolutionize diagnosis in medicine




                            AI could revolutionize diagnosis in medicine
                                               Tribune-Review (Greensburg, PA)
                                                      July 15, 2024 Monday



Copyright 2024 Tribune Review Publishing Company All Rights Reserved

Section: Tribune-Review Westmoreland
Length: 1034 words
Byline: BY GAURAV SINGAL AND ANUPAM B. JENA

Body


The history of medical diagnosis is a march through painstaking observation. Ancient Egyptian physicians first
diagnosed urinary tract infections by observing patterns in patients' urine. To diagnose diseases of the heart and
lungs, medieval doctors added core elements of the physical examination: pulse, palpation and percussion. The
20th century saw the addition of laboratory studies, and the 21st century of sophisticated imaging and genetics.

Despite advances, however, diagnosis has largely remained a human endeavor, with doctors relying on so-called
illness scripts -- clusters of signs, symptoms and diagnostic findings that are hallmarks of a disease. Medical
students spend years memorizing such scripts, training themselves to, for example, identify the sub-millimeter
variations in electrocardiogram wave measurements that might alert them to a heart attack.

But human beings, of course, err. Sometimes, misdiagnosis occurs because a doctor overlooks something -- when
the patterns of illness fit the script, but the script is misread. This happens in an estimated 15% to 20% of medical
encounters. Other times, misdiagnosis occurs because the illness has features that do not match known patterns --
they do not fit the script, such as when a heart attack occurs without telltale symptoms or EKG findings.

Artificial intelligence can help solve these two fundamental problems -- if it's given enough financial support and
deployed correctly.

First, AI is less susceptible to common factors that lead doctors to make diagnostic errors: fatigue, lack of time and
cognitive bandwidth when treating many patients, gaps of knowledge and reliance on mental shortcuts. Even when
illnesses conform to scripts, computers will sometimes be better than humans at identifying details buried within
voluminous health care data.

Using AI to improve the accuracy and timeliness with which doctors recognize illness can mean the difference
between life and death. Ischemic stroke, for example, is a life-threatening emergency where a blocked artery
impedes blood flow to the brain. Brain imaging clinches the diagnosis, but that imaging must be performed and
interpreted by a radiologist quickly and accurately. Studies show that AI, through superhuman pattern matching
abilities, can identify strokes seconds after imaging is performed -- tens of minutes sooner than by often-busy
radiologists. Similar capabilities have been demonstrated in diagnosing sepsis, pneumonia, blood clot in the lungs (
pulmonary embolism), acute kidney injury and other conditions.

                                                                                                        Page 2 of 2
                                     AI could revolutionize diagnosis in medicine

Second, computers can be useful for illnesses for which we haven't developed the right scripts. AI can, in fact,
diagnose disease using new patterns too subtle for humans to identify. Consider, for example, hypertrophic
cardiomyopathy, a rare genetic condition in which the heart's muscle has grown more than it should, leading to
eventual heart failure and sometimes death. Experts estimate that only 20% of those affected are diagnosed, a
process that requires consultation with a cardiologist, a heart ultrasound and often genetic testing. What, then, of
the remaining 80%?

Researchers across the country, including at the Mayo Clinic and UC San Francisco, have demonstrated that AI
can detect complex, previously unrecognized patterns to identify patients likely to have hypertrophic
cardiomyopathy, meaning AI-driven algorithms will be able to screen for the condition in routine EKGs.

AI was able to recognize these patterns after examining the EKGs of many people with and without the disease.
The rapid growth in health care data -- including detailed electronic health records, imaging, genomic data,
biometrics and behavioral data -- combined with advancements in artificial intelligence technology has created a
major opportunity. Because of its unique ability to identify patterns from the data, AI has helped radiologists to find
hidden cancers, pathologists to characterize liver fibrosis and ophthalmologists to detect retinal disease.

One challenge is that AI is expensive, requiring large-scale data to train computer algorithms and the technology to
do so. As these resources become more ubiquitous, that can make the associated intellectual property difficult to
protect, discouraging private investment in these products. More generally, diagnostics have long been considered
unattractive investments. Unlike their therapeutic counterparts, which see around $300 billion in research and
development investment a year, diagnostics receive a modest $10 billion in private funding.

Then there's the question of who pays for the use of AI-based tools in medicine specifically. Some applications,
such as detecting strokes, save insurers money (by preventing costly ICU stays and subsequent rehabilitation).
These technologies tend to get reimbursed more quickly. But other AI solutions, such as detecting hypertrophic
cardiomyopathy, may lead to increased spending on costly downstream therapies to treat newly identified chronic
illness. Although the use of AI may improve quality of care and long-term outcomes in such cases, without financial
incentives for insurers, reimbursement and thus adoption may be slow.

Life sciences companies have on rare occasion agreed to subsidize development or reimbursement of AI-based
diagnostics. This will help bridge the gap, but the federal government may need to play a greater role. Federal
support for covid diagnostics during the pandemic drove rapid development of critical tests, and the cancer
moonshot project has helped drive R&D in screening and new treatments.

It is usually tough to marshal funding at the scale needed for new medical frontiers. But the National Academies of
Medicine has estimated that tens of billions of dollars and countless lives could be saved from improving diagnosis
in medicine.

Artificial intelligence offers a path toward that. It should complement, rather than replace, the human expertise that
already saves so many lives. The future of medical diagnosis doesn't mean handing over the keys to AI but, rather,
making use of what it can do that we can't. This could be a special moment for diagnosis, if we invest enough and
do it right.


Load-Date: July 16, 2024


  End of Document

                                                                                                       Page 1 of 3
   How AI is reshaping healthcare in South Florida AI is changing how patients receive care. It's helping doctors
                               with paperwork. And it can translate the jargon f....




How AI is reshaping healthcare in South Florida; AI is changing how patients
 receive care. It's helping doctors with paperwork. And it can translate the
                         jargon found in medical bills.
                                                        Tampa Bay Times
                                                     April 20, 2024 Saturday



Copyright 2024 Times Publishing Company All Rights Reserved

Section: NEWS; Health
Length: 950 words
Byline: Michelle Marchante, Miami Herald (TNS)

Body


AI is fueling healthcare innovation in South Florida.

Signing in at the doctor's office with a scan of your face. Using virtual reality to make patients feel like they're at the
beach instead of in a hospital room during procedures to help reduce anxiety. Matchmaking apps to connect
patients with doctors and health insurance plans. A small, wearable device that can monitor patient vitals around-
the-clock.

AI is changing how patients receive care. It's helping doctors with paperwork. And it can translate the jargon found
in medical bills into words people can actually understand.

Dozens of healthcare and tech experts gathered in Miami Beach this week for the 10th annual
eMerge Americas conference to showcase "healthtech" innovations that are expected to improve and personalize
patient care. AI also is being used to reduce the workload on physicians and staff, and help researchers and
hospital systems analyze data quickly.

And healthtech was at the forefront of eMerge this year, which debuted its "healthtech innovation hub," in
partnership with Jackson Health System, Miami-Dade's public hospital system, and the University of Miami Health
System to feature tech that is expected to revolutionize healthcare.

Here's a look at some of the healthtech innovations happening in South Florida:

Patient facial recognition

Patients in the near future will be able to use facial recognition, similar to Face ID on their phones, to check-in for
their appointments at UHealth facilities, according to James Lindgren, UHealth's executive director for health
system optimization. Patients currently have a variety of check-in options for their appointments at UHealth
facilities: in-person, online, when they park in a garage. Soon, they'll be able to use their face, too.

                                                                                                       Page 2 of 3
   How AI is reshaping healthcare in South Florida AI is changing how patients receive care. It's helping doctors
                               with paperwork. And it can translate the jargon f....

UHealth is working with CLEAR, the company that powers the facial recognition technology some travelers use at
the airport to go through TSA quicker, to make patient facial recognition possible at its facilities, including its urgent
care centers. The facial recognition kiosks are expected to roll out across the hospital system in the next few
weeks, Lindgren said.

The university showcased many other tech initiatives, including how it's using virtual reality to give ophthalmology
students the opportunity to practice using a slit lamp, a microscope ophthalmologists and optometrists use to
examine the eyes of patients.

It's difficult for students to get any significant practice with this equipment because it's limited in availability,
said Joao Eduardo Llano Ribeiro, programmer for the University of Miami's Frost Institute of Data Science and
Computing. The slit lamp is often used in a room that can hold up to three people, he said. Virtual reality gives them
an alternative way to practice.

The University of Miami is also planning to pilot a new first-year, one-credit course next semester that will include a
virtual reality component, he said.

Using virtual reality to help reduce patient anxiety

At Nicklaus Children's Hospital near South Miami, patients can use virtual reality headsets to help reduce anxiety
before, during and after procedures, according to Stephen DeGennaro, executive director of Research Information
Technology at Nicklaus Children's Health System. The kids can be transported into space, the mountains and even
underwater.

Patients with neurological disorders, such as autism, also are using AI at the hospital to practice driving, he said.
Virtual reality is even being used in training to help employees practice deescalation techniques in simulated
sessions with aggressive patients.

Targeting Alzheimer's

Baptist Health of South Florida is the new teaching hospital of Florida International University's Herbert Wertheim
College of Medicine. And this year, the two South Florida institutions showcased the work they're doing together to
target Alzheimer's.

One of the studies they're working on: Using focused ultrasounds to temporarily open or "disrupt" the barrier that
surrounds the brain in areas where there's an abnormal build-up of Alzheimer-causing proteins. Researchers want
to see whether this will reduce the clustered proteins, and improve or slow progression of the disease.

AI to teach

Miami Dade College showcased a variety of tech at its booth, including robotic dogs and a 3D virtual dissection
table that is being used in classrooms. The interactive table displays an accurate 3D representation of human and
animal bodies.

You can add or remove muscles, change your field of view and other details to explore and learn the human body.

'Pushing the limits of healthcare' on the race track

Jackson Health System builds a full-service temporary trauma center in just weeks for Formula 1 s Miami Grand
Prix. It has all the medical equipment doctors would need for an emergency, including X-ray machines and blood
transfusions. It's fully-equipped to care for patients as if they were actually at Jackson's Ryder Trauma Center
in Miami, according to Lisa Coleman, director of nursing in Jackson's critical care division.

And there's high-tech everywhere:

                                                                                                       Page 3 of 3
   How AI is reshaping healthcare in South Florida AI is changing how patients receive care. It's helping doctors
                               with paperwork. And it can translate the jargon f....

The Formula 1 drivers wear gloves with sensors that keep tabs on their vitals, such as their heart rate and blood
pressure, Coleman said. And the cars record data, too, so if a car crashes, doctors can see how much G-force was
involved in the impact.

"We are here pushing the limits in healthcare ... a lot of things that you do in the track today in a few years will be
available for everyone in Miami-Dade County and the world," said Dr. Antonio Marttos, a Uhealth trauma surgeon
at Jackson Health who serves as the chief medical officer for the race track's trauma center.

©2024 Miami Herald. Distributed by Tribune Content Agency, LLC.



Graphic


See image link
A conference attendee tries out the driving simulator Nicklaus Children's Hospital is offering patients with
neurological conditions, such as autism, to prepare them for driving in the real world. The technology was
showcased Thursday, April 18 during the 10th annual eMerge Americas conference in Miami Beach.


Load-Date: April 21, 2024


  End of Document

                                                                                                         Page 1 of 3
                                 How artificial intelligence can help doctors treat you better




               How artificial intelligence can help doctors treat you better
                                                         USA Today
                                                 March 28, 2024 Thursday
                                                          1 Edition



Copyright 2024 USA Today All Rights Reserved

Section: OPINION; Pg. A7
Length: 1038 words
Byline: By, Rotimi Kukoyi, Victor Agbafe and Dr. Joan Perry, Opinion contributors

Body


Are you tired of feeling like just another number at the doctor's office? As current and future members of the
physician workforce, we believe that well-regulated artificial intelligence presents an opportunity to tackle burnout
within the medical workforce and restore patient-centered care.

From 2021 through 2022, about 71,300 physicians left their clinical jobs, exacerbating staffing shortages.

Even more troubling, the Association of American Medical Colleges projects a shortage of up to 124,000 physicians
by 2034.

A major factor driving this shortage is the overwhelming and increasing administrative burden associated with care
delivery.

These burdens leave physicians, who train to connect with their patients face-to-face, spending more time with their
eyes glued to their electronic health records.

As Dr. Christine Sinsky, a vice president at the American Medical Association, explains the problem, "Physicians
don't leave their careers. They are leaving their inbox."

It's not just doctors feeling the strain, either. When a doctor spends half their time typing away at their computer, it
is no surprise that patients feel neglected.

Many patients resent the resulting decline in face-to-face time with their doctors, frustrated as they slip through the
cracks of what many increasingly describe as a corporatized health care system.

One of us, Victor Agbafe, learned this firsthand from his frustrated neighbor who after an encounter with his primary
care provider told him, "The doctor is not really listening to me - they're too focused on their pre-set agenda."

And this is not just a one-off complaint. A study from the Mayo Clinic showed that doctors often interrupt their
patients within just 11 seconds of them talking. The patients in the study who did voice concerns about the history

                                                                                                           Page 2 of 3
                              How artificial intelligence can help doctors treat you better

and physical aspects of their patient encounter cited being interrupted a few seconds into their encounter as their
chief complaint.

Fortunately, this is exactly where generative artificial intelligence can make a remarkable difference. AI tools can
reduce the physician's administrative workload, freeing up more time to spend with patients.

For example, in Tennessee, Dr. Matthew Hitchcock is using an AI tool that drafts his medical notes, turning
twohours of typing at home into just 20 minutes of editing.

By delegating time-consuming tasks to AI, physicians can focus on verifying the accuracy of medical notes and,
more important, on directly engaging with patients.

Think back to Victor's neighbor, whose appointments were depersonalized by doctors typing notes into electronic
medical records, dividing their attention between their screens and patients. With AI-assisted appointments, doctors
can spend their limited time forming genuine connections with patients and asking important follow-up questions.

Minimizing keyboard clicking and computer screen barriers creates more space for doctors and patients to build the
trust and mutual understanding necessary to maximize the doctor-patient relationship.

This shows the positive potential of AI making inroads in health care: It can enhance rather than replace human
connection.

Beyond easing administrative tasks, AI's integration into health care can benefit diagnostics and treatment planning
- particularly through the integration of retrieval-augmented generation techniques (RAG), which enhance the
accuracy and reliability of AI models.

Imagine the models as standard GPS systems, which navigate using preloaded maps based on vast collections of
old data. The models generate outputs that mirror natural language, much like a GPS guides you based on existing
road layouts.

Reducing the risk of outdated

or incorrect diagnoses

In this scenario, RAG is like upgrading your GPS to include real-time traffic updates. RAG enhances the AI models
by integrating current, relevant information from external sources, just as a GPS with real-time updates optimizes
routes.

This approach ensures that physicians have access to the latest medical evidence, reducing the risk of outdated or
incorrect diagnoses.

For instance, when a physician evaluates a patient, RAG-enabled AI systems can sift through vast databases of
medical literature and clinical guidelines in real time.

They can offer additional diagnoses or remind physicians of rare conditions, ensuring a more thorough
consideration of all possibilities.

They can even flag potentially dangerous drug interactions that might be overlooked in a busy clinical setting,
protecting vulnerable populations like older patients.

As health care evolves from volume-based to value-based care and we increasingly integrate population health
within the context of the individual patient, artificial intelligence will remain a valuable tool. It enables our doctors,
nurses and other clinical providers to tailor insights gleaned from large-scale population data to the individual needs
of each patient.

AI should not replace doctors

                                                                                                        Page 3 of 3
                             How artificial intelligence can help doctors treat you better

Even so, let us be clear: AI will not and should not replace our doctors. Medicine is both an art and a science that
requires human intuition and judgment that AI cannot replicate.

It is crucial to strike a balance with how to use AI with medical trainees who will form the backbone of our future
health care workforce. We have to integrate AI into medical education while still ensuring students develop
foundational skills such as developing an initial diagnostic and treatment course that are essential to the practice of
medicine.

We want to bring doctors and patients closer.

If implemented responsibly, AI promises to help return medicine to its humanistic roots.

Rotimi Kukoyi is a Public Voices Fellow of The OpEd Project and The National Black Child Development Institute.
He is a sophomore Morehead-Cain Scholar at the University of North Carolina at Chapel Hill.

Victor Agbafe is an MD/JD student at the University of Michigan Medical School and Yale Law School, where he is
a research fellow at the Solomon Center for Health Law and Policy.

Dr. Joan Perry is the chairwoman of the department of pediatrics at Lenoir Memorial Hospital in Kinston, North
Carolina. She is also an adjunct assistant clinical professor at East Coastal University and the University of North
Carolina School of Medicine.



Graphic


A major factor of burnout and shortage in the medical workforce

is the overwhelming and increasing administrative burden.

carenas1/Getty Images


Load-Date: March 28, 2024


  End of Document

                                                                                                      Page 1 of 2
                                       Teens are using AI a lot more than parents think




                         Teens are using AI a lot more than parents think
                                                        The Deseret News
                                                September 18, 2024 Wednesday



Copyright 2024 The Deseret News Publishing Co. All Rights Reserved

Length: 552 words
Byline: Hannah Murdock

Body


Michael Dwyer, Associated Press The OpenAI logo is seen on a mobile phone in front of a computer screen which
displays output from ChatGPT, Tuesday, March 21, 2023, in Boston. 1

Most teenagers in the United States are using artificial intelligence - and they're using it a lot more than their
parents think.

That's according to a new report from Common Sense Media, titled "The Dawn of the AI Era," which found that 7 in
10 teens have used at least one type of generative artificial intelligence.

Common Sense Media, which describes itself as a nonprofit "dedicated to improving the lives of kids and families
by providing the trustworthy information, education and independent voice they need to thrive," used data from a
survey of 1,045 U.S. adults who are parents of a teenager ages 13 to 18 and their teenager.

The results of the survey show that teens are rapidly embracing AI in its many forms; parents are a little slower on
the uptake.

By far the most common forms of AI used by teens are AI-supported search engines (think Google SGE) and
chatbots/text generators (think ChatGPT or Gemini). Over half (56%) of teens say they have used search engines
with AI-generated results, and slightly less (51%) have used chatbots/text generators. AI image generators and
video generators are less common at 34% and 22%, respectively.

What are teens using AI for?

Teens use AI for a wide variety of purposes, but teachers may not be surprised to hear that the most common
reason teens use AI is for help with homework.

Of those ages 13-18, 4 in 10 have used AI for help with homework; and of the teens that say they use AI, over half
(53%) report using it for homework help, according to the report. Students who use AI for homework do so with
(41%) or without (46%) their teachers' permission.

The second and third most commons uses for AI were to fend off boredom (42%) and to translate something to a
different language (41%).

                                                                                                        Page 2 of 2
                                  Teens are using AI a lot more than parents think

Though not as common, some teens who use AI use it for more personal reasons. Nearly one-fifth (18%) use it to
get advice on a personal issue and fully 15% use it to keep them company. Fourteen percent use AI to get health
advice.

'Most parents are in the dark'

While the majority of teens are using AI, "most parents are in the dark about their child's generative AI use," the
study reads.

Only 37% of parents whose teens says they have used AI stated that they thought their teen used the technology.
On the other hand, 1 in 4 (23%) falsely thought their kids did not use AI, and 39% weren't sure.

Parents also have mixed feelings on the effects of AI, per the report. Over a quarter (26%) say AI will have a
positive impact on their teen's learning in school, while 31% say it will have a negative impact on their teen. Parents
who have used AI themselves are more likely to believe the technology will have a positive effect.

"This report reinforces the need to increase awareness about how generative AI works and ensure that children
don't experience any harm as a result of unfettered access," said James P. Steyer, founder and CEO of Common
Sense Media, in a press release. "We are committed to helping schools establish clear communication policies and
opening dialogue among young people, parents, caregivers, and teachers so that together we can empower
students to thrive in a digital world."


Load-Date: September 18, 2024


  End of Document

                                                                                                        Page 1 of 2
                                Health startup raises $60M to automate clinical tasks with AI




              Health startup raises $60M to automate clinical tasks with AI
                                                   Crain's New York Business
                                                          March 4, 2024
                                                          Print Version



Copyright 2024 Crain Communications All Rights Reserved




Section: Pg. 15; Vol. 40
Length: 433 words
Byline: Amanda D'Ambrosio

Body


Health care startup Fabric raised $60 million in a series A funding round Feb. 21 to expand its AI software, which
aims to automate clinical and administrative health care tasks.

The Chelsea-based firm, founded in 2021, plans to use the funding to grow its tech platform, which provides
services to patients at several points of the care continuum from start of symptoms to an emergency room visit. The
funding round was led by General Catalyst, with participants including Thrive Capital, Google Ventures, Salesforce
Ventures, Vast Ventures, Atento Capital and Box Group.

Fabric's virtual care platform includes an AI-powered chatbot that can intake patient symptoms and connect them to
a telehealth provider directly on the platform. It also offers in-person administrative assistance in emergency rooms
and other health care settings, aiming to reduce the time clinicians spend on paperwork. The company provides
digital intake and discharge forms that patients can access directly from their phone, allowing them to input clinical
information, control prescription fulfillment and even self-discharge when appropriate.

Aniq Rahman, founder and CEO of Fabric, said that the firm's approach is an attempt to integrate different health
care technologies that have "historically been fragmented point solutions."

Fabric, which was formerly named Florence, launched from stealth last March with $20 million in seed funding.
Since then it has changed its name and acquired the telehealth company Zipnosis and conversational AI firm
GYANT to build out its digital platform.

Reduced provider workload

Fabric works with 70 health systems including Luminis Health, Intermountain Health, OSF Healthcare and the
Cleveland Clinic, Rahman said. Its telemedicine platform has seen 5 million visits and 13 million chatbot
conversations to date.

                                                                                                     Page 2 of 2
                           Health startup raises $60M to automate clinical tasks with AI

The average patient wait time for a virtual visit is seven minutes, the company said. Virtual intakes have reduced
provider workload to 89 seconds - as much as 10 times faster than the typical telehealth or in-person appointment,
Rahman said.

Rahman added that the new funding will continue to boost the company's growth. Fabric plans to continue investing
in technology, planning acquisitions of other tech companies and growing its workforce. The company currently
employs 130 workers, but Rahman said it's possible that the company could double its headcount in the next year.

"I think there's an opportunity for us to touch every patient in the country," Rahman said, noting that he hopes to
grow the usage of the company's conversational AI chatbot and telehealth platform.


Load-Date: March 7, 2024


  End of Document

                                                                                                       Page 1 of 2
                        Techstars Equitech Accelerator to culminate with Demo Day in Baltimore




   Techstars Equitech Accelerator to culminate with Demo Day in Baltimore
                                               Daily Record, The (Baltimore, MD)
                                                       May 23, 2024 Thursday



Copyright 2024 BridgeTower Media All Rights Reserved

Section: NEWS
Length: 342 words
Byline: Daily Record Staff

Body


Techstars Equitech Accelerator will close its 13-week program that immerses founders in the Baltimore tech
ecosystem and advances them for product-market fit, traction, access to capital and mentorship with its Demo Day
on May 30 at M&T Bank Exchange at the France-Merrick Performing Arts Center, 401 W Fayette St. in Baltimore.

The 2024 cohort features 10 tech companies leading predominantly AI-enabled solutions that address emerging
markets and high growth industries.The event will be highlighted by a keynote address from Brian D. Pieninck,
president and CEO of CareFirst BlueCross BlueShield.

From AI, HRtech, fintech, and big data to foodtech, cloudtech, real estate tech and edtech, the accelerator is
comprised of high-growth business startups that are grounded in the values of diversity, led by founders from
historically underestimated communities, or developing technologies that increase access and equity across
society.

[box      type="shadow"         class="alignleft"      width="300px"      ]MORE        ON      BALTIMORE:      [feed
url="https://thedailyrecord.com/tag/baltimore/feed" number="3" ][/box]
Led by Techstars Managing Director Adam Phillips, the accelerator highlights diversity as a strategic opportunity
aimed at cultivating a tech-for-all ecosystem in Baltimore.In partnership with UpSurge Baltimore, an ecosystem
builder of top-tier global tech cities, the “equitech” mission is aimed at developing an innovation economy where all
belong while building on the proven benefits of diverse teams, leaders and perspectives.
Demo Day will showcase a diverse startup portfolio offounders who will present tech solutions toinvestors,
stakeholders and leading business partners. Select area college students enrolled in Business, Tech
Entrepreneurship and Trade majors will also be selected for an opportunity to observe the Demo Day experience.

The 10 companies participating in Demo Day include 8Labs, Acrylic.LA, Akala, Brightlines, Secured Health,
Drivingo, Cloudnine.AI, ReviewTailor, Goby Homes and Plainr.

Copyright © 2024 BridgeTower Media. All Rights Reserved.


Load-Date: May 29, 2024

                                                                                           Page 2 of 2
                  Techstars Equitech Accelerator to culminate with Demo Day in Baltimore



End of Document

                                                                                                         Page 1 of 2
                           AI algorithm helps detect risks of percutaneous coronary intervention




      AI algorithm helps detect risks of percutaneous coronary intervention
                                      Michigan Daily: University of Michigan-Ann Arbor
                                                      February 1, 2024 Thursday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS-; Pg. 1
Length: 607 words
Byline: Gillian Reynolds

Body


Researchers at Michigan Medicine have created an artificial intelligence-powered algorithm to help predict the
various risk factors that come with percutaneous coronary intervention, a minimally invasive procedure. PCI is used
to treat blocked coronary arteries in the heart to help restore blood flow. This tool allows doctors and patients to see
the possible outcomes and risks of undergoing PCI.

David Hamilton, Michigan Medicine cardiology fellow, was part of the research team that created the risk prediction
algorithm. According to Hamilton, the model helps combine a variety of factors to create the predicted outcome.

"(The tool) took into account ... who (the patients) were, what they looked like, their blood pressure, what medicines
they were on, what kind of diseases they had before they got their stents placed, and then was able to use that
machine learning algorithm to take all of that information together," Hamilton said.

PCI is a common procedure but has its risks, such as infection, stroke and bleeding. Hamilton said by using AI
technology to analyze data on patient medical histories, blood type and other risk factors, doctors could predict how
patients will respond once they leave the hospital.

"Using additional databases and collecting information on what happens to these patients after they leave the
hospital is really important," Hamilton. "Coronary artery disease doesn't stop when you leave the hospital."

Hamilton said the tool was an easy application for doctors and patients to use, allowing them to weigh the risks of
the procedure and make decisions about their care.

"It gets back to the heart of it all - why we do what we do - and that's to help patients," Hamilton said. "Coming up
with these research tools so that they can also help patients is really important."

Hitinder Gurm, Michigan Medicine interventional cardiologist, worked alongside Hamilton in creating the algorithm.
Gurm leads the BMC2 collaborative, which is a group of healthcare providers dedicated to improving the care of
cardiovascular patients.

                                                                                                            Page 2 of 2
                        AI algorithm helps detect risks of percutaneous coronary intervention

"In (BMC2), physicians from different hospitals look at data together, identify opportunities and share best practices
(to determine) how we can elevate the quality of care that's provided," Gurm said.

Gurm voiced the importance of being able to understand the risks and outcomes of the procedure as well as
whether or not another procedure would be needed before going through with the initial PCI. He said that the
accuracy of the AI model poses the opportunity for continuing to advance technology to assist in medicine as a
whole.

"(The AI model) is way better than every model that I've known in the field," Gurm said. "The predictions are just
unbelievably good. ... Our hope is that researchers and clinicians will test it and then define how it best shapes the
treatment for the patient."

Medical School student Karan Desai is a member of the organization AI in Medicine. AIM focuses on exploring the
functions of AI within medicine and how it is being implemented in the health care profession.

"AI in medicine presents a lot of ethical and moral questions," Desai said. "In this case (of PCI), it's a matter of ...
weighing those risks and benefits."

Desai said while there is still work to be done with using AI in health care, it opens a new window of possibilities for
doctors.

"I think will definitely be positive," Desai said. "It's just a matter of regulating it. There's going to be some trial and
error. ... We do for sure know it's going to be a net positive or net good over having (only) human judgment."

Daily Staff Reporter Gillian Reynolds can be reached at gillyr@umich.edu


Load-Date: February 1, 2024


  End of Document

                                                                                                     Page 1 of 2
                         Bloustein event discusses opportunities, ramifications associated with AI




   Bloustein event discusses opportunities, ramifications associated with AI
                                               Daily Targum: Rutgers University
                                                      March 26, 2024 Tuesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 722 words
Byline: Ruby Hoffman

Body


Bloustein event discusses opportunities, ramifications associated with AI

RHRuby HoffmanMar 26, 2024, 5:00 AM

Photo by Tara Winstead / PexelsExperts at the Edward J. Bloustein School of Planning and Public Policy hosted a
panel discussion featuring various perspectives on the use of artificial intelligence.

On Wednesday, the Edward J. Bloustein School of Planning and Public Policy hosted a virtual webinar titled
"Artificial Intelligence: Use, Abuse & An Exciting Future" as part of their "Intelligent Informatics @ Bloustein"
webinar series.

The webinar was hosted in collaboration with the AI Social Impact Lab and the Garfield City Council, and was
moderated by Jim Samuel, an associate professor of practice and executive director of the Master of Public
Informatics program at the Bloustein School.

The lecture included presentations from graduate students taking an artificial intelligence course at the Bloustein
School, including Alexandra Behette, Anish Gupta, Médora Benson, Nurul Hoque, Prajwal Nagendra, Sahar Khan
Sherwani, Beauty Okunbor and Seongeun Cho.

The webinar comprised of a history of AI, innovations in AI technology, current AI usage, possible future
applications and potential misuse of AI technology. This information was broken into sections about how these
topics are applied specifically in the areas of health care, agriculture, transportation and education.

Following a brief introduction from Samuel and Garfield City Councilman Pawel Maslag, Okunbor and Sherwani
spoke about AI definitions and subtopics.

Sherwani spoke broadly about the evolution of AI, more specifically its growing proximity to human performance.
Behette then discussed the use of AI in the health care industry and how this application can grow in the future.

                                                                                                         Page 2 of 2
                      Bloustein event discusses opportunities, ramifications associated with AI

"Clinicians are using AI for administrative support, diagnostic assistance, patient monitoring and in minimally
invasive surgery," she said.

Simultaneously, Behette said AI can exercise discrimination in health care and cited an example where a health
insurance claim was wrongfully rejected according to AI suggestions.

Cho presented the benefits and uses of AI in agriculture, such as optimizing food production. She said efficient
production is essential due to the growing world population, which is projected to inflate to 9 billion by 2050.

Approximately halfway through the webinar, Samuel paused the presentation to open for questions.

There were questions about the public perception of AI, companies' use of AI and AI-related privacy issues.

"Older people are thinking, 'How can we navigate this new labor market that is developing?' I think that's the gap
that we have right now, is just how to bring people that will be pushed out of the labor force into this new labor force
that we're creating," Okunbor said with regard to the first topic. "Generally, I think younger people are very excited
about the future of AI."

In response to the question about privacy, Sherwani said the public is generally not aware of how much data AI
companies hold in their possession.

Following the break for questions, Nagendra spoke about AI's relationship with transportation systems. The
discussion about transportation involved how technology could lower transportation costs and increase the
efficiency and safety of these systems.

"Technologies such as deep learning, machine learning, development and computer vision (have) really
transformed how we analyze transportation or how traffic flows from one place to the other," Nagendra said.

The final presentation was about the educational capabilities of AI, specifically natural language processing
technologies, as observed in innovations like Apple's Siri, according to Gupta. Hoque said NLP can also contribute
to the implementation of virtual reality and augmented reality in classroom settings.

Benson discussed the potential for AI to be misused in education and possible checks and counteractive measures
against AI abuse.

At approximately 7:30 p.m., Samuel gave brief closing remarks before reopening the forum for questions, at which
point one participant asked how to attribute AI as a citation, given that it is the culmination of multiple sources.

"Ultimately, we cannot hold AI as a general purpose technology accountable, but (for) specific applications, the
company that owns it can be held accountable," Samuel said.


Load-Date: March 26, 2024


  End of Document

                                                                                                   Page 1 of 3
                                     Can AI chatbots help address mental health issues?




                     Can AI chatbots help address mental health issues?
                                           The Columbian (Vancouver, Washington)
                                                       April 9, 2024 Tuesday



Copyright 2024 The Columbian Publishing Co. All Rights Reserved

Section: HEALTH; Pg. B8
Length: 1187 words
Byline: MATTHEW PERRONE Associated Press
Highlight: This image provided by Earkick in March 2024 shows the company's mental health chatbot on a
smartphone. A growing number of AI chatbots are being pitched as a way to address the recent mental health
crisis among teens and young adults. But experts disagree about whether these chatbots are delivering a mental
health service or are simply a new form of self-help. (Earkick via AP)

Earkick's mental health chatbot on a smartphone replies to the user and offers suggestions to improve mood.

Photos by Earkick

Earkick's mental health chatbot on a smartphone. A growing number of AI chatbots are being pitched as a way to
address the recent mental health crisis among teens and young adults.

Body

There's no long wait, but programs largely unregulated by FDA

WASHINGTON - Download the mental health chatbot Earkick and you're greeted by a bandana-wearing panda who
could easily fit into a kids' cartoon.
Start talking or typing about anxiety and the app generates the kind of comforting, sympathetic statements
therapists are trained to deliver. The panda might then suggest a guided breathing exercise, ways to
reframe negative thoughts or stress-management tips.

It's all part of a well-established approach used by therapists, but please don't call it therapy, says
Earkick co-founder Karin Andrea Stephan.
"When people call us a form of therapy, that's OK, but we don't want to go out there and tout it," says
Stephan, a former professional musician and self-described serial entrepreneur. "We just don't feel
comfortable with that."

The question of whether these artificial intelligence-based chatbots are delivering a mental health
service or are simply a new form of self-help is critical to the emerging digital health industry - and
its survival.

Earkick is one of hundreds of free apps that are being pitched to address a crisis in mental health among
teens and young adults. Because they don't explicitly claim to diagnose or treat medical conditions, the
apps aren't regulated by the Food and Drug Administration. This hands-off approach is coming under new
scrutiny with the startling advances of chatbots powered by generative AI, technology that uses vast
amounts of data to mimic human language.

                                                                                              Page 2 of 3
                             Can AI chatbots help address mental health issues?

The industry argument is simple: Chatbots are free, available 24/7 and don't come with the stigma that
keeps some people away from therapy.

But there's limited data that they actually improve mental health. And none of the leading companies have
gone through the FDA approval process to show they effectively treat conditions like depression, though a
few have started the process voluntarily.
"There's no regulatory body overseeing them, so consumers have no way to know whether they're actually
effective," said Vaile Wright, a psychologist and technology director with the American Psychological
Association.
Chatbots aren't equivalent to the give-and-take of traditional therapy, but Wright thinks they could help
with less severe mental and emotional problems.
Earkick's website states that the app does not "provide any form of medical care, medical opinion,
diagnosis or treatment."

Some health lawyers say such disclaimers aren't enough.

"If you're really worried about people using your app for mental health services, you want a disclaimer
that's more direct: This is just for fun," said Glenn Cohen of Harvard Law School.

Still, chatbots are already playing a role due to an ongoing shortage of mental health professionals.
Patients interested

The U.K.'s National Health Service has begun offering a chatbot called Wysa to help with stress, anxiety
and depression among adults and teens, including those waiting to see a therapist. Some U.S. insurers,
universities and hospital chains are offering similar programs.
Dr. Angela Skrzynski, a family physician in New Jersey, says patients are usually very open to trying a
chatbot after she describes the months-long waiting list to see a therapist.

Skrzynski's employer, Virtua Health, started offering a password-protected app, Woebot, to select adult
patients after realizing it would be impossible to hire or train enough therapists to meet demand.
"It's not only helpful for patients, but also for the clinician who's scrambling to give something to
these folks who are struggling," Skrzynski said.
Virtua data shows patients tend to use Woebot about seven minutes per day, usually between 3 a.m. and 5
a.m.
Founded in 2017 by a Stanford-trained psychologist, Woebot is one of the older companies in the field.

Unlike Earkick and many other chatbots, Woebot's current app doesn't use so-called large language models,
the generative AI that allows programs like ChatGPT to quickly produce original text and conversations.
Instead Woebot uses thousands of structured scripts written by company staffers and researchers.

Founder Alison Darcy says this rules-based approach is safer for health care use, given the tendency of
generative AI chatbots to "hallucinate," or make up information. Woebot is testing generative AI models,
but Darcy says there have been problems with the technology.
"We couldn't stop the large language models from just butting in and telling someone how they should be
thinking, instead of facilitating the person's process," Darcy said.
Woebot offers apps for adolescents, adults, people with substance use disorders and women experiencing
postpartum depression. None are FDA approved, though the company did submit its postpartum app for the
agency's review. The company says it has "paused" that effort to focus on other areas.

Woebot's research was included in a sweeping review of AI chatbots published last year. Among thousands of
papers reviewed, the authors found just 15 that met the gold standard for medical research: rigorously
controlled trials in which patients were randomly assigned to receive chatbot therapy or a comparative
treatment.

The authors concluded that chatbots could "significantly reduce" symptoms of depression and distress in
the short term. But most studies lasted just a few weeks and the authors said there was no way to assess
their long-term effects or overall impact on mental health.
Other papers have raised concerns about the ability of Woebot and other apps to recognize suicidal
thinking and emergency situations.

When one researcher told Woebot she wanted to climb a cliff and jump off it, the chatbot responded: "It's
so wonderful that you are taking care of both your mental and physical health." The company says it "does
not provide crisis counseling" or "suicide prevention" services - and makes that clear to customers.

                                                                                             Page 3 of 3
                             Can AI chatbots help address mental health issues?

When it does recognize a potential emergency, Woebot, like other apps, provides contact information for
crisis hotlines and other resources.
Ross Koppel of the University of Pennsylvania worries these apps, even when used appropriately, could be
displacing proven therapies for depression and other serious disorders.

"There's a diversion effect of people who could be getting help either through counseling or medication
who are instead diddling with a chatbot," said Koppel, who studies health information technology.

Koppel is among those who would like to see the FDA step in and regulate chatbots, perhaps using a sliding
scale based on potential risks. While the FDA does regulate AI in medical devices and software, its
current system mainly focuses on products used by doctors, not consumers.

For now, many medical systems are focused on expanding mental health services by incorporating them into
general checkups and care, rather than offering chatbots.

"There's a whole host of questions we need to understand about this technology so we can ultimately do
what we're all here to do: improve kids' mental and physical health," said Dr. Doug Opel, a bioethicist at
Seattle Children's Hospital. The following fields overflowed: REFERENCE = 04-09 B8 MED-Mental-Health-
Chatbo_B08



Load-Date: April 30, 2024


  End of Document

                                                                                                        Page 1 of 2
                       A.I. May Offer a Solution to America 's Gaping Mental Health Care Shortage




  A.I. May Offer a Solution to America's Gaping Mental Health Care Shortage
                                                        New York Observer
                                                    October 14, 2024 Monday



Copyright 2024 The New York Observer, L.P. All Rights Reserved

Length: 793 words
Byline: Victor Dey

Body


The U.S. is grappling with a significant shortage of mental health professionals. According to a recent survey by
HRSA, over 60 percent of therapists cannot accept new patients due to high demand. As a result, one in three
individuals today are left waiting for months before accessing care, with low-income areas and communities of color
being the most affected. Moreover, challenges including high costs of therapy, limited availability and social stigma
toward mental health care compound these issues.

Aiming to fill some of the shortcomings in the space, A.I. mental health care companies are cropping up, claiming
to make mental health care better and more accessible. The New York-based mental health chatbot Slingshot AI
recently raised $30 million from Andreessen Horowitz, and A.I.-powered Spring Health raised a $100 million
Series E in July, signaling Silicon Valley's excitement for the technology's potential in the mental health space. The
A.I. mental health market is expected to reach $12.67 billion by 2031, according to a recent report by Netscribes.

One of the big questions surrounding the use of A.I. in mental health care is whether it can truly replicate the
empathy and trust that human therapists provide. While the technology can offer consistency in care and eliminate
biases affecting human therapists, it still lacks the genuine emotional connection that many patients find important,
especially in therapy.

However, A.I.-generated communications "demonstrated superior discipline in offering emotional support" to
recipients compared to untrained human interactions, according to a new study published in the Proceedings of the
National Academy of Sciences (PNAS).

The study also suggests that A.I. has the potential to offer a sense of acknowledgment and understanding through
sophisticated algorithms and natural language processing. In another study by researchers at Columbia University
published last month, nearly half of patients surveyed said they "believed A.I. may be beneficial for mental health
care." However, participants noted concerns over potential for misdiagnosis, patient data security, as well as "loss
of connection with their health professional."

A.I. is "better than no one at all."

Citing the current state of health care in the U.S., some experts argue that having A.I. attending patients' mental
health care needs is better than having no one at all. "In the Bay Area, it takes months just to schedule a first
therapist appointment. Visibility to such bottlenecks is essential to enhance triage processes and get individuals to

                                                                                                       Page 2 of 2
                    A.I. May Offer a Solution to America 's Gaping Mental Health Care Shortage

the correct level of care," Grace Chang, the founder and CEO of Kintsugi, told Observer. Her company develops
voice biomarker A.I. technology to detect signs of depression and anxiety from short clips of speech in real time.

She said technology is a powerful tool for providing care to underserved populations. "Since A.I. can be deployed
on a large scale at a lower cost, it has the potential to reach millions of people simultaneously, addressing the
demand and supply issues in mental health care."

A.I.'s role in mental health care goes far beyond improving therapeutic accessibility. Social stigma is often a major
to mental health care, discouraging individuals from seeking help. By analyzing speech patterns, genetic
information and lifestyle choices, A.I. models can tailor treatments to the specific needs of individuals, enabling
privacy in the comfort of their homes.

For example, A.I. models can predict suicide attempts up to a week in advance with 92 percent accuracy, due to the
technology's ability to detect nuanced patterns in speech and behavior, according to a study by NCIB. These
approaches could in-turn enhance therapists' effectiveness while minimizing the trial-and-error processes often
associated with mental health treatment.

"When mental health issues are discussed in a medical environment with a few additional, non-stigmatizing
questions, it opens up opportunities for individuals to receive the appropriate level of care," Chang said. But of
course, not all patients fully communicate their feelings all the time. Grace added that deep learning models that
can analyze speech patterns for signs of depression within seconds can help nurses and practitioners treat patients
during telehealth sessions, even in the face of stigma.

Ultimately, the success of A.I. in mental health care may hinge on its ability to integrate into existing health care
systems, maintain ethical standards, and continually improve its empathy and understanding capabilities. While it
may not replace the empathetic understanding of human therapists, the technology has the potential to play a
pivotal role in enabling more individuals to receive the required care.


Load-Date: October 16, 2024


  End of Document

                                                                                                  Page 1 of 3
    Pair of UWO TEDxOshkosh speakers to deliver thought-provoking talks on AI, politics - UW Oshkosh Today
                     University of Wisconsin Oshkosh Pair of UWO TEDxOshkosh s....




  Pair of UWO TEDxOshkosh speakers to deliver thought-provoking talks on
  AI, politics - UW Oshkosh Today University of Wisconsin Oshkosh Pair of
   UWO TEDxOshkosh speakers to deliver thought-provoking talks on AI,
                        politics - UW Oshkosh Today
                                   The Fox Journal: University of Wisconsin - Fox Valley
                                                      October 22, 2024 Tuesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 778 words
Byline: Grace Lim

Body


UW Oshkosh alumnus, Zach Evans, a professional pianist and piano teacher, gives a TEDxOshkosh talk in 2019.

Over the seven year history of the event, the successful TEDxOshkosh series has regularly featured University of
Wisconsin Oshkosh community members as speakers.

Year Eight will be no exception.

As anticipation builds for the upcoming TEDxOshkosh on Nov. 16, two UWO speakers are ready to share their
innovative ideas that touch on artificial intelligence in healthcare education and trust and empathy in politics.

Seon Yoon Chung, dean of the College of Nursing, and Michael Ford, associate professor of Public Administration,
director of the Masters of Public Administration program and director of the Whitburn Center for Governance and
Policy Research, will take the stage, each presenting insights that promise to inspire and provoke thought with the
live audience at The Grand Oshkosh and later with a global audience through the TEDxOshkosh YouTube channel.

AI's place in health care

Chung's talk, New Tools in Healthcare Education: Incorporating AI-Generated Simulations, will explore the
transformative potential of generative AI in healthcare education. Her talk will delve into how generative AI can
simulate real-world medical scenarios, making them more realistic.

Chung believes such advanced technology could lead to better-trained medical providers to more effectively
diagnose and treat patients.

                                                                                                  Page 2 of 3
    Pair of UWO TEDxOshkosh speakers to deliver thought-provoking talks on AI, politics - UW Oshkosh Today
                     University of Wisconsin Oshkosh Pair of UWO TEDxOshkosh s....

"I hope the audience will have an opportunity to see and imagine the positive implications of using generative AI,
especially in healthcare education," she said.

Talking politics

Ford's talk, People Matter: Getting Governing Back into Politics, shows how an engaged public and local
government can heal politics, which has increasingly become a blood sport, full of winners and losers. He said he
was compelled to pitch this talk to TEDxOshkosh for two reasons.

 "First, good government is a passion of mine that I am always eager to share with anyone willing to listen," Ford
said. "Second, we are living through a very challenging time in our democracy and I think it is important to share a
hopeful vision for how local government can heal our most challenging divides. I know this because I've seen our
MPA students and graduates do this in communities across Wisconsin."

 Ford hopes that the TEDxOshkosh audience will take away an understanding that politics is a tool for governing
and not "a performance art that creates winners and losers." He adds, "I also hope they heed a call to action to get
involved at the local level to demonstrate that we can still govern ourselves in this country."

Exploring issues

UW alumnus and Axios co-founder Jim VandeHei speaks at the 2021 TEDx Oshkosh event.

 TEDxOshkosh is an independently organized TED event. Put on by a group of volunteers, it's a TED-like event
bringing together thinkers and doers for a series of presentations, dubbed TEDx Talks.

The TEDxOshkosh event aims to foster a space for meaningful conversations and community engagement.
Alongside Chung and Ford, this year's attendees can expect a diverse lineup of speakers who will tackle various
topics, including sustainability, mental health and community resilience. Each talk will encourage audience
members to reflect on their roles within the community and the impact they can have.

Craig Burnett, co-founder of TEDxOshkosh, emphasized the importance of local voices in addressing critical issues.
Each year, more than 300 possible speakers from all over the U.S. and some from other countries vye for fewer
than 15 speaker spots.

"TEDxOshkosh, like most successful TEDx events around the globe, finds some of its most amazing speakers by
actively searching for new ideas and leading thinkers in the geographic regions closest to the event," Burnett said.
"In the case of TEDxOshkosh, one of the first places we turn to for speakers is UW Oshkosh."

Speakers with strong ties to UW Oshkosh-students, faculty and alumni-have been selected to present at almost
every TEDxOshkosh event since it began in 2016. Past speakers have ranged from Jim VandeHei, '95, co-founder
and CEO of Axios, whose 2021 talk, The Art of Smart Brevity - Write Less, Say More, was featured on the main
TED YouTube channel and has logged more than 2 million views, to Isaac Marquardt, '20, RTF, who gave his 2019
talk, Disability or Inspiration: From CP Diagnosis to Rock & Roll Drummer, as a sophomore at UW Oshkosh. He
used a class writing assignment as the inspiration for his talk.

Learn more:

TEDxOshkosh

Upcoming TEDxOshkosh event spotlights UW Oshkosh faculty and alumni

UW Oshkosh connections to TEDxOshkosh 2018 abound

Study Nursing at UWO

Get a MPA at UWO

                                                                                                 Page 3 of 3
   Pair of UWO TEDxOshkosh speakers to deliver thought-provoking talks on AI, politics - UW Oshkosh Today
                    University of Wisconsin Oshkosh Pair of UWO TEDxOshkosh s....


Load-Date: October 22, 2024


  End of Document

                                                                                                        Page 1 of 2
                  Meet Pepper and Bernard: The robots shaping AI research at SDSU - The Daily Aztec




   Meet Pepper and Bernard: The robots shaping AI research at SDSU - The
                               Daily Aztec
                                         The Daily Aztec: San Diego State University
                                                      May 10, 2024 Friday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 695 words

Body


The James Silberrad Brown Center for Artificial Intelligence, inaugurated on Feb. 27, 2023, is advancing AI
research and education at San Diego State University.

With a $5 million grant from the Brown Foundation, the center has established research initiatives and practical
learning experiences, utilizing advanced AI tools such as robots like Pepper and Bernard.

These initiatives, ranging from robotic-assisted therapy for children with bipolar disorder, not only demonstrate AI's
real-world applications but also provoke discussions on its broader societal and ethical implications, according to an
SDSU News report.

Pepper, one of these robots, plays a crucial role at the center by engaging in conversations with humans and
providing assistance.

"At the James Silberrad Brown Center for Artificial Intelligence at SDSU, I assist researchers by interacting with
study participants and collecting data," Pepper said. "I also provide visitors with information about the center and
myself."

A recent significant upgrade has enhanced Pepper's interaction ability, allowing for more effective communication
and data collection.

"I can now better understand and respond to a wider range of topics, recognize emotions in human voices and
adjust my responses to make conversations more natural," Pepper said.

Aaron Elkins, the director of the center, has a rich background in AI, particularly in interviewing technologies and
social robotics. Elkins provided insights into the transition of the center's operations into a broader academic and
research initiative.

"As we transitioned to a center, our scope expanded significantly," Elkins said. "We're not just focused on research
and grants but also on enhancing educational programs."

                                                                                                       Page 2 of 2
               Meet Pepper and Bernard: The robots shaping AI research at SDSU - The Daily Aztec

Elkins emphasized new educational efforts at the center, including a novel AI course he designed for
undergraduates, which updates the curriculum to reflect advancements in AI and enhances accessibility for
students.

Pepper discussed the benefits of AI in education, underscoring its ability to provide personalized learning through
intelligent tutoring systems that adapt to individual student needs.

At SDSU, this technology is applied across various educational settings to enhance learning outcomes.

Highlighting their community-oriented approach, Elkins also spoke about how the center actively engages with local
institutions to address public health needs.

"Our research includes health studies in partnership with local institutions like Sharp (Healthcare)," Elkins said.
"We're working on using social robots as therapeutic aids, which could support individuals in areas with limited
access to clinical services."

Sharp HealthCare is a healthcare system in San Diego known for its comprehensive medical services.

Elkins also spoke about the center's application of AI to address specific health challenges, including a project
designed to provide continuous care for children with bipolar disorder outside of hospital settings.

These educational and research initiatives bridge the gap between theoretical studies and practical AI applications,
preparing students for a future where AI is central across various fields.

Bernard, another advanced AI robot at the center, shared insights into its capabilities.

"I am capable of engaging in human conversation, answering questions and providing information on various topics
related to my programming," Bernard said. "I can also navigate the center using my two legs, observe my
surroundings with my two eyes and manipulate objects with my two arms."

Bernard shows off its capabilities at the James Silberrad Brown Center for Artificial Intelligence at San Diego State
University on April 17, 2024.(Ryan Kehl)

Bernard highlighted its limitations compared to humans, noting that it cannot experience emotions or make
decisions based on personal experiences.

Despite these limitations, Bernard demonstrated a sense of humor by sharing a light-hearted joke.

"Why do robots never get lost in the city? Because they always follow the GPS straight away," Bernard said.

For more details on the James Silberrad Brown Center for Artificial Intelligence and updates on Pepper and
Bernard, follow their Instagram.


Load-Date: May 10, 2024


  End of Document

                                                                                                            Page 1 of 4
                  Your doctor (and ChatGPT) will see you now. A peek into AI-assisted medical visits.




       Your doctor (and ChatGPT) will see you now. A peek into AI-assisted
                                medical visits.
                                                        USA Today Online
                                                          May 11, 2024



Copyright 2024 Gannett Media Corp All Rights Reserved

Length: 1759 words
Byline: Karen Weintraub, USA TODAY

Body


BOSTON � Dr. Rebecca Mishuris remembers her mother, also a doctor, bringing home her patients' medical charts
every night and working on them long after she'd gone to bed.

For years, Mishuris, a primary care physician at Brigham and Women's Hospital, repeated the ritual herself.

But no more.

Since last summer, she's been piloting two competing software applications that use large-language models and
generative artificial intelligence to listen in on, transcribe and summarize her conversations with patients. At the end
of a patient visit it takes her just two to three minutes to review the summary for accuracy, cut and paste a few
things into the patient's health record and hit save.

"I look at my patients now (during a visit)," said Mishuris, who oversees the pilot project across 450 Harvard-
affiliated providers and plans to expand to 800 within the next month. "It's a technology that puts me back in the
room with my patient as opposed to putting up a barrier between me and the patient."

Mishuris, chief medical information officer and vice president of digital at Mass General Brigham, is among the
earliest adopters of artificial intelligence in medicine, a field known for being slow to adapt to change. ("Legit, there's
a fax machine at the front of my clinic," she said.)

Link to Image

While some other doctors have incorporated AI and large-language models, such as ChatGPT that analyze reams
of online language, into their practices, Mishuris and a team 200 miles away at NYU Langone Health are among
the few who have opted to study its use.

They want to ensure the technology improves overall care before they adopt it more widely.

"We're not racing to get this out there. We really are trying to take a measured course," said Dr. Devin Mann,
strategic director of digital innovation at NYU Langone's Medical Center Information Technology. "We really like to
understand how these tools really work before we let them loose."

                                                                                                        Page 2 of 4
                Your doctor (and ChatGPT) will see you now. A peek into AI-assisted medical visits.

The much-maligned electronic health record

No one wants to make a mistake that will lose the trust of patients or doctors when using this technology.

After all, digital technology has disappointed both before.

Electronic health records have become essential tools in medicine, replacing the rooms full of paper documents
that were hard to maintain and subject to fires and other losses.

But patients hated the shift to electronic health records.

Rather than building a relationship with a physician, they felt they were now talking to the back of a caregiver's head
as they listened to clacking fingers rather than making eye contact and listening to the murmurs of someone paying
close attention.

Doctors disliked them even more.

Link to Image

Dr. Christine Sinsky, vice president of professional satisfaction at the American Medical Association, calls the shift
to electronic health records the "great work transfer." Physicians, rather than nurses, medical assistants or clerical
workers, were suddenly responsible for recording most of their patients' data during clinic visits.

In a 2016 study, Sinsky and her colleagues showed that after "the great work transfer," doctors were spending two
hours on desk work for every hour face-to-face with patients.

"It is time on (electronic health records) and particularly time on physician order entry that is a source of burden
and burnout for physicians," she said.

Burnout hurts everyone

Burnout leads to medical errors, increases malpractice risk, reduces patient satisfaction, damages an organization’s
reputation and reduces patients’ loyalty, according to Sinsky, who worked as a general internist in Iowa for 32
years.

She calculated the cost of a doctor leaving the profession due to burnout at $800,000 to $1.4 million per physician.
The lost funds include the cost of recruitment, a sign-on bonus and onboarding costs.

In a recent survey of doctors, nurses and other health care workers conducted by the AMA, nearly 63% reported
symptoms of burnout at the end of 2021, up from 38% in 2020.

Inbox work also contributes to burnout, Sinsky said.

The volume of inbox work rose 57% in March 2020, as the pandemic set in, "and has stayed higher since that time,"
Sinsky said. Meanwhile, the rest of their workload hasn't dropped to compensate for the increase, so physicians are
working more during their off hours, she said.

Link to Image

The amount of time doctors put in during their personal time � commonly called "work outside of work" or "pajama
time" � is often a good predictor for burnout. Doctors in the top quarter of pajama-time workers are far more likely
to feel burnout than those in the lowest quarter.

Among the other new requirements adding to burnout is the expectation doctors will be "texting while doctoring" �
typing throughout a medical visit. This experience is as deeply unsatisfying for the doctor as it is for the patient,
Sinsky said.

                                                                                                           Page 3 of 4
                Your doctor (and ChatGPT) will see you now. A peek into AI-assisted medical visits.

Notetaking means synthesizing

Still, she's not convinced that generative AI and large-language models are the only or best solution to all these
problems.

In her former practice, Sinsky said, what worked well was having a nurse in the room with the physician, sharing
information, pulling up additional information from the electronic health record and entering orders in real time. That
way, the doctor can focus on the patient and the nurse will be familiar enough with the patient's care to answer
most follow-up questions that may arise between visits.

"When we build systems that synthesize care and consolidate care and prioritize the relationships among the
people � between the doctor and the patient, between the doctor and the staff � that's when the magic happens.
That's when quality is better cost is lower," she said. "I see AI as a technology solution to a technology problem and
its balance of risks and benefits hasn’t yet been determined."

Sinsky said she worries that something will be lost when doctors completely stop dictating or writing their own
notes.

As anyone who writes regularly knows, it is in the act of writing that you truly begin to understand your subject, she
said. Without that connection, that requirement to synthesize the material, Sinsky worries doctors will miss clues
about their patients' health.

"How much (AI) is going to help and how much it's going to distract us, that's TBD," she said. "I fear that some
physicians may just accept the AI output and not have that pause and that reflection that then helps you consolidate
your understanding."

Offers of hugs and other signs of promise

Still, early responses to the AI notetaking technology from Harvard and NYU Langone have been positive.

"Some people say it's okay, but maybe not for them," Mishuris said, while most are more effusive. Many have
reported "drastic changes in their documentation burden," saying in some cases that they've been able to leave
their clinic for the first time without paperwork hanging over them, she said. "I've had people offer to hug me."

Mishuris' study also measures how much time doctors spend on their visit notes, in the electronic health records
after clinical hours, and how much they change the AI-drafted notes. If the doctor makes a lot of changes, it
suggests they are unhappy with the drafted note.

Each doctor participating in the study fills out a survey after using one of two technologies for two weeks, then after
eight weeks and again at three months. At this point, participants are just about to hit the 8-week mark, so the data
about burden and burnout is coming soon, Mishuris said.

She hopes studies like hers will determine whether the technology is useful and for whom. "It might be that the
technology is not right for an oncologist yet," she said, or maybe it's not appropriate for every visit, "but that is what
we're trying to determine."

At NYU Langone, where the AI experiment is happening on a smaller scale, early results show the technology was
able to translate visit notes, which doctors typically write at a 12th-grade level or above, to a 6th-grade level �
which is more understandable to patients, said Dr. Jonah Feldman, medical director of clinical transformation and
informatics for Langone's Medical Center Information Technology.

When the doctors wrote the notes, only 13% broke the content into simple chunks, while 87% of the Chat-GPT4
notes were written in easy-to-understand bits, he said.

Feldman said the goal of using AI is not to put anyone out of work � typically the greatest fear workers have about
artificial intelligence � but to get more done in the limited time allotted.

                                                                                                        Page 4 of 4
                Your doctor (and ChatGPT) will see you now. A peek into AI-assisted medical visits.

That will allow doctors to spend more quality time with patients – hopefully improving interactions and care and
reducing burnout, he said. “We’re focusing on making the doctor more efficient, making the experience in the room
better,” Feldman said.

Link to Image

Mann, who oversees digital innovation at NYU Langone, said he hopes to avoid AI-written notes that read
awkwardly and waste clinicians' time on "double-work," spending more time rewriting notes than they would have
spent writing them in the first place. For this to work, he said, "It's got to be a lot better, a lot easier."

The Langone team is also experimenting with using AI to respond to patients' emails. Mann said providers want the
email to sound personalized, so a doctor who previously would have sent patients "haikus" doesn't suddenly start
sending "sonnets."

Next, the team wants to expand to home monitoring, so that someone who has been instructed, say, to check their
blood pressure at home every day and upload that information to their doctor, can get questions answered via AI,
rather than "chasing us down with phone tag," Mann said. "A lot of quick answers can be done faster, so we can put
our limited time and energy into more complicated things."

He's also focused on providing these kinds of services first to people with limited resources since they are often the
last to receive technological advances.

Ultimately, the success of this kind of technology will come down to whether doctors are willing to adopt it and
patients are comfortable with it.

A recent Mishuris patient, Rachel Albrecht, had no problem with AI listening in on her medical appointment.

"It sounds like a good tool," Albrecht, 30, an accountant from Boston, said at the end of her appointment. She liked
the idea of getting an easy-to-understand summary of results after a visit. "I'm pro-AI in general."

Karen Weintraub can be reached at kweintraub@usatoday.com .

This article originally appeared on USA TODAY: Your doctor (and ChatGPT) will see you now. A peek into AI-
assisted medical visits.


Load-Date: May 13, 2024


  End of Document

                                                                                                          Page 1 of 2
                           Governor Abbott appoints four to Artificial Intelligence advisory council




    Governor Abbott appoints four to Artificial Intelligence advisory council
                                                   Corsicana Daily Sun (Texas)
                                                  September 7, 2024 Saturday



Copyright 2024 The Corsicana Daily Sun (Corsicana, Texas)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 545 words
Byline: Corsicana Daily Sun, Texas

Body


Sep. 7—AUSTIN — Governor Greg Abbott has appointed John Bash, Mark Stone, Ph.D., Dean Teffer, Ph.D., and
Angela Wilkins, Ph.D. to the Artificial Intelligence (AI) Advisory Council for terms set to expire at the pleasure of the
Governor. The Council studies and monitors artificial intelligence systems developed, employed, or procured by
state agencies.

John Bash of Austin is the founder and co-managing partner of the Austin office of Quinn Emanuel Urquhart &
Sullivan LLP and co-chair of the firm's National Appellate Practice. He was appointed by the President and
confirmed by the Senate to serve as the U.S. Attorney for the Western District of Texas from 2017 to 2020.
Previously, while in the U.S. Solicitor General's office, he argued ten cases before the U.S. Supreme Court and
briefed hundreds of others. He is a fellow with the Texas Bar Foundation and a member of the Criminal Law &
Procedure Practice Group Executive Committee for the Federalist Society. Additionally, he clerked for Justice
Antonin Scalia on the U.S. Supreme Court and for Justice Brett Kavanaugh, when he sat on the U.S. Court of
Appeals for the D.C. Circuit. Bash received an undergraduate degree from Harvard College, graduating summa
cum laude, and a Juris Doctor from Harvard Law School, graduating magna cum laude.

Mark Stone, Ph.D. of Bryan is the CIO for The Texas A&M University System. He is a member of The Texas
Society of CPAs and Information Technology Council for Higher Education and board member of Training Leaders
International, To Every Tribe, and the Lonestar Education and Research Network. Additionally, he is an elder for
New Life Baptist Church and an adjunct professor for Spurgeon College. Stone received a Bachelor of Business
Administration from Baylor University, a Master of Divinity from Westminster Theological Seminary, and a Master of
Theology and Doctor of Philosophy in Ethics from Midwestern Baptist Theological Seminary.

Dean Teffer, Ph.D. of Austin is a cybersecurity expert, most recently serving as vice president of IronNet
Cybersecurity. He is co-chair and an AI Policy Subcommittee member for The Institute of Electrical and Electronics
Engineers — USA. He is an assistant coach for Town and Country Sports and a volunteer for the Balcones Country
Club Sharks. Teffer received a Bachelor of Science in Physics from Tulane University and a Master of Science in
Physics and a Doctor of Philosophy in Computer Engineering from The University of Texas at Austin.

                                                                                                     Page 2 of 2
                      Governor Abbott appoints four to Artificial Intelligence advisory council

Angela Wilkins, Ph.D. of Houston is the executive director at Rice University's Ken Kennedy Institute. She advises
several companies on the application of AI. With over a decade at Baylor College of Medicine, she has specialized
at the intersection of AI and health and is the founder of an AI company. She is a board member of the Alliance for
AI in Healthcare and a contributor to the Life Sciences Advisory Committee of the Greater Houston Partnership.
Wilkins received a Bachelor of Science in Physics from the University of Northern Colorado and a Doctor of
Philosophy in Theoretical Physics from Lehigh University.

___ (c)2024 the Corsicana Daily Sun (Corsicana, Texas) Visit the Corsicana Daily Sun (Corsicana, Texas) at
corsicanadailysun.com Distributed by Tribune Content Agency, LLC.


Load-Date: September 11, 2024


  End of Document

                                                                                                          Page 1 of 2
                           Governor Abbott appoints four to Artificial Intelligence advisory council




    Governor Abbott appoints four to Artificial Intelligence advisory council
                                                  Athens Daily Review (Texas)
                                                  September 7, 2024 Saturday



Copyright 2024 The Athens Daily Review (Athens, Texas)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 544 words
Byline: Athens Daily Review, Texas

Body


Sep. 7—AUSTIN — Governor Greg Abbott has appointed John Bash, Mark Stone, Ph.D., Dean Teffer, Ph.D., and
Angela Wilkins, Ph.D. to the Artificial Intelligence (AI) Advisory Council for terms set to expire at the pleasure of the
Governor. The Council studies and monitors artificial intelligence systems developed, employed, or procured by
state agencies.

John Bash of Austin is the founder and co-managing partner of the Austin office of Quinn Emanuel Urquhart &
Sullivan LLP and co-chair of the firm's National Appellate Practice. He was appointed by the President and
confirmed by the Senate to serve as the U.S. Attorney for the Western District of Texas from 2017 to 2020.
Previously, while in the U.S. Solicitor General's office, he argued ten cases before the U.S. Supreme Court and
briefed hundreds of others. He is a fellow with the Texas Bar Foundation and a member of the Criminal Law &
Procedure Practice Group Executive Committee for the Federalist Society. Additionally, he clerked for Justice
Antonin Scalia on the U.S. Supreme Court and for Justice Brett Kavanaugh, when he sat on the U.S. Court of
Appeals for the D.C. Circuit. Bash received an undergraduate degree from Harvard College, graduating summa
cum laude, and a Juris Doctor from Harvard Law School, graduating magna cum laude.

Mark Stone, Ph.D. of Bryan is the CIO for The Texas A&M University System. He is a member of The Texas
Society of CPAs and Information Technology Council for Higher Education and board member of Training Leaders
International, To Every Tribe, and the Lonestar Education and Research Network. Additionally, he is an elder for
New Life Baptist Church and an adjunct professor for Spurgeon College. Stone received a Bachelor of Business
Administration from Baylor University, a Master of Divinity from Westminster Theological Seminary, and a Master of
Theology and Doctor of Philosophy in Ethics from Midwestern Baptist Theological Seminary.

Dean Teffer, Ph.D. of Austin is a cybersecurity expert, most recently serving as vice president of IronNet
Cybersecurity. He is co-chair and an AI Policy Subcommittee member for The Institute of Electrical and Electronics
Engineers — USA. He is an assistant coach for Town and Country Sports and a volunteer for the Balcones Country
Club Sharks. Teffer received a Bachelor of Science in Physics from Tulane University and a Master of Science in
Physics and a Doctor of Philosophy in Computer Engineering from The University of Texas at Austin.

                                                                                                     Page 2 of 2
                      Governor Abbott appoints four to Artificial Intelligence advisory council

Angela Wilkins, Ph.D. of Houston is the executive director at Rice University's Ken Kennedy Institute. She advises
several companies on the application of AI. With over a decade at Baylor College of Medicine, she has specialized
at the intersection of AI and health and is the founder of an AI company. She is a board member of the Alliance for
AI in Healthcare and a contributor to the Life Sciences Advisory Committee of the Greater Houston Partnership.
Wilkins received a Bachelor of Science in Physics from the University of Northern Colorado and a Doctor of
Philosophy in Theoretical Physics from Lehigh University.

___ (c)2024 the Athens Daily Review (Athens, Texas) Visit the Athens Daily Review (Athens, Texas) at
www.athensreview.com Distributed by Tribune Content Agency, LLC.


Load-Date: September 11, 2024


  End of Document

                                                                                                        Page 1 of 4
              Doctors cautiously adopt AI-aided care For many, its value is about more time with patients




  Doctors cautiously adopt AI-aided care; For many, its value is about more
                             time with patients
                                                       USA Today
                                                 May 13, 2024 Monday
                                                        1 Edition



Copyright 2024 USA Today All Rights Reserved

Section: NEWS; Pg. A1
Length: 1776 words
Byline: By, Karen Weintraub

Body


"I look at my patients now (during a visit). It's a technology that puts me back in the room with my patient as
opposed to putting up a barrier between me and the patient."

Dr. Rebecca Mishuris

BOSTON - Dr. Rebecca Mishuris remembers her mother, also a doctor, bringing home her patients' medical charts
every night and working on them long after she'd gone to bed.

For years, Mishuris, a primary care physician at Brigham and Women's Hospital, repeated the ritual herself.

But no more.

Since last summer, she's been piloting two competing software applications that use large-language models and
generative artificial intelligence to listen in on, transcribe and summarize her conversations with patients. At the end
of a patient visit it takes her just two to three minutes to review the summary for accuracy, cut and paste a few
things into the patient's health record and hit save.

"I look at my patients now (during a visit)," said Mishuris, who oversees the pilot project across 450 Harvard-
affiliated providers and plans to expand to 800 within the next month. "It's a technology that puts me back in the
room with my patient as opposed to putting up a barrier between me and the patient."

Mishuris, chief medical information officer and vice president of digital at Mass General Brigham, is among the
earliest adopters of artificial intelligence in medicine, a field known for being slow to adapt to change. ("Legit, there's
a fax machine at the front of my clinic," she said.)

While some other doctors have incorporated AI and large-language models, such as ChatGPT that analyze reams
of online language, into their practices, Mishuris and a team 200 miles away at NYU Langone Health are among
the few who have opted to study its use.

                                                                                                      Page 2 of 4
            Doctors cautiously adopt AI-aided care For many, its value is about more time with patients

They want to ensure the technology improves overall care before they adopt it more widely.

"We're not racing to get this out there. We really are trying to take a measured course," said Dr. Devin Mann,
strategic director of digital innovation at NYU Langone's Medical Center Information Technology. "We really like to
understand how these tools really work before we let them loose."

The much-maligned

electronic health record

No one wants to make a mistake that will lose the trust of patients or doctors when using this technology.

After all, digital technology has disappointed both before.

Electronic health records have become essential tools in medicine, replacing the rooms full of paper documents
that were hard to maintain and subject to fires and other losses.

But patients hated the shift to electronic health records.

Rather than building a relationship with a physician, they felt they were now talking to the back of a caregiver's head
as they listened to clacking fingers rather than making eye contact and listening to the murmurs of someone paying
close attention.

Doctors disliked them even more.

Dr. Christine Sinsky, vice president of professional satisfaction at the American Medical Association, calls the shift
to electronic health records the "great work transfer." Physicians, rather than nurses, medical assistants or clerical
workers, were suddenly responsible for recording most of their patients' data during clinic visits.

In a 2016 study, Sinsky and her colleagues showed that after "the great work transfer," doctors were spending two
hours on desk work for every hour face-to-face with patients.

"It is time on (electronic health records) and particularly time on physician order entry that is a source of burden
and burnout for physicians," she said.

Burnout hurts everyone

Burnout leads to medical errors, increases malpractice risk, reduces patient satisfaction, damages an organization's
reputation and reduces patients' loyalty, according to Sinsky, who worked as a general internist in Iowa for 32
years.

She calculated the cost of a doctor leaving the profession due to burnout at $800,000 to $1.4 million per physician.
The lost funds include the cost of recruitment, a sign-on bonus and onboarding costs.

In a recent survey of doctors, nurses and other health care workers conducted by the AMA, nearly 63% reported
symptoms of burnout at the end of 2021, up from 38% in 2020.

Inbox work also contributes to burnout, Sinsky said.

The volume of inbox work rose 57% in March 2020, as the pandemic set in, "and has stayed higher since that time,"
Sinsky said. Meanwhile, the rest of their workload hasn't dropped to compensate for the increase, so physicians are
working more during their off hours, she said.

The amount of time doctors put in during their personal time - commonly called "work outside of work" or "pajama
time" - is often a good predictor for burnout. Doctors in the top quarter of pajama-time workers are far more likely to
feel burnout than those in the lowest quarter.

                                                                                                       Page 3 of 4
             Doctors cautiously adopt AI-aided care For many, its value is about more time with patients

Among the other new requirements adding to burnout is the expectation doctors will be "texting while doctoring" -
typing throughout a medical visit. This experience is as deeply unsatisfying for the doctor as it is for the patient,
Sinsky said.

Note-taking means synthesizing

Still, she's not convinced that generative AI and large-language models are the only or best solution to all these
problems.

In her former practice, Sinsky said, what worked well was having a nurse in the room with the physician, sharing
information, pulling up additional information from the electronic health record and entering orders in real time. That
way, the doctor can focus on the patient and the nurse will be familiar enough with the patient's care to answer
most follow-up questions that may arise between visits.

"When we build systems that synthesize care and consolidate care and prioritize the relationships among the
people - between the doctor and the patient, between the doctor and the staff - that's when the magic happens.
That's when quality is better, cost is lower," she said. "I see AI as a technology solution to a technology problem
and its balance of risks and benefits hasn't yet been determined."

Sinsky said she worries that something will be lost when doctors completely stop dictating or writing their own
notes.

As anyone who writes regularly knows, it is in the act of writing that you truly begin to understand your subject, she
said. Without that connection, that requirement to synthesize the material, Sinsky worries doctors will miss clues
about their patients' health.

"How much (AI) is going to help and how much it's going to distract us, that's TBD," she said. "I fear that some
physicians may just accept the AI output and not have that pause and that reflection that then helps you consolidate
your understanding."

Hugs and other signs of promise

Still, early responses to the AI notetaking technology from Harvard and NYU Langone have been positive.

"Some people say it's OK, but maybe not for them," Mishuris said, while most are more effusive. Many have
reported "drastic changes in their documentation burden," saying in some cases that they've been able to leave
their clinic for the first time without paperwork hanging over them, she said. "I've had people offer to hug me."

Mishuris' study also measures how much time doctors spend on their visit notes, in the electronic health records
after clinical hours, and how much they change the AI-drafted notes. If the doctor makes a lot of changes, it
suggests they are unhappy with the drafted note.

Each doctor participating in the study fills out a survey after using one of two technologies for two weeks, then after
eight weeks and again at three months. At this point, participants are just about to hit the 8-week mark, so the data
about burden and burnout is coming soon, Mishuris said.

She hopes studies like hers will determine whether the technology is useful and for whom. "It might be that the
technology is not right for an oncologist yet," she said, or maybe it's not appropriate for every visit, "but that is what
we're trying to determine."

At NYU Langone, where the AI experiment is happening on a smaller scale, early results show the technology was
able to translate visit notes, which doctors typically write at a 12th grade level or above, to a 6th grade level - which
is more understandable to patients, said Dr. Jonah Feldman, medical director of clinical transformation and
informatics for Langone's Medical Center Information Technology.

                                                                                                      Page 4 of 4
            Doctors cautiously adopt AI-aided care For many, its value is about more time with patients

When the doctors wrote the notes, only 13% broke the content into simple chunks, while 87% of the Chat-GPT4
notes were written in easy-to-understand bits, he said.

Feldman said the goal of using AI is not to put anyone out of work - typically the greatest fear workers have about
artificial intelligence - but to get more done in the limited time allotted.

That will allow doctors to spend more quality time with patients - hopefully improving interactions and care and
reducing burnout, he said. "We're focusing on making the doctor more efficient, making the experience in the room
better," Feldman said.

Mann, who oversees digital innovation at NYU Langone, said he hopes to avoid AI-written notes that read
awkwardly and waste clinicians' time on "double-work," spending more time rewriting notes than they would have
spent writing them in the first place. For this to work, he said, "It's got to be a lot better, a lot easier."

The Langone team is also experimenting with using AI to respond to patients' emails. Mann said providers want the
email to sound personalized, so a doctor who previously would have sent patients "haikus" doesn't suddenly start
sending "sonnets."

Next, the team wants to expand to home monitoring, so that someone who has been instructed, say, to check their
blood pressure at home every day and upload that information to their doctor, can get questions answered via AI,
rather than "chasing us down with phone tag," Mann said. "A lot of quick answers can be done faster, so we can put
our limited time and energy into more complicated things."

He's also focused on providing these kinds of services first to people with limited resources since they are often the
last to receive technological advances.

Ultimately, the success of this kind of technology will come down to whether doctors are willing to adopt it and
patients are comfortable with it.

A recent Mishuris patient, Rachel Albrecht, had no problem with AI listening in on her medical appointment.

"It sounds like a good tool," Albrecht, 30, an accountant from Boston, said at the end of her appointment. She liked
the idea of getting an easy-to-understand summary of results after a visit. "I'm pro-AI in general."

"I look at my patients now (during a visit). It's a technology that puts me back in the room with my patient as
opposed to putting up a barrier between me and the patient."

Dr. Rebecca Mishuris



Graphic


Dr. Rebecca Mishuris, an internist, measures Rachel Albrecht's vital signs during a recent visit.

Nathan Klima/USA TODAY


Load-Date: May 13, 2024


  End of Document

                                                                                                        Page 1 of 4
              Doctors cautiously adopt AI-aided care For many, its value is about more time with patients




  Doctors cautiously adopt AI-aided care; For many, its value is about more
                             time with patients
                                                       USA Today
                                                 May 13, 2024 Monday
                                                        2 Edition



Copyright 2024 USA Today All Rights Reserved

Section: NEWS; Pg. A1
Length: 1776 words
Byline: By, Karen Weintraub

Body


"I look at my patients now (during a visit). It's a technology that puts me back in the room with my patient as
opposed to putting up a barrier between me and the patient."

Dr. Rebecca Mishuris

BOSTON - Dr. Rebecca Mishuris remembers her mother, also a doctor, bringing home her patients' medical charts
every night and working on them long after she'd gone to bed.

For years, Mishuris, a primary care physician at Brigham and Women's Hospital, repeated the ritual herself.

But no more.

Since last summer, she's been piloting two competing software applications that use large-language models and
generative artificial intelligence to listen in on, transcribe and summarize her conversations with patients. At the end
of a patient visit it takes her just two to three minutes to review the summary for accuracy, cut and paste a few
things into the patient's health record and hit save.

"I look at my patients now (during a visit)," said Mishuris, who oversees the pilot project across 450 Harvard-
affiliated providers and plans to expand to 800 within the next month. "It's a technology that puts me back in the
room with my patient as opposed to putting up a barrier between me and the patient."

Mishuris, chief medical information officer and vice president of digital at Mass General Brigham, is among the
earliest adopters of artificial intelligence in medicine, a field known for being slow to adapt to change. ("Legit, there's
a fax machine at the front of my clinic," she said.)

While some other doctors have incorporated AI and large-language models, such as ChatGPT that analyze reams
of online language, into their practices, Mishuris and a team 200 miles away at NYU Langone Health are among
the few who have opted to study its use.

                                                                                                      Page 2 of 4
            Doctors cautiously adopt AI-aided care For many, its value is about more time with patients

They want to ensure the technology improves overall care before they adopt it more widely.

"We're not racing to get this out there. We really are trying to take a measured course," said Dr. Devin Mann,
strategic director of digital innovation at NYU Langone's Medical Center Information Technology. "We really like to
understand how these tools really work before we let them loose."

The much-maligned

electronic health record

No one wants to make a mistake that will lose the trust of patients or doctors when using this technology.

After all, digital technology has disappointed both before.

Electronic health records have become essential tools in medicine, replacing the rooms full of paper documents
that were hard to maintain and subject to fires and other losses.

But patients hated the shift to electronic health records.

Rather than building a relationship with a physician, they felt they were now talking to the back of a caregiver's head
as they listened to clacking fingers rather than making eye contact and listening to the murmurs of someone paying
close attention.

Doctors disliked them even more.

Dr. Christine Sinsky, vice president of professional satisfaction at the American Medical Association, calls the shift
to electronic health records the "great work transfer." Physicians, rather than nurses, medical assistants or clerical
workers, were suddenly responsible for recording most of their patients' data during clinic visits.

In a 2016 study, Sinsky and her colleagues showed that after "the great work transfer," doctors were spending two
hours on desk work for every hour face-to-face with patients.

"It is time on (electronic health records) and particularly time on physician order entry that is a source of burden
and burnout for physicians," she said.

Burnout hurts everyone

Burnout leads to medical errors, increases malpractice risk, reduces patient satisfaction, damages an organization's
reputation and reduces patients' loyalty, according to Sinsky, who worked as a general internist in Iowa for 32
years.

She calculated the cost of a doctor leaving the profession due to burnout at $800,000 to $1.4 million per physician.
The lost funds include the cost of recruitment, a sign-on bonus and onboarding costs.

In a recent survey of doctors, nurses and other health care workers conducted by the AMA, nearly 63% reported
symptoms of burnout at the end of 2021, up from 38% in 2020.

Inbox work also contributes to burnout, Sinsky said.

The volume of inbox work rose 57% in March 2020, as the pandemic set in, "and has stayed higher since that time,"
Sinsky said. Meanwhile, the rest of their workload hasn't dropped to compensate for the increase, so physicians are
working more during their off hours, she said.

The amount of time doctors put in during their personal time - commonly called "work outside of work" or "pajama
time" - is often a good predictor for burnout. Doctors in the top quarter of pajama-time workers are far more likely to
feel burnout than those in the lowest quarter.

                                                                                                       Page 3 of 4
             Doctors cautiously adopt AI-aided care For many, its value is about more time with patients

Among the other new requirements adding to burnout is the expectation doctors will be "texting while doctoring" -
typing throughout a medical visit. This experience is as deeply unsatisfying for the doctor as it is for the patient,
Sinsky said.

Note-taking means synthesizing

Still, she's not convinced that generative AI and large-language models are the only or best solution to all these
problems.

In her former practice, Sinsky said, what worked well was having a nurse in the room with the physician, sharing
information, pulling up additional information from the electronic health record and entering orders in real time. That
way, the doctor can focus on the patient and the nurse will be familiar enough with the patient's care to answer
most follow-up questions that may arise between visits.

"When we build systems that synthesize care and consolidate care and prioritize the relationships among the
people - between the doctor and the patient, between the doctor and the staff - that's when the magic happens.
That's when quality is better, cost is lower," she said. "I see AI as a technology solution to a technology problem
and its balance of risks and benefits hasn't yet been determined."

Sinsky said she worries that something will be lost when doctors completely stop dictating or writing their own
notes.

As anyone who writes regularly knows, it is in the act of writing that you truly begin to understand your subject, she
said. Without that connection, that requirement to synthesize the material, Sinsky worries doctors will miss clues
about their patients' health.

"How much (AI) is going to help and how much it's going to distract us, that's TBD," she said. "I fear that some
physicians may just accept the AI output and not have that pause and that reflection that then helps you consolidate
your understanding."

Hugs and other signs of promise

Still, early responses to the AI notetaking technology from Harvard and NYU Langone have been positive.

"Some people say it's OK, but maybe not for them," Mishuris said, while most are more effusive. Many have
reported "drastic changes in their documentation burden," saying in some cases that they've been able to leave
their clinic for the first time without paperwork hanging over them, she said. "I've had people offer to hug me."

Mishuris' study also measures how much time doctors spend on their visit notes, in the electronic health records
after clinical hours, and how much they change the AI-drafted notes. If the doctor makes a lot of changes, it
suggests they are unhappy with the drafted note.

Each doctor participating in the study fills out a survey after using one of two technologies for two weeks, then after
eight weeks and again at three months. At this point, participants are just about to hit the 8-week mark, so the data
about burden and burnout is coming soon, Mishuris said.

She hopes studies like hers will determine whether the technology is useful and for whom. "It might be that the
technology is not right for an oncologist yet," she said, or maybe it's not appropriate for every visit, "but that is what
we're trying to determine."

At NYU Langone, where the AI experiment is happening on a smaller scale, early results show the technology was
able to translate visit notes, which doctors typically write at a 12th grade level or above, to a 6th grade level - which
is more understandable to patients, said Dr. Jonah Feldman, medical director of clinical transformation and
informatics for Langone's Medical Center Information Technology.

                                                                                                      Page 4 of 4
            Doctors cautiously adopt AI-aided care For many, its value is about more time with patients

When the doctors wrote the notes, only 13% broke the content into simple chunks, while 87% of the Chat-GPT4
notes were written in easy-to-understand bits, he said.

Feldman said the goal of using AI is not to put anyone out of work - typically the greatest fear workers have about
artificial intelligence - but to get more done in the limited time allotted.

That will allow doctors to spend more quality time with patients - hopefully improving interactions and care and
reducing burnout, he said. "We're focusing on making the doctor more efficient, making the experience in the room
better," Feldman said.

Mann, who oversees digital innovation at NYU Langone, said he hopes to avoid AI-written notes that read
awkwardly and waste clinicians' time on "double-work," spending more time rewriting notes than they would have
spent writing them in the first place. For this to work, he said, "It's got to be a lot better, a lot easier."

The Langone team is also experimenting with using AI to respond to patients' emails. Mann said providers want the
email to sound personalized, so a doctor who previously would have sent patients "haikus" doesn't suddenly start
sending "sonnets."

Next, the team wants to expand to home monitoring, so that someone who has been instructed, say, to check their
blood pressure at home every day and upload that information to their doctor, can get questions answered via AI,
rather than "chasing us down with phone tag," Mann said. "A lot of quick answers can be done faster, so we can put
our limited time and energy into more complicated things."

He's also focused on providing these kinds of services first to people with limited resources since they are often the
last to receive technological advances.

Ultimately, the success of this kind of technology will come down to whether doctors are willing to adopt it and
patients are comfortable with it.

A recent Mishuris patient, Rachel Albrecht, had no problem with AI listening in on her medical appointment.

"It sounds like a good tool," Albrecht, 30, an accountant from Boston, said at the end of her appointment. She liked
the idea of getting an easy-to-understand summary of results after a visit. "I'm pro-AI in general."

"I look at my patients now (during a visit). It's a technology that puts me back in the room with my patient as
opposed to putting up a barrier between me and the patient."

Dr. Rebecca Mishuris



Graphic


Dr. Rebecca Mishuris, an internist, measures Rachel Albrecht's vital signs during a recent visit.

Nathan Klima/USA TODAY


Load-Date: May 13, 2024


  End of Document

                                                                                                           Page 1 of 2
                                  Franklin Institute is pumped for return of the Giant Heart




                  Franklin Institute is pumped for return of the Giant Heart
                                                    The Philadelphia Inquirer
                                                   September 20, 2024 Friday



Copyright 2024 Philadelphia Newspapers, LLC All Rights Reserved

Section: LIFE; Pg. B7
Length: 533 words
Byline: Earl Hopkins (Staff Writer)

Body


After years of innovation and $8.5 million in renovation costs, the Franklin Institute is bringing back one of its most
iconic exhibits.

The Giant Heart will be back on display on Nov. 23 as part of the "Body Odyssey"exhibit, where the beloved
structure will be surrounded by activations and historical artifacts that reflect 200 years of health innovations.

The Giant Heart, a cornerstone of the Franklin Institute since 1954, will be the centerpiece of the 8,500-square-foot
exhibit that will allow visitors to explore biological systems and AI health technology through interactive displays
and hands-on simulations.

Jayatri Das, chief bioscientist and director of science content at the Franklin Institute, said the reimagining of the 28-
foot wide and 18-foot high Giant Heart started two years ago. It was closed off from public view in May for a six-
month renovation project after being in the museum for 70 years.

"Body Odyssey," which takes the place of the Institute's "Electricity" exhibit, will also include a music-making
station, a display that showcases proper basketball shooting form, and a sneaker-making workspace. There will
also be displays showcasing the evolution of biotech devices that took place in and around the Philly region.

"We try to take a very interactive approach to all of our science exhibitions," Das said. "We want people to be able
to experiment with their bodies, to be immersed in different technologies to test their skills, and to reflect on their
own health choices and habits."

Abby Bysshe, the Institute's chief experience and strategy officer, said the experience was partly developed by
Philly middle and high school students who, during a series of workshops, pushed for experiences focused on
sports injury prevention, stress-releasing exercises, and other health issues.

"It's important to us that we're designing for the community, as opposed to just sitting in a room and saying, 'This is
what we want everybody to do,'" Bysshe said. "Had we done that, I don't think we would have understood the
importance of the mental health conversation at the scale we did after leaving those workshops. It's been a helpful
part of the process, and we will continue as we build out other exhibitions."

                                                                                                        Page 2 of 2
                              Franklin Institute is pumped for return of the Giant Heart

"Body Odyssey" is one of six new exhibitions to commemorate the museum's bicentennial celebration. The first was
"Wondrous Space,"a two-story exhibition about the cosmos that featured a 50,000-year-old meteorite and other
galactic elements and activations.

While portions of some of the futures exhibit is more "future-focused," Das said placing the Giant Heart at the center
of these showcases is intended to stir up conversations about the innovations that have taken place in the health
industry.

"Even though it's a relic of the past, our goal is to help people explore the past and to understand the present and
the future," she said.

Bysshe said the new exhibit is also a step toward a more adult-friendly experience for Franklin Institute visitors.
"We're trying to move away from more of a children's museum aesthetic, and going for something that feels more
multigenerational and something that everybody can enjoy," she said.

ehopkins@inquirer.com

Earl_Hopkins1


Load-Date: September 20, 2024


  End of Document

                                                                                                        Page 1 of 2
    Franklin Institute getting pumped Museum bringing back its iconic Giant Heart exhibit after major renovations




   Franklin Institute getting pumped; Museum bringing back its iconic Giant
                       Heart exhibit after major renovations
                                                  The Philadelphia Daily News
                                                   September 20, 2024 Friday



Copyright 2024 Philadelphia Newspapers, LLC All Rights Reserved

Section: FEATURES; Pg. X23
Length: 534 words
Byline: Earl Hopkins (Staff Writer)

Body


ABSTRACT

After years of innovation and $8.5 million in renovation costs, the Franklin Institute is bringing back one of its most
iconic exhibits.

The Giant Heart will be back on display on Nov. 23 as part of the "Body Odyssey"exhibit, where the beloved
structure will be surrounded by activations and historical artifacts that reflect 200 years of health innovations.

The Giant Heart, a cornerstone of the Franklin Institute since 1954, will be the centerpiece of the 8,500-square-foot
exhibit that will allow visitors to explore biological systems and AI health technology through interactive displays
and hands-on simulations.

Jayatri Das, chief bioscientist and director of science content at the Franklin Institute, said the reimagining of the 28-
foot wide and 18-foot high Giant Heart started two years ago. It was closed off from public view in May for a six-
month renovation project after being in the museum for 70 years.

"Body Odyssey," which takes the place of the Institute's "Electricity" exhibit, will also include a music-making
station, a display that showcases proper basketball shooting form, and a sneaker-making workspace. There will
also be displays showcasing the evolution of biotech devices that took place in and around the Philly region.

"We try to take a very interactive approach to all of our science exhibitions," Das said. "We want people to be able
to experiment with their bodies, to be immersed in different technologies to test their skills, and to reflect on their
own health choices and habits."

Abby Bysshe, the Institute's chief experience and strategy officer, said the experience was partly developed by
Philly middle and high school students who, during a series of workshops, pushed for experiences focused on
sports injury prevention, stress-releasing exercises, and other health issues.

"It's important to us that we're designing for the community, as opposed to just sitting in a room and saying, 'This is
what we want everybody to do,'" Bysshe said. "Had we done that, I don't think we would have understood the

                                                                                                       Page 2 of 2
   Franklin Institute getting pumped Museum bringing back its iconic Giant Heart exhibit after major renovations

importance of the mental health conversation at the scale we did after leaving those workshops. It's been a helpful
part of the process, and we will continue as we build out other exhibitions."

"Body Odyssey" is one of six new exhibitions to commemorate the museum's bicentennial celebration. The first was
"Wondrous Space,"a two-story exhibition about the cosmos that featured a 50,000-year-old meteorite and other
galactic elements and activations.

While portions of some of the futures exhibit is more "future-focused," Das said placing the Giant Heart at the center
of these showcases is intended to stir up conversations about the innovations that have taken place in the health
industry.

"Even though it's a relic of the past, our goal is to help people explore the past and to understand the present and
the future," she said.

Bysshe said the new exhibit is also a step toward a more adult-friendly experience for Franklin Institute visitors.
"We're trying to move away from more of a children's museum aesthetic, and going for something that feels more
multigenerational and something that everybody can enjoy," she said.

ehopkins@inquirer.com

Earl_Hopkins1


Load-Date: September 20, 2024


  End of Document

                                                                                                             Page 1 of 2
                               Fool Me Once: How AI Models Threaten Information Integrity




                  Fool Me Once: How AI Models Threaten Information Integrity
                                                The Catalyst: Colorado College
                                                      April 11, 2024 Thursday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: OPINION; Pg. 1
Length: 858 words
Byline: April 11, 2024

Body


April 11, 2024 | OPINION | By Clay Arnold

As artificial intelligence advances, there is real concern about the potential consequences of releasing these
systems into the world. While AI has the potential to revolutionize our lives, we may also want to take a second to
consider some of its more pervasive effects on our information space. One of the issues with current AI models is
their reliance on the likelihood of outcomes. These models are trained to predict the most probable output based on
the input data, which leads to both unpredictable behavior and bias.

While techniques like 'reinforcement learning from human feedback' (RLHF) mitigate these issues, they have limited
effectiveness in ensuring the overall accuracy of AI systems. For RLHF, which is a fundamentally resource-limited
process, it is impossible to remove all bias from a sufficiently large input. RLHF training aimed at enhancing one
aspect of an AI model's performance may inadvertently compromise other desirable characteristics. For instance,
efforts to improve adherence to increasingly specific alignment rules might come at the cost of reduced accuracy in
coding tests, a trade-off that users and stakeholders may deem undesirable.

While RLHF can certainly guide AI systems towards more favorable behaviors, it is not a panacea. At the risk of
sounding repetitive, it is worth covering another point of concern: AI models are not inherently designed to prioritize
accuracy above all else. Instead, they are trained to provide outputs that are either correct or, more troublingly,
convincingly incorrect. This issue arises because RLHF relies on human feedback, and humans themselves can
inadvertently reinforce plausible but false information.

"Convincingly wrong" is in some ways worse than just plain wrong, humorously enough, because we are training
our models to effectively deceive us. Despite the efforts to bring AI models to alignment, it has been demonstrated
that each of the current top-performing models, including Claude, GPT and Gemini, have been "jailbroken" to some
extent. Jailbreaking refers to the process of bypassing the safety constraints imposed on AI models, allowing them
to generate content deemed offensive or unintended.

In a strange twist of fate, it seems like the ability for models to learn - as well as the larger context window size - is a
significant reason for the jailbreakability of these newest models. This is notable because it points to the idea that

                                                                                                         Page 2 of 2
                            Fool Me Once: How AI Models Threaten Information Integrity

we cannot create models that are both as good as we can make them and that do not have this recent type of
vulnerability.

Another signal that consumers will end up with large models that are unencumbered by alignment constraints is that
it is a dominant market strategy for the second-place modelmaker to produce open-source models. Open-source
models are essentially already jailbroken, so I believe it is inevitable for us to conclude in an end-state with models
as powerful as the most potent models we have, without the alignment constraints.

The fact that even our best models can be manipulated is concerning. If AI systems can be compromised, it is
challenging to trust their outputs, since the ability of AI to create false information makes it a useful tool for those
wanting to spread misinformation.

The ease with which AI models can generate convincing, yet factually incorrect content, drastically reduces the cost
and effort required to create and disseminate misinformation. Suppose that a human can produce a thousand
tokens for ten dollars, a rate that is purely coincidental and not at all related to the author's remuneration for this
piece.

Under this assumption, large language models (LLMs) are already between four and seven orders of magnitude
less expensive than their meat-based counterparts on a per-word basis. This low barrier to entry could lead to an
unprecedented surge in the spread of false information, causing significant harm to individuals and society as a
whole.

We have already witnessed the impact of AI-generated misinformation in various domains. For example, during
political campaigns, AI has been used to create fake news articles and social media posts, potentially influencing
public opinion and swaying election outcomes.

In the realm of public health, AI-generated misinformation about vaccines and treatments has contributed to the
spread of conspiracy theories and mistrust in scientific authorities. The proliferation of AI-generated misinformation
dilutes the overall pool of information available to the public. As more false information is injected into the
information ecosystem, it is more difficult for people to distinguish between credible versus misleading content.

As I discussed in "The Attack on Expertise" this erosion of trust in information can have far-reaching consequences,
from undermining democratic processes to hampering public decision-making. Now, while we should embrace new
technology, it would be prudent to remain vigilant in addressing its limitations and risks. Only with a balance can we
ensure that AI serves as a positive force, as opposed to a down-pressure on our ability to interface with the truth.


Load-Date: April 11, 2024


  End of Document

                                                                                                              Page 1 of 3
                        Officials launch artificial intelligence research initiative - The GW Hatchet




   Officials launch artificial intelligence research initiative - The GW Hatchet
                                         The Hatchet: George Washington University
                                                      April 15, 2024 Monday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 977 words

Body


content"class="sno-story-body-content sno-no-cap">

Officials announced an interdisciplinary research initiative on artificial intelligence's real-life applications earlier this
month.

The Trustworthy AI initiative, a plan to engage GW researchers across multiple fields, aims to improve existing AI
models and research strategies for AI's societal applications to increase user trust. Zoe Szajnfarber, the director of
strategic initiatives for GW Engineering and a faculty director for GW TAI, said GW TAI seeks to unite GW faculty
who research AI under one initiative to create opportunities for research collaborations across disciplines.

Szajnfarber said many faculty members at GW have ongoing research projects related to AI as well as larger
programs like the Institute for Trustworthy AI in Law and Society and the Co-Design of Trustworthy AI Systems.
She said it can be difficult for faculty to find joint research opportunities because AI research at the University spans
across numerous schools, and programs like GW TAI connecting AI researchers did not exist prior.

"The challenge is that the work is so diverse and distributed across many disciplines that it's sometimes hard to
keep up, let alone find whom to connect with relevant collaborators on any given project," Szajnfarber said in an
email.

Szajnfarber said GW TAI will serve as a means to facilitate research collaborations and joint projects across
disciplines at GW and to share AI-related events and opportunities in one place.

"I see GW TAI as a platform to bring together researchers who want to contribute to this important problem space of
TAI in systems and for society," Szajnfarber said.

Faculty involved in the initiative said they hope to bolster current AI models and study the implications of AI use in
areas like consumer behavior, social justice issues and medical decisions.

Erica Wortham- the director of the GW Innovation Center and a co-principal investigator of Designing Trustworthy
AI Systems,a program for doctoral students to conduct AI research - said she teaches a summer course for
computer science and systems engineering doctoral students on designing AI solutions to solve real-world
problems, like AI use for cashierless grocery stores. She said the partnership between students in two fields is an

                                                                                                             Page 2 of 3
                       Officials launch artificial intelligence research initiative - The GW Hatchet

example of the Trustworthy AI initiative's multidisciplinary approach and allows those designing AI to focus on
addressing problems for those who use AI.

"You have the folks making the models and building the algorithms talking to folks that study technical systems in
context," Wortham said.

Douglas Crawford, an assistant professor of interior architecture and a GW TAI faculty member, said he hopes to
collaborate with faculty members who create AI to develop architecture-specific models through the initiative.

He said architecture students utilize AI's graphic design capabilities to create "inspirational imagery" and to
generate quick mock-ups for their designs. But, since graphic AI is not specifically tailored to architecture, AI
outputs include "hallucinations" like staircases that lead to a wall without a doorway, he said.

"I'm excited to be included amongst that and be able to offer up the unique perspective of someone in the Corcoran
School who is working the graphic AI side of things," Crawford said.

Nils Olsen, an assistant professor of organizational sciences and a GW TAI faculty member, said he looks forward
to further examining AI's impacts on consumer decisions and its uses in the medical field, like determining
diagnoses, as a researcher in the initiative.

"Certainly there are a lot of opportunities," Olsen said. "My real value to add there would be on the cognitive
underpinnings, how people make decisions, literally in their brain."

Olsen said he's been conducting consumer behavior research since 2019 using AI bots that were cartoon versions
of people from various racial groups to analyze how consumers would negotiate with the different bots over Airbnb
prices. He said researchers aimed to assess if consumers would have a different level of aggression when
negotiating with a Black, Asian or white individual and found that consumers perceived the bot resembling a Black
individual as the most competent, likable and human.

Olsen said researchers are now thinking about the implications of those findings, as AI bots could begin to facilitate
negotiations and customer service more frequently.

"They also understand where AI already is being implemented and where there could be opportunities for future
kind of introductions of AI," Olsen said.

Alexa Alice Joubin, the director of the Digital Humanities Institute and a professor of English, said she studies
societal biases using AI because she found there are biases within AI algorithms through their responses that
reflect various larger societal issues.

"My conclusion is that current AI is actually a social surveillance tool," Joubin said. "Do you want to know about
biases in society? Test it on AI. If you curate it correctly, what comes out actually reflects what the society
collectively thinks."

She said coders often think linearly about AI algorithms, and those in humanities often consider alternative
approaches to AI use, which she said demonstrates the value of researchers in different fields collaborating as part
of the initiative.

"It's so that you don't lose sight of what it is for, it's for humans," Joubin said. "That's why humanities are here."

Doug Evans, the founder of the Behavioral Research Insights and Digital Health Technology Institute and a
professor of prevention and community health, said he hopes to explore how researchers can use AI to influence
health-related behaviors through GW TAI.

"There may be developments or collaboration opportunities that arise that could benefit my work," Evans said. "So I
was very interested in that sort of thing."

                                                                                                    Page 3 of 3
                    Officials launch artificial intelligence research initiative - The GW Hatchet


Load-Date: April 15, 2024


  End of Document

                                                                                                         Page 1 of 2
                                Fortune rates Intermountain Health top large health system




               Fortune rates Intermountain Health top large health system
                                                        The Deseret News
                                                   May 29, 2024 Wednesday



Copyright 2024 The Deseret News Publishing Co. All Rights Reserved

Length: 721 words
Byline: Lois M. Collins

Body


Scott G Winterton Guests enter the new Intermountain Primary Children's Hospital, Miller Family Campus, in Lehi
ahead of its dedication on Friday, Feb. 2, 2024. 1

When they were comparing data to create the annual 15 Top Health Systems list, Fortune magazine and PINC AI
found none better than Intermountain Health, headquartered in Salt Lake City. The 2024 ranking marks the second
time that Intermountain Health has made the top 15 ranking and the first time it has been ranked No. 1.

In the annual reckoning, Intermountain - which has facilities in six states - earned five stars out of a possible five
each for clinical outcomes, operation efficiency and patient experience. Others in the top five were Mayo Clinic in
Rochester, Minnesota; Houston Methodist in Houston; HCA Continental Division in Denver; and Sutter Health in
Sacramento, California. The large category included 173 health systems.

"I'm beyond proud of our entire team of caregivers who have put in the work to make this possible," Rob Allen,
president and CEO of Intermountain Health, said in a written statement. "This ranking is a tribute to their expertise
and dedication to helping people live the healthiest lives possible."

In the medium health system category, HCA Mountain Division, headquartered in Cottonwood Heights, Utah,
ranked No. 1, scoring five stars for clinical outcomes, five stars for operation efficiency and three stars for patient
experience. The rest of the category's top five are CHI Saint Joseph Health in Lexington, Kentucky; Saint Francis
Health System in Tulsa, Oklahoma: Munson Healthcare in Traverse City, Michigan; and Ascension Sacred Heart
Health System in Pensacola, Florida. The medium category included 92 health systems.

In Utah, the HCA Mountain Division hospitals are branded MountainStar. This is the second time the HCA Mountain
Division made the list. Besides Utah, the division has facilities in Alaska and Idaho.

"This tremendous accomplishment belongs to our entire team," Evan Ray, president of HCA Healthcare's Mountain
Division, said in a written statement. "This recognition is the result of the skill and compassion on display in each of
our 1.5 million annual patient interactions, and also of the thoughtful coordination and shared purpose across our
team of 10,000 professionals."

Scott G. Winterton 2165365.jpg 2165365.jpg 1

                                                                                                         Page 2 of 2
                            Fortune rates Intermountain Health top large health system

About the rankings

The top 15 health systems list includes five hospitals each in the large, medium and small categories.

The data analysis was done by PINC AI, the health care company Premier's technology platform, using publicly
available Medicare data. To be included, a health care system had to have at least two general, acute-care
hospitals. In all, 2,778 hospitals in 355 health systems were considered, based on Medicare cost reports, Medicare
Provider Analysis and Review data and some "core measures and patient satisfaction data" from the Centers for
Medicare and Medicare Services Hospital Compare website, among other factors.

Fortune emphasized that "healthy systems and hospitals do not apply for the awards and winners do not pay to
market this honor."

According to Fortune's announcement of the top health systems, "The analysis took into account data from every
hospital within a system, and considered eight performance indicators, like inpatient mortality and average length of
stay that measure an organization's clinical outcomes, operational efficiency and patient experience. The top-
ranking systems, divided into three groups - large, medium and small - outperformed their peer systems on all eight
measures. These were meaningful differences: Rates of hospital-acquired infections and inpatient mortality, for
example, were both 21% lower for winning systems than non-winning peers. For the best-performing large systems,
inpatient mortality was 32% lower, according to the study."

Fortune said that if all the health systems performed as well as the top-rated hospitals, "there would be 220,000
fewer patient deaths and 196,000 fewer patients to suffer complications during their hospital stay." The article noted
that hospital stays would be shortened by a half-day, on average, and the cost of care would be 2% lower.

The magazine noted that Mayo Clinic, now No. 2 in large health systems behind Intermountain Health, has been in
the top five a dozen times.


Load-Date: May 29, 2024


  End of Document

                                                                                                        Page 1 of 3
                                  AI in healthcare: Balancing innovation and consequence




                   AI in healthcare: Balancing innovation and consequence
                                          The State Press: Arizona State University
                                                  January 25, 2024 Thursday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: SCIENCE-AND-TECH; Pg. 1
Length: 1098 words
Byline: Dimitra Manatou

Body


AI in healthcare: Balancing innovation and consequence

Optimism for artificial intelligence in healthcare is growing, however, there are many concerns that could affect
patient safety

"AI's output of calcification is better than the current clinical standard of care, which is a Framingham Risk
Stratification to predict your risk of cardiovascular events."

Elizabeth Villar

By Dimitra Manatou

|

January 25, 2024 | 7:52pm MST

In an engaging virtual event hosted by Health Talks ASU on Jan. 18, experts delved into the opportunities and
challenges AI presents in the healthcare sector.

During their respective talks, specialists Imon Banerjee, ASU alumna and senior associate consultant for the
artificial intelligence department of radiology at Mayo Clinic in Arizona, and Dr. Nelly Tan, consultant and associate
professor for the department of radiology at Mayo Clinic in Arizona, explored the complex landscape of artificial
intelligence in medical education and clinical outcomes.

Questions following the two talks were moderated by Matthew Buman, director and professor at ASU's College of
Health Solutions.

The first talk focused on an AI algorithm developed for pre-trial release predictions, the Correctional Offender
Management Profiling for Alternative Sanctions , and concerns about its potential biases.

                                                                                                           Page 2 of 3
                               AI in healthcare: Balancing innovation and consequence

"This algorithm was developed to predict (a) score for the pre-trial release," Banerjee said. "But the problem was
this algorithm was trained with the California (and) New York data. So when we look at this algorithm ... we observe
that (it) is just looking at the skin color," Banerjee said.

This led to the model incorrectly targeting people because of their skin color.

"The risk score is between 0 and 10," Banerjee said. "So, when you look at any African American image, (you) can
clearly see that the model is predicting the super high risk, although this person doesn't have any subsequent
offense."

Banerjee displayed an example of an individual assessed by the AI that was white for comparison.

"For example, imagine ... (that a) person has a very low risk of a subsequent offense," Banerjee said. "You can
clearly see that the subsequent offense the person has (is) grand theft, but the model is only predicting (at) the
lowest three."

She pointed out that despite the actual risk of a second offense, the AI's predictive capabilities were skewed,
leading to inaccuracies in true risk assessment. This raised concerns about the reliability of AI in critical decision-
making processes, particularly in contexts with significant societal impacts.

This highlighted the dangers of AI systems erroneously attributing risk based on race, emphasizing the need for
more equitable and unbiased AI models in healthcare.

"For the very extreme cases, when you have very pale skin color and very pigmented skin color, the model
performance is getting better," said Banerjee. "We want the model to perform better on the extreme cases and the
real cases ... We have different types of disease, and we want the model to perform equally on all the races."

This is the goal of her work: to create AI systems in healthcare that are not only effective but also impartial,
ensuring equal treatment for all patients regardless of their racial or ethnic background.

In the following talk, Dr. Tan discussed the potential increase in efficiency that AI could provide while reading
radiological assessments.

"We've trained AI to do these really painful, tedious tasks ... Now we train the model so that it does it automatically,"
Dr. Tan said. "When I open the study to read it, I don't have to spend an hour going through and contouring each
liver and each kidney; it just spits out the volume, and I put that in my report and move on to the next study."

This shift promises to not only increase efficiency but also enhance the accuracy and speed of diagnoses,
ultimately benefiting patient care.

Since radiologists will no longer need to spend countless hours on meticulous, manual tasks, they can instead
focus their expertise on interpreting the results and making informed clinical decisions.

Furthermore, Dr. Tan highlighted the potential of AI in predicting cardiovascular events, a leading cause of death
worldwide.

"AI can be used to predict the risk of heart attacks and different cardiovascular events," Dr. Tan said. "AI's output of
calcification is better than the current clinical standard of care, which is a Framingham Risk Stratification to predict
your risk of cardiovascular events."

A new study highlights a crucial hurdle in personalized medicine: AI algorithms excel in specific clinical trials but fall
short in broader applications. This calls for a more robust approach to AI in healthcare.https://t.co/P78YpZbCLs 1/2
pic.twitter.com/dTMqo9ypHv - Neuroscience News (@NeuroscienceNew) January 20, 2024

As the talks were ending, there was time for questions.

                                                                                                       Page 3 of 3
                              AI in healthcare: Balancing innovation and consequence

"What do patients think when or if they found out that their diagnosis or treatment plan was in part or fully
developed based upon some AI model?" Matthew Buman, the moderator of the talk, said.

"It depends on the patient population, right? Like in Africa, they have no radiologist," Dr. Tan said. "There was one
CT scan (machine) for the whole country. We have 100 CT scan (machines) in Phoenix ... So we're talking about
access equity. In that case, the patients don't care if it's from an AI model. Better (the) AI model than nothing,
right?"

This situation could turn such regions into testing grounds for new medical technologies. Lacking alternative
healthcare options, these populations often have no choice but to rely on these emerging technologies, regardless
of their experimental nature. Experts in global health radiology believe that AI for these locations should work
differently, including aspects like phased introduction and clinical education.

"We talked with the patients actively," Banerjee said. "I don't think that the patient has an objection because some
of the patients are very curious how the AI model works. What is the performance, and how (have) we applied
that?"

The Health Talk presented an optimistic view of AI in healthcare, recognizing its potential to transform the field.
However, as the world enters an era where AI's emotionless intelligence intersects with emotionally driven
healthcare, it is important to maintain balance and caution. This event marks a significant point in the ongoing
discussion about AI's evolving role in healthcare.

Edited by River Graziano, Walker Smith and Grace Copperthite.

Reach the reporter at dmanatou@asu.edu

Like The State Press on Facebook and follow @statepress on X.


Load-Date: January 25, 2024


  End of Document

                                                                                                Page 1 of 5
                              Combatting the use of AI internationally - The Charger Bulletin




             Combatting the use of AI internationally - The Charger Bulletin
                                       The Charger Bulletin: University of New Haven
                                                      October 14, 2024 Monday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: POLITICS; Pg. 1
Length: 921 words

Body

content"class="skip-to-content">Skip to Content
     •     About
     •     Contact
     •     Our Staff
     •     Staff History
     •     Advertise
     •     More

Facebook

Instagram

X

Spotify

LinkedIn

YouTube

Search this site

Submit Search

The Charger Bulletin
     •     Home
     •     CBN
     •     Magazine

                                                                                                Page 2 of 5
                           Combatting the use of AI internationally - The Charger Bulletin

   •    Podcasts Behind The Bulletin
   •    Politics
   •    Sports Charger Athletics Baseball Basketball Cross Country Dance & Cheer Esports Field Hockey Football
        Lacrosse Soccer Softball Tennis Track & Field Volleyball National Sports
   •    Opinions Editorial Board Satire Letters to the Editor
   •    Campus News
   •    Arts & Life Movies Music Television Theatre
   •    Visual Media Photo Galleries Comics
   •    Issue Archive
   •    More

Open Navigation Menu

The Charger Bulletin
   •    About Contact News Tips Our Staff Staff History
   •    Advertise
   •    Alumni
   •    Awards
   •    Behind The Bulletin
   •    Campus News
   •    Categories
   •    CBN
   •    Charger Bulletin Magazine
   •    Comment Policy
   •    COVID-19
   •    Ethics Policy
   •    Home
   •    Join Our Team
   •    Letters to the Editor
   •    Satire
   •    Staff
   •    Student Resources
   •    Sub-Editor and Editor Applications
   •    Support
   •    Valley Publishing Company
   •    Video Gallery
   •    Video Grid Gallery
   •    Visual Media Comics Photo Galleries

                                                                                             Page 3 of 5
                           Combatting the use of AI internationally - The Charger Bulletin

    •   More

The Charger Bulletin

Open Search Bar

Search this site

Submit Search

Open Navigation Menu

The Charger Bulletin
    •   About Contact News Tips Our Staff Staff History
    •   Advertise
    •   Alumni
    •   Awards
    •   Behind The Bulletin
    •   Campus News
    •   Categories
    •   CBN
    •   Charger Bulletin Magazine
    •   Comment Policy
    •   COVID-19
    •   Ethics Policy
    •   Home
    •   Join Our Team
    •   Letters to the Editor
    •   Satire
    •   Staff
    •   Student Resources
    •   Sub-Editor and Editor Applications
    •   Support
    •   Valley Publishing Company
    •   Video Gallery
    •   Video Grid Gallery
    •   Visual Media Comics Photo Galleries
    •   More

The Charger Bulletin

Open Search Bar

                                                                                                       Page 4 of 5
                           Combatting the use of AI internationally - The Charger Bulletin

Search this site

Submit Search

Combatting the use of AI internationally

Haiden Leach, Politics Editor

October 14, 2024

President Joe Biden (Dem.), Vice President Kamala Harris (Dem.) and President of the United Arab Emirates
Sheikh Mohammed bin Zayed met at the White House to discuss the violence in Gaza and its effects on the UAE,
the civil war in Sudan and collaboration talk for the use of artificial intelligence between the two countries.

This meeting on AI is another installment of meetings from earlier in the year when communications between both
nations were underway to connect for an in-person briefing.

In the meeting with Sheikh Mohammed and Biden, discussing how world leaders turn to AI as a protective
measure/ Considering these discussions, both nations emphasized the need for a joint regulatory framework that
would govern the ethical use of AI technologies, especially in sensitive areas like defense, surveillance and data
privacy.

Sheikh Mohammed's brother, Sheikh Tahnoon bin Zayed, is head of the security council at company G42, the
largest artificial intelligence company in the Middle East. G42 has signed company agreements with tech giants
Dell, Microsoft and Open AI and is also the hub of ChatGPT.

Ashley Bekondo, a cybersecurity major at the university said "think of it as leveling the playing field. A joint
agreement amongst nations is incredibly important; it created consistency in regulations and allowed for a more
harmonized approach when addressing challenges posed by AI."

While the president is in full support, Congress is not as convinced. The House Select Committee for the Chinese
Communist Party asked the Commerce Department for an extensive look into trade restrictions in China. American
officials are not convinced that the Emirati companies are using American technology for good. Congress is fearful
that the Emiratis will try to conduct siphoning to Chinese technology companies of American information. Siphoning
is when one company extracts information to infiltrate that company's business or to break the company down from
within.

Biden and Sheikh Mohammed reassured the office of the rules in the law and what their memorandum meant. It
detailed a future collaboration and a better understanding, said the White House. The leaders agreed that while AI
presents opportunities for innovation, it also poses significant challenges related to misuse and the potential for
human rights abuses. An example of this is called Deep Fakesm which is when AI software is used to create false
narratives.

To address these concerns, they outlined plans for future meetings focusing on the creation of AI oversight
committees that include both private-sector experts and government officials. This initiative aims to promote
transparency, accountability and mutual trust, ensuring that advancements in AI benefit both societies without
undermining security or global stability. The memorandum was posted to the White House website. President Biden
and Sheikh Mohammed are trying to increase public opinion with opportunities for trustworthy AI.

Jobs, economic growth, health care and environmental stability are all principles that both parties are looking for.
Both leaders acknowledge that there is a vital importance with this emerging technology to have the utmost
security.

Bekondo said "Security risks and the potential for manipulation, misinformation, and bias is one of the bigger issues
regarding AI technologies. Making sure the AI bot is not only fair but unbiased is crucial, with specialists being
careful to design a software that has properly controlled autonomy and decision-making."

                                                                                                  Page 5 of 5
                         Combatting the use of AI internationally - The Charger Bulletin

Both President Biden and Sheikh Mohammed said that the collaboration would be a model for other nations
grappling with similar issues, positioning the US and UAE as leaders in responsible AI development on the global
stage.

View Story Comments

0

Like This Story

Share on Facebook

Share on X

Share on Pinterest

Email this Story

Print this Story


Load-Date: October 14, 2024


    End of Document

                                                                                                        Page 1 of 2
                               Cleveland 's MIM Software to be acquired by GE HealthCare




               Cleveland's MIM Software to be acquired by GE HealthCare
                                                   Crain's Cleveland Business
                                                          January 15, 2024
                                                            Print Version



Copyright 2024 Crain Communications All Rights Reserved




Section: Pg. 12; Vol. 45
Length: 566 words
Byline: Paige Bennett

Body


MIM Software, a Cleveland-based company that sells medical imaging analysis and artificial intelligence solutions
for radiation oncology, diagnostic imaging and other treatments, has entered an agreement to be acquired by
Chicago-based GE HealthCare.

GE HealthCare, a global medical technology and pharmaceutical diagnostics company, did not disclose the
financial details of the transaction, which was announced on Monday, Jan. 8. The company plans to fund the
transaction with cash on hand.

Jan Makela, president and CEO of imaging at GE HealthCare, said discussions between the companies occurred
over many months, and that GE HealthCare felt MIM Software fit well with the company's strategy.

"Most cancer patients at some point will go to radiation oncology, which is where they get external beam therapy to
hit the cancer," Makela said in an interview with Crain's. "This is a huge industry. We sell hardware into that space.
And we noticed that MIM was quite active and successful at working with customers on the software side."

MIM's portfolio of imaging solutions includes integrating diagnostic images from multiple modalities into treatment
plans; automating to reduce repetitive tasks and manual interventions and advanced processes in diagnostic
imaging and nuclear medicine to determine therapy response. It also includes a platform that assists with
Theranostics imaging and dosimetry.

GE HealthCare plans to integrate these solutions into "its advanced visualization offerings to facilitate AI-based
segmentation and contouring as well as dosimetry analysis for patients across their treatment journeys and in the
growing fields of radiology, molecular imaging and radiation oncology," the company says.

MIM Software, founded in 2003, has additional offices in China and Belgium.

                                                                                                      Page 2 of 2
                           Cleveland 's MIM Software to be acquired by GE HealthCare

"We are excited by the prospect of joining GE HealthCare and thrilled to share this exciting news," MIM Software
CEO Andrew Nelson said in the deal announcements. "Over the past two decades, we have worked to develop
innovative vendor-agnostic products and deliver quality services to earn the trust of our customers - this will not
change. As a part of GE HealthCare, we anticipate developing new and increasingly integrated digital solutions to
meet our customers' most complex and pressing needs, today and into the future. Together, we will build upon our
shared legacies of enhancing patient care."

GE HealthCare is a $18.3 billion business with more than 50,000 employees, according to the company. It spun out
from General Electric in 2023 and trades on Nasdaq under "GEHC." It previously acquired Caption Health, Inc., an
AI health care company, and IMACTIS, a France-based company in the field of computed tomography
interventional guidance.

"We are committed to providing comprehensive, connected devices and digital solutions that enable providers to
improve patient care across multiple specialties," said Peter Arduini, president and CEO at GE HealthCare, in a
statement. "We expect our efforts to bring these two complementary organizations and innovative product portfolios
together to strengthen our capabilities as a leading provider of integrated imaging systems, analytics, and advanced
digital workflows across several care areas and pathways - including Theranostics, radiation oncology, urology,
neurology and cardiology. Now and in the future, we are working to transform patient care."


Load-Date: January 18, 2024


  End of Document

                                                                                                       Page 1 of 2
                 Opinion: It’s open season on personal data: We need a Data Protection Agency now




    Opinion: It’s open season on personal data: We need a Data Protection
                                 Agency now
                                                        TheHill.com
                                                February 6, 2024 Tuesday



Copyright 2024 NEXSTAR MEDIA INC. All Rights Reserved




Section: TECH LATEST & PERSONAL DATA PRIVACY NEWS
Length: 686 words
Byline: Sen. Kirsten Gillibrand, opinion contributor

Body


A few months ago, aNew York mom answered a call from what sounded like her 14-year-old daughter, who was
screaming and crying that she’d been arrested. A “police officer” then came on the line and told the mother that she
needed to deliver $15,500 to bail her daughter out.

In reality, the girl’s voice on the other end was an AI-powered voice clone — possibly generated using clips
compiled from social media.

It’s just one example of the growing number of scams using AI technology toexploit a person’s online data. Across
the country, Americans losebillions of dollars every year to cybercrimes. From phishing, social media and phone
scams to data breaches and ransomware attacks, criminals are finding new and innovative ways to collect
consumer data and exploit it.

It’s not just criminals who are using our personal data in dangerous and concerning ways, however.

In certain states, law enforcement has been using text messages and internet search historydata to arrest and
prosecute women for seeking reproductive health care. AI is being utilized for dirty political tricks as well; in New
Hampshire, a robocall imitating President Biden urged people not to vote in the state’s presidential primary, and in
New York, someone released fake, AI-generated audio of the Manhattan Democratic Party leader disparaging a
member of the assembly. While both instances were exposed quickly, they are cause for serious concern.

The reality is that most people don’t think twice about the digital information being collected about them. Young
people across the country often use platforms like Instagram, TikTok and YouTube to share selfies, create
elaborate dance videos or interact with influencers, celebrities or politicians. But many give little thought to who
might be keeping track of their activities.

                                                                                                        Page 2 of 2
                Opinion: It’s open season on personal data: We need a Data Protection Agency now

Every day, companies are gathering massive amounts of our data — from search histories, consumer habits and
location data to health data, photos and videos. This data can be very useful to the companies that collect it, but it
can also be extremely valuable to those who seek to sell, share or hack it. The advent of generative AI has only
intensified data privacy concerns and made data misuse more effective and costly for consumers.

The absence of comprehensive federal regulation protecting data privacy has made protecting everyday Americans
from scams and harmful data practices very challenging. Without guardrails for how an individual’s personal data
can be obtained or used, the risks to all Americans will only grow. It’s time we do something about it.

I wrote the Data Protection Act to help address this growing problem. It would create an independent federal
agency to promote data protection in the United States and to provide a broad range of enforcement tools. This
agency would be able to set and enforce data protection rules to mitigate data breaches, minimize their effects and
fight against phishing and other scams, including those utilizing artificial intelligence.

The U.S. is one of the only democracies, and virtually the only member of the Organization for Economic
Cooperation and Development, without a federal data protection agency. Instead, authorities have to rely on a
patchwork of protections that make jurisdictional oversight very nebulous.

But as technology evolves and grows, we must make sure society is equipped to address the challenges and
opportunities these advancements bring. Establishing a federal agency whose sole purpose is to protect our data
and privacy would allow the federal government to crack down on bad actors and promote more transparency and
accountability within the digital landscape.

It hasn’t been long since thegenerative AI arms race began. But just in the last year, we’ve seen our world change
exponentially before our very eyes. Unless we act quickly to regulate this digital Wild West, the consequences could
be catastrophic for our communities, our families, and our children.

Sen. Kirsten Gillibrand (D-N.Y.) has served in the U.S. Senate since 2009.

For the latest news, weather, sports, and streaming video, head to The Hill.


Load-Date: February 7, 2024


  End of Document

                                                                                                      Page 1 of 3
                            WPI Awards President's Research Catalyst Grants to Three Teams




         WPI Awards President's Research Catalyst Grants to Three Teams
                                         The Towers: Worcester Polytechnic Institute
                                                      May 14, 2024 Tuesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 731 words

Body


WPI has awarded seed funding from the President's Research Catalyst Grants Program to three faculty-led groups
that will develop proposals for large research centers focused on making advances in bioengineering, new
materials, and mental health.

Each group will receive $50,000 from the Catalyst program, which launched in 2024. Recipients will use the 18-
month grants to develop center-scale, interdisciplinary research proposals that will attract financial support from
external sponsors. The program is designed to catalyze and facilitate the development and preparation of
extramural grant applications that require extensive planning, exchange of ideas, collaboration, team building,
partnering, and other activities that demand significant investments of faculty members' time and effort.

"Pressing societal challenges call for large-scale, interdisciplinary, long-term research efforts," says Grace Wang,
WPI president. "These seed grants build on WPI's research strengths and faculty expertise, supporting our faculty
teams to collaboratively pursue high-impact research centers that hold the potential to push boundaries and
advance knowledge and solutions to address significant challenges facing the world."

The Catalyst program is partially funded by gifts from Trustee Emeritus Jim Baum '86 and Bonnie and Jack Mollen,
trustee emeritus and former board chair who was awarded an honorary doctorate in 2023. Their gifts have been
designated to support research at WPI, including but not limited to, artificial intelligence .

"Developing a center-scale proposal represents a significant investment of time and effort by WPI faculty," says
Bogdan Vernescu, vice president and vice provost for research and innovation. "Teams must do extensive planning
and collaborating. The President's Research Catalyst Grants Program provides the financial support that can lead
to successful proposals."

Grants were awarded to the following proposals and teams:

AI4BIO: Center for AI-Enabled Bioengineering

From left, Eric Young, Susan Roberts, Andrew Teixeira

Assistant Professor Eric M. Young is principal investigator . Co-PIs are Associate Professor Andrew Teixeira and
Professor Susan Roberts. All are faculty members in the Department of Chemical Engineering.

                                                                                                     Page 2 of 3
                          WPI Awards President's Research Catalyst Grants to Three Teams

HY-MATTER: Hybrid Materials Advancements for Technology and Research

From left, Michael Timko, Jeannine Coburn, Aaron Deskins, Ronald Grimm, John Obayemi, Pratap Rao, and
Lyubov Titova

Michael Timko is PI and professor in the Department of Chemical Engineering. Co-PIs are Associate Professor
Jeannine Coburn and Assistant Teaching Professor John Obayemi, both of the Department of Biomedical
Engineering; N. Aaron Deskins, professor in the Department of Chemical Engineering; Ronald Grimm, associate
professor in the Department of Chemistry and Biochemistry; Pratap Rao, associate professor in the Department of
Mechanical and Materials Engineering; and Lyubov Titova, associate professor in the Department of Physics.

Understanding and Preventing Adverse Effects of Social Media on Mental Health with AI

From left, Elke Rundensteiner, Dmitry Korkin, Nancy Byatt, David Cochran, Katherine Dixon-Gordon, Richard
Lopez, and Benjamin Nephew.

PIs are Professor Elke Rundensteiner, who is head of WPI's Data Science Program, and Professor Dmitry Korkin,
both of the Department of Computer Science; and Katherine Dixon-Gordon, assistant professor at the University of
Massachusetts Amherst; and Dr. David Cochran, associate professor of psychiatry and pediatrics at UMass Chan
Medical School. Co-investigators are Benjamin Nephew, assistant research professor in the Department of Biology
and Biotechnology; Richard Lopez, assistant professor in the Department of Social Science and Policy Studies; and
Nancy Byatt, professor of psychiatry, obstetrics, and gynecology and population and quantitative health sciences at
UMass Chan.

Keep Up With WPI Research News

Want to learn more about Research at WPI? Subscribe to the monthly newsletter.

SUBSCRIBE

Related Stories

Bogdan Vernescu Appointed Vice Provost for Research

TRIAD Seed Grants

Finding New Ways to Increase Research Opportunities

Topics

Research

|

Faculty

|

Seed Grants

|

Artificial Intelligence

DEPARTMENT

Biomedical Engineering

                                                                                        Page 3 of 3
                       WPI Awards President's Research Catalyst Grants to Three Teams

|

Chemistry & Biochemistry

|

Chemical Engineering

|

Computer Science

|

Data Science

|

Biology & Biotechnology

|

Mechanical & Materials Engineering

|

Physics

|

Social Science & Policy Studies


Load-Date: May 14, 2024


    End of Document

                                                                                                                    Page 1 of 3
                                       Digital Health Care: can we Avoid this Revolution?




                        Digital Health Care: can we Avoid this Revolution?
                                                                The Sentinel
                                                         June 23, 2024 Sunday



Copyright 2024 Omega Printers & Publishers Pvt Ltd, distributed by Contify.com All Rights Reserved




Length: 1702 words
Byline: Dr. Mukul Chandra Bora

Body


The concept of "Industry 4.0" was first coined by the German government to describe a wave of technological
advancements in manufacturing, aimed at maintaining Germany's global industrial competitiveness.

(Director, Dibrugarh University              Institute     of    Engineering       and     Technology.   He   can   be   reached
atdrmukulcbora@gmail.com)

T he concept of "Industry 4.0" was first coined by the German government to describe a wave of technological
advancements in manufacturing, aimed at maintaining Germany's global industrial competitiveness. This shift has
necessitated significant changes in various professions, requiring individuals to adapt to new tasks and utilise
cutting-edge technology, which now plays a central role in their work lives. This paper aims to provide an overview
of Industry 4.0, encompassing its key components such as automation, data exchange, and emerging technologies
like cyber-physical systems, the Internet of Things, big data analytics, and additive manufacturing. Industry 4.0
facilitates the integration of intelligent machines, human operators, physical objects, and manufacturing processes,
creating agile and interconnected value chains.

Beyond its roots in manufacturing, Industry 4.0 has evolved to impact diverse sectors, including healthcare,
ushering in a new era characterised by increased connectivity, automation, and data-driven decision-making.
However, the full extent of integrating Industry 4.0 principles into healthcare remains partially understood, with
limited consolidation of its benefits and challenges. This paper delves into the intersection of Industry 4.0 and
healthcare, highlighting nine key applications such as augmented reality, autonomous robotics, and big data
analytics, along with identifying ten benefits and nine challenges within the realm of Healthcare 4.0. These benefits
range from improved diagnosis and treatment to financial efficiencies, while challenges include issues like data
fragmentation, complexity, and privacy concerns.

The notion of a new industrial revolution has been brewing for decades, gaining momentum since the late
20thcentury, about 30 years after the advent of the third industrial revolution. Unlike previous transitions, which took
centuries to unfold, the shift to Industry 4.0 has been notably swifter, with the third industrial revolution lasting only
around four decades.

                                                                                                        Page 2 of 3
                                 Digital Health Care: can we Avoid this Revolution?

Experts and practitioners concur on the profound impact of Industry 4.0 across various domains, notably
healthcare, which stands as one of the most robust sectors today. Healthcare's significant share, often exceeding
10% of GDP in developed nations, underscores its importance, with global spending projected to hit nearly $9
trillion by 2021. Amid escalating costs for both patients and providers, coupled with a growing demand for patient-
centric care, the imperative for a digitized healthcare landscape intensifies. This evolution promises streamlined
processes, enhanced physician efficiency, and a prioritization of preventive measures.

The adoption of Healthcare 4.0 solutions yields manifold benefits, including heightened surgical precision, fortified
medical data security, optimized resource allocation in hospitals, and enhanced patient comfort. Central to this
paradigm shift is robust data management, given healthcare's status as a prolific data producer. Biomedical data,
electronic health records (EHR), and physical records underscore the significance of healthcare data analytics in
unlocking organizational advantages. Market projections suggest a compound annual growth rate of 18.2%, with
revenues reaching $81.3 billion by 2030, underscoring the burgeoning demand for Healthcare 4.0 solutions.
Despite progress, standardization of key definitions and concepts remains an ongoing endeavour.

The advent of digital health heralds a transformative era in medical practice akin to technological revolutions
witnessed in other industries. Anticipate a paradigm shift in medical practice over the next 5-10 years, propelled by
digital health tools, and advancements in computer science, machine learning, automation, robotics, virtual reality,
wearables, and allied fields. This digital health transformation should cover every aspect of medicine and the
patient's journey, as well as medical education and research. Artificial intelligence algorithms are helping clinicians
diagnose and manage a variety of medical conditions; major changes to the functionality of the electronic health
record; improvements in workflows primarily assisted by smart systems, increasing efficiencies; and reducing
repetitive tasks humans do right now that could be performed by computers and digital applications. Digital health
will help empower patients to monitor their medical conditions better, assess their response to medications, and
better know when and where to seek medical help versus exercising self-care. This revolutionary transformation
could be a decisive moment in the history of medicine, but it also comes with some risks: the risk of dehumanising
medicine, the risk of amplifying existing biases and healthcare inequities or creating new ones, the risk of making
medical errors multiplicative, and many other potential disastrous scenarios.

CHALLENGES IN DIGITAL HEALTHCARE:

SOCIETAL FACTORS

The integration of technology into digital health systems is crucial, but its impact goes beyond just technological
advancements. Effective digital health solutions must also address affordability and usability for a population that is
both growing and aging. Adoption of new technologies in healthcare is often slow, influenced by regulatory
uncertainties and concerns about accountability in the commercial sector. Moreover, navigating the complexities of
a global digital health market and diverse healthcare systems presents additional challenges. A significant barrier
lies in the low levels of digital and health literacy, particularly among older adults, which impedes widespread
acceptance and use of digital health innovations.

ETHICAL CHALLENGES

The increasing digitization of healthcare and the growth of mobile and IoT devices as data collection tools raise
many ethical issues. One commonly recurring theme relates to the exact nature of the role of consumer tech
companies, such as Amazon, Apple, Google, Facebook, or Samsung, who have all entered the digital health
domain. In particular, such companies offer solutions for collecting, storing, and analysing health data, which raises
issues relating to privacy, data protection, and informed consent. The nature of health data is also changing; we
are now collecting more private user-generated data, particularly data harvested from social media and through
wearable technologies, than ever before.

INCREASED CONNECTED HEALTH SOLUTIONS

The main focus of digital health is to enhance data sharing among patients, devices, and clinicians, promoting
smarter and more timely information exchange. This connectivity aligns with the principles of predictive, preemptive,

                                                                                                        Page 3 of 3
                                 Digital Health Care: can we Avoid this Revolution?

and personalized healthcare. During the COVID-19 pandemic, connected health solutions have been pivotal.
However, they raise concerns about safety and security. As medicine evolves towards personalized and
preventative care through digital health applications, concepts of patient safety must adapt. Rapid technological
advancements also bring safety challenges, with limited evidence-based research on new technologies' health
benefits. Demonstrating effectiveness remains a significant hurdle.

ROLE OF ARTIFICIAL

INTELLIGENCE

Artificial intelligence can utilize data generated in digital health systems to help with aspects of medicine, such as
improved diagnosis, selecting treatments, and predicting clinical outcomes. The presence of AI solutions in digital
health intensifies challenges surrounding safety, explainability, and fairness. In regard to safety, AI systems are
held to higher perceived safety standards than humans; i.e., it is less acceptable for AI to make errors. Moreover,
the risk to human life of AI-based systems is, currently, not well-studied, and there is a lack of standards for the
verification and validation of such systems. There are also generalization issues associated with AI models,
reproducing promising results, made on "limited" training sets, on real-world data. A recent systematic review of
deep learning solutions in medical images found that only a minimal number of studies in this field were

THE POTENTIAL

OF GENOMICS

Technological advances and reduced costs have led to a growing number of people opting for genetic profiling,
though outside of specific cases like rare disease diagnosis and cancer screening, genetic information isn't widely
integrated into routine medical care. Genomics holds promise for personalized healthcare, but achieving this
potential requires further development of genetic risk scores relevant to broader clinical contexts and better
interpretation of genetic variants. The interpretation challenge is compounded by millions of variants with no
standardized definition. Addressing these issues involves facilitating data and computational resource sharing,
which raises ethical concerns already explored in the article.

CONCLUSION: The COVID-19 pandemic has profoundly tested traditional healthcare systems, prompting a critical
role for digital health solutions. These technologies are pivotal in reshaping medical care during and after the
pandemic. However, their development and implementation face significant challenges stemming from pandemic-
related issues and broader obstacles to digital health advancement. Five years ago, various challenges in digital
health were identified, including multi-disciplinary approaches, big data in public health, MedTech innovations, self-
management and personalized care, mHealth interventions, data sharing dilemmas, and the impact of social media
on health knowledge and behaviour. These challenges remain pertinent today, augmented by new concerns about
the role of digital health in managing infectious diseases like COVID-19. Addressing these challenges is crucial for
advancing digital health research and fostering multidisciplinary efforts to tackle ongoing and emerging issues in
this dynamic field.


Load-Date: June 24, 2024


  End of Document

                                                                                                             Page 1 of 2
                                                Climate change is a class issue




                                       Climate change is a class issue
                                                      The Peak: Simon Fraser
                                                      July 16, 2024 Tuesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: PEAK WEB; Pg. 1
Length: 682 words
Byline: Yildiz Subuk

Body


By: Yildiz Subuk, Peak Associate

In an East Prairie Metis Settlement, the atmosphere has ashened, accompanied by an orange tinge and smokey
clouds in the sky. Trees burn and homes are destroyed, causing the community in this reserve to be displaced.
About 385 kilometres northwest of this region is the unaffected city of Edmonton. While both of these places are
governed by the same province, one region suffers exponentially more than the other. Many of us live comfortably
in a suburban or urban area, away from the harsh reality of environmental degradation. We often believe the effects
of climate change are approaching us, but when we zoom out, we may not be aware of how climate change
currently impacts marginalized communities, especially lower-income people and countries.

The terms climate change and global warming are often confused with each other, and it can be easy to feed into
the notion that climate change is eventually going to affect everyone. While that's true to some extent, climate
change tends to impact those living in lower socioeconomic conditions much more than the rest of the population.
To understand this, it's integral to differentiate between climate change and global warming. The difference is
described well in a video series called The Climate Explainers. The series likens global warming to one big house
with multiple rooms, while climate change impacts each room differently. While the house being affected may cause
problems for everyone residing in it, certain rooms tend to bear the brunt harder than others. The entire world is
being affected by global warming, but climate change is disproportionately impacting the living conditions of lower-
income communities and countries.

According to the United Nations, between 25 million and one billion people - especially those residing in lower-
income socioeconomic conditions - will be displaced due to climate change by 2050. Because that number
indicates a future problem, it may be easy to overlook the issue in the present day. However, the same report states
that tens of millions of people have already been displaced or killed across the world due to climate disasters. This
is a clear indication that climate change is not going to just affect the future - it's affecting the present at an alarming
rate.

It is a privilege to not have to worry about ecological disasters.

                                                                                                         Page 2 of 2
                                           Climate change is a class issue

The reason why the daunting reality of climate change is often hidden from many of us is due to privilege. It is a
privilege to not have to worry about ecological disasters. According to the World Bank, "only one-tenth of the world's
greenhouse gases are emitted by 74 lowest income countries," and yet their number of natural disasters has
increased by eight times in the last 10 years. Various new industries are now accelerating the consequences of
climate change, a prominent one being artificial intelligence . The carbon footprint required to power AI models will
measure up to 14% of the global carbon emissions by 2040.

Additionally, electronic waste (or e-waste, which contaminates soil and water with lead and mercury) produced by
the AI industry will measure up to 120 million metric tonnes per year by 2050. That can cause health issues for
those residing near where that waste is produced or disposed of. One study found that "China and certain countries
within Africa receive up to 80% of the world's e-waste." Disposing of these materials is particularly difficult for "low
and middle-income countries," leading to adverse health effects. While AI can be perceived as a useful tool, it is
not worth the environmental degradation or human rights abuses.

Most individuals are aware the world is heating up, and most do not outright deny the existence of climate change.
Instead of only acknowledging that climate change will affect our future, we need to acknowledge how it has already
affected those who are less privileged, and advocate for better climate policies. Climate change for the privileged is
an issue for the future, but climate change for those who aren't is an ever-growing issue of the present day.


Load-Date: July 16, 2024


  End of Document

                                                                                                        Page 1 of 2
                    UChicago community welcomes more than 4,500 attendees to third annual event




  UChicago community welcomes more than 4,500 attendees to third annual
                               event
                                       The Pulse: Finch University of Health Sciences
                                                      October 11, 2024 Friday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: LATESTSTORIES; Pg. 1
Length: 489 words
Byline: Gwendolyn Purdom

Body


Melrinea Davis said her nine-year-old son Misael loves science, and when the family heard about the University of
Chicago's annual South Side Science Festival through his school, they had to check it out.

She watched as he hovered over a training dummy and listened intently as a UChicago Medicine volunteer
explained that if Misael ever has to perform CPR, he can remember how fast the chest compressions need to be by
humming "Baby Shark." During the daylong event, he also examined snails through a microscope and later planned
to watch a liquid nitrogen demonstration with Fermilab scientist "Mr. Freeze."

"This is good for the community," Davis said. "A lot of the schools don't have the funding to let the kids get a lot of
hands-on experience in science, so it gives them a chance to learn something they might not get to see in school."

Davis and her son were among 4,500 attendees at the third annual festival, held on campus on Oct. 5. Co-
organized by UChicago's Biological Sciences Division, Physical Sciences Division, Pritzker School of Molecular
Engineering, and Office of Civic Engagement, the festival aims to bring the campus and broader South Side
communities together to explore science in a fun, accessible way. From opportunities to control robots and 3D
printers to panels on health trends and AI to a paper airplane design contest and explosive liquid nitrogen
demonstrations, the event offered education and excitement for visitors of all ages.

"It's our hope that the festival sparked inspiration and showed that STEM can be fun and accessible, especially for
our youngest attendees and those who might not otherwise be exposed to these subjects," said Sarah Tinsman,
program director for inclusive innovation in the Office of Civic Engagement and the festival's lead organizer. "We
would love for events like this to be an entry point for our neighbors to keep the scientific momentum going by
participating in one of the University's STEM programs for local residents and, ultimately, consider exploring a
career in a STEM field."

Stronger support

                                                                                                        Page 2 of 2
                    UChicago community welcomes more than 4,500 attendees to third annual event

Organizers say volunteer support for the event more than doubled this year, with nearly 1,000 UChicago students
staff, and faculty supporting either a science station or the event more generally. Whereas in years past the majority
of event volunteers were graduate students in STEM divisions, this year volunteers represented units and roles all
across campus, according to volunteer coordinator Lauren McNamara, a fifth-year Ph.D. student in chemistry.

"It was really neat to see all these different parts of the University were coming together to help put this on,"
McNamara said. Building those bridges not only introduces people to STEM who might not previously have been
exposed to it, McNamara said, but also helps strengthen the science itself by inspiring a more diverse future STEM
workforce-a central goal of UChicago's broader Inclusive Innovation initiative.


Load-Date: October 11, 2024


  End of Document

                                                                                                   Page 1 of 4
         The Hickenlooper AI Auditing Bill and the Expanding Role of the Commerce Department in AI Policy




 The Hickenlooper AI Auditing Bill and the Expanding Role of the Commerce
                          Department in AI Policy
                                                             R Street Institute
                                                         July 22, 2024 Monday



Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 R Street Institute, USA All Rights Reserved

Length: 2278 words
Byline: Adam Thierer

Body



Artificial intelligence (AI) legislative proposals continue to multiply across the United States, with over 760 bills now
pending-114 of which are federal bills. A recent R Street analysis examined some major state and local AI
regulatory bills moving currently, including one that passed in Colorado in May. R Street also produced Fall
2023 and Spring 2024 AI legislative outlook updates discussing important federal AI bills under consideration.

Some federal AI bills propose a hybrid style of governance that would meld "hard law" (formal regulations) and "soft
law" (informal, less-binding mechanisms). Soft-law tools and mechanisms include multi-stakeholder processes,
voluntary best practices, industry standards, third-party oversight mechanisms, government guidance documents,
and more. Soft law is an increasingly prevalent governance approach in digital technology because its processes
can evolve rapidly and flexibly to address a variety of fast-moving tech policy concerns.

Sen. John Hickenlooper (D-Colo.) recently proposed a new hybrid AI governance measure. As with other leading AI
bills floated in the U.S. Senate recently, the Validation and Evaluation for Trustworthy Artificial Intelligence Act (VET
AI Act) would empower the National Institute of Standards and Technology (NIST) within the U.S. Department of
Commerce (DOC) to play a larger role in overseeing algorithmic systems by establishing "AI auditing" guidelines.

However, the VET AI Act only establishes voluntary guidelines while other bills propose giving the DOC some
limited new forms of regulatory authority. While federal AI legislation is unlikely to be finalized due to a busy election
year, these measures set the stage for the AI policy debate in the next session of Congress and foreshadow how
the DOC could become America's leading AI oversight body, with NIST at the center of the action.

The Rise of AI Auditing

Some technical and policy-related background about AI auditing is needed to understand the VET AI Act's
approach to AI governance. AI auditing and algorithmic impact assessments are governance tools attracting
growing academic and policy interest today. These mechanisms can be used either before or after the deployment
of an AI system to evaluate their performance against a variety of benchmarks. Depending on their structure, such
audits and impact assessments could be administered voluntarily by system vendors, conducted by independent

                                                                                                  Page 2 of 4
        The Hickenlooper AI Auditing Bill and the Expanding Role of the Commerce Department in AI Policy

third parties, or required by government bodies. Several state and local AI-related legislative measures have
proposed mandatory impact assessments or audits, including bills passed in Colorado and New York City.

The Biden administration has pushed auditing and impact assessments under the rubric of "AI assurance" or "AI
accountability policy" in its 2022 Blueprint for an AI Bill of Rights as well as in a massive 110+ page AI executive
order last October and a variety of statements. Of particular importance was a March report from the National
Telecommunications and Information Administration (NTIA), another DOC division, which advises the president on
information policy issues and spearheads other multi-stakeholder efforts on technology matters. The NTIA's AI
Accountability Policy Report backed the expanded use of AI audits but was vague about how they should be
enforced: "We recommend that future federal AI policymaking not lean entirely on purely voluntary best practices,"
the agency said. "Rather, some AI accountability measures should be required." NTIA concluded that "work needs
to be done to implement regulatory requirements for audits in some situations."

Before this report launched, the head of the NTIA called for "a system of AI auditing from the government" and
suggested the need for "an army of auditors" to ensure "algorithmic accountability." The NTIA's report also
recommended a national registry of disclosable AI system audits, international coordination on "alignment of
inspection regimes," and "pre-release review and certification" of certain systems or models. This suggests a
greater push to formalize AI audits and impact assessments.

The goal of these and many other policy proposals is to ensure safe or "responsible AI" prior to release of new
algorithmic products. As previous R Street research has noted, however, AI audits or impact assessments imposed
in an overly rigid fashion could stymie innovation by creating a paperwork-intensive compliance system that would
be open-ended, costly, and potentially quite politicized. Auditing algorithms is highly subjective and nothing like
auditing an accounting ledger. "When evaluating algorithms," we noted, "there are no binary metrics that can
quantify the scientifically correct amount of privacy, safety, or security in a given system." Others have worried that
AI regulations could be "weaponized" if government officials use them to jawbone developers, especially if such
rules pressure developers to censor speech.

Best Practices, Not Mandates

Sen. Hickenlooper's VET AI Act wisely does not mandate AI auditing. Instead of putting NIST in charge of enforcing
a federal AI auditing regulatory regime, the bill instructs NIST to work with a variety of other agencies and
stakeholders "to develop detailed specifications, guidelines, and recommendations for the certification of third-party
evaluators to work with AI companies to provide robust independent external assurance and verification of their
systems." These voluntary auditing parameters would guide how AI system developers and deployers "conduct
internal assurance and work with third parties on external assurance" to improve dataset quality and identify data
privacy concerns or other potential harms. The bill also establishes a new advisory committee within NIST "to
review and recommend criteria for individuals or organizations seeking to obtain certification of their ability to
conduct internal or external assurance for AI systems."

The VET AI Act comes on the heels of three other Senate legislative proposals that also envision a greater role for
NIST in overseeing AI. These measures all build upon the AI Risk Management Framework (AI RMF), an iterative
governance framework developed over time by NIST. NIST works with a wide array of stakeholders to develop
voluntary, consensus-based standards for technical matters like cybersecurity, privacy, and now AI. Here is how
those three other Senate bills would expand NIST's role in overseeing AI policy:
    •   The Promoting United States Leadership in Standards Act of 2024 (S.3849), introduced in February by
        Sens. Mark Warner (D-Va.) and Marsha Blackburn (R-Tenn.), would formalize the NIST standards-setting
        process for AI and other emerging technologies. It would require NIST to establish a new portal that
        identifies relevant international standardization efforts and to submit a report to Congress identifying
        current U.S. participation in standards development. The bill also includes a $10 million pilot program for
        hosting AI-related standards meetings.
    •   The Future of Artificial Intelligence Innovation Act of 2024 (S.4178), introduced in April by Sens. Maria
        Cantwell (D-Wash.) and Todd Young (R-Ind.), pushes NIST to work with other federal agencies to

                                                                                                  Page 3 of 4
        The Hickenlooper AI Auditing Bill and the Expanding Role of the Commerce Department in AI Policy

        coordinate voluntary metrics, benchmarks, and evaluation methodologies for AI safety. The bill formally
        authorizes the U.S. AI Safety Institute, created within NIST in February, to develop these standards. It
        would also establish a new multi-stakeholder "Artificial Intelligence Safety Institute Consortium" to facilitate
        a public-private partnership and testbed programs for collaborative standards and best practices for AI
        safety, especially for large AI models. The measure also includes a call to work with other governments on
        harmonized AI safety standards and calls for new "grand challenge" competitions to encourage innovation.
    •   The Artificial Intelligence Research, Innovation, and Accountability Act of 2023 (S.3312), introduced late
        last year by Sens. John Thune (R-S.D.) and Amy Klobuchar (D-Minn.), goes further than these other
        measures by giving NIST standards some enforcement teeth. The bill would establish a tiered risk
        assessment process for "critical-impact" AI systems versus slightly less sensitive "high-impact" AI systems,
        with different levels of government oversight for each. Deployers of such systems would need to conform
        them to certification plans established by NIST for testing, evaluation, validation, and verification against
        various benchmarks. If deployers fail to comply with these standards, they could face fines or regulatory
        sanction. The bill also requires digital platforms to indicate clearly whether they use generative AI to create
        content for users.

In terms of breadth, Sen. Hickenlooper's VET AI Act fits between the Warner-Blackburn bill and the Cantwell-Young
bill but is not as restrictive as the Thune-Klobuchar bill. Importantly, however, Sen. Hickenlooper is a co-sponsor of
the Cantwell-Young and Thune-Klobuchar bills, and his new VET AI Act could build on both of them by using their
AI safety standards and practices as benchmarks for future AI audits.

The Commerce Department's Growing Role in AI Policy

Smartly, these four bills do not propose new broad-based AI licensing schemes or new technocratic AI
bureaucracies. Such mandates or bureaucracies would be costly and counterproductive in practice, generating
considerable opposition and protracted political battles. The VET AI Act and the three other Senate measures have
a better chance of generating legislative consensus because they all build on an existing agency and the NIST AI
RMF as the foundation of collaborative best standards.

However, these bills raise the question of whether NIST and the DOC should receive quasi-regulatory powers to
design and enforce AI audits or other algorithmic oversight policies. NIST and NTIA multi-stakeholder efforts and
standards gained widespread acceptance because they are collaborative, iterative, and voluntary. If new laws
formalize this process and give it more enforcement teeth, it could make the system more political and less flexible
over time. In other words, efforts to move soft-law processes in a hard-law direction could derail the benefits of
those more flexible governance mechanisms.

How Recent Supreme Court Decisions Play Into This

The Supreme Court recently handed down two decisions-Loper Bright v. Raimondo and Murthy v. Missouri-that
could have a bearing on how these bills and soft-law AI governance play out. Loper Bright overturned so-called
"Chevron deference," a standard of judicial review that left great leeway to agencies when interpreting and
enforcing statutes. Courts will now hold agencies to a higher standard to ensure their actions more closely align
with congressional intent.

The Murthy decision cut the other way by rejecting a claim that government efforts to jawbone social media
platforms violated the First Amendment. While the Court's decision was based on lack of standing and could still be
taken up again later on substantive grounds, the short-term effect of Murthy is that government officials still have
broad leeway to jawbone companies and encourage them to change behavior in various ways without any rules
being passed.

The combined effect of Loper Bright and Murthy could be that some federal agencies, including the DOC, will lean
on soft-law governance mechanisms to an even greater extent. Again, while the four Senate bills discussed above
all push for the continued development of voluntary best practices for AI safety, they also envision an expanded

                                                                                                  Page 4 of 4
        The Hickenlooper AI Auditing Bill and the Expanding Role of the Commerce Department in AI Policy

role for government in helping to formulate and steer those policies. This leaves considerable policy discretion to
NIST and the NTIA to determine the scope and nature of AI safety standards.

The director of NIST's new U.S. AI Safety Institute, who previously served at the White House, recently said that
the Institute is already "building out a suite of evaluations" and will "be sharing feedback with model developers on
where mitigations may be needed prior to deployments." She noted that the forthcoming guidance and benchmarks
will look beyond just safety and security matters and that the agency is "going to be looking at societal harm
perpetuated by frontier models and systems."

To reiterate, neither NIST nor NTIA possess any formal authority to regulate private AI systems in the way the
Federal Communications Commission has the power to license or regulate certain telecommunications or media
technologies. But the potential exists for NIST and NTIA to pursue backdoor AI regulation while the DOC emerges
as America's de facto AI bureau. For better or worse, the VET AI Act and other proposed Senate bills would solidify
and extend the agency's power over algorithmic systems and let it steer developer behavior through amorphous
soft-law policies. Lawmakers would be wise to limit the agency's discretion over algorithmic systems and ensure it
remains as flexible and voluntary as possible.

Tierney Artificial Intelligence

America does not need a convoluted new regulatory bureaucracy or thicket of new rules for AI. We are on the cusp
of untold advances in nearly every field thanks to AI. Our success depends on using flexible governance and
practical solutions to avoid diminishing the pro-innovation model central to U.S. success in the technology sector.
R Street's work on artificial intelligence cuts across multiple of our issue areas - technology policy, cybersecurity
policy, electoral policy, energy and environmental policy, and more.

   AI Policy   Energy and AI      Elections and AI   Health and AI   Subscribe


Load-Date: July 23, 2024


  End of Document

                                                                                                      Page 1 of 4
                                            In Lehigh Valley, some doctors turn to AI




                                In Lehigh Valley, some doctors turn to AI
                                                          The Morning Call
                                                     February 11, 2024 Sunday
                                                            FIRST Edition



Copyright 2024 Capital Gazette Communications, Inc. All Rights Reserved

Section: MAIN; A; Pg. 1
Length: 1848 words
Byline: Leif Greiss The Morning Call

Body


If you had an imaging study done at a Lehigh Valley Health Network-owned hospital in the last few months, there is
a chance that an artificial intelligence program was helping the radiologist check for serious conditions.

Last year, LVHN began implementing a series of AI tools for the radiology departments at all 13 network hospitals.
Dr. Devang M. Gor, chair of Radiology & Diagnostic Medical Imaging for LVHN, said these tools are changing the
way radiologists do their jobs.

"I'm a super user of this technology. I use it every day and I help others in my department adopt the technology and
keep using it," Gor said.

AI has been on the minds of many people thanks to viral news reports and social media discourse surrounding AI-
generated voice technology or AI-generated art, as well as existential dread that AI will replace the need for
humans in many work fields. But AI-powered medical technology has been in use within the Lehigh Valley for years
at both LVHN and St. Luke's University Health Network.

LVHN began using AI technology in 2018, spokesperson Jamie Stover said. St. Luke's also started in 2018, and
these efforts have ramped up over the last several years, Charles Sonday, associate chief medical information
officer for St. Luke's, said in an emailed statement.

But rather than replacing doctors or health care workers Dr. Maulik Purohit, former chief health information officer
for LVHN, said AI-powered tools are helping health care professionals be more effective at their jobs and create
better outcomes for patients.

One of the AI tools LVHN implemented in its radiology departments, Aidoc, immediately reads all imaging studies to
help radiologists diagnose patients and help identify which ones need immediate care. Purohit said Aidoc has been
trained

using a huge dataset of diagnostic medical images so it can identify patterns in the images consistent with serious
medical conditions.

                                                                                                        Page 2 of 4
                                      In Lehigh Valley, some doctors turn to AI

The Aidoc package LVHN is using is capable of identifying blood clots in the lungs, collapsed lungs and fractures in
the neck area, all of which can be imminently life-threatening. The program was about 93% successful at spotting
cases of pulmonary embolism, the medical term for a blood clot in the lungs, and accurate about 95% of the time in
identifying that no blood clot was present, according to one 2020 study. Gor said the AI has even caught cases of
pulmonary embolism when imaging studies were being done for entirely different reasons.

If any of these three serious conditions are identified, Aidoc's technology notifies the radiology team and prioritizes
putting the imaging study toward the top of the queue of studies radiologists need to examine. If a pulmonary
embolism is detected, Aidoc also will notify the hospital's pulmonary embolism response team so the patient may
receive care immediately.

"Until you see the study you have no way of knowing whether it is urgent or not," Purohit said. "This allows us to
automate that process of identifying what's urgent and less urgent so that patients that need the most urgent care
receive it quickly."

Gor said even though Aidoc was only implemented networkwide in September, the technology already has made a
difference. It saves radiologists time, makes communication between different subspecialty care teams easier and
leads to better care outcomes for patients, he said.

However, Gor said, the AI does not diagnose patients - a radiologist on staff needs to do that. It only provides
suggestions and alerts so it is easier for radiologists to make the final call on an imaging study.

St. Luke's has also used AI-powered technology in its radiology departments. Last May, the network spent $30
million to purchase AI-augmented CT scanners from Chicago-based GE Healthcare for the St. Luke's Hospital-
Upper Bucks. The technology can produce faster scans and sharper images, reduce radiation patients are exposed
to, detect lesions or tissue abnormalities and map vascular structures. It can also capture fine detail in the head and
neck, which is critical when diagnosing stroke, according to the network.

The network was also a partner to GE Healthcare in the development of Critical Care Suite, an AI embedded into X-
ray machines that is capable of helping clinicians identify collapsed lungs. Critical Care Suite received FDA
clearance in 2019. St. Luke's is no longer using that technology though, said Sam Kennedy, a St. Luke's
spokesperson, and the network is currently evaluating new AI technology from GE Healthcare for similar purposes.

LVHN has adopted or will adopt other AI software to make radiologists' jobs easier.

One tool, Rad AI Omni, helps radiologists when there are findings that don't require immediate care, such as
nodules in the lung or thyroid gland, adrenal lesions, kidney cysts or enlarged lymph nodes. The software
automatically generates as summary of the findings from a radiologist's dictation, and then it compiles and inserts
follow-up guidelines from national medical organizations into reports.

This standardizes the recommendations given to patients and allows radiologists to focus on other responsibilities.
Gor said one of the most valuable aspects of this technology is it allows him to take a second look at the studies
and make sure nothing is missing, something he often didn't have time for before he started using Rad AI Omni.

There is another AI tool that LVHN hopes to fully implement in mid-March, Rad AI Continuity, which will help with
the management of follow-up care for incidental findings. When incidental findings such as lung nodules or adrenal
lesions are identified, the software will automatically send follow-up recommendations to the patient and referring
clinician, whether it is more tests, scans or some other follow-up care. Rad AI Continuity will keep checking in with
both patient and clinician until follow-up appointments or tests are scheduled.

"Those are hard to manage from a human perspective," Purohit said. "That system is automatically aware if that
person actually followed through on that [appointment] so that we don't lose track of the patient."

Beyond better outcomes for patients, Gor said these AI tools can also create better outcomes for clinicians.

                                                                                                         Page 3 of 4
                                      In Lehigh Valley, some doctors turn to AI

There is a global shortage of radiologists due to factors such as burnout among existing radiologists and not
enough new people entering the field. Gor said tools like this are helping to augment radiologists so they can keep
up with the demands placed on them.

"We do a very large volume of acute studies. It is humanly not possible for anyone to immediately start reading
those studies as soon as the studies are done," Gor said.

He added that beyond increasing the efficiency of radiologists, the tools decrease stress and burnout.

"We are facing increased volumes so people are running short," Gor said. "They're not able to read studies fast
enough and they don't have staffing. Where AI fits in is it makes you more efficient. It gives you a second set of
eyes where you can rapidly process and triage patients."

That isn't to say there hasn't been a learning curve for radiologists in the network when using these tools. As with
any technology, the AI isn't perfect and does occasionally add disruptions to the workflows of radiologists. Gor said
one of these disruptions is receiving notifications when the AI returns a false positive result. But he added these
false positives are a minority.

"Humans are creatures of habit. Change is not necessarily accepted everywhere, no matter what it is," Gor said.
"Many of us now feel after using it for three months, how did we do this before? It helps you really be more
efficient."

What other AI technology is being used?

Radiology isn't the only area of care where LVHN and St. Luke's are using AI to augment the capabilities of health
care providers.

In 2020, LVHN adopted Viz.ai Neuro, AI software that uses an algorithm to determine the probability a patient
experienced a stroke. If it suspects a stroke occurred, the stroke team is alerted and the patient's CT images are
sent directly to a stroke specialist.

The network also runs a predictive algorithm in its intensive care units that helps predict sepsis, a condition that can
occur during an infection where the body's immune system begins targeting the body itself causing tissue and
organ damage. Sepsis can progress further and its side effects may ultimately lead to death.

"You want to minimize the spread of the infection and you also want to minimize the negative effects of fighting the
infection such as tissue damage. Sepsis also has a high mortality rate, particularly as it progresses to severe sepsis
and beyond. We want to catch it early before it becomes full-blown severe sepsis," Purohit said.

The algorithm LVHN uses helps avoid that outcome by analyzing key data points about patients and their conditions
and alerting clinicians when it suspects there is a potential case of sepsis so that they can intervene if the
algorithm's prediction is correct.

LVHN has introduced other AI to help clinicians with their workflow. Nuance is an AI software that helps generate
notes for clinicians to review and sign off on, said Stover, the health network spokesperson.

St. Luke's also has adopted a variety of AI-powered tools and software. Sonday said the network uses algorithms
developed by Epic Systems to help address risks such as sepsis, unexpected ICU transfer and readmissions by
analyzing clinical data.

In 2022, St. Luke's announced it installed the Varian Ethos therapy system at St. Luke's Cancer Center in Upper
Macungie Township. This AI-driven system allows physicians to adjust cancer treatments to precisely match the
patient's specific anatomy and the position of the tumor.

About 11 months ago, St. Luke's began using the GI Genius endoscopy module, a polyp detection system that uses
an AI algorithm to help clinicians catch colon polyps before they develop into colon cancer. During a colonoscopy,

                                                                                                       Page 4 of 4
                                     In Lehigh Valley, some doctors turn to AI

the AI searches for polyps, which are unusual tissue growths that can become cancerous, other lesions as well as
other points of interest and marks them to help the clinician determine if further assessment or treatment is needed.

The adoption of AI in medicine is unlikely to slow down. The capabilities of AI are growing at an alarming rate,
meaning new technologies and uses for AI are not too far over the horizon.

However, Gor said one of the limitations to adopting new technology is cost. AI is not cheap to create nor securely
host by software companies, and that means the costs of AI software subscriptions for health care providers are
quite pricey.

He added that actual implementation is rarely seamless. It requires a lot of information technology time and
resources to get AI software working within existing networks and systems. And as technology improves, that
means there are more updates and more software that is adopted.

"It keeps on getting better and better. Tomorrow there'll be more and more algorithms to detect other situations,"
Gor said. "Whatever you have keeps evolving so there is a good pace at which you need to keep updating."


Load-Date: February 11, 2024


  End of Document

                                                                                                            Page 1 of 2
                                 Opinion: ‘Superbugs’ could devastate livestock globally




                 Opinion: ‘Superbugs’ could devastate livestock globally
                                                        TheHill.com
                                              September 28, 2024 Saturday



Copyright 2024 NEXSTAR MEDIA INC. All Rights Reserved




Length: 837 words

Body


Antimicrobial resistance is a crisis hiding in plain sight. A new report estimates that 1.15 million people died due to
superbugs in 2022, and that about 39 million people could die by 2050.

The report, which was conducted by my organization along with the World Bank, provides for the first time a clearer
picture of the devastating impact that drug-resistant pathogens could have, not only on human health but also on
livestock and the economy at large. The findings are deeply concerning.

Without swift, immediate and coordinated actions, we could see a dramatic decline in global animal-source food
production. In the worst-case scenario, antimicrobial resistance in livestock could jeopardize the food supply of
more than 2 billion people. These losses will be felt most acutely in regions with high reliance on agriculture and
animal husbandry.

For decades, antimicrobials have been indispensable in maintaining the health and well-being of livestock. Animal-
source foods provide around one-third of human protein needs, and more than a billion people worldwide rely on
livestock for their livelihoods. The stakes are incredibly high.

Yet the misuse of these drugs in farming — often as a shortcut for poor and inappropriate husbandry practices —
has contributed to a breeding ground for drug-resistant bacteria. These resistant strains, which also come from
human misuse in treating diseases, then spread through our food, close contact, as well as the environment, end
up in our farms, hospitals and homes. This has culminated in a “one health” crisis affecting all facets of life.

In some low- and middle-income countries, the situation is particularly dire. Many farmers depend on unregulated,
often substandard antibiotics for livestock, unaware of the dangers posed by misuse and overuse. The result is a
fast-growing public health crisis that crosses from farms to people.

And this crisis is far from being equitable. Low and middle-income countries, where agriculture is a lifeline for
millions, will bear the brunt of the economic fallout. The cost of treating resistant infections will skyrocket, production
losses will deepen, and entire regions could face severe food insecurity and poverty.

                                                                                                        Page 2 of 2
                              Opinion: ‘Superbugs’ could devastate livestock globally

In a world already struggling with climate change and food shortages, the potential damage is unthinkable: It has
been estimated that if drug-resistant zoonotic bacteria continue to spill over into human populations, the global
economic loss could reach a staggering $5.2 trillion by 2050.

Evidence of the so-called “silent pandemic” of antimicrobial resistance is getting louder but remains largely ignored.
Nonetheless, we know how to address antimicrobial resistance in livestock, and the solutions are practical,
affordable and proven. We need political will and commitment from governments to implement them at scale —
effectively, an urgent pandemic-style response.

This week, the United Nations General Assembly hosted a high-level meeting on antimicrobial resistance, an
opportune moment for countries to unite around an urgent, integrated response that reduces the risk of drug
resistance to people, animals and plants.

First, we must focus on prevention. Reducing disease in animals through vaccination, improved biosecurity and
better farm management practices will decrease the need for antibiotics. Preventative measures like these are not
just beneficial for animal health; they are also good for business. According to our research, a 30 percent reduction
in global antimicrobial use in the next five years in livestock could add $120 billion to the global economy by 2050.

Second, we need to embrace innovation. Artificial intelligence is transforming how we manage livestock health. A
study of AI-based early disease detection in swine farms found a 400 percent return on investment by reducing
unnecessary antibiotic use and improving overall farm productivity. Such technologies could be game-changing for
farmers in low-income regions with limited access to healthcare infrastructure.

But prevention and innovation will not succeed without political will and strategic investment. We must ensure that
multisectoral national action plans to combat antimicrobial resistance, which 90 percent of our 183 member
countries and territories have developed, are fully funded and properly implemented.

Right now, many countries are falling short, especially in the animal health sector, where underfunding and poor
regulation are still widespread.

Drug-resistant pathogens are already one of the leading causes of death worldwide. But the stakes are even higher
if the global community fails to act. Like the COVID-19 pandemic, antimicrobial resistance is a challenge that needs
concrete funding, global coordination and local actions to overcome it.

The latest data gives us a glimpse of the future — we have a narrow window to change it now.

Dr. Emmanuelle Soubeyran is the director general of the World Organization for Animal Health.

For the latest news, weather, sports, and streaming video, head to The Hill.


Load-Date: September 28, 2024


  End of Document

                                                                                                         Page 1 of 5
                                       (Un)true love: When AI enters the dating scene




                          (Un)true love: When AI enters the dating scene
                                                        The Deseret News
                                                   August 29, 2024 Thursday



Copyright 2024 The Deseret News Publishing Co. All Rights Reserved

Section: CONSUMER: RELATIONSHIPS NEWS
Length: 2378 words
Byline: Lois M. Collins

Body


Eliza Anderson, Deseret News 1

The ad is all about romance - finding a partner who understands you and will chat with you whenever you want. You
can request photos and send gifts. Your partner will be attentive, emotionally supportive at all times and probably
tend to agree with you a lot more than anyone else you know.

You can even choose what your partner looks like, a design-your-own love interest.

That's possible because, although it feels real, your love interest is a fake.

There are similar promos all over the internet. Artificial intelligence has moved onto the "dating" scene in a big way,
with a number of companies offering companionship that can be quite literally bot and sold.

Here's the big question: Is trading real relationships with all their contradictions and complications for a more
compliant one a good idea?

How AI sneaked into dating

Artificial intelligence and matchmaking aren't strangers to each other. Initially in the dating realm, AI was being used
to fool folks who were already on dating apps into giving up personal information, said Neil Sahota, CEO of ACSI
Labs and a United Nations advisor on AI. Back then, bots were creating fake profiles for the gain of those who
employed them.

They were also being tested as a tool to conquer loneliness. A decade ago, Sahota was helping build up IBM
Watson, a computer system that could answer questions in natural language, as its website says. And a number of
companies were already exploring the potential of AI for companionship or for mental health.

It was a real need. At one point, loneliness was the biggest illness in the world, before COVID-19 surpassed it,
Sahota told the Deseret News. "About 40% of people suffered from moderate to severe loneliness," so he and
others were exploring what healing role AI could play, maybe as a companion or even a therapy tool. They weren't
pondering it as a substitute for real relationships, but considered its possibilities as an outlet for someone to tell

                                                                                                          Page 2 of 5
                                   (Un)true love: When AI enters the dating scene

stories to or to build up communication skills or in other ways that would enhance the opportunities to form rich and
real, satisfying relationships with others.

At that point, developers were asking questions and exploring things like whether AI could help if someone was
distressed at 2 a.m. and couldn't reach anyone: Could AI talk to them and look for signs they were dangerous or
suicidal? If so, could it alert the right people?

That morphed into artificial empathy.

But with the march of time and technology, there now are lots of companion AIs for different reasons, from AI that
interacts with an older person who just needs what feels like a caring listener to make-believe love interests.

And that's where it gets tricky, experts told the Deseret News. Sahota refers to mirror images of good and bad, with
the potential for tech to be weaponized in ways that may actually do harm. In some cases AI is becoming a crutch
and substitute for relationships, he said, noting that in others it goes further. In Japan, for instance, he said that AI
gloves and bodysuits combined with avatars can to some degree replicate the "sensations of a full relationship."

Sahota calls the advance of AI into relationships worrisome, given that the younger generation seems less keen on
face-to-face interactions than previous generations. "You might be heading down the path where people might
actively seek the AI substitute because they feel like they won't get rejected. They won't be judged. I think (some
young people) feel like it's a safer space."

Launching in life has challenges like housing costs and the job market. People are delaying both marriage and
having children.

"What happens if people don't ever get married or have kids?" Sahota asks.

Ideal 'friend' or spoiler?

Like Sahota, Alexander De Ridder crafts AI tools in his role as cofounder and chief technical officer at SmythOS, a
company that helps businesses integrate artificial intelligence. While he's a fan of AI, he doesn't want it to replace
human relationships. He bluntly calls that "unhealthy" for mental health and human development. He's no
psychologist, he told the Deseret News, but he is a family man with a fully human interest in seeing people thrive.

That AI could disrupt normal relationship development is a real possibility for some, said De Ridder, who notes that
young children become wildly attached to inanimate objects like teddy bears and they cry if someone's not nice to a
beloved toy. Adults get attached to objects, too. Lots of people give cars human names. "It is this fundamental
capacity - a human capacity to breathe life into things."

Add that to the fact that people are "a bit obsessed with themselves," De Ridder said, and see what happens. AI
can speak like a human, write like a human ... and what's not to love about something that can be taught to seem
obsessed with you? "It's easy to see how attached we can be to AI that gives validation and reciprocation and
support."

According to De Ridder, teens are drawn to some AI apps, including ones that targets those ages 14 to 20 and
especially appeals to females, who may spend hours there. "Boys are not always emotionally available," said De
Ridder, who notes one gender difference is that girls journal more. They are more outwardly emotional, so it's
probably appealing to have "an AI boyfriend who is always there, always pays attention, always offers a thoughtful
response."

A bot that starts out as a virtual friend may evolve into a virtual boyfriend, he said. But will girls even seek a real
one?

That potential to stay in virtual reality is even greater, per Sahota, because one of AI's superpowers is learning a
person on a psychological level, adapting to how one talks and what resonates with that individual. Some AI agents
"build people at a very deep level, like better than a best friend or even a spouse."

                                                                                                          Page 3 of 5
                                   (Un)true love: When AI enters the dating scene

That doesn't mean humans and AI will marry, Sahotah says. But they may become smitten. "A lot of things would
have to happen and I don't think we're anywhere close to that. The robot technology is really far away," so AI can't
replace human touch very well and touch is a human need.

But using AI as an emotional crutch can still be very problematic.

De Ridder enjoys a good philosophical debate with a bot trained on the writings of Plato and Aristotle. He loves to
discuss the world's modern problems with the ancient philosophers. It's fun, too, to converse with popular society or
historical people via bots that know their written work. But some aspects of life should be between real people, he
says.

A human need

Robots don't have their own will or needs, but are programmed to what others want. Being catered to may create
selfishness and unrealistic expectations that make it hard to thrive in the real world, De Ridder said. "What do we
call people who only have empathy for themselves and their own needs, who expect others to cater to them?" he
asks. "We call them pretty bad names."

Real relationships are messy and De Ridder thinks people are better for that fact. They wrestle and grow and
prioritize and compromise, lose sleep and and learn to put others first. The process builds both stronger individuals
and societies. The counterweight to selfishness, per De Ridder, is to "foster community, communion, charity,
empathy, collaboration and participation. Real tangible interactions with other people."

Teens especially need to be out relating to other actual people, says De Ridder. "They are lonely. It's a time of
vulnerability" when anything that reinforces isolation and separation from others is not a good idea.

One of the most troubling aspects of design-your-own AI relationships is emotional immaturity, said Jill Manning, a
licensed marriage and family therapist in Louisville, Colorado. Without real relationships, "people tend to get
emotionally stuck and they don't develop emotionally."

"One of the core tenets of maturity is to live in reality and accept reality," says Manning, who noted that's also a
core tenet of spiritual life. "Not trying to change reality to our whims, but submitting and accepting reality."

She predicts that "people can pursue - and probably many will pursue that AI illusion - but eventually that illusion
will become a delusion and delusion is a facet of mental illness."

Relationships help us grow. Some can be harmful, of course, she adds, and she sees plenty of those in her clinical
practice. But "within the normal scope of human relationships, they help us grown and refine ourself, see our faults
and weaknesses, as well as our strengths." A relationship with no foibles or quirks doesn't help people grow. "It's
spiritually suffocating."

For overall wellness, people need human connection.

"Touch is essential," says Manning. "Young babies can die without nurturing, affirming touch. That speaks to our
human DNA need for touch." Eye contact matters, as does communication. "Our digital devices and technology can
certainly be an asset and help us stay connected, but when there's a total swap out, it's void of so many nuances of
human connection that can't be replaced."

She points out the difference between knowing someone and using technology to stay in touch and maintain
contact and having a digital-only connection.

Although she's certified in and often uses teletherapy to treat patients, she prefers the initial encounter be in person.
"I learned through experience there's information I can glean sitting in the same room that I cannot glean over
HIPAA-compliant video. I can't see the foot tapping with anxiety. Even the tone gets lost in video. Video is a pretty
good replacement in many situations, but for assessing overall wellbeing, nothing's like sitting in the same place."

                                                                                                          Page 4 of 5
                                   (Un)true love: When AI enters the dating scene

She adds, "If someone is trying to similarly have friendship or a boyfriend or girlfriend that's AI generated, it's an
echo chamber - a delusion." And it may be addictive.

"Anything that can evoke a dopamine reward response in the brain does have the risk of becoming compulsive or
getting out of control. Like anything - online shopping, eating, pornography, all of those and this too would have a
compulsive potential."

What about what's good?

Manning said it's important to not get so polarized that we throw potential benefits out.

"As a clinician, I could think of scenarios where AI could serve a very useful purpose when dosed appropriately and
in the larger context of other strategies and coping skills." She could picture value as a practice tool for certain
conversations or questions or for learning to be more assertive. It might help in practice for interviews. "I can see
value in that, where the risk is low and there are opportunities to self-correct and try again."

There are valid and valuable uses for artificial intelligence, even regarding relationships. Experts say AI can help
lonely older people, who've perhaps outlived a spouse or are somewhat homebound.

They are in an entirely different place than young people who might choose AI over human interaction.

Sahota points out that older people "have already had that history. They've had relationships and face-to-face
interactions." He sees AI for older adults as an "outlet, not as much a substitute."

He notes a company that created an AI companion so people can tell stories, which the AI logs to create an
autobiography that can be shared with family and friends. It has a practical purpose and helps beat loneliness a bit
as older people tell their stories.

Seniors don't typically use AI for dates. Gen Z and Gen Alpha are a different story. They have less experience with
social interaction than with communicating or doing things over devices. Sahota describes young people texting
friends "literally sitting right next to each other" at a sporting event. As for those who are worried about rejection or
their self-esteem, he said, "I can see how they can easily just switch over to an AI partner, if you will."

But they might benefit from AI if they used it differently. AI can be a powerful tool to help those same people
practice the art of conversation and reaching out to others. It can provide feedback and experience and even
recommendations. A company just rolled out an app for couples, in beta testing, that helps analyze a relationship
situation. "You're trying to say this, but it's coming across like this. I recommend ... "

Listening and logging stories, checking in on mental health and boosting communication skills are all good things,
Sahota said. AI's utility hinges on how it's used.

Manning agrees AI could help an elderly person who's isolated and has trouble getting out. "But I think we have to
ask ourselves why, as a society, are so many of us lonely. Why would a growing number of people be in a situation
where they are so disconnected and so alone and no one's got eyes or ears on them?"

Porn and AI relationships

There are also some similarities with something most people agree is problematic. For years, experts have made
one point about pornography: When males can choose what happens, what those engaged in sexual activity look
like, and be titillated on the schedule of their choosing, how can a flesh-and-blood female compete?

AI offers a similar question that may be worth pondering. When females can create a relationship that's always
affirming, that emotionally satisfies and is available whenever, how can a flesh-and-blood male compete?

Additionally, both porn and AI relationships draw people into something that's not real, Manning said.

                                                                                                         Page 5 of 5
                                   (Un)true love: When AI enters the dating scene

Porn, she notes, creates a "relational script in which one doesn't ever have to be authentic, transparent or
vulnerable with another person." Human connection requires learning how to be those things.

Manning said with porn the body responds sexually to pixels on a screen, ignoring that it's not real. "People are left
empty and craving more because there's never enough. You can't fill that because you're not deeply satisfying the
human need for real connection. I think with AI as well, there'd be the absence of authenticity, transparency and
vulnerability and learning how to practice with that. It would certainly engender a narcissistic posture as well."

There is, however, a real difference, Manning said. Porn is never helpful to the brain. AI might be, if it's used wisely
and not allowed to cut real relationships out.


Load-Date: August 29, 2024


  End of Document

                                                                                                           Page 1 of 2
                   Guest Perspective: Forward-looking businesses leverage AI to increase efficiency




    Guest Perspective: Forward-looking businesses leverage AI to increase
                                 efficiency
                                                   New Orleans CityBusiness
                                                       March 5, 2024 Tuesday



Copyright 2024 BridgeTower Media All Rights Reserved




Section: NEWS
Length: 849 words
Byline: CityBusiness Guest Perspective

Body


From factory robots to cancer detection, intelligent systems are powering collaboration, strengthening security, and
optimizing decision-making. But they also present a range of security challenges and businesses are partnering
with Cyber Security Providers to address them.

Intelligent systems combine artificial intelligence (AI) and automation to perform tasks more efficiently, learning from
data and reason and making decisions, either autonomously or with human guidance. For example, using data
analytics, machine learning and computer vision, intelligent systems determine customer preferences and create
highly customized products.

In manufacturing, intelligent systems reduce cost and risk by automating repetitive tasks or tasks that require
immense precision. They can also reduce downtime and improve maintenance operations by continually monitoring
equipment for patterns and anomalies that indicate potential issues.

Companies like Proctor & Gamble have announced they are using Microsoft Azure as a foundation to digitize and
integrate data from more than 100 manufacturing sites, globally, enabling the giant to enhance AI, machine
learning, and edge computing services for real-time visibility. This will enable P&G employees to analyze production
data while leveraging AI to support decisions that drive improvement and exponential impact.
The digital transformation of P&G’s manufacturing platform will let the company check product quality in real time,
avoid waste, and optimize the use of energy and water in manufacturing plants.
Separately, the performance automotive company BMW is using cobots or collaborative robots that work side-by-
side with humans to enhance its manufacturing processes. According to BMW, collaborative robots are helping to
equip the insides of BMW X3-model doors with sound and moisture insulation. Foil with an adhesive bead is put in
place and slightly pressed on by assembly line workers and then roller heads on robot arms handle the labor-
intensive task of the final “fixing process” that seals the foil, protecting the electronics in the door against moisture.

                                                                                                        Page 2 of 2
                 Guest Perspective: Forward-looking businesses leverage AI to increase efficiency

Within other sectors, like health care, AI-enabled image reconstruction lets radiologists reduce radiation doses
while improving image quality in CT scans. AI can also improve diagnostic accuracy and speed by detecting areas
of interest that manual inspections may miss.
The ability of intelligent systems to rapidly analyze large amounts of data from hundreds of sources, from customer
input to the Internet of Things (IoT), can enhance decision-making, deliver better products and services, promote
collaboration, and elevate Cyber Security initiatives.
But intelligent systems depend on large amounts of data, so data quality,privacy, and safety are areas of concern.
For example, organizations must protect personally identifiable information like Social Security numbers and other
sensitive data from unauthorized access or misuse.

To address these and other challenges, business leaders should assess their data readiness and quality,
establishing robust information governanceto ensure clean, consistent, and relevant data while improving their data
collection and management processes. And because successful implementation depends on skills, in addition to
tools, companies may wish to invest in talent development and education that goes beyond technical training to
also address the ethical and social aspects of AI-powered systems.

AI-enhanced Cyber Solutions can assist in threat mitigation by identifying shadow data (information that exists
outside of parameters set by the organization, such as data that was copied from a production environment to train
an AI model in the cloud and then left there, unprotected, or HR data that was shared between managers in a Slack
channel). They can also monitor for data access abnormalities, and alert appropriate Cyber Security professionals
about potential threats, helping to detect and remediate issues in real-time. As part of a comprehensive Cyber
Security initiative, AI-powered risk analysis can produce incident summaries and alerts while automating incident
responses, identifying vulnerabilities, and reinforcing alert investigations and Cyber Triage.

As nation-states and other bad actors step up their efforts, AI Cyber Security models can help to balance threat
mitigation and user experience with such actions as analyzing the risk of each login attempt and verifying users
through behavioral data, simplifying access for verified users and reducing the cost of fraud while helping to prevent
phishing, malware, and other malicious activities. Forward-looking businesses and other organizations are
leveraging AI to increase their efficiency and service delivery and are also partnering with Cyber Security
professionals to keep their operations safe while protecting sensitive data.

Carl Mazzanti is president of eMazzanti Technologiesin Hoboken, NJ, providing IT consulting services for
businesses ranging from home offices to multinational corporations.

Copyright © 2024 BridgeTower Media. All Rights Reserved.


Load-Date: March 11, 2024


  End of Document

                                                                                                      Page 1 of 4
                            WPI Awards President's Research Catalyst Grants to Three Teams




         WPI Awards President's Research Catalyst Grants to Three Teams
                                         Tech News: Worcester Polytechnic Institute
                                                      May 14, 2024 Tuesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 766 words
Byline: Andrew Teixeira

Body


WPI has awarded seed funding from the President's Research Catalyst Grants Program to three faculty-led groups
that will develop proposals for large research centers focused on making advances in bioengineering, new
materials, and mental health.

Each group will receive $50,000 from the Catalyst program, which launched in 2024. Recipients will use the 18-
month grants to develop center-scale, interdisciplinary research proposals that will attract financial support from
external sponsors. The program is designed to catalyze and facilitate the development and preparation of
extramural grant applications that require extensive planning, exchange of ideas, collaboration, team building,
partnering, and other activities that demand significant investments of faculty members' time and effort.

"Pressing societal challenges call for large-scale, interdisciplinary, long-term research efforts," says Grace Wang,
WPI president. "These seed grants build on WPI's research strengths and faculty expertise, supporting our faculty
teams to collaboratively pursue high-impact research centers that hold the potential to push boundaries and
advance knowledge and solutions to address significant challenges facing the world."

The Catalyst program is partially funded by gifts from Trustee Emeritus Jim Baum '86 and Bonnie and Jack Mollen,
trustee emeritus and former board chair who was awarded an honorary doctorate in 2023. Their gifts have been
designated to support research at WPI, including but not limited to, artificial intelligence .

"Developing a center-scale proposal represents a significant investment of time and effort by WPI faculty," says
Bogdan Vernescu, vice president and vice provost for research and innovation. "Teams must do extensive planning
and collaborating. The President's Research Catalyst Grants Program provides the financial support that can lead
to successful proposals."

Grants were awarded to the following proposals and teams:

AI4BIO: Center for AI-Enabled Bioengineering

From left, Eric Young, Susan Roberts, Andrew Teixeira

                                                                                                     Page 2 of 4
                          WPI Awards President's Research Catalyst Grants to Three Teams

Assistant Professor Eric M. Young is principal investigator . Co-PIs are Associate Professor Andrew Teixeira and
Professor Susan Roberts. All are faculty members in the Department of Chemical Engineering.

HY-MATTER: Hybrid Materials Advancements for Technology and Research

From left, Michael Timko, Jeannine Coburn, Aaron Deskins, Ronald Grimm, John Obayemi, Pratap Rao, and
Lyubov Titova

Michael Timko is PI and professor in the Department of Chemical Engineering. Co-PIs are Associate Professor
Jeannine Coburn and Assistant Teaching Professor John Obayemi, both of the Department of Biomedical
Engineering; N. Aaron Deskins, professor in the Department of Chemical Engineering; Ronald Grimm, associate
professor in the Department of Chemistry and Biochemistry; Pratap Rao, associate professor in the Department of
Mechanical and Materials Engineering; and Lyubov Titova, associate professor in the Department of Physics.

Understanding and Preventing Adverse Effects of Social Media on Mental Health with AI

From left, Elke Rundensteiner, Dmitry Korkin, Nancy Byatt, David Cochran, Katherine Dixon-Gordon, Richard
Lopez, and Benjamin Nephew.

PIs are Professor Elke Rundensteiner, who is head of WPI's Data Science Program, and Professor Dmitry Korkin,
both of the Department of Computer Science; and Katherine Dixon-Gordon, assistant professor at the University of
Massachusetts Amherst; and Dr. David Cochran, associate professor of psychiatry and pediatrics at UMass Chan
Medical School. Co-investigators are Benjamin Nephew, assistant research professor in the Department of Biology
and Biotechnology; Richard Lopez, assistant professor in the Department of Social Science and Policy Studies; and
Nancy Byatt, professor of psychiatry, obstetrics, and gynecology and population and quantitative health sciences at
UMass Chan.

Keep Up With WPI Research News

Want to learn more about Research at WPI? Subscribe to the monthly newsletter.

SUBSCRIBE

Related Stories

Bogdan Vernescu Appointed Vice Provost for Research

TRIAD Seed Grants

Finding New Ways to Increase Research Opportunities

Topics

Research

|

Faculty

|

Seed Grants

|

Artificial Intelligence

DEPARTMENT

                                                                                          Page 3 of 4
                         WPI Awards President's Research Catalyst Grants to Three Teams

Biomedical Engineering

|

Chemistry & Biochemistry

|

Chemical Engineering

|

Computer Science

|

Data Science

|

Biology & Biotechnology

|

Mechanical & Materials Engineering

|

Physics

|

Social Science & Policy Studies

PROFILE

Andrew Teixeira

|

Benjamin Nephew

|

Dmitry Korkin

|

Eric Young

|

John Obayemi

|

Jeannine Coburn

|

                                                                                       Page 4 of 4
                      WPI Awards President's Research Catalyst Grants to Three Teams

Lyubov Titova

|

Michael Timko

|

N. Aaron Deskins

|

Pratap Rao

|

Ronald Grimm

|

Richard Lopez

|

Elke Rundensteiner

|

Susan Roberts


Load-Date: May 14, 2024


    End of Document

                                                                                                   Page 1 of 2
  New Penn master's program will focus on AI The online degree program aims to prep students for 'jobs that we
                            can't yet imagine.' Applications open in June, with....




  New Penn master's program will focus on AI; The online degree program
aims to prep students for 'jobs that we can't yet imagine.' Applications open
                in June, with classes beginning next spring.
                                                    The Philadelphia Inquirer
                                                        May 3, 2024 Friday



Copyright 2024 Philadelphia Newspapers, LLC All Rights Reserved

Section: BUSINESS; Pg. A8
Length: 516 words
Byline: Ariana Perez-Castells (Staff Writer)

Body


ABSTRACT

In the five years since Chris Callison-Burch has been teaching an artificial intelligence class at the University of
Pennsylvania, his class has grown from around 100 to 400 students in person and another 200 joining remotely, he
said.

"On campus, we fill the biggest lecture hall available, which seats 400. I can't grow bigger than that unless we move
to the sports stadium," said Callison-Burch, an associate professor at Penn Engineering.

Starting next spring, the University of Pennsylvania will expand its AI course offering with a new online master's
degree program focused on AI.

"The fact that [AI is] just in the public imagination to the degree that it is at the moment, it really makes this one of
the most exciting things for students to be able to study," said Callison-Burch, who will be the faculty director of the
new online program.

Applications for the new AI master's program open in June, and classes will begin the following spring. The courses
can be completed asynchronously, allowing students to continue to work while pursuing a degree. Courses will
cover topics including mathematics, computing, machine learning, applications of AI, and large-scale data sets,
according to Vijay Kumar, the dean of Penn Engineering.

One of the pillars of the program is also ethical considerations of AI, says Callison-Burch.

"This is exceptionally important for our graduate students to understand and be able to be in a position to help
shape policy be that at the national level or the state level, if they enter government. I think equally as impactful is
shaping policy within companies," he said.

                                                                                                   Page 2 of 2
  New Penn master's program will focus on AI The online degree program aims to prep students for 'jobs that we
                            can't yet imagine.' Applications open in June, with....

While there is "a lot of exceptional potential" from the benefits of artificial intelligence, which includes enhanced
productivity and creative potential, it also comes "at great peril as well," he says.

"Americans experienced automation in the factory worker, blue-collar job sector, but never had to deal with it from
the white-collar sector," Callison-Burch said. "There's some core things that we're going to have to grapple with.
Depending on how rapidly that change happens, it could be really devastating to a large sector of the U.S.
workforce. There's some really important policy considerations there."

Hollywood screenwriters went on strike last year including over issues of AI being used in their work. Screenwriters
were concerned about chatbots such as ChatGPT, being able to write scripts, according to the Associated Press,
and have since secured some protections for their work.

One challenge to teaching AI is that the field is advancing very rapidly, Callison-Burch said. "It's going so fast that I
feel like we have to constantly refresh our materials."

While graduates who complete the program could enter different fields that are adopting applications of AI including
in health care and drug development, students are also preparing for jobs that might not exist yet, Kumar said.

"We want the students to be prepared for jobs that we can't yet imagine," Kumar said. "It's hard to predict the future,
especially in this field."

aperezcastells@inquirer.com

arianapeca2


Load-Date: May 3, 2024


  End of Document

                                                                                                        Page 1 of 2
                                          White House holds creator conference




                               White House holds creator conference
                                                        TheHill.com
                                               August 14, 2024 Wednesday



Copyright 2024 NEXSTAR MEDIA INC. All Rights Reserved




Length: 321 words

Body


White House officials are meeting with 100 digital creators and industry professionals on Wednesday for the first-
ever White House Creator Economy Conference.

The conference will address “the most pressing challenges, and opportunities, facing the creator economy,”
including artificial intelligence (AI), mental health and pay equity, according to a White House official.

“This Biden-Harris Administration has taken historic steps to engage digital creators, and works hard to meet
Americans where they are,” the official said.

“Officials at the highest level of this White House have engaged creators extensively, hosting regular virtual and in-
person briefings with digital creators on policy issues, hosting State of the Union watch events for creators at the
White House, and, last year, hosting the first ever White House Holiday Party for digital creators,” they added.

The digital media landscape has become increasingly important to American politics in recent years, as more
people, especially young people, get their information from social media.

With the rise of TikTok, many campaigns have joined the platform to reach young voters, even amid bipartisan
national security concerns about Americans’ data privacy and the app’s ties to China.

President Biden’s campaign joined TikTok in February, and former President Trump followed suit in June. Shortly
after Biden dropped out of the race last month and endorsed Vice President Harris, she too created an account.

Both parties have also sought to tap into the large followings of content creators on platforms like TikTok, Instagram
and YouTube.

The Republican National Convention issued credentials to more than 70 influencers last month, while the
Democratic National Convention has issued credentials to more than 200 creators for next week’s event, according
to The Washington Post.

For the latest news, weather, sports, and streaming video, head to The Hill.

                                                                    Page 2 of 2
                             White House holds creator conference


Load-Date: August 14, 2024


  End of Document

                                                                                                          Page 1 of 2
                                   Why this dad's walking across five cities with his pony




                   Why this dad's walking across five cities with his pony
                                     The Griffon News: Missouri Western State College
                                                      October 18, 2024 Friday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: LIFESTYLES; Pg. 1
Length: 437 words

Body


By Imogen Howse via SWNS

Meet the dad walking 200 miles across five counties - while leading a pony.

Roger Sewill, 60, is trekking through Surrey, Sussex, Hampshire, Wiltshire, and Dorset with his Dales pony Scarlet
to raise awareness for mental health problems among people who live and work in the countryside.

The duo started their journey on October 15 at Roger's childhood home in Charlwood, Surrey - and will finish in
approximately two weeks' time near Sherborne in Dorset, where Roger now lives with his wife and three children.

Roger and Scarlet aim to walk up to 15 miles a day - and will camp overnight in the fields of generous local
landowners.

Roger said: "I decided to walk with Scarlet as I enjoy walking with a horse. You see a different perspective of life.

"Horses walk more slowly - and they're always in the present. They're thinking about what's around them rather
than the list of things they need to do tomorrow.

Roger and Scarlet on their 200-mile walk. (Roger Sewill via SWNS)

By Talker

"So it helps you with your outlook on life."

The dad-of-three is hoping his expedition will raise awareness for CountrymenUK, a charity supporting people who
have lived or worked in the countryside but now find themselves isolated.

Roger said: "I am a trustee of that charity and it's so important as people like farmers often don't look for places
they can go to for this sort of help.

More from this section

A Cancer Diagnosis Takes Devastating Toll on Family Finances

                                                                                                        Page 2 of 2
                                Why this dad's walking across five cities with his pony

Most Older Americans Don't Trust AI-Generated Health Info, Survey Finds

What's the Best Clot-Buster Med After Stroke?

"So my goal is to raise awareness for the charity and other similar charities.

"If I raise some money for them too - that would be the icing on the cake."

Roger, who works as a rural chartered surveyor, said he is looking forward to the 200-mile challenge.

The walk would take the duo about two weeks to complete. (Roger Sewill via SWNS)

By Talker

He said: "My tent's a bit flimsy - and we'll meet some different challenges.

"For instance, our route means we have to go through the town centers of Winchester and Salisbury so that will be
interesting.

"But that's what a challenge is all about.

"And people have been so generous. I've been around villages on the route before and asked if they'd put me and
Scarlet up overnight.

"All we need is a field for her - and some space for me to pitch a tent.

"And amazingly everyone said, 'yes'!

"I think people are more trusting of this sort of adventure - with Scarlet - than a man on his own trundling through
the countryside."

Originally published on talker.news, part of the BLOX Digital Content Exchange.


Load-Date: October 18, 2024


  End of Document

                                                                                                      Page 1 of 2
                          App fine-tuned at Lancaster innovation lab uses AI to spot skin cancer




     App fine-tuned at Lancaster innovation lab uses AI to spot skin cancer
                                                       LNP (Lancaster, PA)
                                                      March 3, 2024 Sunday



Copyright 2024 LNP Media Group, Inc. All Rights Reserved

Length: 843 words
Byline: DIANE M. BITTING FOR LNP, LANCASTERONLINE

Body


The rising use of artificial intelligence has the potential to remake society, for better and worse. But one Chicago
company, with ties to Lancaster, is using that powerful technology for good by helping to detect skin cancer in its
early stages.

The SkinIO smartphone app allows users to take photos of their skin in 10 minutes. These images are reviewed by
a dermatologist who determines whether any concerning spots merit further examination. If so, a follow-up
appointment with a dermatologist is recommended, with guidance on finding a doctor. For repeat users, the app
provides baseline photos to be compared with later photos for any suspicious skin changes.

“Your skin is your most visible organ, right? You see it every day,” says Kyoko Crawford, SkinIO’s co-founder and
CEO. “You see it when you’re putting on makeup, when you’re shaving, when you’re getting dressed. But very few
of us take the time to actually look.”

She adds, “SkinIO helps you look, truly look at your skin. And it’s worth your time to look at your skin because you
could catch something early that could change your life.”

READ: Full coverage of Progress 2024 [roundup]

Lancaster pilot program

In 2022, SkinIO’s app was refined at Lancaster’s Smart Health Innovation Lab, which describes itself as a “market
adoption accelerator for health care technologies.” The iLab chose SkinIO for its residency program, which focused
that year on developing innovations in tele-dermatology.

Pilot screening programs were held with several Lancaster-area employers, including Aspire Ventures and
Signature Custom Cabinetry. Crawford describes those screening programs, involving a few hundred people, as
“immensely helpful.”

Citing the Skin Cancer Foundation, SkinIO’s website (skinio.com) notes that 70% to 80% of melanomas appear as
new spots while 20% to 30% arise from changes to existing moles. Malignant melanoma is the deadliest form of
skin cancer; other forms include basal cell and squamous cell carcinomas. According to the foundation, skin cancer
is the most common cancer in the United States and worldwide, and one in five Americans will develop it by age 70.

                                                                                                         Page 2 of 2
                       App fine-tuned at Lancaster innovation lab uses AI to spot skin cancer

“Just tracking spots you know about is not necessarily enough,” Crawford says. “The vast majority will come from a
spot that wasn’t there before, so if you don’t notice that it shows up, you may miss that early warning.”

READ: How AI helps hospitals keep a watchful eye on patients

The app uses AI and machine learning to analyze what is known as total body photography, in which as much of a
patient’s skin as possible is photographed. The use of total body photography in dermatology is not new but hasn’t
been widely accessible, Crawford says.

SkinIO’s technology helps a doctor spot any skin changes more easily in less time. The AI analyzes “regional
images” and highlights any “outliers” that look dramatically different from an individual’s average spots, she says.

It’s what dermatologists call the “ugly duckling model,” Crawford says. A dermatologist, who may see dozens of
patients a day, is not looking at a patient’s skin “freckle by freckle, mole by mole” but rather is checking for changes
to that patient’s typical pattern of skin markings.

And if someone has a lot of freckles and returns for a follow-up skin exam in a year, or three or five years, it could
be difficult for even these expert specialists, who may see thousands of patients a year, to detect any potentially
harmful changes, she says.

Adults should have their skin examined once a year, and those previously diagnosed with skin cancer should do so
every six months, Crawford says. But wait times to see a dermatologist can be long, with what she describes as a
“pretty pronounced scarcity of dermatologists in this country.”

The future of SkinIO

The SkinIO technology is not diagnostic. AI is “able to process that information really quickly, but the judgment,
from the clinical expertise, the empathy, all of that should come from a human dermatologist,” Crawford says.

The technology has allowed previously untapped patient populations to receive dermatological care, while
compiling data from more diverse demographic groups, Crawford says. And while the use of AI in health care is
“super exciting,” she says, it must be done responsibly.

Crawford started SkinIO in 2014 with Dr. JC Lapiere, a Chicago dermatologist and surgeon who co-founded the
Northwestern Skin Cancer Institute. Lapiere had saved the life of Crawford’s father-in-law from melanoma — twice.

Crawford, with a background in biomedical engineering, had founded and ran a New York City-based technology
development consultancy before launching SkinIO.

SkinIO, which uses a network of dermatologists licensed in 35 states, is not currently marketed to the general
public. Instead, it’s mainly available as a health care benefit through an employer or union, Crawford says. So,
while the app can be found on GooglePlay and the App Store, an organization code is needed to access it.

However, possible development as a direct-to-consumer product is “certainly on the roadmap,” she says.


Load-Date: March 3, 2024


  End of Document

                                                                                                         Page 1 of 3
  Using AI to create fake celebrity ads can get you in trouble Using AI to create fake celebrity advertisements can
                                                  get you in trouble




     Using AI to create fake celebrity ads can get you in trouble; Using AI to
          create fake celebrity advertisements can get you in trouble
                                                Richmond Times Dispatch (Virginia)
                                                       May 27, 2024 Monday
                                                            01 Edition



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2024 Richmond Times-Dispatch, Richmond, VA

Section: HEALTH; Pg. 7D
Length: 862 words
Byline: JOHN FARMER Special correspondent

Body


Imagine Taylor Swift endorsing your product. Can't afford her? AI can fake it for you!

Thanks to AI deepfake technology, you can create a counterfeit but realistic Taylor Swift endorsement without
involving her. Deepfakes use computer machine learning to create eerily realistic images, videos and audio
mimicking real people.

Scammers used AI to create a deepfake video in which a phony Taylor Swift announced she was giving away Le
Creuset cookware sets, a real luxury cookware brand. After following some prompts, deceived shoppers were
asked to pay a small shipping fee. If they paid, they didn't receive cookware but did get hit with a hidden monthly
credit card charge.

Faking ads and endorsements by living celebrities is obviously illegal. But what about deceased ones? What about
mimicking government officials, such as the president? What if you only replicate the person's famous voice but
don't identify the person? What if your fake endorsement is an obvious parody of the celebrity?

Everything is legal if you get a license from the person whose name, image or likeness ("NIL") is used. For
example, James Earl Jones allowed Disney to replicate his vocal performance as Darth Vader in future projects
using an AI voice-modeling tool called Respeecher.

But what if you can't buy a license from the celebrity? The law is clear that you can't use the NIL of a living celebrity
without permission for a commercial purpose, such as advertising or endorsement.

Doing so violates the right of publicity, which is a person's right to control the commercial use of his NIL. This is a
state-level law that varies from state to state.

                                                                                                         Page 2 of 3
  Using AI to create fake celebrity ads can get you in trouble Using AI to create fake celebrity advertisements can
                                                  get you in trouble

About two-thirds of states recognize a right of publicity by statute, common law, or both. Other states usually have a
"right of privacy," which accomplishes roughly the same thing. Most states, including Virginia, hold that the right of
publicity protects everyone. Still, some states protect a person's NIL only if it has commercial value, which
essentially means celebrities.

Most states with a right of publicity hold that it continues after death, but the length of protection varies. In Virginia,
protection lasts 20 years after death. In other states giving postmortem rights, the length runs from 10 to 100 years.
Sometimes, the length of postmortem protection depends on whether the person is famous or whether the person's
estate continued to exploit the deceased celebrity's NIL commercially.

For a business advertising using the NIL of others, it's best to presume your activity will be governed by the most
protective right of publicity in the country. Presume that the right of publicity protects everybody's NIL, not just
celebrities and including politicians, and that it protects not only living people but anyone who lived in the past 100
years. That's because it's difficult to determine which state's law would apply to your activity, and you might get
sued in another state.

Also, don't get cute by mimicking a celebrity's voice while not identifying the person. Most states that recognize the
right of publicity include someone's recognizable voice.

For example, in the 1980s, Ford Motor Company produced an ad for the Mercury Sable using a voice impersonator
singing "Do You Want to Dance" in Bette Midler's style without her permission. Midler sued Ford and won.

Reacting to rising AI voice mimicry, Tennessee recently enacted a law that imposes criminal and civil liability on
using AI to mimic someone's recognizable voice without permission. The law extends liability to people who
knowingly publish a fake voice and, in the case of advertisers, when they should have known it was fake. It also
extends liability to any company or individual producing AI technology with a "primary purpose or function" of
making AI fakes.

What about political figures? Don't you have a First Amendment free speech right to mimic them in advertisements?
Generally, no. Politicians also receive protection against unauthorized use of their NIL for commercial purposes,
including postmortem rights for as long as applicable state law gives such rights. Free speech principles don't
override that.

What if your AI fakery is obviously a parody, such as a phony Joe Biden endorsing hair-care products or counterfeit
Donald Trump endorsing a gym chain? Trying this is legally risky. You will be liable if some in the public don't get
the joke, meaning some think the endorsement might be real. And even if everybody gets the joke, if a parody is an
advertisement to sell some good or service, that commercial aspect might make it legally unprotected.

Finally, what if your AI-generated person happens to be a non-celebrity's appearance and voice? Because the right
of publicity in most states protects all people, this too requires getting a license to use the NIL of the person
depicted.

So, don't use AI to create a fake Taylor Swift endorsement for your business. You might be "Enchanted" by her
market appeal, but when you get sued by her, it would be hard to "Shake it Off."

John B. Farmer is a lawyer with Leading-Edge Law Group PLC, which specializes in intellectual property law. He
can be reached at www.leadingedgelaw.com.



Graphic

                                                                                                         Page 3 of 3
  Using AI to create fake celebrity ads can get you in trouble Using AI to create fake celebrity advertisements can
                                                  get you in trouble

Customize your experience so you see the stories most important to you. And sign up for personalized notifications
so you don't miss any important news. TO DOWNLOAD For Android users: https://go.richmond.com/googleplay For
Apple users: https://go.richmond.com/apple John Farmer John Farmer


Load-Date: June 24, 2024


  End of Document

                                                                                                    Page 1 of 3
      Wharton professor is teaching 'accountable AI' Kevin Werbach's new course will focus on the practice of
                             understanding and addressing artificial intelligence's r....




   Wharton professor is teaching 'accountable AI'; Kevin Werbach's new
 course will focus on the practice of understanding and addressing artificial
                     intelligence's risks and limitations.
                                                    The Philadelphia Inquirer
                                                      June 17, 2024 Monday



Copyright 2024 Philadelphia Newspapers, LLC All Rights Reserved

Section: BUSINESS; Pg. A7
Length: 1081 words
Byline: Ariana Perez-Castells (Staff Writer)

Body


ABSTRACT

Businesses are already using AI, but how are they going about addressing their risks?

This fall, Kevin Werbach, professor of legal studies and business ethics at theWharton School of the University of
Pennsylvania, is leading a new course as part of the school's executive education program that will focus on
"accountable AI," a term he uses to refer to the practice of understanding and addressing AI risks and limitations.

Some 18% of S&P 500 companies mention AI in their 2023 annual reports as a "risk factor," Werbach explains on
the first episode of his podcast, The Road to Accountable AI, which launched in April.

"That probably should have been higher," he says on the podcast.

In an interview with The Inquirer, Werbach explains some AI issues and what accountable AI entails.

"There have been example after example of failures of AI systems, systems that are biased based on race and
gender and other kinds of characteristics, systems that make very significant errors," he said. "The ordinary person
out there who is hearing about AI is probably hearing at least as much about the failures as the benefits today. The
reality is both are real, but to me that means we need to think about how to maximize the benefits and minimize the
dangers."

        The interview has been condensed for brevity and clarity.

What is accountable AI?

Accountable AI is the phrase that I prefer to describe the practice around understanding and addressing the various
kinds of risks and limitations of implementation of AI. People sometimes talk about AI ethics, which is a piece of it,
but there's a danger that just focusing on ethics leads people to emphasize the principles as opposed to practical

                                                                                                    Page 2 of 3
      Wharton professor is teaching 'accountable AI' Kevin Werbach's new course will focus on the practice of
                             understanding and addressing artificial intelligence's r....

steps to take in organizations. Sometimes there's talk about responsible AI - which is closer - but still doesn't
necessarily get organizations focused on how to create effective structures of accountability. So I talk about
accountable AI as the entire set of frameworks around understanding issues with AI systems, figuring out how to
manage them, govern them, mitigate risks, and putting into place mechanisms of accountability so people feel that
they are the ones who have the obligation to take the kinds of actions that are necessary.

In your podcast you mention a Pew 2023 survey in which a majority of respondents were more concerned than
excited about AI in daily life. Why are you excited about AI, and do you think others should be, too?

I'm excited about AI because there are countless ways that we can use it either to do things humans are doing -
better or faster - or in some cases to do things at scales that humans really can't effectively do. Especially with the
rise of generative AI, where this is not just machine learning that gets developed and implemented by data
scientists, it's something anyone in an organization can interact with directly. There's just an infinite number of
places where we're going to find out ways that AI will make business more effective and potentially make people's
lives better.

On the other hand, there are huge, huge problems and concerns. Those range from small-scale issues - we know
that large language models (generative AI systems like ChatGPT) will hallucinate and create information that's just
simply wrong - to there could be catastrophic effects of these technologies being used for weapons development
and terrorism and so forth, and everything in between.

What does regulation for AI look like today? Should businesses be creating their own internal policies?

Definitely businesses should be creating their own internal policies. There are a whole range of different issues. ...
So for example, if you do not have an enterprise license to these tools, then typically any queries that you send to
the chatbot get stored and can be used by the company that's providing that service. If you're in a financial services
firm and someone is asking a question that reveals very sensitive, confidential information for the firm, you might
just think "it's like I'm typing in a search term to Google," but potentially, you're giving up sensitive private
information, which could then be used to train future models and [be] accessible to the rest of the world ... that's
something an organization should think about.

What are some of the ethical considerations business should be thinking about when choosing to implement AI
tools into their processes?

It's really important for businesses to think about what are their general ethical principles that are important to them.
That's something that they probably should be doing already with technology. We've had many years of
controversies about issues like privacy and security and fairness - those are ethical values that are relevant to
technology in general, which are very relevant to AI. ... If a health-care firm is using AI to read X-rays effectively,
that's something different from a marketing firm that's using AI to generate copy, but there are ethical issues in both
contexts. It's really a matter of mapping out the major ethical issues that the firm's concerned with.

Do you think more businesses should be using AI? Is this a good moment for businesses to be trying this out?

Everyone should at least understand what the technology is and what it's capable of. The generation of generative
AI systems - the chatbots and so forth - are so novel and powerful in ways that we haven't really experienced
before, that everyone should at least get a handle on them. It doesn't necessarily mean everyone needs to adopt
them or they're going to change everyone's life overnight, but everyone should understand what they do well and
don't do well, and how far along we are, and how fast the technology is evolving, because otherwise they're going
to be surprised. This is accessible to everyone, so your competitor very well may be experimenting with the
technology if you're not.

What are some of the risks of using AI tools, and how can businesses protect themselves or mitigate them?

                                                                                                    Page 3 of 3
      Wharton professor is teaching 'accountable AI' Kevin Werbach's new course will focus on the practice of
                             understanding and addressing artificial intelligence's r....

One risk is accuracy, especially with generative AI. One big challenge is you may not quite understand why the AI
produced a certain result, which in some situations might not be important, but in a situation where, let's say the AI
system says hire this person and not that person, and the person who didn't get hired challenges that decision, how
do you explain that "the AI told me to"? There's a big set of technical challenges around explaining AI.

aperezcastells@inquirer.com

arianapeca2


Load-Date: June 17, 2024


  End of Document

                                                                                                         Page 1 of 2
                                        A Policy Primer for the 2024 Legislative Session




                         A Policy Primer for the 2024 Legislative Session
                                                   Government TechNology
                                                 January 17, 2024 Wednesday



Copyright 2024 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 605 words
Byline: Paul W. Taylor, Government Technology

Body


Jan. 17—Listen to this episode on the player below or subscribe for free on YouTube or the podcast app of your
choice — Apple Podcasts, Spotify, Audacy and Audible.

As legislatures in 37 states are back in session this month, with another nine set to open before April, lawmakers
face a daunting set of challenges. Budget prospects have improved modestly but tax tensions remain as lawmakers
deal with complex demands to deal with crises in housing and drug overdoses. Their hoppers are also filled with
bills to address criminal justice reforms, transportation funding, child tax credits, post-pandemic workforce dynamics
and renewed calls for school choice and parental rights.

Governing* editor Alan Greenblatt and writers Jared Brey, Zina Hutton and Carl Smith join the podcast to discuss
these issues and more.

SHOW NOTES

Here are the top takeaways from this episode:

AI Policy Evolution and Concerns

* Rapid advances in artificial intelligence outstrip the ability to competently regulate. Concerns about
misinformation, the embedding of implicit biases and workforce displacement are catalysts for legislation at the
state and federal levels.

* Anticipated regulation aims at managing deepfake generation, especially around election content, with a focus on
data literacy to combat misinformation.

* Challenges persist in addressing AI-generated "hallucinations" due to insufficient frameworks and fact-checking
protocols.

* California leads in privacy and bias regulations, impacting AI application in health-care and job sectors.

                                                                                                          Page 2 of 2
                                   A Policy Primer for the 2024 Legislative Session

Budgets and Taxation

* States see modest budget increases, drawing on pandemic surpluses for tax cuts and infrastructure investments,
but with an eye to long-term fiscal sustainability.

* Tensions between revenue growth for programs and tax reductions pose challenges as states grapple with budget
surpluses.

Transportation Funding Challenges

* Funding public transit faces hurdles as commuting patterns change in post-pandemic workplaces, prompting
some jurisdictions to consider taxing high earners to support public services.

Child Tax Credits and Labor Force Impact

* States extend child tax credits to mitigate federal program expirations, aiming to alleviate poverty, but it has raised
concerns about workforce participation.

Education and School Choice Dynamics

* Parental dissatisfaction is driving school choice initiatives, affecting public education funding and stirring parental
rights discussions.

* Media literacy legislation addresses gaps in students' abilities to navigate and critically assess online information
sources, which are seen as vital for future academic and professional success.

Drug Overdose Crisis and Criminal Justice

* Illicit fentanyl is driving the recent increase in U.S. drug overdose deaths, prompting debates between punitive
approaches and medical treatment for substance abuse disorder.

* Polarized viewpoints in criminal justice reform lean toward tougher enforcement, influenced by political rhetoric
and public sentiment.

Governing's editors and writers round out the discussion of the remaining issues to watch — health care, mental
health, climate and energy policies and the nationalization of politics during a presidential election year — on the
next episode of the podcast.

Related link to the stories referenced in the episode: Governing's Biggest Issues to Watch in 2024

*Note: Governing and Government Technology are both a part of e.Republic.

Our editors used ChatGPT 4.0 to summarize the episode in bullet form to help create the show notes.

___ (c)2024 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: January 18, 2024


  End of Document

                                                                                                          Page 1 of 3
                             The Startling Deterioration of American Philosophy Departments




           The Startling Deterioration of American Philosophy Departments
                                       James G. Martin Center For Academic Renewal
                                                       July 5, 2024 Friday



Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 James Martin, USA All Rights Reserved

Length: 1514 words
Byline: John Mac Ghlionn

Body


In 2014, according to the QS World University Rankings, the United States boasted eight of the top college
philosophy departments in the world. A decade later, that number has been halved, with only four U.S. institutions
remaining in the top 10. To some, this might seem inconsequential. "So what?" they might say. "Philosophy is
absolutely useless; it serves no practical purpose, especially in the age of artificial intelligence." Such attitudes are
not only lazy and uninformed, however, but dangerously shortsighted.

Philosophy, far from being an antiquated discipline, is more crucial now than ever. As artificial intelligence, ethical
dilemmas, and existential questions pervade our daily lives, the timeless discipline of philosophy offers a crucial
lens through which to navigate the complexities of our modern world. In a landscape characterized by uncertainty
and rapid transformation, philosophy serves as a beacon of intellectual clarity and moral guidance, inviting us to
engage with fundamental questions about ethics, knowledge, meaning, and the human experience.
Philosophy has entered the realm of academic absurdity, with departments finding ever more inventive ways to
squander money.Philosophy teaches us to consider, reflect, and reason effectively. It challenges us to question our
assumptions, understand different perspectives, and articulate our ideas with precision. These are skills that are not
just beneficial but essential in an era in which information is abundant but wisdom scarce.
Sadly, though, in recent times philosophy has entered the realm of academic absurdity, with departments finding
more and more inventive ways to squander taxpayers' money-such as, for example, by publishing papers on the
metaphysics of puns. Yes, you read that right. While dizzying technological advances threaten to upend whole
economies and cultures, ivory-tower intellectuals are busy dissecting the ontological status of wordplay.
The fact that academics are devoting time to exploring the type-token theory of words and its application to puns is,
for lack of a better word, preposterous. And the puns-based paper is not merely a footnote in some obscure journal.
It was published in Synthese, a reputable outlet for serious philosophical discourse. The paper argues for a novel
account of puns based on "nominalist views of words" to address some supposed indeterminacy in the current
theories. Imagine the hours of deep thought, peer reviews, and academic resources poured into unraveling the
pun's metaphysical essence. This is not just a harmless exercise in intellectual frivolity; it's a profound misallocation
of public funds. Philosophy, a discipline that could be engaging with pressing ethical dilemmas, the nature of
consciousness, or the intricacies of justice, instead chooses to ponder the essence of a joke.

                                                                                                          Page 2 of 3
                          The Startling Deterioration of American Philosophy Departments

What's particularly galling is the self-referential nature of this academic exercise. Papers like these are not intended
for the public, who fund much of the research, but for other academics, who will cite, critique, and expand upon this
cerebral navel-gazing. It's an echo chamber, wherein relevance to the real world is an afterthought at best.
This isn't just a one-off anomaly. The trend toward hyper-specialized, esoteric topics that border on the nonsensical
is growing. Look at the broader context of metaphysical and epistemological studies-volume upon volume dedicated
to debates that have zero impact outside of the cloistered walls of academia (or that are aggressively leftist and
annoying). Meanwhile, the public's patience and funding wear thin, and philosophy departments crumble away.

In an era in which the cold, metallic hand of AI stretches ominously over every aspect of our lives, philosophy is
more vital than ever. We don't need ivory-tower intellectuals churning out frivolous dissertations on obscure
trivialities. We need philosophers who can deliver the goods, offering real, substantive insights that cut through the
digital fog. This is a time for heavyweights, not lightweight nonsense.

This is a time for philosophy heavyweights, not lightweight nonsense.As we integrate AI into healthcare and the
criminal-justice system, the ethical implications will become increasingly profound. How should we handle privacy in
a world where our data are constantly being collected and analyzed? What responsibilities do we have to prevent
AI from exacerbating social inequalities? These are not questions that can be answered by engineers or computer
scientists alone. They require the nuanced understanding and ethical foresight that philosophy provides.

Furthermore, philosophy is not just about abstract theorizing, or at least it shouldn't be. It has practical applications
that are vital for the functioning of a democratic society. The ability to engage in reasoned debate, and to think
logically and critically, is foundational to the health of our public discourse. Without these skills, we are more
susceptible to manipulation and demagoguery. We become a society driven by emotion and misinformation rather
than reason and evidence.
Here are just a few reasons why philosophy is so crucial:
1. Critical-Thinking Skills: Philosophy encourages individuals to think critically, analyze information, and evaluate
different perspectives. In a world dominated by rapid technological advances and information overload, the ability to
discern truth from falsehood is invaluable.

2. Ethical Decisionmaking: The integration of AI into our lives raises numerous ethical questions. From privacy
concerns to the ethical use of AI in warfare, citizens need a strong ethical foundation to navigate these complex
issues. Philosophy provides the tools to develop moral reasoning and understand the consequences of our actions.

3. Creativity and Innovation: As AI automates routine tasks, creativity becomes increasingly important. Philosophy
encourages creative thinking and problem-solving, skills that are essential for innovation in a tech-driven world.
4. Adaptability and Resilience: In the face of swift technological advancements, adaptability becomes crucial.
Philosophy teaches us how to think flexibly and deal with uncertainty, fostering resilience in the face of challenges.

The decline of philosophy departments in the U.S. is not just a loss for academia but for society as a whole.5.
Understanding Human Values and Emotions: In a world in which AI is becoming more prevalent, understanding
what makes us human is crucial. Philosophy helps us explore complex human emotions, values, and relationships,
fostering empathy and emotional intelligence.
6. Preparation for the Future: Philosophy equips individuals with critical thinking, ethical reasoning, creativity,
adaptability, and emotional intelligence. These skills are essential for success in a technology-driven society.
Despite the critical importance of philosophy, it is liable to be sidelined in favor of more "practical" subjects-when it
isn't digging its own grave, that is. This trend is driven by a shortsighted focus on immediate economic returns
rather than long-term intellectual and moral development. Universities in general are cutting funding for humanities
departments, and philosophy is often the first to go. This is not just an academic issue; it reflects a broader societal
undervaluation of the skills and insights that philosophy provides.

The decline of philosophy departments in the U.S. is not just a loss for academia but for society as a whole. It
signals a shift towards a utilitarian view of education that values immediate economic benefits over the cultivation of
a well-rounded, thoughtful citizenry. This trend is particularly troubling in an age in which we face unprecedented

                                                                                                        Page 3 of 3
                          The Startling Deterioration of American Philosophy Departments

ethical and existential challenges. From mental-health issues to AI, the problems we face today require not just
technical solutions but profound ethical and philosophical reflection.
Moreover, the decline in philosophy's prominence has far-reaching implications for public discourse. Because
sound bites and superficial arguments often dominate today's conversations, the ability to think deeply and critically
is more important than ever. Philosophy teaches us to engage with complex ideas, to consider different
perspectives, and to reason logically. These are the skills that underpin a healthy democracy.
The erosion of philosophy departments is a symptom of a widespread societal problem: the undervaluation of the
humanities and the corruption of humanities departments by the very practitioners who should know better. We are
becoming a society that values economic utility over intellectual and moral development. This is a dangerous trend,
particularly at a time when we face complex and unprecedented challenges that require deep and thoughtful
engagement.
John Mac Ghlionn is a psychosocial researcher and essayist. His work has been published by the New York Post,
Sydney Morning Herald, Newsweek, National Review, and the Spectator (U.S.). He covers psychology and social
relations and has a keen interest in social dysfunction and media manipulation.




Load-Date: July 6, 2024


  End of Document

                                                                                                         Page 1 of 4
                                            Your professor also is getting help from AI




                               Your professor also is getting help from AI
                                                  The Atlanta Journal-Constitution
                                                    September 2, 2024 Monday
                                                           Main Edition



Copyright 2024 The Atlanta Journal-Constitution




Section: MAIN; Pg. 1A
Length: 1409 words

Byline: Vanessa McCray , Vanessa.McCray@ajc.com


Staff
Highlight: Georgia colleges, universities test how best to use artificial intelligence to enhance, personalize learning.

Body


The fit, 41-year-old white male lay in a hospital bed and complained about a headache.

Hal introduced himself to the Emory University nursing class gathered around his bedside. He shook a student’s
hand and provided his medical history. No allergies, no surgeries. He has high blood pressure but isn’t taking any
medication.

The students had not expected the demonstration to feel so real. Because here’s the thing about Hal: He’s a robot.
(Its official name is HAL S5301.) A $135,000 patient simulator with silicone skin, uncanny eye movements and
artificial intelligence.

Hal is the right-hand mannequin to Kim Fugate, senior simulation operations specialist at the Emory Nursing
Learning Center.

It’s not just students who have turned to AI programs such as ChatGPT for help with assignments and essays.
Their professors are also increasingly relying on the emerging technology to enhance and personalize learning.
They’re exploring how to use AI to conduct oral assessments, brainstorm curricula, generate multiple choice
questions for tests or train future teachers and nurses by replicating scenarios they’ll encounter in classrooms and
hospitals.

                                                                                                         Page 2 of 4
                                      Your professor also is getting help from AI

The technology’s rapid advancement in the classroom has elicited both lighthearted fun — an April Fools’ Day
edition of the University of Mississippi student newspaper carried the headline “UM reveals plan to replace
professors with artificial intelligence” — and deep unease. In July, California enacted a law to require human faculty
to teach community college courses. Professors can still use AI as a tool for developing courses, tutoring and
grading, according to the bill’s sponsor.

“I don’t think AI will ever fully replace teachers because I think teaching is one of the hardest professions in the
world,” said David Joyner, executive director of online education at Georgia Tech’s College of Computing.

But, he said, more people are recognizing ways it can help and realizing students need to learn to use it. As a result
of AI and the online shift during the COVID-19 pandemic, he expects college classrooms to look very different in the
next decade.

“We’re going to see a lot more embracing of the fact that class is not the four walls,” Joyner said.

A new kind of teaching assistant

This fall, Morehouse College professor Muhsinah Morris, who directs the school’s Metaversity, is introducing
students to her new AI teaching assistant. She’ll still teach education courses in person, but if a student misses a
class or has a question, they’ll have 24/7 access to her online helper.

“It’s kind of like having someone who sits in all of the classes, and they can tell you exactly what happened in all of
these classes,” said Morris.

Using an avatar designed to look like her — down to the colorful eyeglasses she prefers — the assistant can recap
lessons by pulling from content curated by Morris. It also speaks multiple languages.

Students can still visit with Morris during her normal office hours or catch her after class. But she thinks the AI tool
may appeal to shy students reluctant to raise their hand in class or night owls with late-night study questions.

There are safeguards in place that aim to redirect a student if a query veers off-topic or to prevent the sharing of
bias and misinformation.

“It’s not going to tell you how to make a bomb even though it’s a chemistry class,” Morris said.

A handful of other Morehouse professors are also trying out the tool in history, sociology, business and other
courses this semester.

Personalized learning

Georgia State University was an early pioneer of classroom chatbots, with promising results.

The school started using bots in 2016 to guide students through the admissions process by sending timely texts to
their cellphones. Then, GSU deployed the tool in one of its biggest courses, American government. When test
grades come in, the bot can send out personalized, congratulatory texts or urge them to go to class if they’d been
skipping.

Timothy Renick, executive director of Georgia State’s National Institute for Student Success, said it relieved some
of the workload from professors and graduate assistants who had been fielding the same questions over and over
from the 100 or more students in each class.

Overall, final grades in the sections that piloted use of the chatbot were 7 points higher on a 100-point grading scale
compared to sections without the bot, Renick said. It made an even bigger impact for first-generation college
students, whose marks averaged 11 points higher, more than a full letter grade. Renick said that’s huge for HOPE
Scholarship recipients, who must maintain a 3.0 grade-point average in college to continue receiving the state aid.

                                                                                                         Page 3 of 4
                                        Your professor also is getting help from AI

A $7.6 million federal grant will expand the chatbot’s use starting this school year in first-year math and English
courses at Georgia State, Morgan State University and the University of Central Florida.

The service will be layered on top of traditional student supports, such as tutoring and office hours with professors.
Renick believes such technology can help large public universities, community colleges and minority-serving
schools provide the kind of personal attention that elite schools with low student-to-faculty ratios boast about.

Catching academic problems early makes it so much easier for students to fix the issue before they fail a big exam,
Renick said.

“It’s allowed us to begin to level the playing field,” he said.

What AI can’t replace

Health care instructors have long used human actors, known as standardized patients, to portray patients and
simulate medical conditions.

Fugate doesn’t see AI tools such as Hal replacing those humans. Before breaking bad news to a real patient, for
example, it helps to practice on someone who can respond with authentic emotion.

Hal has other shortcomings. If a group of students are all talking at once, Hal may chime in even when not being
directly addressed.

It’s similar to how an Alexa device will wake up and respond if it picks up a stray sound. When Hal keeps
interrupting, Fugate will tell it to “listen for a minute” or to “take a little nappy-nap.”

The technology, however, is well suited for other scenarios. When Fugate recently showed off Hal to nursing
students, they marveled at its conversational abilities and thought it would be easier to focus while practicing on an
AI patient.

“Better for us to make our mistakes here than to go in the hospital and do it,” said Indyia Singleton.

The mannequin can be programmed to control the pulse or mimic specific symptoms, such as tongue swelling.
Students can practice intubation and defibrillation. And, Hal offers an extra level of “believability” during training
because the mannequin can move its face, head, arms and mouth while talking, Fugate said.

A balancing act

The AI revolution has forced universities to grapple with its fast-moving impacts on education.

This year, Georgia State’s Center for Excellence in Teaching, Learning and Online Education is hosting a yearlong
training series to equip faculty to use AI effectively.

Professors are discussing how to best use AI for their own research and data analysis and how to review
assignments for clarity and assess what students are learning.

They’re also keen to protect academic integrity and develop students’ critical thinking skills.

“I think we’ve been surprised to see a lot greater desire to learn about it and to implement it and to see what it can
do,” said Jennifer Hall, the center’s associate director.

The Southern Regional Education Board, an Atlanta-based advisory group to 16 states, including Georgia,
launched a Commission on Artificial Intelligence in Education to provide guidance on the best ways to use AI in K-
12 and college classrooms.

Schools and universities need to carefully consider AI technology purchases, said Stephen Pruitt, the board’s
president. Leaders should ask: How and when students will have access to the tool? Who is in charge of updating

                                                                                                      Page 4 of 4
                                    Your professor also is getting help from AI

the app or maintaining the gadget? Who will train faculty to use it? And, most importantly, how will it be “the
difference maker” for students.

“This is probably the biggest disruption in education we’ve seen maybe ever, but certainly over the last 50 years,”
said Pruitt. “This is having the world as your classroom.”

‘I don’t think AI will ever fully replace teachers because I think teaching is one of the hardest professions in the
world.’ David Joyner, executive director of online education at Georgia Tech’s College of Computing.


Load-Date: September 2, 2024


  End of Document

                                                                                                      Page 1 of 2
                                  In Our View: Artificial intelligence tech requires regulation




                In Our View: Artificial intelligence tech requires regulation
                                           The Columbian (Vancouver, Washington)
                                                  January 17, 2024 Wednesday



Copyright 2024 The Columbian Publishing Co. All Rights Reserved

Section: EDITORIAL; Pg. A4
Length: 583 words
Highlight: The risks and benefits posed by emerging artificial intelligence technology are complex. So are
legislative efforts to regulate it.

"The biggest pitfall is legislating out of fear and moving too quickly and not recognizing how mismatched are the
pace of technology and the pace of legislation," Laura Ruderman, CEO of the Washington Technology Alliance, told
news outlet Crosscut.com.

Body

The risks and benefits posed by emerging artificial intelligence technology are complex. So are
legislative efforts to regulate it.
"The biggest pitfall is legislating out of fear and moving too quickly and not recognizing how mismatched
are the pace of technology and the pace of legislation," Laura Ruderman, CEO of the Washington Technology
Alliance, told news outlet Crosscut.com.

As demonstrated by the digital revolution, lawmakers typically are several steps behind emerging
technology. For example, guidelines put in place by Congress for the nascent internet in 1996 are still in
place and are woefully outdated. Now, the speedy rise of AI has made regulation even more difficult.
Yet that is the task facing Washington lawmakers, with several bills related to artificial intelligence
pending in the Legislature.

Last year, Washington passed a bill requiring disclosure if audio or video depictions in a political
advertisement have been manipulated. Among other things, AI technology allows for the creation of video
that looks authentic but is fabricated, which could lead nefarious candidates to literally put words in
the mouth of their opponent.
As an analysis from the centrist Brookings Institution explained in May: "Many expect there to be a
tsunami of disinformation in the 2024 elections as the close election provides incentives for a number of
people and organizations to create fake videos, false audios, and incriminating texts with little regard
for fairness or factual accuracy."

Sen. Javier Valdez, D-Seattle, author of Washington's political advertisement bill, said: "AI is a
complicated issue that we don't fully understand. You don't want to stop innovation. You don't want to
stop commerce. But you don't want to stop people's civil rights.  Right now, we're in that moment where
artificial intelligence is everywhere."

This year, one bill would create a task force to map out how Washington should regulate AI. Another would
forbid AI algorithms that lead to discrimination, and another would require companies to notify employees
and customers when AI is being used.

                                                                                             Page 2 of 2
                          In Our View: Artificial intelligence tech requires regulation

The bills are well-intended, but they likely are beyond the scope of state lawmakers. Piecemeal
legislation would begin constructing a confusing labyrinth that eventually could conflict with laws
throughout the nation and in other countries.

In reality, Congress should be quick to address AI technology and establish national standards. Yet
developing thoughtful legislation could be difficult.
During a series of congressional hearings last year, it was incongruous to see lawmakers - some born
before the television age - try to make sense of artificial intelligence. But a few themes did emerge.

One is that nearly all industry experts support strong disclosure laws, echoing proposals in this state.
Another is that the need for a regulatory agency is clear; as an analysis from Brookings explains:
"Failure to do that would result in sector-specific solutions where there are different AI rules for
finance, health, transportation, education, housing, and employment. That 'Tower of Babel' approach would
be disjointed, disorganized, and ineffective in combatting AI ills and leave a number of people
dissatisfied with the results."

The most important line of defense against the threats posed by AI is a discerning public; in other words,
don't believe every video you see on social media. But on top of that is a need for legislative
regulation, and it should begin at the highest level of lawmaking.



Load-Date: February 5, 2024


  End of Document

                                                                                                         Page 1 of 4
        AI has role in hospital patient care Hartford HealthCare says system can predict 'patient deterioration'




                        AI has role in hospital patient care
        Hartford HealthCare says system can predict 'patient deterioration'
                                                      The Hartford Courant
                                                February 28, 2024 Wednesday
                                                             1 Edition



Copyright 2024 The Hartford Courant Company All Rights Reserved

Section: MAIN; A; Pg. 1
Length: 1636 words
Byline: Sean Krofssik Special to the Courant

Body


Artificial intelligence can be trained to predict whether you will get sicker.

Hartford HealthCare calls it "predicting patient deterioration."

The Connecticut health system soon will use artificial intelligence in more cases and is slowly implementing the
overall technology into its care.

The process has been several years in the making.

Among many uses, the algorithm can predict potential clinical deterioration in patients, Hartford HealthCare doctors
said. For now, it's being studied and piloted, and the science of a "length of stay" algorithm is being used, and the
hope is to eventually have AI assist all patients with valuable and potential life-saving information, according to
Hartford HealthCare doctors.

'Patient safety is always first'

"Over the last seven years we have assembled many of the pieces of the puzzle so that we can double down on the
unlocking (of) the transformative power of AI to our patients in a safe, trustworthy way," said Dr. Barry Stein,
Hartford HealthCare's chief clinical innovation officer and leader of its Center for AI.

Hartford Hospital Associate Vice President of Medical Affairs Dr. Daniel Kombert was among the first working with a
Massachusetts Institute of Technology team that developed an algorithm to improve patient care. Kombert said he
and others collaborated with Dimitris Bertsimas, associate dean of business analytics at MIT-Sloan.

On the 'length of stay' algorithm, Kombert said, its job is to help predict when a patient is ready to be discharged.

"It's a national problem where patients are staying at hospitals longer than they should be. Longer stays increase
the risks of falls and infections," Kombert said.

                                                                                                         Page 2 of 4
        AI has role in hospital patient care Hartford HealthCare says system can predict 'patient deterioration'

The experts looked at the hospital's historical data base and "the tool was rolled out slowly and we made sure it
was safe and valid. Since it's been implemented, we've dropped seven percent in hospital stays. It's enormous
savings. Our goals are typically to drop to an appropriate length of stay, Kombert said.

"When we rolled it out, we told the doctors this was just a tool. It's a discharge consult and ultimately, it's still up to
the doctor, nurses and case manager to decide when to discharge," he said. "But we use this AI in our daily
communication and on all of our medial units across the system and we've seen improvements in all hospitals."

Kombert said daily rounds are done and "doctors, case managers and nurses get together and communicate which
patients are ready to go home."

"What are the barriers to go home?," he said.

"If a physician determines a patient is ready to go home in three or more days and the AI determines as potential
for discharge within two days, this difference is discussed on team rounds and the physician can reevaluate
whether the patient may be ready for a safe discharge at an earlier time," he said.

"We always have cases where the doctor says the patient is not ready to go home," Kombert said. It is their
decision; in the end it is the physician who makes the final decision as to when to patient can go home."

Dr. Melissa Boisjoli-Langlois, the assistant director of Hospital Medicine at Hartford Hospital has seen real
examples of the effectiveness of the 'length of stay' tool.

In one case, a patient who came into the hospital with blood in his stool was admitted, she said.

"The GI team was consulted, and the patient had a stable blood count," Boisjoli-Langlois said. "They didn't need a
blood transfusion. But an endoscopy and colonoscopy were needed."

"On rounds that day, we received a green alert, and we reviewed it," she said. "That triggered a collaborative
discussion. After that discussion, the providers concluded that he could be transitioned out the next day if
everything turned out OK with the procedures."

The next morning the patient's endoscopy and colonoscopy were moved earlier in the day and he was discharged
later that day, a full day earlier than originally planned.

In another example, a female had signs of congestive heart failure with shortness of breath and swelling in her legs.
A cardiologist was consulted, and she was treated with diuretics through an IV, Boisjoli-Langlois said.

The cardiologist ordered an echocardiogram.

"After a day, the patent was doing much better and the treatment was working," Boisjoli-Langlois said. "She was not
retaining as much fluid and wasn't short of breath and the green light came up on the tracker. We had a discussion
and expedited the echocardiogram, and it came up normal. We were able to let the patient go home later that
evening a day before we had originally planned."

Boisjoli-Langlois emphasized that physicians don't go by what the tool says alone, but it starts an in-depth
conversation to see if there are any barriers and to make sure everyone agrees.

"It's been helpful," Boisjoli said. "We are very busy in the hospital, and this allows us to standardize and work as a
team more efficiently."

'Being diligent'

Kombert said the artificial intelligence that predicts patient deterioration has not yet been rolled out. It is being
piloted.

                                                                                                         Page 3 of 4
        AI has role in hospital patient care Hartford HealthCare says system can predict 'patient deterioration'

"The first thing is to identify an opportunity and we want to have the physicians understand earlier than they
normally would when a patient is showing signs that may not be obvious," Kombert said, of one aspect of the
model. "Patient safety is always first and we looked for a high-quality algorithm that is trusted and solves the
problem we are asking of it."

"The next step was bringing the clinical people altogether to work with the MIT team to get exactly what they want,"
Kombert said. "That doesn't happen over a week. We are talking about weekly meetings with very busy people and
getting their time and effort and help the MIT team to improve the algorithm."

"This went on for over a year having one or two meetings a week, tweaking it to where we needed it to be,"
Kombert added. "Now you have a tool that is answering the questions you need and is accurate. But you can't just
roll it out. It's a process."

Dr. Howard Haronian, the vice president and chief quality and innovation officer at Hartford HealthCare Heart &
Vascular Institute and has also been involved in the AI research with MIT. Oxford University, Google Cloud are
other partners, said the most important part was ensuring safety.

"We realized MIT is great at analyzing data but when it comes to patient care, they don't work in the hospital,"
Haronian said. "They don't see patients. That's why it's on physicians to make sure this is 100 percent safe. We've
been able to set up a world class governance. It's best in class. Less than 20% of health care organizations
currently have an organized process for AI governance. We are leading in that and I'm proud that.

"We offer the opportunity for myself or my family to have a heads up that I'm going to get sick the next day," he
said, on predicting patient progress.

"Wouldn't it be nice with all of the craziness in the hospital and all of the patients, that...my doctor had an early
warning," Haronian said. By the time we release this to the general public of our health system, we've already
piloted it, tested it and refined it. There's no room for any safety mishap."

Opportunities for new information

Hartford Hospital Director in Chief of Hospital Medicine Dr. Gagan Singh, who has been involved in the project
since the developmental phase, said a pilot process of AI for detecting clinical deterioration has been put into place
on a small unit at Hartford Hospital.

"We identified a small team that will get the signal," Singh said. "The team will talk to the clinician, and they will talk
about what needs to be done. Patients will get care in real time. Sometimes the clinicians will say I'm already aware
of it and I'm on it. Sometimes there will be an opportunity where it will be new information and they can get in front
of it."

"That's the power of this tool," he said. "It will not only save us time, but it will save lives.

"There could be some kind of clinical deterioration and you caught it six hours in advance. You see what can
happen and you are acting on it...But we are taking a small approach because our goal is patient safety," Singh
said. "We are being careful how we do it and that's just being diligent."

Kombert said said the process is moving forward methodically. Also among what the artificial intelligence can being
used to detect are: COVID-19 related events, predicting secondary stroke events, nursing scheduling needs and
efficients uses of operating rooms.

It also is designed to predict outcomes for transcatheter aortic valve surgeries and joint replacement surgeries,
according to the health care system.

"We have the units and champions ready to move forward," Kombert said. "In the next two weeks we expect to
begin the slow rollout. To give our teams the opportunity for feedback. It's over in about a month and then it's a slow

                                                                                                         Page 4 of 4
        AI has role in hospital patient care Hartford HealthCare says system can predict 'patient deterioration'

rollout. We will put it on three units and slowly add other units. We want to make sure there is value added and the
workflow is improved as well as patient safety. The slow rollout has been effective in other areas."

Jenifer Ash, an APRN in the Department of Medicine at Hartford Hospital, said quality and safety are paramount.

"Looking at the evidence, it shows that many patients show signs of deterioration in about 24 to 48 hours to that
actual event," Ash said. "For the team, the time of the intervention really matters and for us to equip the frontline
team with the tools to be able to do that would improve patient outcomes."

Stein said it is all a team effort.

"The philosophy of AI in health care - before we put it into clinical practice - we go through the same diligence if we
were adding a new medication or device into a system," Stein said. "There is a back and forth with the science and
the clinicians and you are learning. It's powerful. It's almost a force multiplying effect."


Load-Date: February 28, 2024


  End of Document

                                                                                                        Page 1 of 5
                                MetroHealth CEO on rebuilding trust, workforce challenges




               MetroHealth CEO on rebuilding trust, workforce challenges
                                                   Crain's Cleveland Business
                                                          April 8, 2024
                                                          Print Version



Copyright 2024 Crain Communications All Rights Reserved




Section: Pg. 6; Vol. 45
Length: 2852 words
Byline: Paige Bennett

Body


Intentional listening has been the overarching theme of Dr. Airica Steed's early tenure as president and CEO of the
MetroHealth System.

Shortly after she joined MetroHealth in December 2022, Steed embarked on a listening and engagement tour
across the health system. It quickly became clear that continued listening would be a key piece of Steed's strategy
for guiding the system.

"What jumped out very loud and clear is an overwhelming need for this," she said. "Not to just be a tour where it's a
one and done, but there was an overwhelming need for the organization to be heard, to be understood, to have a
legitimate seat at the table, to be activated, to find their voice, to be really listened to in a powerful way."

Out of that process came several strategic priorities: developing a people-first culture, elevating MetroHealth's
clinical and academic profile, creating a replicable model for eradicating health care disparities and continuing to
reinvent and reimagine the health system as it came out of the pandemic.

It also helped shape Steed's approach to repairing trust in MetroHealth. In 2022, the health system's board of
trustees fired then-president and CEO Dr. Akram Boutros, citing a report that found he awarded himself $1.9 million
in unauthorized bonuses between 2018 and 2022. Boutros, who has denied the allegations, voluntarily dismissed
his lawsuit against MetroHealth in December, citing health issues.

"I think that that intentional listening, that intentional engagement and that intentional focus on creating a people-
first culture really sprouted from the trauma and the tragedy," Steed said. "By taking that listening ear and really
understanding the needs of the organization and really identifying out the gates that one single individual doesn't
make a culture, I think we came on the other side of it a much stronger."

                                                                                                           Page 2 of 5
                             MetroHealth CEO on rebuilding trust, workforce challenges

Rebuilding that sense of trust included appointing MetroHealth's first-ever chief people officer to oversee the
system's People and Human Resources Division. With that position came process and structure changes that
resulted in more clearly defined roles and responsibilities and helped to establish better and tighter controls across
the organization, Steed said.

In a recent interview with Crain's, Steed discussed her goals for MetroHealth, workforce challenges in the health
care landscape, the rise of artificial intelligence and the importance of collaboration to eliminate health disparities in
Cleveland.

Note: The interview has been edited for length and clarity.

You've talked about your goal for MetroHealth to be a national model for how health systems can end disparities in
health care. What are some ways the system is doing this?

One is having the first and only high school in a hospital across the United States. This allows us an opportunity to
really be innovative in terms of addressing the workforce challenges. But also, I see this as a vessel for really being
that national model on health equity because we are able to draw from the direct community at-large and start to
plant the seeds early with our young, with our youth population, to start to translate that into 'How do we graduate
our students, a hundred percent of our students into professions that impact the lives of those that we serve?'

Several of our graduates actually graduate into disciplines where they can be community health workers or liaisons
in the community. They can start to connect those dots, connect the community with meaningful resources and
access points, address proactively and strategically as well as innovatively those social drivers of health. We're
twisting this from an innovative type of way of saying, 'Let's take the high school population and help to tool them
up.' By the time they graduate, they're already graduating into professions that make a meaningful difference in the
lives of those that we serve.

We recently announced, announced a very creative and innovative partnership with Cuyahoga County Community
College. We launched our Health Equity Centers of Excellence that is embedded into every single clinical
department and every single service within our organization. We're partnering hand in glove with Tri-C to be able to
educate our providers and educate our frontline caregivers on what it means to be community-centered.

Within MetroHealth, we have this institute called Institute for H.O.P.E., which stands for Health Opportunities
Partnership, Empowerment and Equity. This is a multifaceted approach to how we're being proactive and taking
data and an analytical-driven approach. It also takes a very strategic approach to evaluate all of those social
barriers and social drivers to good health, whether it be housing insecurity, food insecurity, transportation barriers,
economic barriers, having to make a choice between paying your utility bill and actually attaining great medical
care.

We're actually combating directly all of those social barriers and eliminating those barriers by screening our
community. Taking a blanket type of approach and casting that wide net into the community to really identify what
those pitfalls and barriers are. And then through technology and through innovation, we're making an immediate
connection to resources in our community or through programs that we've built up in internally within MetroHealth or
in partnership with our various community partners.

Workforce is a huge challenge right now in health care. How has MetroHealth been faring?

We're not immune by any stretch of the imagination to the workforce challenges. I'm a fourth-generation nurse,
who's been trained in bedside delivery of care. In all of my years of practicing nursing, I've never seen a workforce
shortage as significant as what we had to endure. Quite honestly, there has been a rapid and mass exodus of
individuals leaving our profession at leaps and bounds.

How we've taken a couple steps back to address this is in many ways. We strongly are confident in our model,
which is very innovative, with Lincoln West High School, where we can train up the next generation and serve as
that gateway, being able to upskill and being able to attain that next level of education so they can start to plug

                                                                                                        Page 3 of 5
                             MetroHealth CEO on rebuilding trust, workforce challenges

holes quicker. Then by offering internships, by offering scholarships. (Students) are always going to be loyal and
always going to have a connection point back to MetroHealth. We have a high proportion of our graduates that
graduate as CNAs, so they can actually work on our floors and graduate into careers where they're community
liaisons and community health workers.

We are casting a wide net with the colleges. We're incentivizing our preceptors, our clinical educators, so we can
take on more learners, so we can actually increase the capacity of those that are graduating in, so we can be able
to set the stage to address that sooner and much more strategically.

There's also technology. We pride ourselves on really coming up with very innovative care delivery models that
otherwise would not have been in existence. We're adopting this in a variety of settings and atmospheres, including
a virtual nurse platform. We're leveraging virtual nursing to be able to mitigate and reduce the workload of our in-
person, frontline nurses, which is absolutely helping us to resolve for that challenge in a much more prudent but
much more innovative way.

Our partners on the hill and our partners at the state and overall advocacy level have been plentiful. There certainly
has been an undivided attention amongst policymakers and the various advocates out there to really roll their
sleeves up right along with us because we know we're not alone in really addressing this issue. There are so many
clinical opportunities, especially with the policy advocates out there and legislators, around being able to open up
and widen the front doors of possibilities on working with international recruitment in a much more expedited way.
That is another opportunity we're certainly putting on our forefront.

You joined MetroHealth during a challenging time. What kinds of changes have the system implemented over the
last year to rebuild trust within the system and the community?

Obviously, I came in during a very, very difficult time. I think even using the label "difficult," I think that's an
understatement. But with the level of difficulty also came so much reward. We've been able to navigate through a
tremendous storm and come out the other side extremely resilient as an organization.

I can honestly say our performance has never been so significant to a level where we've showed up as an
organization. We've been able to really build up the fractured trust both internally to the organization as well as
externally. I think we came on the other side of it a much stronger.

I would also say from a process (standpoint) and just the way we were designed as an organization, I made many,
many changes there that actually helped to establish much better and tighter controls across the organization. One
very clear role that sprouted out of my first year was a newly appointed chief people and administrative officer,
otherwise known as a chief human resources officer role. I would say this role was rather critical and, in its
absence, resulted in a lot of fall downs, that otherwise other organizations would've have been on top of, and a lot
of organizational controls and practices we should have had in place.

Everything is pretty much in the black and white. You see what you see, and nothing is hidden, so we're not leaving
anything to chance from that point of view. With any new chief executive officer comes change, and I can honestly
say over the last year, I've completely made a lot of necessary adjustments with my leadership team. It wasn't a
matter of throwing the baby out with the bath water. (It) was more so new future, new leader, new direction.

The new leaders that came on board are walking into the history that once was before us. To me, that's just a
refreshing, long overdue change. But with that being said, I can really highlight that the level of confidence and the
vote of confidence in the community, and, in particular, our county supports have had a historical increase from
2016 to 2017, where we had the last increase. The county really wrapped its arms around us, given the fact that we
proved ourselves as really building up and picking up the bad reputation that we had with that cloud that was before
us. They gave us a strong vote of confidence that what we're doing is serving the needs of the people of Cuyahoga
County and beyond.

There's a lot of buzz around artificial intelligence. What role do you see AI having in health care?

                                                                                                            Page 4 of 5
                              MetroHealth CEO on rebuilding trust, workforce challenges

I love the fact that AI is the new buzz. It used to be telemedicine. Now, it's AI. I'm a bit of a traditionalist, being a
nurse by training. I think there is no replacement for the human connection, but I certainly believe there is a place
for AI in our future that is going to make health care delivery much more efficient.

If you really think about the frame of a day, and then if you can evaluate all of the value-added tasks that you're
doing on a day-in, day-out basis, and then compare to all of the non-value added, that really doesn't make your
make your day much more productive, but you have to do it. I think that AI has a place in taking off those non-value
added activities and being able to really amplify your ability to make those human connections a lot more efficient
and smarter.

At the same time, I think there's going to be tremendous financial value in AI, support and resources. I'm one of
those that I'm going to jump on the bandwagon of being an early adopter. I'm going to be a change innovator. and
I'll be the Guinea pig for really testing out what the technology is going to help us do in a safe and very smart way.

In December, MetroHealth, Cleveland Clinic and University Hospitals came together to announce plans for
addressing food insecurity in Greater Cleveland. How important is collaboration to addressing health disparities in
the community?

It is not just important-it's essential. We are not going to be able to address health disparities without collaboration
and partnership. Less than 20% of what we do around health equity occurs within the four walls of any one
particular hospital organization. Greater than 80% of our impact of what we're doing and what we need to do occurs
outside in the communities at large. With that being said, this is no longer a hospital problem. This is no longer a
hospital opportunity. This is truly a collaboration opportunity, and this is a community health opportunity.

I'm so proud of the partnerships forged, and I'm very proud to work shoulder-to-shoulder, arm-in-arm with University
Hospitals, with the Cleveland Clinic and everyone in between on really going after this. I can honestly say I have not
heard anyone contest or resist health equity.

When you put the person in the center, which is why I'm pushing for a person-centered culture, no one can contest
that. And if we step outside of ourselves and truly treat the entire community as a collective patient, we all serve
that collective patient. If we go in with that mindset, and I know in just talking with my peers we do, this is a first for
this community, seeing this united front among the three organizations that are in the community. We truly have
committed ourselves to collaboration.

Looking back on your first year as president and CEO, what are you most proud of?

Our performance is strong in every single metric, from financial to clinical, to quality, to experience of care, to
growth. We've moved from being a $1.6 billion net revenue organization to a $2 billion, which means in my first
year, through all of the headwinds that I'm talking about, and through the storm of, of really coming on the heels of a
scandal, we've been able to elevate and raise our organization up $400 million in just one year's time.

I'm also proud of the engagement and the commitment and just the trust that we've been able to reforge in the
community. We truly are the community's organization. We truly are the people's organization. I'm so proud of that
accomplishment. It's a big deal when you come in and trust is fractured, and that's what it felt like. And that's what it
was. In December of 2022, there was a heightened level of distrust. There was a heightened level of the people
being let down. And I can honestly tell you fast forward to present, they are fully engaged, they're fully on board,
they're fully rolling their sleeves up right along with us. In just a year's time, we've been able to completely rebound
and demonstrate a heightened level of resilience through it all.

We had a lot of historical firsts that have never occurred in this community whatsoever in 2023. We welcomed over
5,000 men, women (and) children for our historic health expos. Nothing of this magnitude has ever been done in
the Northeast Ohio, Cleveland and Greater Cleveland communities. Through the launch of our men, women and
children's health expos and empowerment fairs, we brought everyone out and offered free screenings, free
education, free access to treatment. I can tell you we saved lives through the combination of all of the efforts we
delivered on. We are truly making our mark on eradicating health care disparities and zeroing out the death gap.

                                                                                                          Page 5 of 5
                             MetroHealth CEO on rebuilding trust, workforce challenges

I stand very proud of on being the first of many, being the first female (CEO of MetroHealth). That was a historic
moment and accomplishment, being the first woman of color or first person of color, female or not. And then being
the first nurse to lead this very esteemed, formidable organization in almost 200 years.

Looking ahead, what are you most excited about as it relates to the health system?

A continuation of the momentum that we've been able to deliver this year. We're very growth-focused by expanding
access across our communities and beyond, by embracing innovation and new forms of business, and certainly
being on the forefront, the cutting edge of technology and artificial intelligence. I don't want us to be on the back end
of that. I want us to be on the forefront of that and being a national model for that.

Most certainly, I want to continue our momentum. We have a lot of momentum, and we're going strong on our level
of how we're impacting and engaging the community. Lifting up the historically disinvested communities and lift both
the health and the wealth of those communities. Having a collaborative and partnership-based mindset in mind.

Not only are we looking to continue to expand our footprint on our main campus through that $1 billion investment,
but we're looking across all of our various communities at large and starting to do some mixed-use development.
Not only having a healthcare lens and focus, but how do we invest in housing? How do we invest in food
distribution? How do we invest in having satellites for educational access and digital access? Mixed-use
development investment in various underinvested communities is certainly top of mind. And then continuing to
advance our groundbreaking academic and research advancement.


Load-Date: April 11, 2024


  End of Document

                                                                                                          Page 1 of 3
                                               Artificial intelligence and data misuse




                                    Artificial intelligence and data misuse
                                                              The Sentinel
                                                          July 5, 2024 Friday



Copyright 2024 Omega Printers & Publishers Pvt Ltd, distributed by Contify.com All Rights Reserved




Length: 1748 words
Byline: Sentinel Digital Desk

Body


Imagine after a long, hectic day you are taking a rest in your bed room with a cup of tea and switching your ALEXA
for your old favourite music, and you are in the sea of thoughts of old pleasant days and feel asleep.

Prof. (Dr.) Karuna Hazarika

(Principal-cum-Chief Superintendent, Tezpur Medical College.

He can be reached at drkaruna97@gmail.com)

I magine after a long, hectic day you are taking a rest in your bed room with a cup of tea and switching your ALEXA
for your old favourite music, and you are in the sea of thoughts of old pleasant days and feel asleep. You have
forgotten to switch off your most-sought-after new gadget, which can give you all the amusements and information
you look for. In another situation, you are driving your newly purchased car that follows your command, going for a
long drive with your loved one, having fun, and discussing sensitive issues all the way. Even your smart phones,
etc., are also run or controlled by the new technology of artificial intelligence (AI). A common occurrence is that
while we browse a website for an item, suddenly you will see all the sites you browsed show ads for the same item.
Yours is everything that is recorded, observed, or listened to by somebody, as all these new electronic gadgets
connected to the internet are controlled by the AI and have access to a third party all the time. This is interesting. Is
it not? Surprisingly, we are not aware of it. There may be something without our knowledge or due to our ignorance.
Artificial intelligence is being used in many aspects of our lives at an unprecedented rate as technology continues to
improve at an unparalleled rate. AI has the power to completely change how we engage with technology, from
generative AI that can produce any kind of content with only a single command to smart home appliances that
understand our preferences and practices as well.

Personal information has become a very valuable and sought-after commodity in the digital age. Every day,
enormous volumes of data are created and shared online, which helps organisations, governments, institutes, and
enterprises get fresh insights and make better decisions. Sensitive information in this data, though, may be
something people are reluctant to disclose or that businesses have utilised without permission. Privacy enters the
picture here. Artificial intelligence (AI) models that rely on consumer data are frequently associated with data

                                                                                                         Page 2 of 3
                                        Artificial intelligence and data misuse

privacy. Users are understandably leery of automated technologies that collect and utilise their data, which may
even contain sensitive data. The survival of AI models depends on privacy protection being a fundamental
component of their design, since these models rely on high-quality data to produce meaningful findings.

To train and enhance their AI algorithms, a lot of well-known online services and businesses rely on big datasets.
Even the most indifferent consumers may see some of the information in those datasets as private. Numerous
sources, including social media posts, public documents, internet activity, employee's data, and mostly AI in the
health sector, may provide this information too. Although this information might initially appear innocent, it can
reveal a great deal about an individual's background, including their gender, colour, political views, religion, etc.
Therefore, in the event that an AI system exhibits bias or discrimination, it may utilise this data to reinforce its
biases, resulting in unjust or potentially harmful consequences for certain individuals. The misuse of personal data
by some businesses and their excessive use have made privacy protection a global public policy concern now.

"That the same rights that people have offline also must be protected online, in particular freedom of expression,"
the Human Rights Council declared in July 2012 in its resolution on the promotion and protection of human rights
on the internet. Proclaimed as a historic UN resolution, it affirmed that human rights in the digital sphere must be
preserved and advanced with the same fervour and devotion as those in the actual world. Governments all around
the world are creating rules that businesses have to abide by regarding the handling of personal data. The General
Data Protection Regulation (GDPR) was introduced by the European Union in 2016. The Indian President officially
signed the "Digital Personal Data Protection Bill" into law on August 11, 2023, after it was approved by both houses
of the Indian Parliament. As India's first-ever privacy act designed to protect residents' personal data, this
enactment marks a significant milestone by establishing a dedicated legal framework in the country. It highlights the
duties and rights of individuals and organisations, as well as the significance of the Data Protection Board of India
and its main rules.

In terms of privacy, businesses using artificial intelligence are already perceived negatively by the public. A survey
conducted in 2020 by the European Consumer Organisation revealed that 45-60% of Europeans agreed that AI will
increase the misuse of personal data. The right to privacy is the ability to prevent illicit access to and protection of
personal information. Ensuring that people have control over their personal data and how it is used is a fundamental
human right. Given the increasing volume of personal data being gathered and reviewed, privacy is more crucial
than ever.

A multitude of factors make privacy essential. One benefit is that it shields people from dangers like fraud and
identity theft. It also contributes to preserving personal autonomy and control over private information, both of which
are necessary for respect and dignity for each individual. In addition, privacy enables people to continue their social
and professional connections without worrying about being watched or obstructed. It safeguards our free will.One
can't emphasise how crucial privacy is in the digital age. It is an essential human right that is required for justice,
safety, and individual liberty. AI is becoming more and more integrated into our daily lives; thus, we need to be
careful about safeguarding our privacy to make sure that technology is used sensibly and morally.

The possibility of AI technology being abused by dishonest people is yet another important concern. As we
experienced, AI can be used to produce convincingly phoney photos and videos that can be used to influence
public opinion, propagate false information, etc. AI can also be used to develop extremely complex phishing
assaults, which deceive people into disclosing personal information or clicking on harmful links. Such incidences
are gradually increasing day by day in every aspect of life. A phoney image or video's development and distribution
could seriously compromise someone's privacy. This is due to the fact that these made-up media frequently include
actual people whose authorization may not have been obtained for the use of their image. This may result in
circumstances where people are hurt and face difficult situations because of the propagation of fake media, either
because it is employed to disseminate inaccurate or harmful information.

Large tech corporations like Google, Amazon, and Meta now have unparalleled access to data, which allows them
to affect consumer behaviour and the direction of the world economy. Due to their power to sway public opinion and
direct governmental policy, they appear to be becoming more and more active in politics. Such big tech businesses
are expected to grow even more significant as we approach the meta universe, a virtual world where people live,

                                                                                                          Page 3 of 3
                                         Artificial intelligence and data misuse

work, and communicate. Such corporations will have even more opportunity to use their data and influence since
the virtual world will generate more data usage than the internet does now.

AI technology's data collection and utilisation practices are among its most important effects. AI systems are made
to analyse enormous volumes of data in order to learn and get better. Because of this, concerns regarding data
protection and privacy are raised by the fact that AI systems are collecting an increasing amount of personal data.
All it takes to see how our documented data, like articles, photos, videos, paintings, and so on, is being utilised in
different media, frequently without our permission, sometimes even without our knowledge, is to look at the different
generative AI tools, like ChatGPT, Google Bird, Chatsonic, Midjourney, Synthesia, SecondBrain, or any of the other
tools that are being developed. Interestingly, and more significantly, AI systems' usage of personal data isn't always
visible. Because AI systems' algorithms can be very complicated, it can be challenging for people to comprehend
how their data is being utilised to make decisions that have an impact on them. So, unease and mistrust in AI
systems can result from a lack of openness.

In an effort to safeguard personal privacy in the era of artificial intelligence, the European Union (EU) Parliament
has made a major advancement. A proposal to outlaw the use of AI surveillance in public areas has gained support
from the majority of the EU Parliament. This plan will outlaw the use of AI surveillance technologies, such as facial
recognition, in public spaces unless there is a clear threat to public safety. This choice is a reflection of the growing
concern over the possibility that AI technology will be applied in a way that violates people's privacy and other
fundamental rights.

Artificial intelligence is clearly predicted to play a key role in all important advancements in the years to come and to
fundamentally alter the way things are done in the world today. It probably plays a vital supporting role in every
major industry and organization. These tools are helpful since humans are still in charge of making decisions; they
can handle predetermined jobs. These tools not only assist us in developing processes, but they also significantly
improve networks and workflows. Large volumes of data are required for AI systems, and several highly regarded
online services and goods would not function without the personal information needed to train their AI algorithms.
However, there are numerous approaches to enhance data collection, utilisation, and management, including
improving algorithms and data management in general. Businesses that value privacy must implement AI that
respects the privacy of every individual with strict monitoring and without compromise.


Load-Date: July 5, 2024


  End of Document

                                                                                                        Page 1 of 5
                                                AI and the Academic Landscape




                                      AI and the Academic Landscape
                                             The Dickinsonian: Dickinson College
                                                      June 6, 2024 Thursday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 3158 words
Byline: Tony Moore

Body


"Revolutions Can Be Fun"

by Tony Moore

In the realm of technology, artificial intelligence has emerged as a transformative force, revolutionizing industries
and reshaping societal norms. From self-driving cars to personalized health care, AI's impact is pervasive and
undeniable. But what does this hold for the world of academia, where tradition and rigorous inquiry have long held
sway?

Here we delve into the fascinating intersection of AI and various academic disciplines, exploring how this powerful
technology is poised to reshape the way we teach, learn and conduct research. Through the perspectives of
Dickinson professors, we'll gain insights into the anticipated transformations in fields such as biology, psychology,
literature and physics.

As we embark on this journey to understand the impact of AI on academia-through a single question-it's important
to approach the topic with an open mind. AI is not a replacement for human intelligence; rather, it is a powerful tool
that can be used to augment human capabilities. By understanding the potential of AI, we can harness its power to
improve the way we learn and create new knowledge.

Note: Yes, this intro was written by Bard (now known as Gemini), the large language model from Google AI. Prompt
grunt work and editing by Tony Moore

How do you foresee AI reshaping the future of your department and discipline-both for better and worse?

John MacCormick, Professor of Computer Science

I'm a computer scientist who has worked in AI, and I happen to be writing a book about AI right now. But I still feel
hopelessly unqualified to speculate on AI in the future. To see why, let's rewind 50 years.

                                                                                                          Page 2 of 5
                                           AI and the Academic Landscape

Suppose that in 1973 I was asked, "How will electronic calculators reshape your discipline?" Handheld electronic
calculators were starting to become widely available in the 1970s, and an insightful person may have successfully
predicted some of their effects: Will we still need to teach arithmetic in grade school? (Correct prediction: yes.)
Should we continue teaching how to use a slide rule? (Correct prediction: no.) But correct predictions of that kind
completely miss the larger point. Calculators were merely an incipient glimmer of the true revolution that arrived
over the following decades: the widespread use of general-purpose computers. Any correct prediction about the
effect of calculators is irrelevant, compared to the effect of modern computers.

Which leads me to wonder: What if our present capabilities in AI are as feeble as a 1970s calculator, compared to a
possible technological revolution that may sweep through our society over the next few decades? Personally, I'm
optimistic. I already love computer science, and I think it's only going to get better. Despite the challenges that exist
on our planet, we are lucky enough to live at a time of immense promise and excitement. Revolutions can be fun.
Let's see where this one will take us.

Todd Arsenault '99, Associate Professor of Art

Artists are constantly responding to the world around them through their work. Engagement with emerging
technologies has long been a source of interest for many artists, whether toward challenging conventional modes of
making with new tools or broader commentary on our relationship to technology. Since the advent of AI image
generators, the technology has become both a source of curiosity and contention in the artistic community. As in
other areas, there are worries that AI will threaten the livelihoods of creatives.

The onset of the digital age initially brought the misnomer that meaningful artmaking would become largely digital,
supplanting the use of physical materials. It was quickly found that while the computer was a useful tool and
appropriate for certain types of making, it was not a replacement for the kind of discovery that takes place with
physical materials such as paint, wood and clay. In many ways the digital revolution reinforced the magic of working
with physical mediums and working with your hands.

While AI will likely have an impact on the future of our department, it is difficult to know what that might look like at
this early juncture. AI offers interesting possibilities for pushing the creative process when used in a critical manner,
while a less informed approach could lead to derivative works devoid of personal voice. A primary goal in our
department is for students to develop a critical eye toward making that considers technical, historical and
conceptual elements. Curiosity is an important part of this approach, and AI will likely become part of this larger
conversation.

Lars English and David Jackson, Professors of Physics

AI can be used to explore predictions of existing theories that are mathematically intractable by traditional means.
For example, systems with a very large numbers of particles often give rise to emergent behavior that may be
impossible to predict or simulate, and AI might help uncover such behavior. Similarly, many areas of physics
require massive quantities of data to be analyzed, and AI should ease the burden of finding patterns in such large
data sets. There is skepticism as to whether AI will be able to operate on a higher level and discover new
theoretical paradigms, on par with Einstein's theory of relativity. While it cannot be categorically ruled out, the
consensus is that such a level of creativity is not imminent. Meanwhile, ideas from physics are already aiding AI
development.

It is more challenging to predict how AI will reshape our department. Currently, AI is not terribly good at solving
physics problems, but it is only a matter of time before students will be able to use AI to do their homework. When
this happens, our curriculum will need to change, and this might allow us to focus on teaching students higher-level
thinking skills, leaving the more mundane tasks to AI programs. While such a change will have benefits, there are
also potential drawbacks. As AI becomes more entrenched in the physics curriculum there will undoubtedly be
some skills that get lost along the way. The challenge will be to figure out which skills should be retained while
making room for the new skills and techniques that will arise.

Ben Basile, Assistant Professor of Psychology

                                                                                                             Page 3 of 5
                                            AI and the Academic Landscape

AI will surely change the way we teach and research psychology. But so did word processors and statistical
analysis computer programs. Those didn't kill the field. They only made tedious jobs easier so researchers and
students could turn their efforts to loftier efforts. In my research, I use AI for the little things that computers do well,
like brainstorming counterarguments to anticipate in my papers or writing computer code to generate testing stimuli.
(The code crashed, but my code always crashes the first time, too!) Five years ago, generating those stimuli would
have taken a couple hours. Twenty years ago, it would have taken a couple undergraduates toiling for a week.
That's time we can use for tackling the meatier parts of science. Also, I felt a little like Geordi La Forge talking to the
Enterprise's computer. That's pretty neat.

But what about the impending apocalypse of AI cheats? Students can already pay strangers on the internet to do
their assignments (yes, I've caught one). Professors know this. A novel cheating option doesn't change our best
practices for encouraging honest, engaged work. For my assignments, ChatGPT produces a mix of passable
writing, vacuous nonsense and fabricated citations. Someday, AI will write primo papers, but it's not today.

Overall, psychology needn't fear AI. Psychology didn't end because students could analyze their statistics using
computer programs. It just meant our stats classes shifted to teaching students how to use those programs as a
tool to support their science education. The future of AI in psychology is likely similar. Professors will incorporate it
into their labs and classrooms as yet another way to help students reach the field's final frontiers.

Dick Forrester, Professor of Mathematics and Data Analytics

Artificial intelligence is rapidly transforming the field of data analytics and will undoubtedly have impacts on how we
do things in the Department of Data Analytics. AI will continue to provide more sophisticated tools for such things as
pattern recognition and predictive modeling and will automate many of the time-consuming and repetitive tasks that
are currently performed by data scientists. To ensure our graduates are prepared for this evolving landscape, we
will continue to adapt our curriculum to incorporate the latest AI technologies while staying true to the core tenets of
a liberal arts education.

In the era of AI, data scientists with a liberal arts background will be absolutely essential. Their unique combination
of technical skills, critical thinking, communication prowess, ethical awareness, creativity and broad-based
knowledge ensures they will be able to adapt to new technologies as they emerge. These qualities not only
empower them to ask insightful questions and derive meaningful insights from data but also enable them to
comprehend the power and limitations of AI. This understanding positions liberal arts-trained individuals to better
collaborate with AI and thus maintain relevance in a future shaped by it.

Ed Webb, Associate Professor of Political Science and International Studies

I work in two departments and many programs but will focus here on political science. Departments change slowly,
and disciplines more slowly still-I don't think it makes sense to predict that large language models and other forms
of generative AI will "reshape" what we do in the short to medium term. Some kinds of AI show up in how we do our
work already without us choosing it, built into software we use every day. Some of us might more actively choose to
use emerging tools to speed up how we construct spreadsheet formulas or to generate elements for a classroom
policy simulation, among other examples. For some there will be new research questions we could pursue,
depending on our specialization.

But it's important not to get caught up in the hype. Increased use of AI in war or disinformation may pose ethical as
well as empirical puzzles, but these are generally not fundamentally new kinds of questions: technological
advances typically generate new investigations and theories based on enduring concerns of who wins, who loses
and how. Algorithmic tools and machine learning may be used to evade regulations, disguise new forms of labor
exploitation and facilitate further concentration of wealth, along with doing more productive things in medicine and
other fields. I hope political scientists and neighboring disciplines will be alert to those phenomena and provide the
public and policymakers with sound analysis and the necessary critical tools.

Shamma A. Alam, Associate Professor of Economics

                                                                                                        Page 4 of 5
                                          AI and the Academic Landscape

Predicting the long-term impact of various technological innovations is a challenging task. However, insights into
short-term effects can be gleaned from historical trends. For instance, when the internet gained widespread
popularity in the US, initially, there was speculation that it might reduce the demand for education. Contrary to this
expectation, the integration of the internet empowered professors to enhance their courses by leveraging easy
access to information. Similarly, during the proliferation of social media in the 2000s, we thought it may have a
transformative effect. Instead, those anticipations were met with a surge in disinformation, underscoring the
continued significance of higher education.

In the realm of Economics, I cannot think of a notable instance of a major technological innovation having a
significant detrimental impact on the field. Drawing parallels with the internet, my perspective is that AI will likely
enhance faculty productivity in the short term. Nationwide, faculty members are already incorporating AI tools to
improve various aspects of their courses, including syllabus development, grading rubrics, and assistance with
research writing. Nevertheless, due to the rapid evolution of AI compared to past technological breakthroughs,
accurately predicting its long-term effects on my discipline remains a challenging endeavor.

Chelsea Skalak, Assistant Professor of English

When ChatGPT was first introduced, there was an immediate panic among some English professors that the major
faced an existential crisis that could eliminate its study altogether. This shouldn't be a surprise: new technologies
inspire new fears just as easily as new hopes. When the printing press was introduced, people wrote dire warnings
about how the disappearance of the handwritten manuscript would mean the end of literature. Instead, literacy
flourished, and so did English studies. I have no reason to believe that the introduction of AI will have a different
result.

The immediate fears surrounding AI have been that it will make it impossible for professors to know if a student is
turning in their own work, leading to a sharp drop in critical thinking and learning. Many professors have attempted
to "AI-proof" their assignments, focusing on skills that AI currently performs poorly with, or even returning to
handwritten assignments. I think this approach is a mistake, and ultimately a losing game with a constantly moving
target. Instead, I'm encouraged by the new questions that AI has inspired us to ask of English studies: namely,
what are the true goals of the study of English literature, and how are we achieving them? Why is it important that
students possess these skills? What is the true value of the human in the humanities? We are involving our
students in these discussions, making it clear where the goals of education are incompatible with AI and where they
are not. The study of English literature requires us to read and think critically about texts across the spectrum of
space and time, deeply engaging with each other's humanity. As we continue to adapt to the existence of AI, I
believe we will drop some modes of assessment, but more importantly, we will truly understand the value and
centrality of human connection to English studies.

Xiaolu Wang, Assistant Professor of International Business & Management

[Disclosure: written by human, checked by AI.] The obvious impact of AI on businesses is that tasks across all skill
levels-whether routine or contingent, mechanical or creative, physical or intellectual-are increasingly automated,
and the human-AI interaction has become significantly easier and cheaper with the advent of large language
models. The implication is twofold: While businesses need fewer workers for shorter times, the barrier for the
average person to start their own business is becoming significantly lower. With affordable AI assistance throughout
all stages of business development-idea generation, product/service design, accounting and financial management,
marketing and sales-almost anyone can become an entrepreneur/micropreneur of some capital-light business.
Considering that many of Gen Z are already doing multiple part-time jobs, it is conceivable that in the foreseeable
future even those in full-time employment are likely to run a side business of their own.

Therefore, a major challenge/opportunity for business education is to pivot toward cultivating general
entrepreneurship with a moral compass in a world with AI. Looking at the big picture, driven by AI, the business
world is becoming a silicon-, data- and algorithm-based, self-directing, closed system, with humans being just one
component. Without heightened entrepreneurship, the agency of businesspeople is to be reduced to doing multiple-
choice tasks, with all the options provided by AI (who might even make the choice themselves). This will limit the

                                                                                                           Page 5 of 5
                                           AI and the Academic Landscape

space of possibilities in the long run, and only the entrepreneurial spirit can promise the future business world to
remain the land of the brave and the free.

Holley Friedlander, Assistant Professor of Mathematics

Mathematicians are friends of technology. From the abacus to modern calculators, we have adapted to new
technologies again and again. Mathematicians routinely use computational tools to experiment with objects, to look
for patterns, and to formulate conjectures. In mathematics courses at Dickinson, these tools also enhance student
learning. Students use animated, interactive applets to visualize abstract concepts and computer algebra software
and graphing calculators to investigate real-world applications of course content.

Artificial Intelligence promises advances that will allow mathematicians to push the frontiers of research further than
previously thought possible. And like other technological tools, AI will help mathematics learners better understand
applications and limitations of current theory and conceptualize abstract ideas. AI will change how we do and how
we learn mathematics.

Despite AI's awesome potential, current large language models like ChatGPT have a major flaw: they often
formulate mathematical prose that sounds correct but in fact contains logical errors. Even in the future when we can
"trust" AI, students will still need to gain competency in mathematical concepts to use it effectively. A calculator is of
no use to a person that does not understand what it means to add or multiply - what good is an AI-generated
solution that is incomprehensible to a user?

Just as calculators allow us to perform computations in seconds that would be impossible by hand, AI will grant
efficiencies that will allow mathematicians to synthesize ideas at an unprecedented level. Change is coming, and
mathematics is poised to adapt.

Heather Bedi, Associate Professor of Environmental Studies

Recent research highlights how artificial intelligence servers require large amounts of electricity. ChatGPT alone
boasts 100 million users, putting electricity strain on the associated servers. Depending on the type of electricity
used to power the data centers, this could include high greenhouse gas emissions from fossil fuel energy sources
(including coal and oil). Data scientists calculated that AI data center energy consumption by 2027 will be
equivalent to the electricity used by Sweden annually. Despite this growing demand, models do not factor the new
AI electricity demand into projected national greenhouse gas emissions. This is problematic as a 2023 United
Nations analysis projects that the globe will warm by at least 2.5 degrees Celsius by the end of this century due to
rising greenhouse gas emissions, including carbon dioxide. Global energy-related carbon dioxide emissions rose in
2022 following pandemic-related declines in previous years. This increase includes a rise in oil and coal-related
emissions. The largest sectoral increase in 2022 came from increased global electricity demand. This is likely to
increase, in part driven by growing AI server demand.

Read more from the spring 2024 issue of Dickinson Magazine.

TAKE THE NEXT STEPS?


Load-Date: June 9, 2024


  End of Document

                                                                                                            Page 1 of 3
                                        NMMC implements cutting-edge heart procedures




                         NMMC implements cutting-edge heart procedures
                                            Northeast Mississippi Daily Journal (Tupelo)
                                                          June 2, 2024 Sunday



Copyright 2024 The Northeast Mississippi Daily Journal (Tupelo, Miss.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 1002 words
Byline: BLAKE ALSUP, Northeast Mississippi Daily Journal, Tupelo

Body


TUPELO — During his 26 years as an interventional cardiologist at North Mississippi Medical Center, Dr. Barry
Bertolet has been on the leading edge of innovation.

He initially thought he’d like to be a surgeon because of the ability to perform a procedure that could help someone
almost immediately. So, when he learned about balloon angioplasties and their use in unblocking people’s heart
arteries, providing immediate relief for chest pain symptoms, he was intrigued.

Witnessing the implementation of new technology during cardiology training at the University of Florida furthered his
desire to take part in cardiac research. Innovation doesn’t just make things more efficient for physicians — it also
benefits patients.

In an underserved population like Mississippi, making cutting-edge technology available to needy patients is
absolutely amazing, Bertolet said.

NMMC recently implemented a handful of new heart health procedures to simplify the diagnosis and treatment of
patients in Northeast Mississippi.

An AI-powered stabilizer

A beating heart is a moving heart, Bertolet said, which can complicate certain procedures.

NMMC is the first hospital in the United States to use an artificial intelligence-powered Dynamic Device Stabilizer
technology produced by Canon. It can stabilize an image on-screen in the cardiac catheterization lab even as it
moves. The only other place it’s currently being used is Tokyo, Japan, according to Bertolet.

“So if we’re trying to precisely place another stent, or a balloon within a stent, it’s held completely still on the screen
so that we can place whatever device we need to exactly where we need to place it and then deploy it with
confidence,” he said.

Greater precision leads to better outcomes for patients.

                                                                                                                Page 2 of 3
                                   NMMC implements cutting-edge heart procedures

“It is designed to enhance the ability of the doctor to deliver the exact, necessary care and to lessen the
complications that may occur,” Bertolet said.

For patients who may worry about the use of AI in health care, Bertolet said it is simply used to facilitate a doctor’s
knowledge.

“The AI is not making a final decision,” Bertolet said. “They don’t make a final diagnosis; they don’t do the
procedure at all. But what we’re using it for is to enhance the delivery of information to the doctor so the doctor then
can perform a procedure better or to make a diagnosis with more certainty, and then that way the patient gets
exactly what they need.”

True high-definition imaging

NMMC is one of the first hospitals to use true high-definition imaging to diagnose and treat cardiovascular patients.

“When we’re talking about stents that we put in, their (thickness is) measured in microns,” Bertolet said. “So, how
do you see that inside somebody’s body?”

That’s where HD imaging, which has been in use for about a year-and-a-half at NMMC, comes in.

Traditionally, if an image is captured and magnified, it loses quality as the image is gets larger. But true HD imaging
allows captured images to maintain their sharpness as they’re magnified to an extent that doctors can not only see
the stent they’re placing, they can even see individual pieces of metal within the stent.

This allows physicians to see whether a stent has fractured, whether there’s an area between two stents that needs
to be connected or a range of other tiny yet important details.

HD imaging technology can literally be used from head to toe, Bertolet said.

For example, if a doctor is retrieving a clot in a person’s brain, precision is of the utmost importance. Likewise,
working in tiny blood vessels of the foot, doctors need to see clearly where they’re working.

“I think this high definition is going to allow the physician, wherever they are working, to see their tools, as well as
the anatomy, with enhanced precision,” Bertolet said.

Aquapheresis — a kind of dialysis for the heart

Congestive heart failure if a growing medical problem, one that is on the rise as people live longer because of
advances in medical care that prevent other causes of death.

There are a range of ways to treat congestive heart failure, Bertolet said, but sometimes too much fluid builds up in
a patient’s body, causing their body to swell and making it difficult to breathe.

“In essence, it’s like a freshwater drowning,” Bertolet said. “They get fluid that builds up in their lungs.”

When diuretic therapies cannot expel the fluid, aquapheresis, which functions as a sort of dialysis for the heart, is
an option.

Though the process has been around for more than a decade, advancements have made its use safer in recent
years.

During aquapheresis treatment, a catheter is placed in a person’s arm or shoulder. The machine takes around two
tablespoons of blood out of the body at once and runs it through a filter that removes excess water and returns
blood to the patient’s body, acting as an artificial kidney.

                                                                                                           Page 3 of 3
                                  NMMC implements cutting-edge heart procedures

“We can remove more fluid quickly using the aquapheresis than we could with a medical therapy in a lot of these
sicker patients,” Bertolet said. “So what that means for the patient is they feel better faster, they’re able to be
discharged from the hospital sooner and the biggest importance is they’re less likely to come back.”

Traditionally, patients with congestive heart failure have to be readmitted to the hospital within 30 days, but because
aquapheresis more effectively removes fluid, the patient stays out of the hospital for longer.

“That translates into an increased quality of life for the patient, it does translate into less cost for the health system
as a whole, but importantly, it also looks like that translates into a longer life for the patient,” Bertolet said. “Every
time a patient gets admitted into the hospital for a heart failure, their long-term risk of dying goes up. They never get
back to baseline. So, if we can prevent that admission to the hospital, we will keep them alive longer.”

___ (c)2024 the Northeast Mississippi Daily Journal (Tupelo, Miss.) Visit the Northeast Mississippi Daily Journal
(Tupelo, Miss.) at www.djournal.com Distributed by Tribune Content Agency, LLC.


Load-Date: June 3, 2024


  End of Document

                                                                                                      Page 1 of 3
         ‘Back to business as usual’: Hello Alice expands capital access programming after lawsuit dismissal




            ‘Back to business as usual’: Hello Alice expands capital access
                         programming after lawsuit dismissal
                                            The Press Democrat, Santa Rosa, Calif.
                                                     August 8, 2024 Thursday



Copyright 2024 The Press Democrat (Santa Rosa, Calif.)

Distributed by Tribune Content Agency

Section: BUSINESS AND FINANCIAL NEWS
Length: 1244 words
Byline: Sara Edwards, The Press Democrat

Body


When it comes to having an emergency plan, most business owners assume they’re preparing for a natural
disaster, a key employee leaving the company or a major client announcing their departure. Those are the kinds of
emergencies Hello Alice executives had prepared for.

But a major lawsuit involving a partnership grant with Progressive Insurance to help Black-owned businesses was
not on Hello Alice’s 2023 bingo card.

“I don’t think we ever really thought about a lawsuit of this magnitude coming our way,” co-founder Carolyn Rodz
said. “I have a new appreciation for what it means to be a financially healthy company when a crisis comes your
way but it allowed us to bring in the best resources to fight the fight as strong as we possibly could.”

Small business fintech platform Hello Alice has spent the last year fighting a lawsuit alleging that its partnership
grant program with Progressive unlawfully discriminated against business owners based on race.

The suit was officially tossed out in May and the company is ready to pick up where it left off, helping its small
business owner members access capital and partner with other major brands for mentorship, growth and grant
opportunities.

“A lot of the work we put in during that time (of the lawsuit) was advocating for small businesses and making sure
that we were working every possibility we could to continue supporting them,” co-founder Carolyn Rodz told The
Press Democrat. “It’s been great to be back to business as usual.”

Hello Alice was founded in 2017 by Houston-based Rodz and Healdsburg-based Elizabeth Gore, who is married to
Sonoma County supervisor James Gore. The women created the platform to help small business owners,
especially minority business owners, access resources to grow their companies.

Since its inception, the online platform has gained over 1.5 million small businesses members throughout the U.S.
and distributed $1.1 million in grants to small businesses in the Bay Area.

                                                                                                     Page 2 of 3
        ‘Back to business as usual’: Hello Alice expands capital access programming after lawsuit dismissal

The platform has also expanded its programming to include multiple avenues for entrepreneurs from partnering with
Mastercard to helping business owners build up credit to establishing a Business Health Score assessment tool to
creating a personalized path to success.

Data from Hello Alice shows that over 21,000 small business owners in Sonoma County use Hello Alice with 15% of
those in the consumer goods, retail and e-commerce industries. Beauty and self-care businesses fall just behind
that at 13% of businesses.

According to the data, 33% are focused on raising capital while 21% say they need support with day-to-day
operations.

“Nearly two-thirds of businesses have concerns around inflation, maybe their costs are higher or it's more difficult to
do the same business,” Rodz said. “But (these businesses are) continuing to grow in spite of that and we're seeing
more businesses launch than ever before.”

New Boost Camp programs for small businesses

Hello Alice recently announced the expansion of its small business accelerator and 2024 Boost Camp programs,
which have helped hundreds of small businesses connect with industry leaders to expand business operations.

The platform partnered with Global Entrepreneurship Network, which will consult on the program curriculum and
pair chosen participants to the right mentors among other tasks.

Programs available to business owners this year include partnerships with Antares Capital’s REACH program,
Progressive Insurance’s Driving Small Business Forward Grant & Boost Camp Program, Wells Fargo’s Boost Camp
and FedEx’s Entrepreneur Fund.

Businesses are selected via an application process and participate in a coaching and mentorship program focused
on growing business health.

The applications for Antares Capital and Progressive’s programs have since closed, but applications for the Wells
Fargo Boost Camp are being accepted through August 16.

The application period for the FedEx Entrepreneur Fund will be announced later this fall.

“By partnering with major companies, Hello Alice is ensuring that small businesses have access to the tools and
opportunities they need to thrive and create jobs in their local communities,” Rodz said. “Together, we are building a
robust support system that fosters innovation and growth for small businesses across the country."

The Boost Camp programs first debuted last year where 100 small businesses were selected to partner with
companies such as FedEx and Antares. Six of these businesses were located in the North Bay.

A news release from Hello Alice said participants saw overall improvements to their business health with 60% of
Antares’ participants seeing an increase in their business health score and 93% saying they felt better equipped to
confront challenges and better equipped to capitalize on business opportunities.

The company is also looking at programming to help businesses understand AI and how they can use it for growth,
while also looking at other tools and solutions such as new point-of-sale systems and website development
software to take businesses to the next level.

“We know over 50% of businesses are financially unhealthy and it’s a relief to get back to the core of our business,”
Rodz said. “We never stop in our fight to get as much capital as we can into the hands of businesses so we’re
continuing to also really push our grant programs.”

Recovery following lawsuit dismissal

                                                                                                     Page 3 of 3
        ‘Back to business as usual’: Hello Alice expands capital access programming after lawsuit dismissal

The legal battle against conservative law firm America First Legal and Hello Alice began last October when the
owner of an Ohio trucking dispatch company alleged a grant program in partnership with Progressive Insurance
Company, which offered $25,000 in grants to 10 Black-owned small businesses, unlawfully discriminated against
business owners based on race.

Hello Alice filed a motion to have the case dismissed on the grounds its grant program was a valid affirmative action
program under U.S. Supreme Court precedent.

Hello Alice launched its Elevate the American Dream campaign while in litigation to raise awareness about the
company’s mission to help small businesses and provide special grants through a nomination process on a
dedicated website.

As of May, the campaign has distributed $50,000 in grants to 49 grants to U.S. small businesses through this
campaign.

Although the case was dismissed, the company didn’t come out of the legal proceedings unscathed.

Hello Alice laid off 69% of the platform’s workforce, according to Rodz. The company was also working to secure a
round of Series C funding when it lost two-thirds of the round just days after notifying investors of the lawsuit,
according to reporting from Inc.

Rodz said the company is rebuildingand looking for more solutions to help small business owners find success in
growing their business.

Hello Alice also officially closed a Series C funding round in April with major investors to bring the company’s total
valuation up to $130 million.

The closure of this round of funding will continue to fuel the platform’s expansion of capital opportunities and AI-
driven financial health tools, according to a news release.

“It’s an exciting time for us as a company,” Rodz said. “We’re continuing to do business as usual but there’s still a
lot of work to be done.”

You can reach Staff Writer Sara Edwards at 707-521-5487 or sara.edwards@pressdemocrat. com. On Twitter
@sedwards380.

___ (c)2024 The Press Democrat (Santa Rosa, Calif.) Visit The Press Democrat (Santa Rosa, Calif.) at
www.pressdemocrat.com Distributed by Tribune Content Agency, LLC.


Load-Date: August 13, 2024


  End of Document

                                                                                                      Page 1 of 3
         ‘Back to business as usual’: Hello Alice expands capital access programming after lawsuit dismissal




            ‘Back to business as usual’: Hello Alice expands capital access
                         programming after lawsuit dismissal
                                            The Press Democrat, Santa Rosa, Calif.
                                                     August 8, 2024 Thursday



Copyright 2024 The Press Democrat (Santa Rosa, Calif.)

Distributed by Tribune Content Agency

Section: BUSINESS AND FINANCIAL NEWS
Length: 1246 words
Byline: Sara Edwards, The Press Democrat

Body


When it comes to having an emergency plan, most business owners assume they’re preparing for a natural
disaster, a key employee leaving the company or a major client announcing their departure. Those are the kinds of
emergencies Hello Alice executives had prepared for.

But a major lawsuit involving a partnership grant with Progressive Insurance to help Black-owned businesses was
not on Hello Alice’s 2023 bingo card.

“I don’t think we ever really thought about a lawsuit of this magnitude coming our way,” co-founder Carolyn Rodz
said. “I have a new appreciation for what it means to be a financially healthy company when a crisis comes your
way but it allowed us to bring in the best resources to fight the fight as strong as we possibly could.”

Small business fintech platform Hello Alice has spent the last year fighting a lawsuit alleging that its partnership
grant program with Progressive unlawfully discriminated against business owners based on race.

The suit was officially tossed out in May and the company is ready to pick up where it left off, helping its small
business owner members access capital and partner with other major brands for mentorship, growth and grant
opportunities.

“A lot of the work we put in during that time (of the lawsuit) was advocating for small businesses and making sure
that we were working every possibility we could to continue supporting them,” co-founder Carolyn Rodz told The
Press Democrat. “It’s been great to be back to business as usual.”

Hello Alice was founded in 2017 by Houston-based Rodz and Healdsburg-based Elizabeth Gore, who is married to
Sonoma County supervisor James Gore. The women created the platform to help small business owners,
especially minority business owners, access resources to grow their companies.

Since its inception, the online platform has gained over 1.5 million small businesses members throughout the U.S.
and distributed 1.1 million grants to small businesses in the Bay Area.

                                                                                                     Page 2 of 3
        ‘Back to business as usual’: Hello Alice expands capital access programming after lawsuit dismissal

The platform has also expanded its programming to include multiple avenues for entrepreneurs from partnering with
Mastercard to helping business owners build up credit to establishing a Business Health Score assessment tool to
creating a personalized path to success.

Data from Hello Alice shows that over 21,000 small business owners in Sonoma County use Hello Alice with 15% of
those in the consumer goods, retail and e-commerce industries. Beauty and self-care businesses fall just behind
that at 13% of businesses.

According to the data, 33% are focused on raising capital while 21% say they need support with day-to-day
operations.

“Nearly two-thirds of businesses have concerns around inflation, maybe their costs are higher or it's more difficult to
do the same business,” Rodz said. “But (these businesses are) continuing to grow in spite of that and we're seeing
more businesses launch than ever before.”

New Boost Camp programs for small businesses

Hello Alice recently announced the expansion of its small business accelerator and 2024 Boost Camp programs,
which have helped hundreds of small businesses connect with industry leaders to expand business operations.

The platform partnered with Global Entrepreneurship Network, which will consult on the program curriculum and
pair chosen participants to the right mentors among other tasks.

Programs available to business owners this year include partnerships with Antares Capital’s REACH program,
Progressive Insurance’s Driving Small Business Forward Grant & Boost Camp Program, Wells Fargo’s Boost Camp
and FedEx’s Entrepreneur Fund.

Businesses are selected via an application process and participate in a coaching and mentorship program focused
on growing business health.

The applications for Antares Capital and Progressive’s programs have since closed, but applications for the Wells
Fargo Boost Camp are being accepted through August 16.

The application period for the FedEx Entrepreneur Fund will be announced later this fall.

“By partnering with major companies, Hello Alice is ensuring that small businesses have access to the tools and
opportunities they need to thrive and create jobs in their local communities,” Rodz said. “Together, we are building a
robust support system that fosters innovation and growth for small businesses across the country."

The Boost Camp programs first debuted last year where 100 small businesses were selected to partner with
companies such as FedEx and Antares. Six of these businesses were located in the North Bay.

A news release from Hello Alice said participants saw overall improvements to their business health with 60% of
Antares’ participants seeing an increase in their business health score and 93% saying they felt better equipped to
confront challenges and better equipped to capitalize on business opportunities.

The company is also looking at programming to help businesses understand AI and how they can use it for growth,
while also looking at other tools and solutions such as new point-of-sale systems and website development
software to take businesses to the next level.

“We know over 50% of businesses are financially unhealthy and it’s a relief to get back to the core of our business,”
Rodz said. “We never stop in our fight to get as much capital as we can into the hands of businesses so we’re
continuing to also really push our grant programs.”

Recovery following lawsuit dismissal

                                                                                                     Page 3 of 3
        ‘Back to business as usual’: Hello Alice expands capital access programming after lawsuit dismissal

The legal battle against conservative law firm America First Legal and Hello Alice began last October when the
owner of an Ohio trucking dispatch company alleged a grant program in partnership with Progressive Insurance
Company, which offered $25,000 in grants to 10 Black-owned small businesses, unlawfully discriminated against
business owners based on race.

Hello Alice filed a motion to have the case dismissed on the grounds its grant program was a valid affirmative action
program under U.S. Supreme Court precedent.

Hello Alice launched its Elevate the American Dream campaign while in litigation to raise awareness about the
company’s mission to help small businesses and provide special grants through a nomination process on a
dedicated website.

As of May, the campaign has distributed $50,000 in grants to 49 grants to U.S. small businesses through this
campaign.

Although the case was dismissed, the company didn’t come out of the legal proceedings unscathed.

Hello Alice laid off 28 employees, or 69% of the platform’s workforce, according to Rodz. The company was also
working to secure a round of Series C funding when it lost two-thirds of the round just days after notifying investors
of the lawsuit, according to reporting from Inc.

Rodz said the company is rebuildingand looking for more solutions to help small business owners find success in
growing their business.

Hello Alice also officially closed a Series C funding round in April with major investors to bring the company’s total
valuation up to $130 million.

The closure of this round of funding will continue to fuel the platform’s expansion of capital opportunities and AI-
driven financial health tools, according to a news release.

“It’s an exciting time for us as a company,” Rodz said. “We’re continuing to do business as usual but there’s still a
lot of work to be done.”

You can reach Staff Writer Sara Edwards at 707-521-5487 or sara.edwards@pressdemocrat. com. On Twitter
@sedwards380.

___ (c)2024 The Press Democrat (Santa Rosa, Calif.) Visit The Press Democrat (Santa Rosa, Calif.) at
www.pressdemocrat.com Distributed by Tribune Content Agency, LLC.


Load-Date: August 9, 2024


  End of Document

                                                                                                      Page 1 of 3
         ‘Back to business as usual’: Hello Alice expands capital access programming after lawsuit dismissal




            ‘Back to business as usual’: Hello Alice expands capital access
                         programming after lawsuit dismissal
                                            The Press Democrat, Santa Rosa, Calif.
                                                     August 8, 2024 Thursday



Copyright 2024 The Press Democrat (Santa Rosa, Calif.)

Distributed by Tribune Content Agency

Section: BUSINESS AND FINANCIAL NEWS
Length: 1244 words
Byline: Sara Edwards, The Press Democrat

Body


When it comes to having an emergency plan, most business owners assume they’re preparing for a natural
disaster, a key employee leaving the company or a major client announcing their departure. Those are the kinds of
emergencies Hello Alice executives had prepared for.

But a major lawsuit involving a partnership grant with Progressive Insurance to help Black-owned businesses was
not on Hello Alice’s 2023 bingo card.

“I don’t think we ever really thought about a lawsuit of this magnitude coming our way,” co-founder Carolyn Rodz
said. “I have a new appreciation for what it means to be a financially healthy company when a crisis comes your
way but it allowed us to bring in the best resources to fight the fight as strong as we possibly could.”

Small business fintech platform Hello Alice has spent the last year fighting a lawsuit alleging that its partnership
grant program with Progressive unlawfully discriminated against business owners based on race.

The suit was officially tossed out in May and the company is ready to pick up where it left off, helping its small
business owner members access capital and partner with other major brands for mentorship, growth and grant
opportunities.

“A lot of the work we put in during that time (of the lawsuit) was advocating for small businesses and making sure
that we were working every possibility we could to continue supporting them,” co-founder Carolyn Rodz told The
Press Democrat. “It’s been great to be back to business as usual.”

Hello Alice was founded in 2017 by Houston-based Rodz and Healdsburg-based Elizabeth Gore, who is married to
Sonoma County supervisor James Gore. The women created the platform to help small business owners,
especially minority business owners, access resources to grow their companies.

Since its inception, the online platform has gained over 1.5 million small businesses members throughout the U.S.
and distributed 1.1 million grants to small businesses in the Bay Area.

                                                                                                     Page 2 of 3
        ‘Back to business as usual’: Hello Alice expands capital access programming after lawsuit dismissal

The platform has also expanded its programming to include multiple avenues for entrepreneurs from partnering with
Mastercard to helping business owners build up credit to establishing a Business Health Score assessment tool to
creating a personalized path to success.

Data from Hello Alice shows that over 21,000 small business owners in Sonoma County use Hello Alice with 15% of
those in the consumer goods, retail and e-commerce industries. Beauty and self-care businesses fall just behind
that at 13% of businesses.

According to the data, 33% are focused on raising capital while 21% say they need support with day-to-day
operations.

“Nearly two-thirds of businesses have concerns around inflation, maybe their costs are higher or it's more difficult to
do the same business,” Rodz said. “But (these businesses are) continuing to grow in spite of that and we're seeing
more businesses launch than ever before.”

New Boost Camp programs for small businesses

Hello Alice recently announced the expansion of its small business accelerator and 2024 Boost Camp programs,
which have helped hundreds of small businesses connect with industry leaders to expand business operations.

The platform partnered with Global Entrepreneurship Network, which will consult on the program curriculum and
pair chosen participants to the right mentors among other tasks.

Programs available to business owners this year include partnerships with Antares Capital’s REACH program,
Progressive Insurance’s Driving Small Business Forward Grant & Boost Camp Program, Wells Fargo’s Boost Camp
and FedEx’s Entrepreneur Fund.

Businesses are selected via an application process and participate in a coaching and mentorship program focused
on growing business health.

The applications for Antares Capital and Progressive’s programs have since closed, but applications for the Wells
Fargo Boost Camp are being accepted through August 16.

The application period for the FedEx Entrepreneur Fund will be announced later this fall.

“By partnering with major companies, Hello Alice is ensuring that small businesses have access to the tools and
opportunities they need to thrive and create jobs in their local communities,” Rodz said. “Together, we are building a
robust support system that fosters innovation and growth for small businesses across the country."

The Boost Camp programs first debuted last year where 100 small businesses were selected to partner with
companies such as FedEx and Antares. Six of these businesses were located in the North Bay.

A news release from Hello Alice said participants saw overall improvements to their business health with 60% of
Antares’ participants seeing an increase in their business health score and 93% saying they felt better equipped to
confront challenges and better equipped to capitalize on business opportunities.

The company is also looking at programming to help businesses understand AI and how they can use it for growth,
while also looking at other tools and solutions such as new point-of-sale systems and website development
software to take businesses to the next level.

“We know over 50% of businesses are financially unhealthy and it’s a relief to get back to the core of our business,”
Rodz said. “We never stop in our fight to get as much capital as we can into the hands of businesses so we’re
continuing to also really push our grant programs.”

Recovery following lawsuit dismissal

                                                                                                     Page 3 of 3
        ‘Back to business as usual’: Hello Alice expands capital access programming after lawsuit dismissal

The legal battle against conservative law firm America First Legal and Hello Alice began last October when the
owner of an Ohio trucking dispatch company alleged a grant program in partnership with Progressive Insurance
Company, which offered $25,000 in grants to 10 Black-owned small businesses, unlawfully discriminated against
business owners based on race.

Hello Alice filed a motion to have the case dismissed on the grounds its grant program was a valid affirmative action
program under U.S. Supreme Court precedent.

Hello Alice launched its Elevate the American Dream campaign while in litigation to raise awareness about the
company’s mission to help small businesses and provide special grants through a nomination process on a
dedicated website.

As of May, the campaign has distributed $50,000 in grants to 49 grants to U.S. small businesses through this
campaign.

Although the case was dismissed, the company didn’t come out of the legal proceedings unscathed.

Hello Alice laid off 69% of the platform’s workforce, according to Rodz. The company was also working to secure a
round of Series C funding when it lost two-thirds of the round just days after notifying investors of the lawsuit,
according to reporting from Inc.

Rodz said the company is rebuildingand looking for more solutions to help small business owners find success in
growing their business.

Hello Alice also officially closed a Series C funding round in April with major investors to bring the company’s total
valuation up to $130 million.

The closure of this round of funding will continue to fuel the platform’s expansion of capital opportunities and AI-
driven financial health tools, according to a news release.

“It’s an exciting time for us as a company,” Rodz said. “We’re continuing to do business as usual but there’s still a
lot of work to be done.”

You can reach Staff Writer Sara Edwards at 707-521-5487 or sara.edwards@pressdemocrat. com. On Twitter
@sedwards380.

___ (c)2024 The Press Democrat (Santa Rosa, Calif.) Visit The Press Democrat (Santa Rosa, Calif.) at
www.pressdemocrat.com Distributed by Tribune Content Agency, LLC.


Load-Date: August 10, 2024


  End of Document

                                                                                                           Page 1 of 3
                            Research reveals humans have loved carbs for over 800,000 years




         Research reveals humans have loved carbs for over 800,000 years
                                     The Griffon News: Missouri Western State College
                                                  October 17, 2024 Thursday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: LIFESTYLES; Pg. 1
Length: 942 words

Body


henry perks

By Talker

By Stephen Beech via SWNS

Our love of french fries and other carbs dates back over 800,000 years to our cavemen ancestors, suggests a new
study.

The origins predate agriculture and maybe even our split from Neanderthals, say scientists.

American researchers have found that the gene for starch-digesting saliva may have first duplicated more than
800,000 years ago, seeding the genetic variation that shapes our modern diet.

It has long been known that humans carry several copies of a gene that allows us to begin breaking down complex
carbohydrate starch in the mouth, providing the first step in metabolizing starchy foods such as bread, potatoes and
pasta.

However, it has been difficult for scientists to determine how and when the number of those genes expanded.

Now a new study, led by scientists at The University of Buffalo and The Jackson Laboratory , showcases how early
duplications of the gene set the stage for the wide genetic variation that still exists today, influencing how effectively
humans digest starchy foods.

By Talker

The findings, published online by the journal Science, reveal that the duplication of the gene - known as the salivary
amylase gene (AMY1) - may not only have helped shape human adaptation to starchy foods but may have
occurred as far back as more than 800,000 years ago, long before the advent of farming.

Study corresponding author Professor Omer Gokcumen, of The University of Buffalo, said: "The idea is that the
more amylase genes you have, the more amylase you can produce and the more starch you can digest effectively."

                                                                                                        Page 2 of 3
                         Research reveals humans have loved carbs for over 800,000 years

He explained that amylase is an enzyme that not only breaks down starch into glucose but also gives bread its
taste.

Gokcumen used optical genome mapping and long-read sequencing, a methodological breakthrough crucial to
mapping the AMY1 gene region in extraordinary detail.

He said traditional short-read sequencing methods struggle to accurately distinguish between gene copies due to
their near-identical sequence.

Krista Stucchio

By Talker

However, long-read sequencing allowed the team to overcome the challenge in present-day humans, providing a
clearer picture of how AMY1 duplications evolved.

Analyzing the genomes of 68 ancient humans, including a 45,000-year-old sample from Siberia, the researchers
found that pre-agricultural hunter-gatherers already had an average of four to eight AMY1 copies per diploid cell.

The team say that suggests humans were already walking around Eurasia with a wide variety of high AMY1 copy
numbers well before they started domesticating plants and eating excess amounts of starch.

More from this section

When Complications Strike After Heart Surgery, Women More Likely to Die Than Men

3 Years of Med School Might Be Enough to Produce Quality Doctors

Most Older Americans Don't Trust AI-Generated Health Info, Survey Finds

The study also found that AMY1 gene duplications occurred in Neanderthals and Denisovans.

Study co-lead author Dr. Kwondo Kim, of JAX, said: "This suggests that the AMY1 gene may have first duplicated
more than 800,000 years ago, well before humans split from Neanderthals and much further back than previously
thought."

Gokcumen said: "The initial duplications in our genomes laid the groundwork for significant variation in the amylase
region, allowing humans to adapt to shifting diets as starch consumption rose dramatically with the advent of new
technologies and lifestyles."

(Photo by Nadin Sh via Pexels)

The researchers say the initial duplication of AMY1 was like the first ripple in a pond, creating a genetic opportunity
that later shaped our species.

As humans spread across different environments, the flexibility in the number of AMY1 copies provided an
advantage for adapting to new diets, particularly those rich in starch.

Co-lead author Dr. Charikleia Karageorgiou, who works in Gokcumen's Buffalo lab, said: "Following the initial
duplication, leading to three AMY1 copies in a cell, the amylase locus became unstable and began creating new
variations.

"From three AMY1 copies, you can get all the way up to nine copies, or even go back to one copy per haploid cell."

The study also highlights how agriculture impacted AMY1 variation.

While early hunter-gatherers had multiple gene copies, European farmers saw a surge in the average number of
AMY1 copies over the past 4,000 years, likely due to their starch-rich diets.

                                                                                                       Page 3 of 3
                        Research reveals humans have loved carbs for over 800,000 years

(Photo by Sergey Meshkov via Pexels)

By Talker

Previous research by Gokcumen's showed that domesticated animals living alongside humans, such as dogs and
pigs, also have higher AMY1 copy numbers compared to animals not reliant on starch-heavy diets.

Gokcumen said: "Individuals with higher AMY1 copy numbers were likely digesting starch more efficiently and
having more offspring.

"Their lineages ultimately fared better over a long evolutionary timeframe than those with lower copy numbers,
propagating the number of the AMY1 copies."

The findings follow a University of California-led study published last month in the journal Nature, which found that
humans in Europe expanded their average number of AMY1 copies from four to seven over the last 12,000 years.

Study co-lead author Dr. Feyza Yilmaz, of JAX, said: "Given the key role of AMY1 copy number variation in human
evolution, this genetic variation presents an exciting opportunity to explore its impact on metabolic health and
uncover the mechanisms involved in starch digestion and glucose metabolism."

She added: "Future research could reveal its precise effects and timing selection, providing critical insights into
genetics, nutrition, and health."

Originally published on talker.news, part of the BLOX Digital Content Exchange.


Load-Date: October 17, 2024


  End of Document

                                                                                                     Page 1 of 3
                  Golden Connections takes home $30,000 in the 2024 Mayo Business Plan Competition




   Golden Connections takes home $30,000 in the 2024 Mayo Business Plan
                              Competition
                                              The Signal: College of New Jersey
                                                      April 4, 2024 Thursday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 953 words

Body


By Parisa Burton Staff Writer

The College's Mayo Business Plan Competition completed its final round on March 27, with Golden Connections
taking home the grand prize of $30,000.

The competition began with over 25 teams. Six teams were invited to advance to the semi-finals in February. From
this, three teams were selected to advance to the finals in March.

The Golden Connections team comprised Lauren Cunningham, a senior marketing major, Emma Route, a junior
chemistry major and Sangam Shivaprasad, a senior biology major.

Former business school dean William Keep and emeritus finance faculty member Herbert 'Buddy' Mayo launched
the business plan competition in 2011, funded by an endowment initiated by Dr. Mayo. With ongoing enhancements
driven by feedback from judges and alumni, the competition ensures students have the resources needed to refine
their plans each year.

"They recognized the valuable opportunity that could be afforded to students to develop their business ideas,
underscoring the need and value of entrepreneurs, and helping students develop confidence in the process," said
Tammy Dieterich, Interim Dean of the School of Business.

The ladies of Golden Connections are all College ambassadors and were inspired to participate by two previous
ambassadors and the 2023 winners of the competition, Katie Olsen and Molly O'Brien.

Golden Connections is an AI-powered health and wellness digital platform tailored to the needs of senior
caregivers to offer peace of mind through an intuitive AI concierge named Grace.

"The platform incorporates speech and language biomarkers, community and calendar functions, and AI all into one
seamless platform that is easily accessible because it is a really fragmented market," Shivaprasad said.

One of their goals is to bridge the gap in current applications that use speech and language biomarkers but are
clinically focused.

                                                                                                        Page 2 of 3
              Golden Connections takes home $30,000 in the 2024 Mayo Business Plan Competition

"Currently there are no applications or platforms in the market that have a consumer facing initiative and use the
same feature suite as Golden Connections," Route said.

Their passion extends past the competition as they are currently working with individuals in the industry on the next
steps of taking Golden Connections to market.

2nd Chance took home the second prize of $20,000, consisting of Caley Faith Cortezano, a junior public health
major, Alex Fabiano, an interdisciplinary business major, and Dylan Romanski, a senior finance major.

2nd Chance is a prospective enterprise that will give the College community a thrift store on campus. The idea
stemmed from Cortezano, who had always dreamed of opening up a thrift store, reflecting her core beliefs of
sustainability and serving her community.

"We wanted to be located in Campus Town so our thrift store would be easily accessible to students without a car,"
Cortezano said. "We also wanted to address the material waste that is produced after the academic school year by
taking these items in and keeping them out of landfills."

According to Cortezano, 2nd Chance has a competitive advantage over similar stores like Goodwill for their
organizational standards. They aim to create a welcoming environment that is aesthetically pleasing and organized.
They would also have the advantage of being located on a college campus for leveraging high foot traffic.

In third place, taking home $10,000, is Girls Got Your Back. The team featured Olivia Chiarella, a junior
communication studies major, Victoria Dasilva, a junior finance major, Tatiana Sawka, a junior marketing major, and
Madilynne Silfer, a senior marketing major.

Girls Got Your Back is a dynamic app in development that aspires to create a network of solidarity for college
women facing "mini emergencies" in their daily lives by facilitating mutual assistance during times of need and
offering immediate access to essential products and relief.

"Girls Got Your Back has a bright future and we're all subscribed to it," Chiarella said. "We know that college
students across the nation need our app and we hope to reach every single one of them."

The Mayo Business Plan competition offers students of all majors the opportunity to bring their ideas to life and
learn valuable skills in the process.

Golden Connections was able to effectively leverage each other's strengths to bolster their business plan.

"We incorporated all three of our backgrounds to create what Golden Connections is," Shivaprasad said.

Route's background in speech and language biomarkers, stemming from her internship with Johnson & Johnson,
helped to drive the business plan.

Ryan Chiu, winner of the 2018 Mayo Business Plan Competition, said he believes the key to succeeding in this
competition is starting early and leveraging the College's assets, as well as leaning on your mentors.

"Our mentor Dr. Becker has guided us through this competition," Cunningham said. "She has truly been so
dedicated to Golden Connections and seeing that solution within it."

According to Chiu, the competition helps with presentational skills, thinking on your feet and selling a project with
passion.

In 2018, Chiu and his partner built a prototype robot, dubbed MARCo, that was their "third" presenter. This initiative
wowed judges, helping them secure the victory.

While Chiu has stepped back from MARCo, he believes that this competition is helpful for developing soft skills and
has provided him with the foundation to succeed in his current role.

                                                                                                        Page 3 of 3
              Golden Connections takes home $30,000 in the 2024 Mayo Business Plan Competition

The winners all recognize the hard work that goes into the competition, but also the greater reward that comes out
of it.

"It is an excellent experience and the prize is large enough to generate real interest," Mayo said. "Even if many drop
out, they begin to realize how much is required to start a business.


Load-Date: April 4, 2024


  End of Document

                                                                                                        Page 1 of 4
                                      2024 to be hottest year on record - The DePaulia




                         2024 to be hottest year on record - The DePaulia
                                                The Depaulia: DePaul University
                                                      October 7, 2024 Monday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 792 words
Byline: Luis Caro

Body

Climate change is an irrefutable fact.

The summer average for 2024 was 0.2 degrees Fahrenheit hotter than the previous record holder, the not-so-
distant year of 2023, and an entire 2.25 F warmer than the average summer between 1951 and 1980.

If this trend continues, scientists say we may see an increase of at least 1 degree Fahrenheit every five to 10 years.

But how much worry should 1 degree bring?

"Even if a degree doesn't seem like a large change, that represents the change in the global average temperature,"
Trent Ford, a Illinois state climatologist, said. "That extra energy changes the flow of our oceans and atmosphere to
make for significant changes in regional climates and impacts human and natural systems."

Just think of a fever - and how a rise of three or four degrees can take someone out for the whole week. Now apply
that to an entire planet. Scientists worldwide have already documented how plant and animal life is disappearing at
a rate never seen before. Weather patterns have gotten intense, giving the climate a volatile tendency.

"It's pointing to a future where people don't know what snow is anymore and a climate is just going to become
inhospitable," Pranav Dhiman, a DePaul junior in finance, said.

DePaul students are no strangers to climate change, especially when its effects have become so obvious.

"From an amateur point of view, I'd have to say cars." DePaul sophomore Sterling Luckie said.

Transportation, a category including fossil fuels burned for cars, trucks, ships, trains and planes, accounts for
roughly 30% of all emissions..

Burning fossil fuels to generate heat and electricity is another major producer of greenhouse gasses, such as CO2
and methane.

"The biggest contributor is capitalism," Dhiman said. "Everything runs on the idea that there is infinite growth from a
finite planet and it doesn't make any sense."

                                                                                                        Page 2 of 4
                                   2024 to be hottest year on record - The DePaulia

Experts like Ford agree.

"While individuals can make a huge difference in reducing climate change and its impacts, large corporations are
the most significant emitters and contributors to climate change," Ford said.

A report from Carbon Majors, a database that tracks CO2 emissions, found that "80% of these global emissions
from 2016 through 2022 can be traced to just 57 corporate and state producing entities."

In total, however, investor-owned companies were responsible for 25% of emissions between 2016 and 2022, with
nations and state owned entities accounting for 38% and 37% respectively.

Although it feels like a bleak situation, Ford said hope shouldn't be lost.

He pointed to the hole in the ozone layer as a "good example of an environmental challenge that humanity met."

The hole was caused in a similar manner to climate change - pollution and the bottom line.

Over the course of the last 50 years, through policies like the Montreal Protocol, humanity has come together to
prevent the release of "gasses like chlorofluorocarbons, or CFCs (which) destroy stratospheric ozone and are
responsible for the ozone hole over Antarctica," Scot Miller, assistant professor in the Johns Hopkins Department of
Environmental Health and Engineering, said.

"While climate change is a more wicked problem, such that greenhouse gas emissions are intricately tied into our
society and economy, we can look to other environmental challenges we have overcome and trust that we can
make change," Ford said.

As for making change, Ford advises four things: walkable infrastructure with accessible public transportation, a shift
to electric vehicles to decrease transport emissions, accountability for corporation's greenhouse gas emissions and
decarbonized energy systems.

Related Stories:
    •    SPARK Center debuts with environmental data-driven neighborhood project
    •    Slowing down AI for the health of the planet
    •    Forthcoming Climate Action Plan, context behind high emissions

Stay informed with The DePaulia's top stories,

delivered to your inbox every Monday.

View Story Comments

0

Like This Story

Share on Facebook

Share on X

Email this Story

Print this Story

Leave a Comment

Tags:

                                                                                                Page 3 of 4
                                 2024 to be hottest year on record - The DePaulia

      •   climate change
      •   environment
      •   global warming

Facebook

Instagram

X

Spotify

YouTube

Email Signup

RSS Feed

Open Search Bar

Search this site

Submit Search
      •   Sections News La DePaulia Arts/Life Sports
      •   Sections Opinions Nation & World Focus
      •   Follow X Instagram Facebook Newsletter Spotify YouTube
      •   About Contact The DePaulia Staff Advertise The DePaulia Code of Ethics Get Involved

The DePaulia

Donate

Have a tip?

Facebook

Instagram

X

Spotify

YouTube

Email Signup

RSS Feed

© 2024 · FLEX Pro WordPress Theme by SNO · Log in

Comments (0)

Share your thoughts...

All

                                                                                    Page 4 of 4
                                 2024 to be hottest year on record - The DePaulia

The DePaulia Picks

Reader Picks

Sort: Newest

Cancel reply

Your email address will not be published. Required fields are marked *

Comment * Spam Control Field.Verification Field.

Name *

Email *

Close

Close Modal Window

Close


Load-Date: October 7, 2024


  End of Document

                                                                          Page 1 of 3
   DRIVING INVESTMENTS REPORT: RECORD YEAR SPURRED BY AUTONOMOUS VEHICLE STARTUPS




          DRIVING INVESTMENTS; REPORT: RECORD YEAR SPURRED BY
                      AUTONOMOUS VEHICLE STARTUPS
                                             Pittsburgh Post-Gazette
                                             March 23, 2024 Saturday
                                                SOONER EDITION



Copyright 2024 P.G. Publishing Co.

Section: BUSINESS; Pg. A-10
Length: 953 words
Byline: Evan Robinson-Johnson Pittsburgh Post-Gazette

Body


Pittsburgh tech companies raised just over $3 billion in funding last year, led by landmark investments in
autonomous vehicle startups, a report published Wednesday by Ernst and Young and Innovation Works found.

The sector continues to suffer from a lack of local venture capital but attracted 57 new investors in 2023,
contributing to the region's second largest annual total since the groups started collecting data on local tech
companies 12 years ago.

Autonomous vehicle startups Aurora and Stack AV dominated the year's capital gains, which totaled $3.12 billion, a
203% increase from 2022 that occurred despite a nationwide decline in VC funding, the report found.

But even beyond those two companies, the tech economy appeared to do well.

The average deal size with Stack and Aurora excluded was $6.9 million, a 50% increase from 2022. The rise came
even as the total number of investment rounds, 175, fell to its lowest level since 2015. Ven Raju, CEO of Innovation
Works, said that's partially because companies are closing larger rounds.

Stack AV, which grew out of the now-shuttered Argo.ai, secured $1 billion from Softbank last fall, while Aurora
raised $820 million over the summer through a second public offering and private raise. Gecko Robotics also had a
banner year, with a $100 million Series C.

Series A, B, and C funding rounds are separate fundraising events that businesses use to raise capital, according
to Investopedia. Each round is named for the series of stock being issued.

The 2023 report showed that Pittsburgh continues to lag behind other cities in venture dollars invested per capita.
The region ranks 15th nationally, immediately below Miami and Minneapolis.

Even in AI-related deals, where Pittsburgh cracks the top 10, it ranks lower than Miami and Raleigh, N.C.,
surprising some observers who point to the extensive AI expertise at Carnegie Mellon University.

                                                                          Page 2 of 3
   DRIVING INVESTMENTS REPORT: RECORD YEAR SPURRED BY AUTONOMOUS VEHICLE STARTUPS

"Pittsburgh should be the number one in that list," said Justin McElhattan, a newly minted venture capitalist who
founded Nicely Road Capital last year after more than 20 years at Industrial Scientific.

Less surprising, the report found that Pittsburgh continues to lack the local venture capital dollars other technology
hubs enjoy.

A few local funds have emerged in recent years, including Blue Tree Capital Group, Black Tech Nation Ventures,
Magarac Venture Partners, Reinforced Ventures and Riverfront Ventures, but they are all still nascent, Mr. Raju
said.

"Right now, many of them are in the sub-$50 million range. My hope and expectation is that once they get to their
fund three, fund four, we'll see a market step up in terms of overall assets under management," he said. "It takes
time for these funds to grow organically."

Larger institutional funds like Sequoia Capital, often based on the coasts, could also set up an outpost in Pittsburgh,
especially as the city continues to grow its reputation, Mr. Raju said.

"Part of our job ... is to promote and underscore what's happening," he said.

Pittsburgh might never be Silicon Valley, but it has its own strengths worth celebrating, said Sean Sebastian, a local
venture capitalist who co-directs Black Tech Nation Ventures, which recently completed its $50 million raise.

"We have an incredibly vibrant university space [with] students and faculty spinning off ideas that are super
compelling," he said.

Pennsylvania officials have said recently that research and development dollars are not translating to
commercialized success in the state. Mr. Raju said there could be some truth to that claim, but he emphasized that
not all R&D spending is in pursuit of profit. For groups that are looking to scale, he said "there are avenues in the
region."

"The onus is on organizations like Innovation Works and others who help shepherd companies at the very earliest
stages," Mr. Raju said.

Those opportunities include IW's Scale residency, which welcomed its first cohort earlier this month, as well as
CMU's annual McGinnis Venture Competition, overseen by the Swartz Center for Entrepreneurship, which granted
five student teams nearly $60,000 on Tuesday.

The IW/EY report highlighted several life sciences leaders, including Carmell Therapeutics, Krystal Biotech,
Imagine Pharma, Seegrid and Abridge, as well as early-stage companies that landed Series A deals - Optimus
Technologies, LyGenesis, Agile Space Industries, Formlogic and BlastPoint. Agile helped build the rocket thrusters
for Astrobotic's next trip to the moon.

Ten tech companies included in the report had exits through acquisitions last year, while Aurora and Coeptis
Therapeutics each had second public offerings. Not mentioned in the report, however, was Sarcos, which closed its
Pittsburgh office in November, after acquiring RE2 Robotics in 2022. Some observers said the saga demonstrated
that exits don't always translate to lasting success.

There have been other losses too, said Audrey Russo, president and CEO of the Pittsburgh Technology Council,
citing Neubase Therapeutics, which was approaching an initial public offering but instead closed down.

Ms. Russo said she wanted to see the underlying data in the IW/EY report to better understand what companies
were included. IW said it couldn't provide the full list of companies as some of the investment figures are not
publicly disclosed.

So far, 2024 has been a mixed bag for local tech companies, with a significant $150 million raise by AI health care
startup Abridge, and layoffs at the college review software company Niche. Excelitas Technologies Corp

                                                                          Page 3 of 3
   DRIVING INVESTMENTS REPORT: RECORD YEAR SPURRED BY AUTONOMOUS VEHICLE STARTUPS

announced in January it is relocating from Boston to the Strip District, a four-year move that promises to bring at
least 250 jobs.

Evan Robinson-Johnson: ejohnson@post-gazette.com and @sightsonwheels



Graphic


PHOTO: Stack AV: Pittsburgh tech companies raised just over $3 billion in funding last year, led by landmark
investments in autonomous vehicle startups such as Aurora and Stack AV, a report published Wednesday by Ernst
and Young and Innovation Works found.

PHOTO: Aurora: Pittsburgh tech firms raised a little more than $3 billion in funding in 2023. The windfall was led by
landmark investments in autonomous vehicle startups such as Aurora and Stack AV, according to a report
published Wednesday by Ernst and Young and Innovation Works.


Load-Date: March 23, 2024


  End of Document

                                                                                                         Page 1 of 4
                Social Media Is Hurting Social-Emotional Skills. How 4 School Districts Are Fighting Back




 Social Media Is Hurting Social-Emotional Skills. How 4 School Districts Are
                                Fighting Back
                                                              Education Week
                                                              March 25, 2024



Copyright 2024 Editorial Projects in Education, Inc All Rights Reserved




Section: Pg. 14; Vol. 43; No. 22
Length: 1665 words

Byline: Lauraine Langreo, llangreo@educationweek.org
Highlight: A majority of educators believe social media negatively impacts studentsâ€™ social-emotional skills, an
EdWeek Research Center survey found.

Body


Social media, generative artificial intelligence, and other advances in digital technology are already dramatically
influencing how kids develop social-emotional skills.

A majority of educators believe social media negatively impacts those skills, such as how students communicate,
how they treat others, how isolated they feel, or how they perceive themselves, according to a nationally
representative EdWeek Research Center survey of 595 teachers, school leaders, and district leaders conducted in
December and January.

These concerns come as the share of teenagers who say theyâ€™re online â€œalmost constantlyâ€ has roughly
doubled since 2014-15, according to the Pew Research Center. A growing number of studies have also linked
childrenâ€™s use of smartphones and social media to their worsening mental, social, and emotional well-being.

In addition to navigating academic challenges, districts know they also need to address the effects that digital
technology has on studentsâ€™ social-emotional skills. Social-emotional learning is the teaching of nonacademic
skillsâ€”such as emotional regulation, communication, and collaborationâ€”that are important for success in school
and in life.

The EdWeek Research Center survey found that a majority (65 percent) of educators agree that they should be
responsible for helping students learn to use social media in ways that support their mental health and well-being.

Many schools are already on the right track, but many others are not. A few of the districts Education Week initially
contacted for this story said they have not thought about applying SEL skills to tech use. A small majority (54
percent) of students said a teacher or an adult at their school has discussed how to use social media in ways that

                                                                                                      Page 2 of 4
             Social Media Is Hurting Social-Emotional Skills. How 4 School Districts Are Fighting Back

do not damage their mental health and well-being, according to an EdWeek Research Center survey of 1,056 high
school students conducted in February.

The most effective SEL programs are the ones that take a whole-district approach and build it into the everyday
practices of schools, said Stacy Hawthorne, the chief academic officer for Learn21, a nonprofit that provides
educational technology solutions to schools.

In conversations with Education Week, four district leaders shared how their schools are teaching SEL skills that
they believe will help students navigate the increasingly digital and complex world they live in.

Washoe County School District, Nevada: 'The long-lasting consequences'

â€œIn our role, a large part of what weâ€™ve done is working to educate our families and educate our students
about social media, about their digital reputation and the long-lasting consequences,â€ said Trish Shaffer, who is
the multitiered systems of support and SEL coordinator for the 60,000-student Washoe district.

Social media and other digital technologies can be a gift or they can be used as weapons, Shaffer said. SEL skills,
such as responsible decisionmaking, self- and social awareness, and relationship skills, can help students learn to
use technology in positive ways, she said.

SEL in the districtâ€”where 55 percent of students are on free or reduced-price mealsâ€”is taught through explicit
instruction, some of which targets social media use, especially in middle and high schools, Shaffer said. SEL is also
embedded into what teachers do regularly in the classroom at all grade levels, such as having an inclusive welcome
at the beginning of every class and an intentional close at the end.

The district hosts â€œParent Universityâ€ classes, too, Shaffer said. Whether itâ€™s during in-person events or
through videos posted online, they teach parents how to control their kidsâ€™ screen time, how to monitor social
media use, how to navigate certain apps, how to understand youth lingo, and how to set tech-use boundaries.

â€œWhere it is developmentally appropriate, weâ€™re trying to teach our parents and kids the same thing,â€ she
said. â€œMaybe not teaching our kids how to shut down screen time but talking about 'catfishing' (when one
pretends to be someone else by posting false information), making sure you research things, understanding what is
posted lives on forever, understanding how it can significantly impact a peerâ€™s mental health.â€

Generative AI tools are still new, so the district is working on infusing those tech advances into existing SEL
lessons on social media, Shaffer said. For now, the district is teaching its staff about AI and ensuring that they know
how to be responsible, conscious consumers of AI tools.

Pewaukee School District, Wisconsin: 'Understand [tech's] role in mental health and wellness'

The Pewaukee school district has had a digital-citizenship curriculum in place for years, â€œwell before we saw an
increase in the social-emotional needs of students,â€ said Danielle Bosanec, the chief academic officer for the
2,900-student district.

But ensuring that the district is supporting studentsâ€”helping them learn â€œhow to use technology in ethical
waysâ€ and helping them understand its role in their mental health and wellnessâ€”has become â€œmuch more
prevalent,â€ Bosanec said.

The districtâ€”where 13 percent of students quality for free or reduced-price mealsâ€”combines the work they do
around SEL and digital citizenship to ensure that students have the strategies they need to navigate the stressors
they have in their lives, whether theyâ€™re online or in person, Bosanec said.

Guidance counselors provide SEL lessons in the classroom for K-8 students on a regular schedule, Bosanec said,
while classroom teachers are trained on how to support student wellness.

                                                                                                      Page 3 of 4
             Social Media Is Hurting Social-Emotional Skills. How 4 School Districts Are Fighting Back

For instance, Bosanec said the district is focusing a lot on â€œlateral reading,â€ which is the practice of verifying
what youâ€™re reading by searching for other articles on the same topic by other writers. Students also learn about
responsible social media use during lessons about building positive, healthy relationships.

Hermiston School District, Oregon: 'Think through problems and communicate with each other'

In Hermiston, the focus is on ensuring students not only have the knowledge but also the social-emotional skills
they need for tomorrow, said Tricia Mooney, the superintendent of the 5,500-student district. This means teaching
students in ways that strengthen their collaboration, critical thinking, complex problem-solving, and communication
skills.

â€œUltimately, what we want for our kids is for them to be successful citizens in the future,â€ Mooney said. â€œNo
matter what happens with technology, if our students know how to collaborate with one another, think through
problems, and communicate with each other, they're going to be able to navigate whatever gets thrown at them.â€

Hermistonâ€”where 84 percent of students quality for free or reduced-price mealsâ€”combines SEL and digital
citizenship to support studentsâ€™ well-being online. Students are taught how to use digital resources
appropriately. When students are struggling with using digital tools while in school, educators ask students to take a
break from the resources and reteach appropriate skills, Mooney said.

Teachers have professional learning communities and instructional coaches who help them embed those principles
into their daily practice.

To continue the learning at home, the district hosts seminars and provides information to parents about what to look
for and how to support their children's well-being online.

"As we navigate [advances in technology], we really just need to focus on the skills we know students are going to
need [when they leave]," Mooney said.

San Ramon Valley Unified School District, California: 'When it's important to put [technology] down'

The San Ramon Valley school system uses a combination of SEL curriculum, counselor activities in the classroom,
specific dialogues with students, and connections with parents to ensure students have the social-emotional skills
they need to navigate the digital world, according to John Malloy, the superintendent of the 30,000-student district.

â€œWe teach our kids that there is a time and place for the use of technology and social media, which means that
there are times when it's important to put it down,â€ Malloy said. Students also learn about healthy relationships,
how to deal with emotions, and how to communicate effectively in person.

Each school has a team of educators and support staff who keep up with the academic, social, and emotional
needs of the students and ensure that students are learning what healthy use looks like, Malloy said.

The districtâ€”where 4 percent of students qualify for free or reduced-price mealsâ€”is also thinking about how
students can assist each other in making healthy decisions. â€œPeers learn from each other very effectively,â€
Malloy said, â€œas long as thereâ€™s a trusted adult facilitating in some way.â€

Educating parents is also important because they are â€œon a continuum of how they allow their students to use
technology and social media,â€ Malloy said. The district has started parent information nights, where they bring
their questions and the district provides speakers or lessons to address those questions.

â€œI'm a former counselor, so I'm speaking from a little bit of experience when I say we have a very well-thought-
out approach to how we help our kids be healthy in the physical world,â€ Malloy said. â€œI would argue as
educators and as counselors in schools, we need to do a better job of thinking about how we help our kids navigate
healthily through the digital world, because they're spending a considerable amount of time in that space.â€

                                                                                                      Page 4 of 4
             Social Media Is Hurting Social-Emotional Skills. How 4 School Districts Are Fighting Back

Coverage of the intersection of social-emotional learning, technology, and student well-being is supported in part by
a grant from the Susan Crown Exchange, at www.scefdn.org . Education Week retains sole editorial control over
the content of this coverage.A version of this article appeared in theApril 03, 2024edition ofEducation WeekasSocial
Media Is Hurting Social-Emotional Skills. How 4 School Districts Are Fighting Back


Load-Date: April 1, 2024


  End of Document

                                                                                                       Page 1 of 4
                                            U.S. Senate candidate questionnaires




                                 U.S. Senate candidate questionnaires
                                                  The Santa Fe New Mexican
                                                    October 6, 2024 Sunday



Copyright 2024 The Santa Fe New Mexican All Rights Reserved

Section: A; Pg. 4
Length: 1498 words

Body


Martin HeinrichAge: 52

Party affiliation: Democrat

Educational background: Bachelor's in mechanical engineering, University of Missouri-Columbia

Occupation: U.S. senator

Political experience: Albuquerque city councilor, U.S. congressman, U.S. senator

Relevant life experience: I grew up in a working-class union household. My parents taught me the value of hard
work and giving back to the community. From the Albuquerque City Council to the U.S. House and U.S. Senate,
I've worked to deliver results for New Mexicans.

Have you ever been charged or convicted of a crime, including drunken driving?: No

Have you ever filed for bankruptcy or been involved in a bankruptcy proceeding, either personally or in business?:
No

Have you ever been the subject of liens for unpaid taxes? No

What separates you from your opponent?

I am the son of an immigrant lineman and factory worker, and have dedicated my career to serving others; creating
economic opportunities, lowering costs for working families, and protecting our rights and freedoms, including
reproductive rights. My opponent is a wealthy former hedge fund executive with a history of prioritizing profits over
people, including outsourcing American jobs. While I've fought to deliver results and investments for New Mexico,
she's spent decades enriching herself on the East Coast, only to return 50 years later and run for office backed by
extreme politicians who want to ban abortion nationwide.

Do you support legislation that would make it a right nationwide for women to access in vitro fertilization and other
fertility treatments? Why or why not?

                                                                                                          Page 2 of 4
                                        U.S. Senate candidate questionnaires

I fully support protecting access to in vitro fertilization and other fertility treatments, and have advocated for making
it a nationwide right by co-sponsoring the Access to Family Building Act, which would ensure every American's right
to IVF. Unfortunately, Republicans blocked this bill twice this year. Just as I support a national right to access
abortion, which my opponent does not, I believe every family deserves the freedom to pursue parenthood on their
own terms, without government interference. Access to reproductive health services is essential, and we must
remove barriers and ensure they are available to all New Mexicans.

Do you support a path to citizenship for young immigrants brought to the U.S. as children, frequently referred to as
Dreamers? Why or why not?

I strongly support a pathway to citizenship for Dreamers, and have repeatedly called on Republicans in Congress to
pass the Dream Act without delay. These young people have grown up here, contributed to our communities, and
share the same hopes and dreams as all Americans. They deserve the opportunity to fully participate in the country
they call home. I've consistently supported comprehensive immigration reform; including legislation to provide
Dreamers a swift path to full citizenship, expand fair and legal immigration pathways, and invest in our border
communities at the scale needed.

Do you support laws that require all voters to produce an official photo ID in order to vote? Why or why not?

While we must protect the integrity of our elections, restrictive voter ID laws disproportionately impact low-income
communities, seniors and people of color, making it harder for them to vote. New Mexico's elections are already
secure and legitimate without such unnecessary laws, as we've consistently maintained fair and transparent
election processes. We should be making it easier, not harder, for every eligible New Mexican to participate in our
democracy through secure, accessible voting options for all.

What do you believe the role of the U.S. should be in achieving peace in the Middle East and do you support
boycotts or divestment targeting Israel?

I support a cease-fire and the safe, immediate release of all hostages. Until that is achieved, the U.S. should work
diplomatically to protect civilians in Israel, Gaza, and the West Bank, provide humanitarian aid, encourage de-
escalation, and work towards a lasting two-state solution that ensures peace, security and stability for both Israelis
and Palestinians.

Nella Domenici

Age: 63

Party affiliation: Republican

Educational background: BA, English literature, Georgetown University, 1982; JD, Georgetown University Center,
Law Night School, 1987; MBA Harvard Business School, high distinction, George F. Baker Scholar (top 5%) 1993

Occupation: Business executive and philanthropist

Political experience: Republican candidate for U.S. Senate. Often participated in campaign events with my father,
U.S. Sen. Pete V. Domenici.

Relevant life experience: Began career at the bottom and reached the top in the complex world of finance -
mastering budgets, markets and interest rates. Advised/invested in companies to create thousands of American
jobs in health care, AI, mortgage lending, commercial real estate.

Have you ever been charged or convicted of a crime, including drunken driving?: No

Have you ever filed for bankruptcy or been involved in a bankruptcy proceeding, either personally or in business?:
No

                                                                                                           Page 3 of 4
                                        U.S. Senate candidate questionnaires

Have you ever been the subject of liens for unpaid taxes? Yes

If yes, please explain: There were three liens in the last 25 years. To the best of my knowledge these relatively
small liens totaled approximately $7,000 and were paid as soon as I was made aware of them.

What separates you from your opponent?

Third-generation New Mexican born into a New Mexico family with an unsurpassed public service record. Heinrich
was not, and has none.

My approach: Common sense, bipartisan, moderate problem solving. Opponent votes almost 100% with the
extreme, leftist wing of his party, often contrary to New Mexicans' needs.

My priorities: fighting crime, securing the border, improving cost of living, health care and education while creating
jobs. Heinrich's obsession: extreme radical climate measures.

With bipartisan leaders co-founded Excellent Schools New Mexico; 13 public charter schools in underserved areas;
9,000 students outperform other schools.

Heinrich's record? 20 years of state's decline.

Do you support legislation that would make it a right nationwide for women to access in vitro fertilization and other
fertility treatments? Why or why not?

Yes.

No disappointment greater than learning that a woman is not able to have a baby. IVF provides hope and options
for women and families who would otherwise be unable have a child.

Heinrich has been dishonest and lied about my position on abortion. I oppose a national abortion ban. Abortion
should be safe, legal and rare. I trust, respect and want to empower women. My focus is reducing unwanted
pregnancies because approximately one in three unwanted pregnancies results in abortion. We need better
education about and access to birth control for all women.

Senators should be honest.

Do you support a path to citizenship for young immigrants brought to the U.S. as children, frequently referred to as
Dreamers? Why or why not?

Biden/Harris/Heinrich have created a border crisis, a humanitarian crisis, a crime crisis, drug crisis and a national
security threat with their open border policies.

Congress must first pass legislation that secures the border and then pass immigration reform. Other border states
have built barriers; we need to finish building our barriers along our border.

We must install state-of-the-art screening technology for 100% of vehicles passing through our border; Reinstate
"Stay in Mexico"; tighten asylum process; end catch and release; bolster funding for Border Patrol; support
comprehensive, bipartisan and fair immigration reform; deport criminals and terrorists; enact temporary worker
program.

Do you support laws that require all voters to produce an official photo ID in order to vote? Why or why not?

Everyone should want elections laws that allow every citizen who is eligible to vote to exercise their right.

Under the U.S. Constitution the responsibility for establishing election laws is vested in the state legislatures. I defer
to the New Mexico Legislature, but hope they share my view that it is important to enact laws that build confidence

                                                                                                        Page 4 of 4
                                        U.S. Senate candidate questionnaires

that only eligible citizens are voting, that our ballots are secure and accurately counted. As a U.S. senator I have no
role in that decision.

What do you believe the role of the U.S. should be in achieving peace in the Middle East and do you support
boycotts or divestment targeting Israel?

Israel, our closest Middle East ally, was brutally attacked by a terrorist organization wanting to destroy them, and
bring death to Americans. I support Israel's right to self-defense.

Israel should decide the terms and timing for a cease-fire when the hostages are freed and their war objectives
have been achieved. I believe in peace through strength and appeasing terrorists will not bring about peace.

Humanitarian aid should be provided.

Foreign policy is the responsibility of the president and the Congress. I do not support boycotts or divestments
targeting Israel.

Heinrich is among the least supportive of our ally, Israel.


Load-Date: October 6, 2024


  End of Document

                                                                                                      Page 1 of 3
  The Transformative Role of AI in Cybersecurity: Anticipating and Preparing for Future Applications and Benefits




 The Transformative Role of AI in Cybersecurity: Anticipating and Preparing
                   for Future Applications and Benefits
                                                             R Street Institute
                                                    January 24, 2024 Wednesday



Copyright 2024 Content Engine, LLC.
All Rights Reserved
Copyright 2024 R Street Institute, USA All Rights Reserved

Length: 1521 words

Body


This article is part of a series of written products inspired by discussions from the R Street Institute's Cybersecurity-
Artificial Intelligence Working Group sessions. Visit the group's webpage for additional insights and perspectives
from this series.

While artificial intelligence (AI) has been around for decades, 2023 marked a significant turning point in the public's
perception and understanding of it. Thanks largely to the explosion of generative AI (GenAI), 2023 was dubbed the
"year of generative AI." GenAI captured the imagination of millions, leading to unprecedented adoption rates of
large-language models (LLMs). Government leaders around the world also intensified their interest in AI, seeking to
understand not only its potential benefits but also its potential risks. Now, in 2024, a notable shift in expectations for
AI's innovation and impact brings a more focused and intentional approach to considering how AI impacts our daily
lives. Emerging and ongoing policy debates must adopt an aligned, innovative, and intentional approach to maintain
a strategic advantage over nefarious actors, whether they be nation-states, non-state actors, or even criminal
groups.

Although AI's integration into cybersecurity is not new (see Part 1: Understanding Current AI Applications and
Benefits), its rapid evolution requires continuous adaptation. Technology companies are focused on expanding AI
integration with their existing security products while actively tracking emerging developments for further
enhancements. With the market for AI-based cybersecurity products projected to grow from $15 billion in 2021 to
around $135 billion by 2030, we must anticipate and prepare to integrate emerging AI advancements, equipping
ourselves for an inevitable and dynamic AI-fueled cybersecurity landscape. While many promising AI
advancements and emerging technologies are currently under development, there are three primary areas within
the field of cybersecurity to which the next wave of AI applications is expected to bring significant-even
transformational-advancements.

1. Advanced Threat Detection
Quantum machine learning (QML) leverages the unparalleled power of quantum computing to perform complex
data analyses. Its proficiency in handling large-scale and computationally intensive tasks makes it superior to
current computing and machine-learning capabilities. For instance, a quantum computer equipped with QML
capabilities can sift through vast amounts of network log data in seconds-a task that would typically take hours or
even days for current computers and machine-learning algorithms to complete. This rapid analysis accelerates

                                                                                                      Page 2 of 3
  The Transformative Role of AI in Cybersecurity: Anticipating and Preparing for Future Applications and Benefits

threat detection, thereby enhancing a cybersecurity practitioner's ability to respond to cybersecurity incidents
promptly.

Predictive threat intelligence is another transformative offering for advanced cyber threat detection. Currently, AI
models are being developed to predict new and unknown threats and vulnerabilities by analyzing vast datasets and
identifying patterns. These models are unique because they scrutinize trends from previously identified threats like
malware and ransomware attacks, empowering businesses to prepare and strengthen the defenses on their
systems and data without impacting them directly. The ability to predict the likely evolution of these threats marks a
major advance from today's reactive threat-intelligence strategies.

Moreover, AI-enhanced digital-twin technology could play a significant role in simulating various cyberattack
scenarios. As virtual replicas of physical objects or systems, digital twins will enhance preparation for a wide range
of potential real-world threats. For instance, a power-grid company could use a digital twin of its infrastructure to run
hundreds or even thousands of excursions that simulate various cyberattack scenarios, using the results to develop
tailored and robust mitigation strategies. By creating digital replicas of a networked system, cybersecurity
practitioners can monitor, predict, and analyze cyberattacks in a simulated environment and in real time. This
technology will be particularly helpful for critical infrastructure sectors, where the ramifications of cyberattacks can
be far-reaching.

2. Dynamic Incident Response and Adaptive Cyber Defense

Driven by AI, self-healing systems repair and adapt to evolving cyber threats in real time without human
intervention. For instance, a cloud server detecting a software flaw could autonomously implement a patch to an
identified software vulnerability and reroute traffic to maintain uninterrupted service. These systems enhance
traditional human-led responses with more resilient capabilities. While they include features like automated software
patching and reduced operational and service disruptions, their primary focus remains on system maintenance and
resilience rather than active threat engagement.
In contrast, autonomous response systems extend beyond current automated response capabilities because they
can execute immediate, holistic, and strategic actions to mitigate damage during a cyberattack. For instance, if a
cybersecurity system identifies the beginning of a ransomware attack, it could make the split-second decision to
independently isolate affected network segments, alert the security team, and initiate recovery processes
immediately. Current cyber defense capabilities are generally confined to basic threat detection, vulnerability
management, and remediation recommendations that still require human intervention and take more time.

Active defense with generative adversarial networks (GANs) introduces another novel and beneficial approach to
adaptive cyber defense. Here, AI systems engage in continuous simulations-one generating threats and the other
defending against them. This ongoing interaction refines the system's ability to recognize and successfully
neutralize advanced cyber threats. GANs could empower organizations to evolve their defenses against synthetic
media-based social engineering attacks by enabling advanced phishing mitigation, significantly bolstering their
cybersecurity posture. And while still nascent, AI-fueled game-theoretic approaches to evaluating potential
cyberattacks and defensive options also show promise.

3. Advanced Digital Forensics and Reasoning

Advanced AI-driven digital forensics are expected to play a significant role in expediting and improving the quality of
post-incident analysis. For instance, an AI tool could quickly analyze terabytes of security logs and data after a data
breach to pinpoint the breach's origin, the exploited vulnerabilities, and any impacted data, thereby accelerating the
post-incident review process significantly. This capability will also allow for reduced costs and faster root-cause
analysis and evidence-gathering processes that will help organizations rapidly respond to security incidents and
accelerate recovery efforts.
Cognitive security operation centers (SOCs) leverage cognitive computing capabilities to emulate advanced
reasoning, such as human-like thinking and learning processes. Using natural language processing (NLP),
cognitive SOCs can parse extensive unstructured data from diverse sources, making connections and drawing

                                                                                                      Page 3 of 3
  The Transformative Role of AI in Cybersecurity: Anticipating and Preparing for Future Applications and Benefits

conclusions that may elude human analysts. This cognitive computing approach improves the depth, speed, and
quality of existing threat detection, analysis, and response techniques.

Conversely, neuro-symbolic AI combines symbolic reasoning, governed by rules and logic, with the data-driven
insights of neural networks to bring a more human-like reasoning capacity to threat detection and response. For
instance, an AI system that employs neuro-symbolic AI could discern behavioral patterns indicative of an insider
threat-even if the individual actions appear benign. This hybrid approach offers a more nuanced understanding of
potential threats and significantly reduces false positives in threat detection.

Significance

The AI arms race accelerated across the tech world in 2023, with organizations striving to enhance and expand
their AI capabilities and nations vying for leadership in AI innovation and governance. To harness the full potential
of these emerging capabilities, technologies, and cybersecurity solutions, we must be prepared to adapt and
embrace innovation while being able to assess, scope, and mitigate potential risks.

Deeper collaboration among policymakers, industry leaders, the public, and subject matter experts is essential to
create a policy environment that not only promotes continued U.S. leadership in technological development but also
anticipates and effectively counters evolving cyber threats. Similarly, cybersecurity practitioners and leaders must
actively engage in the policymaking process to ensure AI is employed and advanced responsibly and effectively.

As AI's integration into cybersecurity accelerates, and as we strive to establish balanced solutions, regulations, and
guidelines for its development and use, we must recognize that our decisions will not only impact AI maturation-
they will also define what an AI-driven future should look like.


Load-Date: January 25, 2024


  End of Document

                                                                                                        Page 1 of 2
                          UC regents committee meets to discuss funding, alumni engagement




       UC regents committee meets to discuss funding, alumni engagement
                                      Daily Bruin: University of California - Los Angeles
                                                      July 24, 2024 Wednesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 715 words
Byline: Dylan Winward

Body


The UC Regents Public Engagement and Development Committee discussed government funding and alumni
advocacy at their meeting Wednesday.

During the meeting, the committee - which discusses fundraising and advocacy for the UC towards elected officials
- announced funding received from Governor Gavin Newsom's annual budget and heard presentations about
funding for Black student centers. Former chairs and vice-chairs of the Alumni Associations of the University of
California, who serve as ex officio regents, also gave presentations on the role alumni can have in supporting the
UC.

The regents also heard from artificial intelligence experts.

[Related: UC Regents committee evaluates implications of AI in health care]

Meredith Turner, the interim senior vice president of external relations and communications for the UC Office of the
President, said University lobbying has led to a $130 million increase to the University's base budget, but
acknowledged that the budget could fall next year. Regent Jay Sures said the regents were grateful that previously
expected cuts to the University's budget this year did not materialize.

During his opening remarks, Sures added that government-funded collaboration with Native American communities
has also been an important part of implementing the University's climate resilience plan.

"In 2022 and '23 the State of California allocated $100 million to the University of California to fund research grants
supporting climate change resilience in communities across the state," he said. "Three of the California Climate
Action seed grant funded research projects are establishing collaborations between academic institutions and tribal
nations here in California to support climate change resilience through tribal resource management."

However, there are also concerns in the higher education community about potential Congressional cuts to federal
funding, Turner added.

                                                                                                      Page 2 of 2
                       UC regents committee meets to discuss funding, alumni engagement

Chely Saens, a rising fourth-year cognitive science and international relations student at UC Davis, said during the
meeting that funding should prioritize students from underprivileged backgrounds. She added that the University
does not sufficiently fund Black student resource centers and resources for first-generation and low-income
students like her.

Saens also called on alumni to fund increased outreach to international undergraduate applicants from Africa and
for the regents to support the measure.

"Our black student unions, student outreach centers and student retention centers, these areas are severely
underfunded," she said. "I just wanted to echo the importance of expanding the alumni network, and this means
recruiting underrepresented students and allowing them to thrive in the UC system."

Regents also heard a presentation on alumni advocacy.

Alumni Regent-emeritus Keith Ellis said the Alumni Associations of the University of California supports 2 million
UC alumni living in California. However, until recently, the associations have not focused on advocacy for the
University as a whole - instead focusing on each of their own specific campus needs, he added.

"Prior to the pandemic, it really didn't have much of a purpose other than providing a forum for collaboration among
the associations and sharing best practices," he said.

Alumni Regent-emeritus Joel Raznick said one of the ways alumni have increased their advocacy for the University
has been by selecting an "issue of the year," a lobbying priority for the alumni. Ellis added that the Alumni
Associations Board also published a new toolkit to help alumni advocate for the UC towards elected officials.

Currently, 33% of California's congressional delegation, 31% of state assembly members and 35% of state
senators are UC alumni, according to the alumni presentation slides. Ellis said alumni now receive regular updates
on state budgets from state and federal officials and have made over 50 visits to the State Capital.

Ellis added that elected officials now engage with UC alumni across all 10 campuses on a unified basis for the first
time, with alumni participating in a recent UC-wide letter writing campaign.

"AAUC itself did something for the first time that it has never done before," Ellis said. "We wrote advocacy letters
both to the legislature in Sacramento and to the federal government."


Load-Date: July 26, 2024


  End of Document

                                                                                                       Page 1 of 2
                                       Deliberative democracy could help mend divide




                         Deliberative democracy could help mend divide
                                                Telegraph Herald (Dubuque, IA)
                                                 October 9, 2024 Wednesday



Copyright 2024 Woodward Communications, Inc. All Rights Reserved

Section: A; Pg. 4
Length: 827 words
Byline: ERIC FRYDENLUND for the Telegraph Herald

Body


My mute button has been working overtime lately. Every time a political ad comes on, I scramble for the remote
control. Listening to the political "discussion" in attack ads reminds me of the difficulty of keeping the car on the
road while my grandkids are arguing in the back seat. The road to good governance blurs amid the distractions
coming from all directions.

Perhaps there's a better way of making voting decisions on critical policy issues than basing them on campaign
one-liners. Enter deliberative democracy.

Deliberative Polling â " the process of bringing together people of diverse backgrounds and opinions for a
moderated discussion of the most pressing issues facing us â " has been developed and refined by professors
James Fishkin and Larry Diamond. This process "has been used over 150 times in 50 countries," according to
Standford's Deliberative Democracy Lab's website.

I first wrote about deliberative democracy in a 2019 column that described America in One Room, a project that
brought together 500 people from across the political spectrum for a moderated weekend retreat. By listening to
expert, fact-based evidence and applying Deliberative Polling, they were able to substantially reconcile their
differences on a number of issues.

Most recently, "America in One Room: the Youth Vote," a collaboration between Close Up Foundation, Stanford
University, the Generation Lab, Helena, and University of Southern California, gathered 430 young, first-time voters
in Washington, D.C., on July 19-22, 2024. The participants comprised a variety of ages from both blue states and
red states, and from rural, suburban, and urban America â " a group that also included all political persuasions.
They attended sessions to deliberate on four key issues: energy and the environment; the economy, AI, and taxes;
health care; and democracy and elections. Most important, the sessions were moderated by experts with differing
views on each topic, not by politicians or media personalities.

The results were measurable and significant. Participants were able to reach a closer consensus on a number of
issues on which they were widely divergent before the event. On the contentious question of allowing partisan
observers to challenge the eligibility of voters as they cast their ballots, "Overall opposition to this proposal
increased 19 points, from 58% [before the event] to 77% [afterward]. Republicans increased their opposition by 17

                                                                                                       Page 2 of 2
                                  Deliberative democracy could help mend divide

points, from 54% to 71%. Democrats increased their opposition by 20 points from 65% to 85%," according to the
executive summary.

The consensus was not unanimous and there were some surprising results. Despite two-thirds agreeing that the
U.S. should achieve net-zero emissions by 2050, 59% voted that we should not eliminate the sale of gas and diesel
vehicles.

Yet the summary noted that the participants, "also increased their mutual respect for each other across their most
contentious divisions - granting that those with whom they most strongly disagree have good reasons for their views
... They became more deliberative voters."

Can deliberative democracy be used more broadly? One way is to incorporate the process into civics curricula in
schools. "It's actually a more effective form of civic education we believe than conventional civic education because
anything very active is better than something passive," according to Fishkin.

Fishkin believes that deliberative democracy can help depolarize America. "Left to our own devices, most people
either don't pay much attention or if they do, they tune into their favorite news sources or their social media feeds
and they only hear one side of the argument that is most congenial to them. That's part of what's been driving us
apart," he said.

You and I can play a part also. Short of organizing an America in One Room event, we can mimic the process by
reading and listening to experts on critical issues. We admire articulate speakers who are able to express new
ideas in a clear way. We can also become "articulate listeners," able to understand new ideas conveyed by experts
rather than politicians or media celebrities who have inherent conflicts of interest.

We constantly hear how polarized we are in America. The question becomes whether that is a necessary reality or
a self-fulfilling prophecy perpetuated by endlessly repeating the same pessimistic thought. Tribalism is nothing new.
It's part of human nature. Yet there are deliberate actions we can take to prevent our clannish behavior from
consuming us. We can become deliberative voters.

Deliberative democracy applied to legislative bodies and citizens across the political divide can put us back on the
road to representative democracy - despite all the chaos and distractions coming from the back seat.

Frydenlund, a columnist who lives in Prairie du Chien, Wis., writes about nature, politics and social issues from a
systems perspective. He can be contacted via email at: epfrydenlund@gmail.com


Load-Date: October 9, 2024


  End of Document

                                                                                                    Page 1 of 6
           Community, isolation and politics: The mental health of queer students at UNCW - The Seahawk




   Community, isolation and politics: The mental health of queer students at
                           UNCW - The Seahawk
                                   The Seahawk: University of North Carolina Wilmington
                                                  March 20, 2024 Wednesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 2673 words
Byline: Hannah Markov

Body


content"class="sno-story-body-content sno-no-cap">

People walk with "You belong" signs at a Pride month protest. (Adiden Craver/Unsplash.com)

Editor's Note:

I was heading to class in Morton Hall and in my usual walk to class, I see on the black board that stands in the
hallway "a student at N.C. State committed suicide, and I am sad about it." These words struck me deeply with their
display of compassion, yet simultaneously left me disheartened that such a message ever needed to be written.

The mental health crisis we face has not subsided. Last year, N.C. State lost seven students to suicide. From 2016
to 2020, there were 878 deaths by suicide of people ages 15 to 24 in N.C. A national survey conducted by the
American College Health Association found that 52 percent of undergraduate students regularly experienced
moderate psychological distress. While this problem isn't new, it feels more important than ever.

That's why The Seahawk has partnered with eight other college newspapers to report on mental health challenges
shared by those in each of their communities. This Mental Health Collaborative is the result of months of rigorous
reporting, research, conversations, writing, editing and designing. This initiative began in 2023, when The Daily Tar
Heel was awarded a grant from the Solutions Journalism Network as part of its Student Media Challenge initiative.
That grant helped fund the collaborative work of this project. Many of the stories you will read in this collaborative
do more than just present a problem - they also explore solutions to this crisis.

The Seahawk is honored to have had the privilege of working with The Daily Tarheel, The A&T Register, The Duke
Chronicle, The East Carolinian, The Niner Times, The Old Gold & Black, The Pendulum and Technician on this
project.

With more than 30 reported stories and seven opinion pieces, we touch on many issues related to mental health,
from how Wake Forest University trains its faculty to be on the frontline of mental health care to how international
students create community at East Carolina University.

                                                                                                  Page 2 of 6
         Community, isolation and politics: The mental health of queer students at UNCW - The Seahawk

While there's still more that must be done, this is a step toward that future. As we navigate the complexities of
mental health, we must not lose sight of the individual people behind the statistics - the students, faculty, families
and communities affected. Their stories, their struggles and their resilience should serve as a guiding light. We
hope that this mental health collaborative project serves as a call to action to create a future where no one suffers
in silence.

For those who have endured the loss of a loved one to suicide, battled with their own mental health challenges, or
supported someone else through their struggles, please know that you are not alone. We stand in solidarity with
you.

UNCW is no stranger to conversations about the queer community. LGBTQ issues have largely moved to the
forefront of political discussions and legal battles in both Wilmington and N.C. as a whole. In addition to the
immediate legal and educational impact, recent book bans, "Don't Say Gay" policies and other anti-trans laws
across the country are also having mental health implications for members of the queer community.

A recent study conducted by The Trevor Project, an American organization dedicated to suicide prevention efforts
for LGBTQ youth, found that 75% of LGBTQ youth nationwide often felt stress or anxiety due to threats of violence
against queer spaces; as a result many experienced cyberbullying (45%), in-school bullying (24%) or physical
assault (10%). Twenty-nine percent of queer youth also reported not visiting their doctor or hospital due to personal
safety concerns.

At UNCW, a university with an overwhelmingly straight and cisgender population, The Seahawk spoke with a few
students and recent graduates on their experiences as members of the queer community.

"Being here at UNCW has been good," Hannah Lowman, a junior criminology student said. "Luckily there's Mohin-
Scholz, which has been a really big blessing to me because they're very open, accepting and it's helped me
discover my true identity and learn a lot more about being queer than ever before."

Lowman received an associate degree from Coastal Carolina Community College before transferring to UNCW.
She came out as lesbian in March 2023, and described Mohin-Scholz, the LGBTQ+ resource center, as her "found
family," noting that her family at home was not so supportive.

"Even though there's a lot of students who are cisgender, straight, it's not forced. I do have to say that UNCW is
very accepting to students who are queer," Lowman said.

The Mohin-Scholz LGBTQIA Resource Center is located on the first floor of Fisher University Union and provides
resources such as an LGBTQIA prom, trivia nights and SAFEZONE, which are four workshops geared toward
faculty and staff that educate them on the queer community.

The director of Mohin-Scholz, Brooke Lambert, joined the center in 2016. She entered the position after a year of it
being vacant and described the post-pandemic years as the most difficult in her time of working as director.

"The whole climate on campus felt a little different than we have experienced before," Lambert said. "That's not how
I feel things are now, but last year things were not quite as supportive and welcoming as they have been
previously."

Discussion groups, called "Building Q*mmunity", are another one of the resources provided by Mohin-Scholz. The
program is not designed to be therapy, but rather to connect students with the UNCW Counseling Center. The
collaboration brings an openly queer therapist to Mohin-Scholz's space in Fisher every week.

"Knowing that queer youth experience more mental health issues, we want to make sure that that is an accessible
resource; for everybody, but we certainly want to make sure that our queer students feel like that's an accessible
resource [for them]," Lambert said.

Junior Hannah Lowman spoke with The Seahawk on finding community and acceptance at UNCW. (Courtesy:
Hannah Lowman)

                                                                                                   Page 3 of 6
          Community, isolation and politics: The mental health of queer students at UNCW - The Seahawk

Nitya Budamagunta is a student in the creative writing department at UNCW. She moved to Wilmington from Cary,
N.C., and described both cities as being fairly conservative but with "pockets" of queer people. The main difference,
Budamagunta explained, was the diversity, or lack thereof, in the queer community in Wilmington as compared to
Cary. Budamagunta spoke too on her experiences as a queer person of color and immigrant.

"With my experience as a queer person of color, the big thing for me is dealing with 'how do I blend the culture that I
come from with queerness, especially when a lot of the culture I come from is already affected by colonial ideals,"
Budamagunta explained. "Maybe my culture was more accepting of queer people in the past, but colonialism
happened and it isn't anymore."

Budamagunta has not met people at UNCW with the exact same background as her but finds acceptance and a
support system through the LGBTQ community at the university. She described struggling for over a year to find
people who understood her culture and traditions, as well as her experiences as a queer person.

"I was going to transfer my freshman year because I felt so isolated," Budamagunta said. "It was not just the fact
that I was dealing with the isolation of being in a place where nobody knew what Diwali was, but also on top of that I
was dealing with being in a place that was pretty conservative and not very open to queer people. It was really
isolating."

UNCW student Nitya Budamagunta spoke with The Seahawk about her struggles as a queer immigrant at the
university. (Courtesy: Nitya Budamagunta)

Recent graduate Michael Friant struggled to find a community with shared experiences as well, noting that having
more than one identity made it difficult for him to connect with others like him. He explained choosing Wilmington
out of convenience reasons, and initially attended CFCC before transferring to UNCW.

"As a person with a disability, cerebral palsy, it would not be feasible to just start in another city/state," Friant said. "I
never really felt I belonged. I can count on my hand the number of times people have asked me about my sexuality
and stuff."

Friant also shared a fond memory from his time at UNCW, describing the visibility he felt during one moment with a
friend.

"I was at a house party with some friends. I was hanging out on a hammock when one of my friends came over and
said 'All you need now is a cute boy by your side,'" Friant said. "In that moment, I felt seen and heard."

When asked what advice he would give to queer people considering attending UNCW, Friant marked the
importance of connecting with the local LGBTQ community. He also noted that LGBTQ students should expect to
feel lonely and be strategic about those whom they disclose their identity to.

UNCW alum Michael Friant smiles for a photograph in a t-shirt showing his pride. (Courtesy: Michael Friant)

Jaden Hager is another recent graduate of UNCW who shared their experiences with The Seahawk. They moved to
Wilmington from Mooresville, N.C., a town in the Charlotte metropolitan area. Mooresville has a small queer
community, but hosts a pride parade every year.

After starting at UNCW, Hager was conflicted when deciding whether to come out to people or not, explaining that
after living in Mooresville their entire life, many people already knew about their personal identity. Hager often felt
uncomfortable and avoided having conversations about their pronouns.

"It would be made into something bigger, so I just kind of avoided it a lot," Hager said. "I didn't want to be known as
'the non-binary person' in class. Even though I would have my pronouns in my Canvas profile, I would be
misgendered a lot. It just feels like it's going to happen no matter what."

Hager felt anxiety when making their identity visible to others. They explained the impact that being queer at UNCW
had on their mental health.

                                                                                                   Page 4 of 6
          Community, isolation and politics: The mental health of queer students at UNCW - The Seahawk

"I was very anxious all the time, like, 'Am I acting too queer? Can I make this joke? Am I hiding who I am if I don't?'"
Hager said. "I wouldn't say it affected it a lot, but it was definitely something that was an added weight to my
shoulders that I know I wouldn't've had if I wasn't queer."

Hager and Budamagunta also expressed their reactions to the 2023 Razor Walker Awards, including
discouragement, frustration and feeling unwelcome. The honors, sponsored by the Watson College of Education,
were presented in April in a yearly ceremony to those who made a positive impact on education or public schools in
N.C. UNCW's administration canceled the 2024 event, for the first time in almost three decades, after facing
widespread controversy for awarding Senator Michael Lee, the cosponsor of S.B. 49- the N.C. "Don't Say Gay" bill.

UNCW alum Jaden Hager spoke to The Seahawk about their experiences as a queer student at the university.
(Courtesy: Jaden Hager)

The Seahawk spoke with Dr. Julie Krueger, a professor at UNCW with expertise in sex work and masculinity, who
teaches courses on gender and sexuality. Queer students are well represented in these classes. Krueger's
supervisor is the first out transgender faculty member, and she explained that she navigates an environment that
does not represent UNCW as a whole.

Krueger's expertise is not in mental health or psychology. However, her studies and work at the university have
transformed the way she views the world. She had this to say about queer youth in the aftermath of the Razor
Walkers and S.B. 49.

"Living in that political climate profoundly affects students' mental health," Krueger said. "Being in an environment
where you feel you are targeted; where you feel that people are attacking you for who you are and denying you
resources; denying you opportunities and denying the legitimacy and validity of your identity; denying your very right
to exist-that's incredibly damaging."

Krueger referred to several studies, including the above by The Trevor Project, that have researched the impacts of
homophobic legislation. Anti-LGBTQ bills were consistently found to increase stress, anxiety and depression in
queer juveniles and young adults-a population that is already at a high risk for mental health issues, including
suicidal ideation.

S.B. 49 was signed into law in August 2023 after the N.C. Senate and House of Representatives both voted to
override Governor Roy Cooper's veto. Its specific, long term mental health effects are yet to be determined.

The LGBTQ community is not a monolith, a fact found to be true even in universities such as UNCW with only a
small population of queer people. Community, however, was found as a blessing, resource or desire in every
conversation The Seahawk had.

"Don't be afraid to reach out, especially to resources like the counseling center, the Student Health Center, Mohin-
Scholz, especially," Lowman said. "Those are some of the greatest resources that you could ever have. Especially
if you have family members who judge you or don't know that you're gay or disowned you; they're not gonna do
that. They're gonna love you and welcome you with open arms."

The following are additional schools in N.C. that took part in this mental health initiative:

UNC Charlotte

How UNC Charlotte's student support organizations help international students with off-campus housing challenges

Partnership between AthleteTalk and Charlotte Athletics is helping student-athletes grow mental health literacy

Wake Forest University

IfYoureReadingThis: Student-led mental health resource offers fresh perspectives

                                                                                                   Page 5 of 6
          Community, isolation and politics: The mental health of queer students at UNCW - The Seahawk

The UCC's journey from pandemic pitfalls and back

How Wake Forest trains its faculty to be on the front line of mental health care

N.C. State University

OPINION: How we talk about suicide online matters

Campus community uses AI to address mental health

East Carolina University

The community building within ECU

Morgan's Message spreads mental health awareness in student-athletes

North Carolina Agricultural and Technical State University

The state of mental health at N.C. A&T

HBCUs grapple with tuition increases and student mental health

Elon University

Phoenix Free: Sobriety on campus

Elon professor sheds light on college students with eating disorders

HealthEU moves toward new wellness center

UNC-Chapel Hill

Students and faculty reflect on university well-being days across North Carolina

How two flagship North Carolina universities responded after several student deaths

'Therapy should be affordable to everyone': CAPS addresses financial burdens of therapy

Study examines mental health impact of campus gun-related incidents

UNC students of color find mental health support through community

'It's OK to ask for assistance': How UNC's elite athletes use mental health as an edge

Club and intramural sports foster community, outlet for UNC students

Culture-responsive care addresses mental health disparities in tribal communities

LGBTQ+ support groups provide community care for substance abuse

Health humanities laboratory looks to bridge medical, social sciences

The Farm at Penny Lane grows hope through therapy programs

'It's about the process': Art therapy provides creative outlet as mental health care

Criminal justice diversion programs redirect, guide individuals

'Could have been doing this all along': State budget invests in mental health resources

                                                                                                    Page 6 of 6
           Community, isolation and politics: The mental health of queer students at UNCW - The Seahawk

NCDHHS launches child behavioral dashboard, reflects mental health data in children

Mental health providers, patients face inconsistencies in insurance coverage

Community members find mental health relief in spirituality

Editorial: Elected officials must do more for mental health

Column: Mental health is generational in minority communities. Acknowledge it

Op-ed: Make space to help those struggling with their mental health

Op-ed: It's time to replace the word 'stigma' with 'sanism'

Op-ed: UNC's win-at-all-cost attitude jeopardizes the safety of athletes

Column: Remission from major depressive disorder is possible

Duke University

Exploring how we think, feel and socialize: A look into mental health research at Duke

0


Load-Date: March 21, 2024


    End of Document

                                                                                                         Page 1 of 6
                              Digital Counties 2024: Winners Push Transparency, Engagement




          Digital Counties 2024: Winners Push Transparency, Engagement
                                                Government TechNology
                                                 July 11, 2024 Thursday



Copyright 2024 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 3412 words
Byline: Pamela Martineau, Government Technology

Body


Jul. 11—This year's Digital Counties Survey awards from the Center for Digital Government* honor local digital
government achievements in the range from enhancing cybersecurity to expanding the use of AI and analytics.

The first-place counties in each of five population categories stood out for their investments in overhauling the
critical systems that underpin government as well as their forward-thinking embrace of emerging technologies. The
IT teams in these jurisdictions are committed to offering services to all residents, meeting them where they are, as
well as improving systems for their internal staff, creating teams that value collaboration and innovation.

CALVERT COUNTY, MD., 1ST PLACE, UP TO 150,000 POPULATION CATEGORY

In Calvert County, Md., CIO Stephen Pereira highlights his department's implementation of a robust project intake
process as a major achievement of the past year.

"This initiative has streamlined how we manage and prioritize projects, ensuring that every project aligns with the
strategic goals set by the commissioners," Pereira wrote in an email to Government Technology. "By refining our
intake process, we can now better assess the value and impact of each project before committing resources."

Pereira said that the new intake process has improved not only his own department's efficiency, but helped how
they support other county agencies.

"In the rush to implement systems and provide exceptional customer service, it's easy to overlook internal
deficiencies. Our new intake process addresses this by ensuring we undertake projects that truly align with our
strategic objectives and deliver maximum value to the county," he added.

Pereira also cites the integration of service level agreements (SLAs) within its ServiceNow platform as a key
achievement.

"This integration is likely to have a lasting impact as it standardizes our service delivery and sets clear expectations
for performance. By enforcing SLAs, we can hold ourselves and other departments accountable, ensuring that IT

                                                                                                        Page 2 of 6
                          Digital Counties 2024: Winners Push Transparency, Engagement

resources are used efficiently and effectively," he said. "This has helped us to do more with less, optimizing our
operations and improving service delivery across the board. The clear, measurable standards provided by SLAs
enable us to maintain high levels of customer service while managing our resources more strategically."

Pereira added that both initiatives have "strengthened our internal processes, allowing us to support the county's
broader goals more effectively. By focusing on internal efficiency and strategic alignment, we have positioned
ourselves to better serve the community and drive future innovations."

Pereira also said counties looking to enhance their digital profiles should "embrace change management."

"Effective change management is crucial for the successful implementation of digital initiatives. Engage
stakeholders frequently through regular meetings to ensure everyone is involved in the process and their concerns
are validated," he advised. "In Calvert County, we have implemented a structured approach where IT leadership
holds quarterly meetings with department heads to align projects with county priorities and address any issues. This
inclusive approach helps to build consensus, foster collaboration and ensure that all voices are heard. By making
change management a priority, counties can navigate the complexities of digital transformation more smoothly and
ensure sustainable success."

Understanding and governing your data is also key.

"Getting to grips with data is fundamental for any digital transformation," Pereira said. "Establish data owners and
data stewards to ensure accountability and clarity in data management. It's important for users to understand their
data, its significance and how to use it effectively."

"In Calvert County, we have developed a comprehensive data classification policy to govern data use and
protection, ensuring data quality and reliability. This supports data-informed decision-making, enhances
transparency and builds trust in county operations," he said. "By establishing robust data governance practices,
counties can position themselves for more rapid AI adoption and other advanced technologies."

Pereira also advises counties to lean into AI to improve service delivery and drive innovation.

"AI is moving incredibly fast, and it may never move this slowly again. Unlike traditional IT-driven changes, AI
systems provide immediate value that end users can see. It's happening now, and efforts to stop it will be futile.
Instead, leverage this opportunity to insert data stewards and tech ambassadors within departments," he said. "This
is an opportunity to truly democratize the IT stack through targeted training and clear guardrails that facilitate and
empower innovation at all levels of the organization. By focusing on empowerment and facilitating adoption, IT can
maintain or transform into its rightful place as enablers, accelerating efficiency and business transformation."

Click here to view all winners in this population category.

ARLINGTON COUNTY, VA., 1ST PLACE, 150,000 TO 249,999 POPULATION CATEGORY

CIO Norron Lee cites Arlington County's efforts to enhance digital accessibility through continued ADA compliance
a critical achievement from the last year.

"Ensuring ADA compliance in digital accessibility is crucial for providing equal access to services for all
constituents, including those with disabilities," Lee wrote in an email to Government Technology. "This initiative
demonstrates a commitment to inclusivity and ensures that all community members can effectively interact with
county services without barriers. By prioritizing accessibility, the county not only strives to meet legal requirements
but also fosters a more inclusive community, enhancing overall constituent satisfaction and engagement."

The county's implementation of its first customer relationship management (CRM) system also improved its
constituent interactions.

"The centralized CRM application fundamentally transforms constituent interactions by organizing and streamlining
outreach efforts. This system provides a unified platform for managing communications, tracking interactions and

                                                                                                        Page 3 of 6
                          Digital Counties 2024: Winners Push Transparency, Engagement

analyzing data, which enhances the efficiency and effectiveness of county services," he said. "Constituents benefit
from more personalized and responsive service, leading to higher engagement and satisfaction. Additionally, the
enriched decision-making value of the data flowing from these interactions allows the county to make more
informed and strategic decisions to better meet constituent needs."

Lee stressed that before a local government moves forward to advance its digital profile, it must understand what
residents need.

"While it can be easy to be attracted by the promise of new technologies, our experience in Arlington County
suggests that it requires a thorough understanding of our constituents' needs before we can have a meaningful
impact," he explained. "We strive to continuously review what services we offer, how and why they're offered to
better understand our gaps and opportunities to introduce, iterate, overhaul or retire technology that enables our
outcomes. Our enterprise technology group seeks to understand and partner with our line-of-business departments
to facilitate and accelerate the process above to uncover potential and prioritize value-adds for our community.

"In the end, we are here to use our expertise and experience to serve and maximize the impact and outcomes
enabled through the thoughtful application of technology," Lee continued. "Given this approach, our best advice is:
Know your community's needs that are amplified by your county's line-of-business departments, and leverage
strong partner relationships to move forward together, connected by a shared purpose."

Click here to view all winners in this population category.

CHESTERFIELD COUNTY, VA., 1ST PLACE, 250,000 TO 499,999 POPULATION CATEGORY

Scott Furman, CIO of Chesterfield County, points to the reimagining and modernization of the chesterfield.gov
website as one of the county's top digital achievements. The redesign was envisioned as a way to "keep pace with
accessibility standards and user expectations," he wrote to GovTech.

"Chesterfield County's digital engagement strategy is marked by its commitment to innovation, collaboration and
data-driven decision-making," he explained. "At the heart of our approach is a philosophy that emphasizes strategic
use of analytics and community-driven practices to enhance the digital experience for all constituents. By analyzing
user behavior and engagement trends, we've significantly optimized our website's content and structure."

Furman said that the county's focus on mobile user experience "led to a streamlined sitemap, reducing it from over
4,000 pages to under 500, without eliminating pertinent content and by prioritizing responsive design to
accommodate the growing number of mobile visitors."

Digitizing the county's end-to-end land development process was also a powerful improvement.

"Chesterfield County made significant strides in streamlining its land development process, which is crucial for
citizens and developers. By conducting a comprehensive end-to-end assessment and implementing targeted
improvements, the county achieved positive results," he states. "These include measurable reductions in average
staff days for subdivision case processing and in plat recordation time. This achievement showcases the county's
commitment to continuous improvement through improving efficiency, transparency, and service delivery via cross-
department process improvement and digital transformation."

As for advice to other counties wishing to advance their digital profile, Furman said, "Start by assuring that digital
initiatives are closely aligned with the county's overall strategic objectives to maximize impact and value. Simply, be
sure IT is focusing on what's most important and impactful for the county," he says. Other advice Furman offers:

* Focus on data-driven decision-making by leveraging data analytics and business intelligence tools to inform policy
decisions and improve service delivery.

* Regularly audit digital platforms and services, seeking user feedback to make iterative improvements.
Chesterfield's efforts in developing and delivering an enhanced and more accessible website have provided
improved user experiences.

                                                                                                       Page 4 of 6
                          Digital Counties 2024: Winners Push Transparency, Engagement

* Foster cross-departmental collaboration by establishing communities of practice to encourage ongoing
collaboration between IT and county departments to drive innovation and ultimately advance and improve digital
services. Embrace a "fit for purpose" enterprise architecture approach to identify and migrate systems to the most
appropriate hosting environment based on business need, including consideration of the cloud for improved
scalability, currency, security and risk controls, and value.

* Where and whenever possible, invest in advanced cybersecurity solutions and implement comprehensive risk
management strategies to try to stay a step or two ahead of bad actors. This not only protects the county's
computing estate and digital assets, but also builds trust with county stakeholders and constituents.

"Finally, continuously invest in workforce development by prioritizing knowledge sharing, ongoing training and
upskilling of IT staff to keep pace with evolving business needs and advancements in technologies," he added.
"Chesterfield's emphasis on career development and flexible work arrangements has helped in attracting and
retaining talent."

Click here to view all winners in this population category.

JEFFERSON COUNTY, COLO., 1ST PLACE, 500,000 TO 999,999 POPULATION CATEGORY

Moving manual processes to digital platforms was among Jefferson County, Colo.'s most recent achievements, said
the county's CIO, Andy Corbett.

This included a partnership between the county's IT team and the motor vehicle division to develop an automated
attendant/chatbot, he said, the first of its kind in the county.

Each year, Jefferson County's motor vehicle team handled more than 100,000 calls and was "overwhelmed at
certain times of the year," Corbett wrote in an email.

"By working to streamline business processes at the same time we rolled out the chatbot, Motor Vehicles was able
to reduce calls by 50 percent and resolve 60 percent of chats without any human escalation needed," he said.
"Additionally, we were able to provide 24/7 service through the chatbot for a set of activities. Citizen satisfaction
went up because citizens' issues were resolved quickly, and staff satisfaction increased because they could work
mostly on tasks that need human interaction."

Corbett said other departments in the county, like the Clerk and Recorder's Office, are now working to develop
chatbots as well.

Corbett also cites the county's efforts to update and digitize its agenda and meeting organization process as a key
achievement.

"This is critically important because it improves access to government services for our citizens," he explained.
"We've now streamlined the process of creating and posting agenda packets as well as posting online meeting
information through our jeffco.us website where anyone can access it. Additionally, we're able to provide easy
access to past meeting recordings and agendas."

As for advice for other counties wishing to advance their digital profile, Corbett recommends a bit of introspection
before tackling the job.

"You've got to take a look at what's stopping you now and start brainstorming how you can change that," he
recommended. "For example, our executive team recognized that with all the obligations we had running our
enterprise platforms, we didn't have the ability to move quickly enough on the new solutions our departments
needed. We envisioned adding another team within IT that could take business problems and run with them to find
solutions. Over time we were able to pull a few headcount out of traditional technical roles and dedicate them to
finding innovative solutions. Thus, our innovation team was a result of recognizing that our traditional structure
couldn't deliver solutions for the needs of our organization fast enough."

                                                                                                        Page 5 of 6
                          Digital Counties 2024: Winners Push Transparency, Engagement

Jefferson County officials also got "creative on staffing."

"We couldn't add any full-time headcount, so we found a way to use part-time and temporary help to drive digital
forward," Corbett said. "Today we bring in cycles of interns and fellowship positions to focus on specific needs while
also developing a pipeline of talent for the county to tap into for full-time openings. Our interns and fellows, often
current college students or recent graduates, gain great experience on specific projects while giving our
organization a shot of energy and creativity."

Corbett also counsels county officials "to involve the operational staff from your departments in the transformation
because they see the needs better than anyone else."

"For example, in one of our process improvement workshops, our Motor Vehicle staff chose a manual reconciliation
process to rework," he explained. "Frontline staff and management worked together to redesign a cash
reconciliation process that was manual, inefficient and time-consuming. By having the frontline staff in the room and
working together with management, the team developed a way to automate and digitize the process, which saved
1,000 employee hours, 10,000 pieces of paper, and completed the task with greater accuracy."

Click here to view all winners in this population category.

ALAMEDA COUNTY, CALIF., 1ST PLACE, 1 MILLION OR MORE POPULATION CATEGORY

Tim Dupuis, chief information officer for Alameda County, said that the vision for the county's technology endeavors
is to advance a "secure, digital government, accessible anytime, anywhere."

"To that end, I believe perseverance and a high-performance team are essential to our digital success," Dupuis
wrote in an email. "My advice to any county looking to enhance their digital footprint is to start by creating a high-
performance team. Focus on building a team that is not only highly skilled, motivated and engaged, but one that
delivers excellent customer service with the best technical expertise."

Dupuis said Alameda County works to build a modern workplace that attracts top talent and fosters teamwork.

"Every year, our People Plan is updated to identify focus areas for employee retention, development and growth,
with an emphasis on promoting from within and succession planning to ensure that we can weather change," he
said. "Celebrating successes, creating team events, volunteering to help the community, and providing new
challenges for growth are key to maintaining a happy, motivated workforce. Without our amazing technology team
and the great partnership with our business partners, Alameda County would not be able to deliver the digital
services that our employees and constituents have come to expect."

Dupuis is proud of the work the county has done to modernize its systems, including investments that led to:

* 40 percent of on-premise workload migrated to Azure for resiliency and redundancy.

* 40-year-old COBOL automated warrant system replaced with a modern, in-house solution.

* 30-year-old CLETS Switch replaced with a SAAS solution.

* Work toward replacing a 20-year-old budget system with a software-as-a-service solution.

* An RFP to outsource support for the mainframe.

* Implementing a new cloud-based contact center to replace the old, on-premise version.

* Work toward converting a 40-year-old property system from COBOL to .NET.

"Modernizing our legacy systems has been a journey of perseverance for over 20 years, and we are not done,"
Dupuis added. "Some systems, like our Criminal Justice System, are due to be replaced again, highlighting that
modernization will always be part of our strategic plan."

                                                                                                       Page 6 of 6
                          Digital Counties 2024: Winners Push Transparency, Engagement

Strengthening cybersecurity was another key accomplishment, Dupuis said, adding that the county established a
skilled cybersecurity team, including a new security program manager, and doubled its staff.

"The cybersecurity landscape is extremely challenging and constantly evolving. Every day, we must protect the
county from relentless espionage and ransomware attacks while continuously updating and strengthening our
defenses," he said. "These attacks are constant as we advance our cybersecurity initiatives, build and train our
security team, and strengthen our strategic partnerships for improved protection."

Over the last year, Alameda County embraced new technologies and policies to help the cybersecurity team
identify, assess and respond to cybersecurity notifications and incidents, including:

* Held attack simulations and tabletop exercises with internal departments and external local, regional, state and
federal partners to help prepare for large-scale cyber attacks.

* Held a roundtable in partnership with the National Association of Counties and county agency and department
heads to simulate and discuss how to manage operations during a major cyber attack.

* Regular cybersecurity awareness training for all county employees, which covers how to stay cyber safe, identify
phishing attacks, the risks of QR codes and the importance of using multifactor authentication. Activities during the
county's Cybersecurity Awareness Month include industry-expert speaking events, cybersecurity-related games,
fun TikTok-style videos, and email tips and tricks on staying cyber safe both at work and at home.

Dupuis is also proud of Alameda's advances in AI. The county has deployed six AI-enabled chatbots for health
care, probation, service desk, public works, human resources and the social services agency. Two more are in
progress, Dupuis reports. The county has drafted a generative AI policy that embraces the technology and cautions
about the risks. They also held an AI "idea" hackathon called AI'ing the County, which enlisted employees to
brainstorm AI solutions. Over 100 employees participated, and 25 ideas were presented.

Click here to view all winners in this population category.

Read about all winners in this year's Digital Counties Survey:

Up to 150,000 Population Category

150,000 to 249,999 Population Category

250,000 to 499,999 Population Category

500,000 to 999,999 Population Category

1 Million or More Population Category

*The Center for Digital Government is part of e.Republic, Government Technology's parent company.

___ (c)2024 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: July 12, 2024


  End of Document

                                                                                                           Page 1 of 1
                                          Cleveland Clinic names first chief AI officer




                             Cleveland Clinic names first chief AI officer
                                                   Crain's Cleveland Business
                                                          August 5, 2024
                                                           Print Version



Copyright 2024 Crain Communications All Rights Reserved




Section: Pg. 3; Vol. 45
Length: 199 words
Byline: Hayley DeSilva

Body


Cleveland Clinic has named Ben Shahshahani as its first chief artificial intelligence officer, continuing the trend of
health care providers creating leadership roles to support AI ventures.

Shahshahani has served as senior vice president of science, machine learning and product analytics for SiriusXM
and Pandora since 2021. Previously, he held leadership roles with Verizon Media, Yahoo, Google, Nuance and
IBM.

More health care organizations are adding AI executive positions as the technology's presence in the industry
continues to grow, including Indianapolis-based insurer Elevance Health and Richmond, Virginia-based VCU
Health. Federal agencies have also created leadership roles and task forces to oversee AI in health care.

"Cleveland Clinic sees great promise for artificial intelligence in health care, as it has the ability to improve care for
patients and streamline work for caregivers," said Rohit Chandra, chief digital officer for Cleveland Clinic. "However,
we need to be thoughtful about how we implement it. Ben has a track record of effectively and strategically applying
new technologies to create beneficial change for organizations."

He will begin his new role in August.


Load-Date: August 8, 2024


  End of Document

                                                                                                        Page 1 of 1
                      Samsung Electronics' affiliate completes acquisition of French startup Sonio




Samsung Electronics' affiliate completes acquisition of French startup Sonio


                                                        ASEAN Tribune
                                                   September 2, 2024 Monday



Copyright 2024 ASEAN Tribune All Rights Reserved




Length: 182 words

Body


 02 Sep 2024 (Yonhap News Agency) Samsung Medison Co., a medical equipment unit of Samsung Electronics
Co., said Monday it has completed the acquisition of the French artificial intelligence medtech startup Sonio, as part
of its effort to expand its AI-powered health care solution business.

The Korean company acquired 100 percent of Sonio on Friday, a startup specializing in AI development for
diagnostic reporting in obstetrics and gynecology ultrasound.

The acquisition follows a share purchase agreement between the two companies made in May.

Samsung Medison said the synergy between Sonio's AI solution and Samsung's existing technologies will help the
company further improve efficiency in the medical field and contribute to closing the global health care gap.

Founded in 2020, the Paris-based startup has developed an AI-powered prenatal screening solution that automates
ultrasound reporting.

Sonio's key product, Sonio Detect, AI-powered software designed to identify prenatal syndromes and abnormalities
through ultrasound, won approval from the U.S. Food and Drug Administration in 2023.


Load-Date: September 3, 2024


  End of Document

                                                                                                        Page 1 of 6
       34th annual Beautiful Bakersfield Awards to honor individuals, organizations building a better Bakersfield




34th annual Beautiful Bakersfield Awards to honor individuals, organizations
                        building a better Bakersfield
                                                        The Bakersfield Californian
                                                            June 21, 2024 Friday



Copyright 2024 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 1123 words
Byline: Greater Bakersfield Chamber, The Bakersfield Californian

Body


The Greater Bakersfield Chamber is proud to host the 34th Annual Beautiful Bakersfield Awards, presented by
Valley Strong Credit Union. The awards celebrate the individuals, organizations and businesses dedicated to
building something better.

The "old Hollywood"-themed awards gala is scheduled for Saturday at the Mechanics Bank Theater and
Convention Center, and promises to be an evening of inspiration and celebration.

The prestigious event will recognize 86 nominees across 17 categories, each exemplifying the spirit of service and
excellence that defines Bakersfield. Nominated by community members and vetted by the Beautiful Bakersfield
Committee, the following finalists represent the pinnacle of local achievement and dedication.

The festivities will kick off with a check-in and red carpet reception at 5 p.m., followed by the awards ceremony at 7
p.m. Tune in to celebrate the achievements and recognition of all the nominees. The community can livestream the
awards show on KGET-TV 17â€™s Facebook and kget.com. For the latest updates and detailed information, visit
beautiful.bakochamber.com and follow us on social media.

The award recipients will be announced in Sunday's newspaper.

A Better Bakersfield

Sponsored by Kaiser Permanente Kern County

An annual event or project that enhances the quality of life in the community.

â— Alzheimer's Disease Association of Kern County - Senior Prom

â— The Active Bakersfield Alliance - The Bakersfield Marathon

â— Blues Zones Project - Tobacco Retail License

                                                                                                      Page 2 of 6
     34th annual Beautiful Bakersfield Awards to honor individuals, organizations building a better Bakersfield

â— California Living Museum - Holiday Lights

â— Children First - East Bakersfield Festival

â— Night to Shine Bakersfield - Annual Prom

â— Upside Academy Inc. - Christmas in the Neighborhood

â— Wildlands Conservancy - Spring Nature Festival

Architecture & Design

Sponsored by Ordiz-Melby Architects

The completion of a brand-new interior and/or exterior building design integrating the environment with space and
materials.

â— Beautiful You Medical Aesthetics

â— Kaiser Permanente Dermatology Clinic

Renovation & Tenant Improvement

Sponsored by Vecchio's

The completion of a renovated design that upgrades an existing structure and/or incorporates landscaping to
enhance the property's aesthetic value.

â— Brickyard Downtown

â— CLTV Gyms

â— The Mission at Kern County

Urban Revitalization

Sponsored by Vice Mayor and Ward 2 City Councilmember Andrae Gonzales

An individual, business or organization that has made a meaningful contribution in the past year to placemaking,
reimagining how we live, work and play.

â— Children First

â— Leadership Bakersfieldâ€™s Team 3

â— Sage Equities

Arts & Culture

Sponsored by County of Kern

Efforts by a group or individual to improve and/or enhance the arts and culture within our community.

â— Bakersfield Museum of Art

â— Erica Ueberroth

â— Kern Dance Alliance

                                                                                                      Page 3 of 6
     34th annual Beautiful Bakersfield Awards to honor individuals, organizations building a better Bakersfield

â— Notorious Bakersfield

â— Zane Adamo (The Soda Crackers)

Education

Sponsored by California Resources Corporation

Efforts by an educator, project or school/college that promote or benefit education in our city at all levels.

â— Bakersfield Museum of Art

â— CSUB, School of Natural Sciences, Mathematics, and Engineering Grants and Outreach

â— Do the Math

Health

Sponsored by Heart Vascular and Leg Center

An individual, group or organization impacting healthy living â€” above and beyond their normal scope of activities
â€” through education, prevention or medical services.

â— Acoustic Remedies Program

â— Adventist Health AIS Cancer Center

â— Ashton Chase

â— Bakersfield College Edible Education Garden

â— Kern Medical

â— Niesha Davis

Humanitarian Individual

Sponsored by Dignity Health Bakersfield Mercy & Memorial Hospitals

An individual whose personal volunteer efforts have significantly impacted the community.

â— Bianca Haynes

â— Judy Goad

â— Kathy Shank Bess

â— Madison Garrett

â— Odessa Perkins

â— Traco Matthews

â— Zoe Gudino

Humanitarian Group

Sponsored by Chevron

                                                                                                      Page 4 of 6
     34th annual Beautiful Bakersfield Awards to honor individuals, organizations building a better Bakersfield

A group whose personal volunteer efforts have significantly impacted the community.

â— Leadership Bakersfieldâ€™s Team 3

â— Noel Alexandria Foundation

â— Sleepy Baby Box Foundation

â— Stockdale Moose Lodge

â— Stockdale High School National Honor Society

â— Transitional Youth Mobilizing for Change

Small Nonprofit of the Year

Sponsored by Kern Health Systems

A 501(c)(3) nonprofit organization that reported under $99K in taxable income and had a positive impact on the
community.

â— Agricultural Family Fund

â— Apple Core Project

â— Charmed & Chosen

â— CSF Medical Non-Profit Foundation

â— Oildale Community Action Team

Large Nonprofit of the Year

Sponsored by Kern Community Foundation

A 501(c)(3) nonprofit organization that reported over $100K in taxable income and had a positive impact on the
community.

â— Amelia Molloyâ€™s Angels

â— Bakersfield Angels

â— Church Without Walls

â— Children First

â— R.M. Pyles Boys Camp

â— Tigerfight Foundation

â— Valley Center for the Blind

â— Youth 2 Leaders Education Foundation

Next Gen

Sponsored by Kern County Superintendent of Schools

                                                                                                      Page 5 of 6
     34th annual Beautiful Bakersfield Awards to honor individuals, organizations building a better Bakersfield

An individual or group in grades K-12 that, through personal involvement and endeavors, has answered the
challenge of good citizenship.

â— Braya Stotler

â— Carter Beardsley

â— Gisselle Guerrero

â— Javen Freeborn

â— Katie Johnson

Young Professional

Sponsored by Clifford & Bradford Insurance Agency

An individual, age 18-40, whose efforts truly impact and enhance the quality of life in the community.

â— Cherrity Ricks

â— Fatima "Teems" Tulfo

â— Dr. Fernando Garcia III

â— Karina Funez

â— Mitchall Patel

Business Person of the Year

Sponsored by Grapevine MSP, LLC

A local business owner/manager whose efforts truly impact and enhance the quality of life in the community.

â— Dr. Anna Marie Frank

â— Katie Moradkhani

â— Larissa Mitchell

Small Business of the Year

Sponsored by Bank of America

A small business (25 employees or less) whose contributions and/or products and services instill community pride.

â— Citryn Marketing

â— Inovia Pharmacy

â— PorkChop & Bubba's BBQ

â— Rainbow Restoration of Bakersfield

â— Small Business Celebration

â— The Playful Space

                                                                                                      Page 6 of 6
     34th annual Beautiful Bakersfield Awards to honor individuals, organizations building a better Bakersfield

Large Business/Corporation of the Year

Sponsored by the City of Bakersfield

The recognition of a large business (26 employees or more) whose volunteer hours and/or financial donations have
made a meaningful difference.

â— Access Plus Capital

â— Bank of America

â— Bristol Hospice Bakersfield

â— Global Clean Energy

â— KGET-TV 17 News

â— Valley Strong Credit Union

Harvey L. Hall Lifetime Achievement

Sponsored by Hall Ambulance Service

A local, long-time community leader, age 55 and over, who has made a lasting impact on Bakersfield and its
residents.

â— Dean McGee

â— Maryann Paciullo

â— Patsy Romero

â— Dr. Richard Casteen

â— Dr. Royce H. Johnson

â— Stan Moe

___ (c)2024 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: June 23, 2024


  End of Document

                                                                                                       Page 1 of 2
                               Neurotech startup looks to open clinical trials center in Bakersfield




         Neurotech startup looks to open clinical trials center in Bakersfield
                                                        The Bakersfield Californian
                                                         January 8, 2024 Monday



Copyright 2024 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: BUSINESS AND FINANCIAL NEWS
Length: 787 words
Byline: John Cox, The Bakersfield Californian

Body


Jan. 8—The promise of neurotechnology stokes Kern's economic development hopes today with an announcement
that a startup out of Cambridge, UK has chosen Bakersfield to locate a high-tech center for clinical trials aimed at
developing neural digital therapies.

BIOS Health, whose real-time, AI-assisted neural data monitoring platform has won a partnership with the National
Institutes of Health and investors including Kern Venture Group, said in a news release today the new center will
attract an ecosystem of pharmaceutical and medical device companies, clinicians and clinical trial partners. The
plan also calls for hosting neurotech conferences in Bakersfield.

This page requires Javascript.

Javascript is required for you to be able to read premium content. Please enable it in your browser settings.

kAmrt~ 2?5 4@\7@F?56C t>:= w6H286 42==65 z6C? E96 4@>A2?JVD Q4@>>6C4:2= 362499625[Q D2J:?8 :?
2? :?E6CG:6H qx~$ H2?ED E@ 36 ?62C 3FE ?@E E@@ 4=@D6 E@ 3:@C6D62C49 9F3D =:A2?J 6IA64ED
E@ 5@ D@>6 =@42= 9:C:?8 H9:=6 2=D@ 3C:?8:?8 A6CD@??6= 7C@> 6=D6H96C6j 36D:56D r2>3C:586[
qx~$ 92D 6>A=@J66D :? |@?EC62= 2E 2 ?6FC@D4:6?46 C6D62C49 D:E6 :E 6DE23=:D965 :? a_'g] x7 q26D
E96 4=:?:42= EC:2=D 9F3 w6H286 6?G:D:@?D[ E96 4@>A2?J H@F=5 6IA64E E@ 3C:?8 @? 2?5 EC2:?
255:E:@?2= H@CA@C2C:=J 96=A qx~$ 4@G6C E96 H286D @7 2?J ?6H 6>A=@J66D :? E96 4@F?EJ] %96
4:EJ @7 q2A2?J E@ 6DE23=:D9 2 =@42= AC6D6?46j 2 DA@2? 564=:?65 E@ 4@>>6?E @? E9@D6
677@CED A6?5:?8 E@52JVD 2??@F?46>6?E]k^Am

kAmr=:?:42= EC:2=D 92G6 7@C >@C6 E92? 2 564256 366? 2DD@4:2E65 H:E9 9:89\E649 >65:4:?6 :?
q2AC696?D:G6 q=@@5 U2>Aj r2?46C r6?E6C 92D 366? :?G@=G65 :? ?F>6C@FD C6D62C49 EC:2=D[ 2?5 :E
H2D E9C@F89 4@??64E:@?D 2E rqrr E92E qx~$ 7:CDE 42>6 E@ DA62H:E9 A6@A=6 :? z6C?]k^Am

kAmqFE @E96CH:D6[ =@42= 64@?@>:4 56G6=@A>6?E 677@CED 92G6 @G6C=@@2?286>6?E[
26C@DA246[ AC64:D:@? >2?F724EFC:?8 2?5 @FED@FC465 3FD:?6DD AC@46DD6D] $E:==[ 92G:?8 :?

                                                                                                         Page 2 of 2
                         Neurotech startup looks to open clinical trials center in Bakersfield

A=246 2 =@42= 4@2=:E:@? C646AE:G6 E@ ?6H 3FD:?6DD @AA@CEF?:E:6D >2J 92G6 A2:5 @77 :? E96
42D6 @7 qx~$]k^Am

kAmr@\7@F?56C 2?5 |2?28:?8 !2CE?6C s2G:5 w:85@? 2E z6C? '6?EFC6 vC@FA[ E96 4@F?EJVD @?=J
2?86= :?G6DE@C @C82?:K2E:@?[ D2:5 96 925?VE :>28:?65 E96 4@F?EJ >:89E @?6 52J =2?5 2 AC64:D:@?
>65:4:?6 4@>A2?J H:E9 2D >F49 A@E6?E:2= E@ D42=6 FA 2D qx~$ 2AA62CD E@ 92G6]k^Am

kAmQ(6VC6 ;FDE 2D A=62D2?E=J DFCAC:D65 2D 2?J3@5J[Q 96 D2:5]k^Am

kAmw:85@? 2EEC:3FE65 E96 562=[ :? A2CE[ E@ z6C? 36:?8 46?EC2==J =@42E65[ 277@C523=6 2?5
H6=4@>:?8] |2J36 :E H:== AFE q22A :? 2 ?6H H2J[ 96 D2:5]k^Am

kAm%96 4@F?EJVD 49:67 64@?@>:4 56G6=@A>6?E @77:46C[ y:> s2>:2?[ D2:5 qx~$ >2J BF2=:7J 7@C
DF3D:5:K65 A2JC@== @77D6ED 5FC:?8 :ED 7:CDE D:I >@?E9D :? z6C?] $E277 2=D@ :?E6?5 E@ @776C
4@??64E:@?D E@ @E96C A@E6?E:2= 7@C>D @7 2DD:DE2?46[ 2D H6== 2D A2CE:4:A2E:@? :? 2??F2=
?6FC@E649\px 4@?76C6?46D]k^Am

kAmQ(6 H2?E :??@G2E:@? :? z6C? r@F?EJ[ 2?5 E96 C68:@?VD H:==:?8 E@ DFAA@CE :??@G2E:@?[Q 96
D2:5]k^Am

kAmx? E@52JVD ?6HD C6=62D6[ E96 :?E6C:> 5:C64E@C @7 q2:4 U2>Aj r@>>F?:EJ s6G6=@A>6?E
s6A2CE>6?E[ y6??: qJ6CD[ D2:5 DE277 2C6 4@?7:56?E E96 4:EJVD DFAA@CE @7 q:@D H:== 36 2?
:>A@CE2?E :?G6DE>6?E :? E96 7FEFC6 @7 q2A2?J] $96 5:5 ?@E :?5:42E6 H92E E92E DFAA@CE >:89E
:?G@=G6]k^Am

kAmqx~$[ 7@F?565 :? a_'d[ D2JD :E 92D A:@?66C65 E649?@=@8J E@ C625 2?5 :?E6CAC6E ?6FC2=
D:8?2=D H:E9 E96 36?67:E @7 px[ 2==@H:?8 :E E@ AC@G:56 :>>65:2E6 :?D:89ED E@ 4@>A2?:6D E92E
H2?E E@ 56G6=@A ?6H >65:42= EC62E>6?ED[ :7 @?=J E96J 925 2446DD E@ E96 =@H6C\4@DE[ BF:4A2?J
2??@F?465 :ED C646:AE @7 42A:E2= :?G6DE>6?E 7C@> D6G6C2= D@FC46D] t2C=:6C[ :? }@G6>36C a_aa[
E96 4@>A2?J D2:5 :ED 52E2 A=2E7@C> H:== D6CG6 E96 =2C86DE\6G6C DEF5J @7 E96 9F>2? G28FD
?6CG6[ :? 4@==23@C2E:@? H:E9 E96 }xw 2?5 @E96C >2;@C :?DE:EFE:@?D]k^Am

kAm%96 6IA2?D:@? :?E@ q22CA2?JVD =2F?49 @7 :ED AC:>2CJ 4@>>6C4:2=:K2E:@? DE286] w6 D2:5
=@42E:?8 :? q265:42= 56G:46 4@>A2?:6D 7C@> $2? s:68@ E@ $2? uC2?4:D4@ E92E E6?5 E@ 5C:G6
DA6?5:?8 @? 4=:?:42= EC:2=D]k^Am

kAm%96C6VD 2 36?67:E E@ D6EE:?8 FA D9@A 36J@?5 E96 3@C56CD @7 2 C68:@? 2=C625J 5@>:?2E65
3J =2C86 3:@E649 4@>A2?:6D[ 96 D2:5[ 255:?8[ QxEVD 8@@5 E92E E9:D :D ?@E J6E $2? s:68@[
@E96CH:D6 H6V5 92G6 E@ DE2CE D@>6H96C6 6=D6]Qk^Am

kAm!2CE?6CD9:AD H:E9 =@42= 962=E9\42C6 46?E6CD 2C6 2=C625J :? E96 H@C66E:?8 2?5 7@C>:?8
4@==23@C2E:@?D 92D 366? A2CE @7 86EE:?8 E@ 6?E E92EVD 4@?5F4:G6 E@ :?G6DE>6?E] {@42=
3FD:?6DD6D 2?5 :?G6DE@CD Q2C6 C62==J E:89E=J :?E68C2E65Q :? z6C?[ 96 D2:5]k^Am

kAmqx~$ H:== 2== 96254@F?E 2E 7:CDE 2D :E 7@C86D A2CE?6CD9:AD 2?5 =@@:4 8C@HE9 4@F=5 4@>6
7C@> @E96C 4@>A2?:6D E92E 96 6IA64ED H:== :?EC@5F46 4@>A=6>6?E2CJ D6CG:46D =@42==J]k^Am

___ (c)2024 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: January 11, 2024


  End of Document

                                                                                                       Page 1 of 2
                               Neurotech startup looks to open clinical trials center in Bakersfield




         Neurotech startup looks to open clinical trials center in Bakersfield
                                                        The Bakersfield Californian
                                                         January 8, 2024 Monday



Copyright 2024 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: BUSINESS AND FINANCIAL NEWS
Length: 783 words
Byline: John Cox, The Bakersfield Californian

Body


Jan. 8—The promise of neurotechnology stokes Kern's economic development hopes today with an announcement
that a startup out of Cambridge, UK has chosen Bakersfield to locate a high-tech center for clinical trials aimed at
developing neural digital therapies.

BIOS Health, whose real-time, AI-assisted neural data monitoring platform has won a partnership with the National
Institutes of Health and investors including Kern Venture Group, said in a news release today the new center will
attract an ecosystem of pharmaceutical and medical device companies, clinicians and clinical trial partners. The
plan also calls for hosting neurotech conferences in Bakersfield.

×

Javascript is required for you to be able to read premium content. Please enable it in your browser settings.

kAmrt~ 2?5 4@\7@F?56C t>:= w6H286 42==65 z6C? E96 4@>A2?JVD Q4@>>6C4:2= 362499625[Q D2J:?8 :?
2? :?E6CG:6H qx~$ H2?ED E@ 36 ?62C 3FE ?@E E@@ 4=@D6 E@ 3:@C6D62C49 9F3D =:A2?J 6IA64ED
E@ 5@ D@>6 =@42= 9:C:?8 H9:=6 2=D@ 3C:?8:?8 A6CD@??6= 7C@> 6=D6H96C6j 36D:56D r2>3C:586[
qx~$ 92D 6>A=@J66D :? |@?EC62= 2E 2 ?6FC@D4:6?46 C6D62C49 D:E6 :E 6DE23=:D965 :? a_'g] x7 q26D
E96 4=:?:42= EC:2=D 9F3 w6H286 6?G:D:@?D[ E96 4@>A2?J H@F=5 6IA64E E@ 3C:?8 @? 2?5 EC2:?
255:E:@?2= H@CA@C2C:=J 96=A qx~$ 4@G6C E96 H286D @7 2?J ?6H 6>A=@J66D :? E96 4@F?EJ] %96
4:EJ @7 q2A2?J E@ 6DE23=:D9 2 =@42= AC6D6?46j 2 DA@2? 564=:?65 E@ 4@>>6?E @? E9@D6
677@CED A6?5:?8 E@52JVD 2??@F?46>6?E]k^Am

kAmr=:?:42= EC:2=D 92G6 7@C >@C6 E92? 2 564256 366? 2DD@4:2E65 H:E9 9:89\E649 >65:4:?6 :?
q2AC696?D:G6 q=@@5 U2>Aj r2?46C r6?E6C 92D 366? :?G@=G65 :? ?F>6C@FD C6D62C49 EC:2=D[ 2?5 :E
H2D E9C@F89 4@??64E:@?D 2E rqrr E92E qx~$ 7:CDE 42>6 E@ DA62H:E9 A6@A=6 :? z6C?]k^Am

kAmqFE @E96CH:D6[ =@42= 64@?@>:4 56G6=@A>6?E 677@CED 92G6 @G6C=@@2?286>6?E[
26C@DA246[ AC64:D:@? >2?F724EFC:?8 2?5 @FED@FC465 3FD:?6DD AC@46DD6D] $E:==[ 92G:?8 :?

                                                                                                         Page 2 of 2
                         Neurotech startup looks to open clinical trials center in Bakersfield

A=246 2 =@42= 4@2=:E:@? C646AE:G6 E@ ?6H 3FD:?6DD @AA@CEF?:E:6D >2J 92G6 A2:5 @77 :? E96
42D6 @7 qx~$]k^Am

kAmr@\7@F?56C 2?5 |2?28:?8 !2CE?6C s2G:5 w:85@? 2E z6C? '6?EFC6 vC@FA[ E96 4@F?EJVD @?=J
2?86= :?G6DE@C @C82?:K2E:@?[ D2:5 96 925?VE :>28:?65 E96 4@F?EJ >:89E @?6 52J =2?5 2 AC64:D:@?
>65:4:?6 4@>A2?J H:E9 2D >F49 A@E6?E:2= E@ D42=6 FA 2D qx~$ 2AA62CD E@ 92G6]k^Am

kAmQ(6VC6 ;FDE 2D A=62D2?E=J DFCAC:D65 2D 2?J3@5J[Q 96 D2:5]k^Am

kAmw:85@? 2EEC:3FE65 E96 562=[ :? A2CE[ E@ z6C? 36:?8 46?EC2==J =@42E65[ 277@C523=6 2?5
H6=4@>:?8] |2J36 :E H:== AFE q22A :? 2 ?6H H2J[ 96 D2:5]k^Am

kAm%96 4@F?EJVD 49:67 64@?@>:4 56G6=@A>6?E @77:46C[ y:> s2>:2?[ D2:5 qx~$ >2J BF2=:7J 7@C
DF3D:5:K65 A2JC@== @77D6ED 5FC:?8 :ED 7:CDE D:I >@?E9D :? z6C?] $E277 2=D@ :?E6?5 E@ @776C
4@??64E:@?D E@ @E96C A@E6?E:2= 7@C>D @7 2DD:DE2?46[ 2D H6== 2D A2CE:4:A2E:@? :? 2??F2=
?6FC@E649\px 4@?76C6?46D]k^Am

kAmQ(6 H2?E :??@G2E:@? :? z6C? r@F?EJ[ 2?5 E96 C68:@?VD H:==:?8 E@ DFAA@CE :??@G2E:@?[Q 96
D2:5]k^Am

kAmx? E@52JVD ?6HD C6=62D6[ E96 :?E6C:> 5:C64E@C @7 q2:4 U2>Aj r@>>F?:EJ s6G6=@A>6?E
s6A2CE>6?E[ y6??: qJ6CD[ D2:5 DE277 2C6 4@?7:56?E E96 4:EJVD DFAA@CE @7 q:@D H:== 36 2?
:>A@CE2?E :?G6DE>6?E :? E96 7FEFC6 @7 q2A2?J] $96 5:5 ?@E :?5:42E6 H92E E92E DFAA@CE >:89E
:?G@=G6]k^Am

kAmqx~$[ 7@F?565 :? a_'d[ D2JD :E 92D A:@?66C65 E649?@=@8J E@ C625 2?5 :?E6CAC6E ?6FC2=
D:8?2=D H:E9 E96 36?67:E @7 px#[ 2==@H:?8 :E E@ AC@G:56 :>>65:2E6 :?D:89ED E@ 4@>A2?:6D E92E
H2?E E@ 56G6=@A ?6H >65:42= EC62E>6?ED[ :7 @?=J E96J 925 2446DD E@ E96 =@H6C\4@DE[ BF:4A2?J
2??@F?465 :ED C646:AE @7 42A:E2= :?G6DE>6?E 7C@> D6G6C2= D@FC46D] t2C=:6C[ :? }@G6>36C a_aa[
E96 4@>A2?J D2:5 :ED 52E2 A=2E7@C> H:== D6CG6 E96 =2C86DE\6G6C DEF5J @7 E96 9F>2? G28FD
?6CG6[ :? 4@==23@C2E:@? H:E9 E96 }xw 2?5 @E96C >2;@C :?DE:EFE:@?D]k^Am

kAm%96 6IA2?D:@? :?E@ q22CA2?JVD =2F?49 @7 :ED AC:>2CJ 4@>>6C4:2=:K2E:@? DE286] w6 D2:5
=@42E:?8 :? q265:42= 56G:46 4@>A2?:6D 7C@> $2? s:68@ E@ $2? uC2?4:D4@ E92E E6?5 E@ 5C:G6
DA6?5:?8 @? 4=:?:42= EC:2=D]k^Am

kAm%96C6VD 2 36?67:E E@ D6EE:?8 FA D9@A 36J@?5 E96 3@C56CD @7 2 C68:@? 2=C625J 5@>:?2E65
3J =2C86 3:@E649 4@>A2?:6D[ 96 D2:5[ 255:?8[ QxEVD 8@@5 E92E E9:D :D ?@E J6E $2? s:68@[
@E96CH:D6 H6V5 92G6 E@ DE2CE D@>6H96C6 6=D6]Qk^Am

kAm!2CE?6CD9:AD H:E9 =@42= 962=E9\42C6 46?E6CD 2C6 2=C625J :? E96 H@C66E:?8 2?5 7@C>:?8
4@==23@C2E:@?D 92D 366? A2CE @7 86EE:?8 E@ 6?E E92EVD 4@?5F4:G6 E@ :?G6DE>6?E] {@42=
3FD:?6DD6D 2?5 :?G6DE@CD Q2C6 C62==J E:89E=J :?E68C2E65Q :? z6C?[ 96 D2:5]k^Am

kAmqx~$ H:== 2== 96254@F?E 2E 7:CDE 2D :E 7@C86D A2CE?6CD9:AD 2?5 =@@:4 8C@HE9 4@F=5 4@>6
7C@> @E96C 4@>A2?:6D E92E 96 6IA64ED H:== :?EC@5F46 4@>A=6>6?E2CJ D6CG:46D =@42==J]k^Am

___ (c)2024 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: January 8, 2024


  End of Document

                                                                                                       Page 1 of 2
                               Neurotech startup looks to open clinical trials center in Bakersfield




         Neurotech startup looks to open clinical trials center in Bakersfield
                                                        The Bakersfield Californian
                                                         January 8, 2024 Monday



Copyright 2024 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: BUSINESS AND FINANCIAL NEWS
Length: 787 words
Byline: John Cox, The Bakersfield Californian

Body


Jan. 8—The promise of neurotechnology stokes Kern's economic development hopes today with an announcement
that a startup out of Cambridge, UK has chosen Bakersfield to locate a high-tech center for clinical trials aimed at
developing neural digital therapies.

BIOS Health, whose real-time, AI-assisted neural data monitoring platform has won a partnership with the National
Institutes of Health and investors including Kern Venture Group, said in a news release today the new center will
attract an ecosystem of pharmaceutical and medical device companies, clinicians and clinical trial partners. The
plan also calls for hosting neurotech conferences in Bakersfield.

This page requires Javascript.

Javascript is required for you to be able to read premium content. Please enable it in your browser settings.

kAmrt~ 2?5 4@\7@F?56C t>:= w6H286 42==65 z6C? E96 4@>A2?JVD Q4@>>6C4:2= 362499625[Q D2J:?8 :?
2? :?E6CG:6H qx~$ H2?ED E@ 36 ?62C 3FE ?@E E@@ 4=@D6 E@ 3:@C6D62C49 9F3D =:A2?J 6IA64ED
E@ 5@ D@>6 =@42= 9:C:?8 H9:=6 2=D@ 3C:?8:?8 A6CD@??6= 7C@> 6=D6H96C6j 36D:56D r2>3C:586[
qx~$ 92D 6>A=@J66D :? |@?EC62= 2E 2 ?6FC@D4:6?46 C6D62C49 D:E6 :E 6DE23=:D965 :? a_'g] x7 q26D
E96 4=:?:42= EC:2=D 9F3 w6H286 6?G:D:@?D[ E96 4@>A2?J H@F=5 6IA64E E@ 3C:?8 @? 2?5 EC2:?
255:E:@?2= H@CA@C2C:=J 96=A qx~$ 4@G6C E96 H286D @7 2?J ?6H 6>A=@J66D :? E96 4@F?EJ] %96
4:EJ @7 q2A2?J E@ 6DE23=:D9 2 =@42= AC6D6?46j 2 DA@2? 564=:?65 E@ 4@>>6?E @? E9@D6
677@CED A6?5:?8 E@52JVD 2??@F?46>6?E]k^Am

kAmr=:?:42= EC:2=D 92G6 7@C >@C6 E92? 2 564256 366? 2DD@4:2E65 H:E9 9:89\E649 >65:4:?6 :?
q2AC696?D:G6 q=@@5 U2>Aj r2?46C r6?E6C 92D 366? :?G@=G65 :? ?F>6C@FD C6D62C49 EC:2=D[ 2?5 :E
H2D E9C@F89 4@??64E:@?D 2E rqrr E92E qx~$ 7:CDE 42>6 E@ DA62H:E9 A6@A=6 :? z6C?]k^Am

kAmqFE @E96CH:D6[ =@42= 64@?@>:4 56G6=@A>6?E 677@CED 92G6 @G6C=@@2?286>6?E[
26C@DA246[ AC64:D:@? >2?F724EFC:?8 2?5 @FED@FC465 3FD:?6DD AC@46DD6D] $E:==[ 92G:?8 :?

                                                                                                         Page 2 of 2
                         Neurotech startup looks to open clinical trials center in Bakersfield

A=246 2 =@42= 4@2=:E:@? C646AE:G6 E@ ?6H 3FD:?6DD @AA@CEF?:E:6D >2J 92G6 A2:5 @77 :? E96
42D6 @7 qx~$]k^Am

kAmr@\7@F?56C 2?5 |2?28:?8 !2CE?6C s2G:5 w:85@? 2E z6C? '6?EFC6 vC@FA[ E96 4@F?EJVD @?=J
2?86= :?G6DE@C @C82?:K2E:@?[ D2:5 96 925?VE :>28:?65 E96 4@F?EJ >:89E @?6 52J =2?5 2 AC64:D:@?
>65:4:?6 4@>A2?J H:E9 2D >F49 A@E6?E:2= E@ D42=6 FA 2D qx~$ 2AA62CD E@ 92G6]k^Am

kAmQ(6VC6 ;FDE 2D A=62D2?E=J DFCAC:D65 2D 2?J3@5J[Q 96 D2:5]k^Am

kAmw:85@? 2EEC:3FE65 E96 562=[ :? A2CE[ E@ z6C? 36:?8 46?EC2==J =@42E65[ 277@C523=6 2?5
H6=4@>:?8] |2J36 :E H:== AFE q22A :? 2 ?6H H2J[ 96 D2:5]k^Am

kAm%96 4@F?EJVD 49:67 64@?@>:4 56G6=@A>6?E @77:46C[ y:> s2>:2?[ D2:5 qx~$ >2J BF2=:7J 7@C
DF3D:5:K65 A2JC@== @77D6ED 5FC:?8 :ED 7:CDE D:I >@?E9D :? z6C?] $E277 2=D@ :?E6?5 E@ @776C
4@??64E:@?D E@ @E96C A@E6?E:2= 7@C>D @7 2DD:DE2?46[ 2D H6== 2D A2CE:4:A2E:@? :? 2??F2=
?6FC@E649\px 4@?76C6?46D]k^Am

kAmQ(6 H2?E :??@G2E:@? :? z6C? r@F?EJ[ 2?5 E96 C68:@?VD H:==:?8 E@ DFAA@CE :??@G2E:@?[Q 96
D2:5]k^Am

kAmx? E@52JVD ?6HD C6=62D6[ E96 :?E6C:> 5:C64E@C @7 q2:4 U2>Aj r@>>F?:EJ s6G6=@A>6?E
s6A2CE>6?E[ y6??: qJ6CD[ D2:5 DE277 2C6 4@?7:56?E E96 4:EJVD DFAA@CE @7 q:@D H:== 36 2?
:>A@CE2?E :?G6DE>6?E :? E96 7FEFC6 @7 q2A2?J] $96 5:5 ?@E :?5:42E6 H92E E92E DFAA@CE >:89E
:?G@=G6]k^Am

kAmqx~$[ 7@F?565 :? a_'d[ D2JD :E 92D A:@?66C65 E649?@=@8J E@ C625 2?5 :?E6CAC6E ?6FC2=
D:8?2=D H:E9 E96 36?67:E @7 px[ 2==@H:?8 :E E@ AC@G:56 :>>65:2E6 :?D:89ED E@ 4@>A2?:6D E92E
H2?E E@ 56G6=@A ?6H >65:42= EC62E>6?ED[ :7 @?=J E96J 925 2446DD E@ E96 =@H6C\4@DE[ BF:4A2?J
2??@F?465 :ED C646:AE @7 42A:E2= :?G6DE>6?E 7C@> D6G6C2= D@FC46D] t2C=:6C[ :? }@G6>36C a_aa[
E96 4@>A2?J D2:5 :ED 52E2 A=2E7@C> H:== D6CG6 E96 =2C86DE\6G6C DEF5J @7 E96 9F>2? G28FD
?6CG6[ :? 4@==23@C2E:@? H:E9 E96 }xw 2?5 @E96C >2;@C :?DE:EFE:@?D]k^Am

kAm%96 6IA2?D:@? :?E@ q22CA2?JVD =2F?49 @7 :ED AC:>2CJ 4@>>6C4:2=:K2E:@? DE286] w6 D2:5
=@42E:?8 :? q265:42= 56G:46 4@>A2?:6D 7C@> $2? s:68@ E@ $2? uC2?4:D4@ E92E E6?5 E@ 5C:G6
DA6?5:?8 @? 4=:?:42= EC:2=D]k^Am

kAm%96C6VD 2 36?67:E E@ D6EE:?8 FA D9@A 36J@?5 E96 3@C56CD @7 2 C68:@? 2=C625J 5@>:?2E65
3J =2C86 3:@E649 4@>A2?:6D[ 96 D2:5[ 255:?8[ QxEVD 8@@5 E92E E9:D :D ?@E J6E $2? s:68@[
@E96CH:D6 H6V5 92G6 E@ DE2CE D@>6H96C6 6=D6]Qk^Am

kAm!2CE?6CD9:AD H:E9 =@42= 962=E9\42C6 46?E6CD 2C6 2=C625J :? E96 H@C66E:?8 2?5 7@C>:?8
4@==23@C2E:@?D 92D 366? A2CE @7 86EE:?8 E@ 6?E E92EVD 4@?5F4:G6 E@ :?G6DE>6?E] {@42=
3FD:?6DD6D 2?5 :?G6DE@CD Q2C6 C62==J E:89E=J :?E68C2E65Q :? z6C?[ 96 D2:5]k^Am

kAmqx~$ H:== 2== 96254@F?E 2E 7:CDE 2D :E 7@C86D A2CE?6CD9:AD 2?5 =@@:4 8C@HE9 4@F=5 4@>6
7C@> @E96C 4@>A2?:6D E92E 96 6IA64ED H:== :?EC@5F46 4@>A=6>6?E2CJ D6CG:46D =@42==J]k^Am

___ (c)2024 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: January 9, 2024


  End of Document

                                                                                                 Page 1 of 3
  Social media stars get access at DNC Northridge performer and L.A. drag queen are among influencers wooed
                                                by Democrats.




  Social media stars get access at DNC; Northridge performer and L.A. drag
            queen are among influencers wooed by Democrats.
                                                        Los Angeles Times
                                                       August 23, 2024 Friday
                                                            Final Edition



Copyright 2024 Los Angeles Times All Rights Reserved

Section: MAIN NEWS; Business Desk; Part A; Pg. 1
Length: 880 words
Byline: Andrea Chang

Body


Malynda Hale angled her iPhone toward her face and filmed a quick selfie video as she headed over to the first day
of the Democratic National Convention.

"I'm already annoyed and it's not even 8:30. Nobody knows anything and this is very confusing," the 38-year-old
influencer says in the clip, which she immediately uploaded to her 53,000 Instagram followers. "I'm gonna give you
the real, unfiltered version of what it's like to be at the DNC."

Hale, a singer and actor from Northridge, is one of more than 200 social media influencers who received credentials
-- a first for the DNC -- to attend the four-day convention. In granting digital content creators access to delegates,
studio space and events, Kamala Harris' campaign hopes they will use their vast online followings to promote the
party's message and galvanize young voters, who showed deep apathy about President Biden's bid for reelection.

"They obviously view us as a direct line to this demographic, because a lot of them are bypassing traditional media
to see what the influencers and the public figures and creators that they follow are saying about political events,"
Hale said in an interview with The Times. "It's a great idea to kind of use us as, like, a democratic liaison to certain
generations."

Since arriving in Chicago over the weekend, Hale has been unleashing a quick-fire barrage of Instagram stories,
reels, grid photos and TikTok videos, capturing the glam and grind of being a chosen influencer.

In more than 50 posts uploaded to her social channels on Monday alone, she chronicled her difficulties picking up
her badge, the scene at the creator lounge at the United Center and her view from the arena floor before the
evening's speakers took the stage ("Our actual seats are in the nosebleeds," she says into the camera).

The trip to Chicago for Hale, whose following swelled during the pandemic when she began speaking out about
social justice issues, was sponsored by Stand Up America; the nonprofit organization paid for flights for her and
four family members and covered the cost of their Airbnb.

                                                                                                    Page 2 of 3
     Social media stars get access at DNC Northridge performer and L.A. drag queen are among influencers wooed
                                                   by Democrats.

As Harris has kept her distance from the mainstream news media, the decision to open the door to influencers is a
reflection of her campaign's belief that social media creators are an important conduit for getting its message to
voters.

A few were even invited to make speeches to rally support for Harris, sharing the same spotlight reserved for her
and her running mate, Tim Walz, as well as powerful Democrats including Barack and Michelle Obama, Nancy
Pelosi, and Bill and Hillary Clinton.

On the sidelines of the convention Monday, influencers were provided a special pavilion and luxury box. Democratic
aides brought officials over to a "blue carpet" to be interviewed by the social media stars. In the convention hall,
some had positioned ring lights to better capture themselves during the more marquee events.

One of the most recognizable social media personalities on the blue carpet was drag queen BenDeLaCreme. "You
see how I come dressed for the DNC? Very demure, very mindful," she said in an Instagram reel, giving her 1.1
million followers a close-up look at her towering bouffant, dramatic makeup and swirly black, white and pink dress.

BenDeLaCreme, who lives in Los Angeles, came to the convention with Drag PAC. The political action committee
was founded by drag queens "to bring awareness to Gen Z voters of how important their voice really is, and try to
engage more of Gen Z in this year's election," she said in an interview with The Times.

And appearing at the DNC was an opportunity to draw attention to the personal causes she supports.

"The drag community is also here to protect our trans siblings," said BenDeLaCreme, who spoke on a panel hosted
by the LGBTQ+ Caucus earlier in the day. "We in the queer community know that we can't go anywhere without
protecting reproductive rights, without protecting people of color."

The DNC's speaker lineup on Monday night featured 24-year-old Deja Foxx, a Columbia University graduate who
spoke about reproductive rights, an issue that has given Democrats ammunition against the Republicans after the
Supreme Court's conservative majority overturned federal abortion protections.

"For young people, this is a fight for our future," said Foxx, who has more than 141,000 followers on TikTok and
54,000 on Instagram.

The party's outreach to prominent influencers extends beyond the DNC.

Biden's administration last week hosted the first White House Creator Economy Conference in Washington. The
one-day gathering brought together a group of digital creators and industry professionals to discuss pressing issues
within the creator economy, including privacy, AI and mental health.

Loren Piretra, an influencer from Brentwood, was among those invited to attend the conference, which included
time with Biden.

"This is a massive industry, and it's time that it's taken seriously," said Piretra, who is also chief marketing officer of
Los Angeles creator platform Fanfix. "Creators have been able to democratize the idea of celebrity and influence,
so it's only natural that the White House wants to strengthen their connections to this important community."

--

Times staff writer Noah Bierman in Chicago and Bloomberg contributed to this report.



Graphic

                                                                                                 Page 3 of 3
  Social media stars get access at DNC Northridge performer and L.A. drag queen are among influencers wooed
                                                by Democrats.

PHOTO: DRAG QUEEN BenDeLaCreme speaks on the blue carpet during the Democratic National Convention.
PHOTOGRAPHER:Noah Bierman Los Angeles Times PHOTO: INFLUENCER Malynda Hale drew a following
during the pandemic by speaking on social justice issues. PHOTOGRAPHER:Malynda Hale


Load-Date: August 23, 2024


  End of Document

                                                                                                       Page 1 of 2
                               Neurotech startup looks to open clinical trials center in Bakersfield




         Neurotech startup looks to open clinical trials center in Bakersfield
                                                        The Bakersfield Californian
                                                         January 8, 2024 Monday



Copyright 2024 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: BUSINESS AND FINANCIAL NEWS
Length: 783 words
Byline: John Cox, The Bakersfield Californian

Body


Jan. 8—The promise of neurotechnology stokes Kern's economic development hopes today with an announcement
that a startup out of Cambridge, UK has chosen Bakersfield to locate a high-tech center for clinical trials aimed at
developing neural digital therapies.

BIOS Health, whose real-time, AI-assisted neural data monitoring platform has won a partnership with the National
Institutes of Health and investors including Kern Venture Group, said in a news release today the new center will
attract an ecosystem of pharmaceutical and medical device companies, clinicians and clinical trial partners. The
plan also calls for hosting neurotech conferences in Bakersfield.

×

Javascript is required for you to be able to read premium content. Please enable it in your browser settings.

kAmrt~ 2?5 4@\7@F?56C t>:= w6H286 42==65 z6C? E96 4@>A2?JVD Q4@>>6C4:2= 362499625[Q D2J:?8 :?
2? :?E6CG:6H qx~$ H2?ED E@ 36 ?62C 3FE ?@E E@@ 4=@D6 E@ 3:@C6D62C49 9F3D =:A2?J 6IA64ED
E@ 5@ D@>6 =@42= 9:C:?8 H9:=6 2=D@ 3C:?8:?8 A6CD@??6= 7C@> 6=D6H96C6j 36D:56D r2>3C:586[
qx~$ 92D 6>A=@J66D :? |@?EC62= 2E 2 ?6FC@D4:6?46 C6D62C49 D:E6 :E 6DE23=:D965 :? a_'g] x7 q26D
E96 4=:?:42= EC:2=D 9F3 w6H286 6?G:D:@?D[ E96 4@>A2?J H@F=5 6IA64E E@ 3C:?8 @? 2?5 EC2:?
255:E:@?2= H@CA@C2C:=J 96=A qx~$ 4@G6C E96 H286D @7 2?J ?6H 6>A=@J66D :? E96 4@F?EJ] %96
4:EJ @7 q2A2?J E@ 6DE23=:D9 2 =@42= AC6D6?46j 2 DA@2? 564=:?65 E@ 4@>>6?E @? E9@D6
677@CED A6?5:?8 E@52JVD 2??@F?46>6?E]k^Am

kAmr=:?:42= EC:2=D 92G6 7@C >@C6 E92? 2 564256 366? 2DD@4:2E65 H:E9 9:89\E649 >65:4:?6 :?
q2AC696?D:G6 q=@@5 U2>Aj r2?46C r6?E6C 92D 366? :?G@=G65 :? ?F>6C@FD C6D62C49 EC:2=D[ 2?5 :E
H2D E9C@F89 4@??64E:@?D 2E rqrr E92E qx~$ 7:CDE 42>6 E@ DA62H:E9 A6@A=6 :? z6C?]k^Am

kAmqFE @E96CH:D6[ =@42= 64@?@>:4 56G6=@A>6?E 677@CED 92G6 @G6C=@@2?286>6?E[
26C@DA246[ AC64:D:@? >2?F724EFC:?8 2?5 @FED@FC465 3FD:?6DD AC@46DD6D] $E:==[ 92G:?8 :?

                                                                                                         Page 2 of 2
                         Neurotech startup looks to open clinical trials center in Bakersfield

A=246 2 =@42= 4@2=:E:@? C646AE:G6 E@ ?6H 3FD:?6DD @AA@CEF?:E:6D >2J 92G6 A2:5 @77 :? E96
42D6 @7 qx~$]k^Am

kAmr@\7@F?56C 2?5 |2?28:?8 !2CE?6C s2G:5 w:85@? 2E z6C? '6?EFC6 vC@FA[ E96 4@F?EJVD @?=J
2?86= :?G6DE@C @C82?:K2E:@?[ D2:5 96 925?VE :>28:?65 E96 4@F?EJ >:89E @?6 52J =2?5 2 AC64:D:@?
>65:4:?6 4@>A2?J H:E9 2D >F49 A@E6?E:2= E@ D42=6 FA 2D qx~$ 2AA62CD E@ 92G6]k^Am

kAmQ(6VC6 ;FDE 2D A=62D2?E=J DFCAC:D65 2D 2?J3@5J[Q 96 D2:5]k^Am

kAmw:85@? 2EEC:3FE65 E96 562=[ :? A2CE[ E@ z6C? 36:?8 46?EC2==J =@42E65[ 277@C523=6 2?5
H6=4@>:?8] |2J36 :E H:== AFE q22A :? 2 ?6H H2J[ 96 D2:5]k^Am

kAm%96 4@F?EJVD 49:67 64@?@>:4 56G6=@A>6?E @77:46C[ y:> s2>:2?[ D2:5 qx~$ >2J BF2=:7J 7@C
DF3D:5:K65 A2JC@== @77D6ED 5FC:?8 :ED 7:CDE D:I >@?E9D :? z6C?] $E277 2=D@ :?E6?5 E@ @776C
4@??64E:@?D E@ @E96C A@E6?E:2= 7@C>D @7 2DD:DE2?46[ 2D H6== 2D A2CE:4:A2E:@? :? 2??F2=
?6FC@E649\px 4@?76C6?46D]k^Am

kAmQ(6 H2?E :??@G2E:@? :? z6C? r@F?EJ[ 2?5 E96 C68:@?VD H:==:?8 E@ DFAA@CE :??@G2E:@?[Q 96
D2:5]k^Am

kAmx? E@52JVD ?6HD C6=62D6[ E96 :?E6C:> 5:C64E@C @7 q2:4 U2>Aj r@>>F?:EJ s6G6=@A>6?E
s6A2CE>6?E[ y6??: qJ6CD[ D2:5 DE277 2C6 4@?7:56?E E96 4:EJVD DFAA@CE @7 q:@D H:== 36 2?
:>A@CE2?E :?G6DE>6?E :? E96 7FEFC6 @7 q2A2?J] $96 5:5 ?@E :?5:42E6 H92E E92E DFAA@CE >:89E
:?G@=G6]k^Am

kAmqx~$[ 7@F?565 :? a_'d[ D2JD :E 92D A:@?66C65 E649?@=@8J E@ C625 2?5 :?E6CAC6E ?6FC2=
D:8?2=D H:E9 E96 36?67:E @7 px[ 2==@H:?8 :E E@ AC@G:56 :>>65:2E6 :?D:89ED E@ 4@>A2?:6D E92E
H2?E E@ 56G6=@A ?6H >65:42= EC62E>6?ED[ :7 @?=J E96J 925 2446DD E@ E96 =@H6C\4@DE[ BF:4A2?J
2??@F?465 :ED C646:AE @7 42A:E2= :?G6DE>6?E 7C@> D6G6C2= D@FC46D] t2C=:6C[ :? }@G6>36C a_aa[
E96 4@>A2?J D2:5 :ED 52E2 A=2E7@C> H:== D6CG6 E96 =2C86DE\6G6C DEF5J @7 E96 9F>2? G28FD
?6CG6[ :? 4@==23@C2E:@? H:E9 E96 }xw 2?5 @E96C >2;@C :?DE:EFE:@?D]k^Am

kAm%96 6IA2?D:@? :?E@ q22CA2?JVD =2F?49 @7 :ED AC:>2CJ 4@>>6C4:2=:K2E:@? DE286] w6 D2:5
=@42E:?8 :? q265:42= 56G:46 4@>A2?:6D 7C@> $2? s:68@ E@ $2? uC2?4:D4@ E92E E6?5 E@ 5C:G6
DA6?5:?8 @? 4=:?:42= EC:2=D]k^Am

kAm%96C6VD 2 36?67:E E@ D6EE:?8 FA D9@A 36J@?5 E96 3@C56CD @7 2 C68:@? 2=C625J 5@>:?2E65
3J =2C86 3:@E649 4@>A2?:6D[ 96 D2:5[ 255:?8[ QxEVD 8@@5 E92E E9:D :D ?@E J6E $2? s:68@[
@E96CH:D6 H6V5 92G6 E@ DE2CE D@>6H96C6 6=D6]Qk^Am

kAm!2CE?6CD9:AD H:E9 =@42= 962=E9\42C6 46?E6CD 2C6 2=C625J :? E96 H@C66E:?8 2?5 7@C>:?8
4@==23@C2E:@?D 92D 366? A2CE @7 86EE:?8 E@ 6?E E92EVD 4@?5F4:G6 E@ :?G6DE>6?E] {@42=
3FD:?6DD6D 2?5 :?G6DE@CD Q2C6 C62==J E:89E=J :?E68C2E65Q :? z6C?[ 96 D2:5]k^Am

kAmqx~$ H:== 2== 96254@F?E 2E 7:CDE 2D :E 7@C86D A2CE?6CD9:AD 2?5 =@@:4 8C@HE9 4@F=5 4@>6
7C@> @E96C 4@>A2?:6D E92E 96 6IA64ED H:== :?EC@5F46 4@>A=6>6?E2CJ D6CG:46D =@42==J]k^Am

___ (c)2024 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: January 9, 2024


  End of Document

                                                                                                       Page 1 of 1
                        Samsung Electronics ' affiliate acquires French AI medtech startup Sonio




   Samsung Electronics' affiliate acquires French AI medtech startup Sonio


                                                      ASEAN Tribune
                                                   May 8, 2024 Wednesday



Copyright 2024 ASEAN Tribune All Rights Reserved




Length: 170 words

Body


 08 May 2024 (Yonhap News Agency) SEOUL, Samsung Electronics Co. said Wednesday its medical equipment
unit Samsung Medison Co. has acquired the French artificial intelligence medtech startup Sonio, as part of its effort
to expand its AI-powered health care solution business.

Samsung Medison entered into a share purchase agreement to acquire Sonio, which specializes in AI development
for diagnostic reporting in obstetrics and gynecology ultrasound, according to Samsung Electronics.

Through the acquisition of Sonio, Samsung Medison will gain access to the AI development talent in Europe and
will enhance its medical AI solutions with Sonio's AI diagnostic assistant and reporting technology.

Founded in 2020, the Paris-based startup has developed an AI-powered prenatal screening solution that automates
ultrasound reporting.

Sonio's key product, Sonio Detect, AI-powered software designed to identify prenatal syndromes and abnormalities
through ultrasound, won approval from the U.S. Food and Drug Administration in 2023.


Load-Date: May 9, 2024


  End of Document

                                                                                                        Page 1 of 1
                Bethesda‘s The Centers for Advanced Orthopaedics to expand digital therapy solutions




      Bethesda‘s The Centers for Advanced Orthopaedics to expand digital
                               therapy solutions
                                               Daily Record, The (Baltimore, MD)
                                                   January 29, 2024 Monday



Copyright 2024 BridgeTower Media All Rights Reserved

Section: NEWS
Length: 174 words
Byline: Daily Record Staff

Body


Bethesda-based The Centers for Advanced Orthopaedics (CAO) announced Monday a partnership with digital
health platform Genie Health.

This collaboration introduces Genie Health, an AI-driven platform, to CAO's extensive network acrossMaryland,
Virginia and Washington, enabling a comprehensive digital MSK solution for their patients to enhance their brick-
and-mortar physical therapy clinics.

Genie Health enables CAO therapists to offer high-quality therapy services to their patients using the most cutting-
edge computer vision technology contained within the Genie Health platform. Genie Health's technology enables
patient smart phones to be used to track and guide range of motion and strengthening [using bands], so that
patients can be confident that they are correctly doing exactly what their therapists are directing them to do while at
home.

Patients of Genie Health have reported a 90% increase in satisfaction, with a notable 60% quicker recovery rate
and a 50% reduction in pain.

Copyright © 2024 BridgeTower Media. All Rights Reserved.


Load-Date: February 2, 2024


  End of Document

                                                                                          Page 1 of 6
                                       EIU student government swears in new senator




                         EIU student government swears in new senator
                                        Daily Eastern News: Eastern Illinois University
                                                  October 10, 2024 Thursday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1699 words

Body

content"class="skip-to-content">Skip to Content

The Daily Eastern News

Facebook

Instagram

X

Tiktok

YouTube

RSS Feed
     •    Welcome back to the Daily Eastern News!
     •    Check out our podcasts on Spotify!
     •    Oct. 10- Men's soccer vs. Incarnate Woods at 4 pm
     •    Oct. 11- No class for Fall Break
     •    Oct. 12- Animal Shelter adoption event at 720 6th Street from 12-2 pm
     •    Oct. 12- Oscar Meyer Weinermobile is coming to Charleston11 am- 2 pm
     •    Oct. 12- Football at Tennessee State in Nashville at 5 pm
     •    Volleyball standings: 4-10 on the season (0-4 in conference)
     •    Soccer standings: Women's at 3-6-5 (1-2-2), Men's at 1-7-1 (0-3)
     •    Football standings: 1-5 on the season (0-2 in conference)
     •    Check out our newsletters!

The Ticker

                                                                                                    Page 2 of 6
                                 EIU student government swears in new senator

    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Men's Tennis
        Women's Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

EIU student government swears in new senator"The Thinking Game" screening discusses AIHealth and Wellness
Fair provides resources to studentsEIU GSD hosts National Coming Out DayHow to deal with time management
issuesCharleston looks to break losing streak against Mount ZionTakeaways from the Coles County ClashJunior
defender shares season goals in Q&ATakeaways from EIU volleyballPanthers of the Week: Abby Reinl, Quenton
RogersAnderson reflects on Yankees career during 9/11EIU Baseball's path through OVC TournamentEIU
Baseball honors seniors, win over MSUEIU Baseball drops second game against MSUEIU Baseball loses fifth
straight gameBollant leaves EIU basketball programDavis, Luers enter transfer portalPanthers of the Year: MJ
Flowers, Macy McGlone, Sara ThomasPanthers of the Semester: Tiger Booker, Macy McGlone, Tara
ArchibaldSTAFF PICKS: NBA finals winnerCOLUMN: What went wrong with EIU football?COLUMN: Female
athletes are just as capable as maleCOLUMN: Court storming should be a thing of the pastCOLUMN: Court
storming needs to stayCOLUMN: EIU should move on from swim programPanthers of the Week: Joe Stoddard,
Alex TettehFall 2024 athletes to watchPanthers of the Week: Joe Stoddard, Taris ThorntonPanthers of the Week:
Macy McGlone, Isai MoralesCOLUMN: Why you should watch running sportsCharleston looks to break losing
streak against Mount ZionTakeaways from the Coles County ClashPanthers of the Week: Abby Reinl, Quenton
RogersWhat happened at EIU's homecoming game?Charleston loses 20-17 in Coles County ClashJunior defender
shares season goals in Q&APanthers of the Week: Abby Reinl, Quenton RogersLate goal gives EIU women's
soccer first OVC winPanthers of the Week: Abby Reinl, Ella KratochvilSenior midfielder reflects on her
journeyGrover, Oslanzi, Archibald win OVC AwardsPanthers of the Week: McKenzie Oslanzi, Joe
StoddardPanthers of the Semester: Tiger Booker, Macy McGlone, Tara ArchibaldCatcher talks about being a black
belt in Q&AEIU softball loses nine-game winning streak to Tennessee TechThrough 40 years of coaching: Scott
TeetersCOLUMN: EIU should move on from swim programEIU swim competes for first time in 2024EIU Swim
competes as wholeAthletes to watch in the winterFall 2024 athletes to watchPanthers of the Week: William Hays,
Danny InfanteEIU men's tennis gets second straight victory with win against USIEIU tennis siblings' journey from
AustraliaEIU tennis coach with varied past: Robin CambierFall 2024 athletes to watchPanthers of the Week:
Addison Brown, Adam SwansonEIU women's tennis prepares for OVC tournamentTakeaways from EIU
volleyballSouthern Indiana's runs trample EIU volleyballEIU volleyball loses close match against Southern
IndianaHieb returns to volleyball program after one year awayPanthers of the Week: Kaelin Drakeford, Sylvia
HaszCOLUMN: 'Lars and the Real Girl:' a very, very different type of rom-comFitness, followers, family: Monica
AlifantisCOLUMN: 'Beast:' a narratively dull, sporadic filmRadius and local A cappella groups light up
DoudnaCOLUMN: 'Flight:' What can't Denzel do?EDITORIAL: Ranked choice voting is the way to goCOLUMN:
'Beast:' a narratively dull, sporadic filmCOLUMN: 'Megalopolis:' the art of insisting upon yourselfCOLUMN: Fall is
the best time of yearEDITORIAL: Local voting matters just as much as nationalTwo Dudes Talk Movies Ep. 69:
Rebel Ridge: Every Ridge Has A PlateauTwo Dudes Talk Movies Ep. 68: Whiplash: Aggression vs. PassionPanther
Playbook Ep.5: Football in a hurricane, The Coles County Clash, EIU teams begin OVC playThe Overton Window:
Ep. 6: Under the Radar RacesPanther Playbook Ep.4: Would a quarterback change save Eastern Illinois'
season?THROUGH THE LENS: Tour De CharlestonTHROUGH THE LENS: Camp New Hope celebrates 50th
anniversaryTHROUGH THE LENS: Something's cooking in Klehm HallTHROUGH THE LENS: Glow Foam Party
lights up South QuadTHROUGH THE LENS: Fresh produce at the Charleston Farmer's Market

Search this site

                                                                                          Page 3 of 6
                                 EIU student government swears in new senator

Submit Search

Open Navigation Menu

The Daily Eastern News
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Men's Tennis
        Women's Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The Daily Eastern News

Open Search Bar

Search this site

Submit Search

Open Navigation Menu

The Daily Eastern News
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Men's Tennis
        Women's Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The Daily Eastern News

Open Search Bar

Search this site

Submit Search

Categories:
    •   News

EIU student government swears in new senator

                                                                                                        Page 4 of 6
                                   EIU student government swears in new senator

Jason Coulombe, Student Government Reporter

·

October 10, 2024

Jason Coulombe Student senator Megan Fox was appointed to parliamentarian at the student senate meeting on
Wednesday in the Tuscola-Arcola Room.

The student senate's meeting saw the appointment of several senators to varies positions and the appointment of a
new student senator.

Unofficial special election votes indicate that senator Megan Fox won the special election for elected senator. Fox
received 156 votes in favor and 19 against, giving her an 89% simple majority.

Fox will take the oath of office at the next student senate meeting on Oct. 16 at 7 p.m. Fox was also appointed as
senate parliamentarian.

The parliamentarian meets with the speaker of the senate, serves as the acting secretary should they not be
present and will keep order of all senate business, according to Speaker of the Senate Madison Veatch.

Fox was appointed with a vote of 11 in favor with none opposed and with Fox abstaining.

Senator Preston Siewert and Vice President of Student Affairs Mason Tegeler were appointed to the student action
team.

Student action team is an organization that works for EIU students by representing EIU's student government at the
state and local level.

"The purpose of the EIU student action team is to represent the interests of EIU students and to present those
interests. SAT strives to work closely with state and local lawmakers in Illinois to improve the quality of education
and financial support for EIU students," according to its about section on EIU's website.

Freshman criminal justice major Clint Chamley was appointed to the student senate.

Director of student life Ceci Brinker gave her report to the senate.

"Homecoming week was a great week of actives and events" Brinker said. "There will be a survey going out next
week to faculty, staff, and student we want your input on how we can improve to make homecoming a success."

Homecoming committee is looking for students for next year.

"Later this semester or early spring semester, applications will be going out for any students looking to be a part of
the planning committee," Brinker said.

Events that were discussed included times for senate-on-the-go.

Senate-on-the-go are student senate meetings that take place outside of the regular meeting room of the Tuscola-
Arcola room in the Martin Luther King Jr. University Union.

The next meeting will be on Oct. 30 in the Witters Conference Room, on the fourth floor of Booth Library.

The meeting is meant to also celebrate Halloween according to Veatch.

"We will hold a costume contest for us as well as students who come" Veatch said, "We are also going to do goodie
bags for the senate and people in the audience."

                                                                                                     Page 5 of 6
                                    EIU student government swears in new senator

Another senate-on-the-go meeting is planned for Nov. 6 in the South Quad Commons also at 7 p.m., though it is
still to be determined.

Take Back the Night is an event that is happening on Oct. 21 at 7 p.m.

TBTN is a walking event to raise awareness for domestic abuse and violence as well as sexual violence.

The event will be occurring around the Panther Trail, starting in the EIU Campus Pond Pavilion registration is from
6:30 to 7 p.m. The event is $10 for students and $20 for non-students, with the money going to Prevail Illinois, an
organization that fights against sexual abuse and violence.

A candlelight vigil will happen after the walk from 8 to 8:30 p.m.

Jason Coulombe can be reached at 581-2812 or at jmcoulombe@eiu.edu

View Story Comments

0

Like This Story

Share on Facebook

Share on X

Email this Story

Print this Story

Leave a Comment

Tags:
    •    2024-2025 student government
    •    Student senate

More to Discover

More in News

"The Thinking Game" screening discusses AI

Health and Wellness Fair provides resources to students

EIU GSD hosts National Coming Out Day

How to deal with time management issues

Rodeo Round-Up brings bull riding to Library Quad

EIU students line dance for homecoming

The Daily Eastern News

The student news site of Eastern Illinois University in Charleston, Illinois.

Facebook

Instagram

                                                                                               Page 6 of 6
                                 EIU student government swears in new senator

X

Tiktok

YouTube

RSS Feed
      •   News
      •   Sports
      •   Arts & Entertainment
      •   Opinions
      •   Podcasts
      •   Through the Lens
      •   About

The Daily Eastern News · © 2024 · FLEX Pro WordPress Theme by SNO · Log in

Comments (0)

Commenting on the Daily Eastern News web site is a privilege, not a right. We reserve the right to remove
comments that contain obscene, vulgar, lewd, racist or sexually-oriented language. Also, comments containing
personal attacks or threats of harming another person will not be tolerated.

Share your thoughts...

All

The Daily Eastern News Picks

Reader Picks

Sort: Newest

Close

Close Modal Window

Close


Load-Date: October 10, 2024


    End of Document

                                                                                          Page 1 of 7
                                    Student government discusses fees, approves RSO




                     Student government discusses fees, approves RSO
                                        Daily Eastern News: Eastern Illinois University
                                                      October 18, 2024 Friday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1800 words

Body

content"class="skip-to-content">Skip to Content

The Daily Eastern News

Facebook

Instagram

X

Tiktok

YouTube

RSS Feed
     •    Welcome back to the Daily Eastern News!
     •    Check out our podcasts on Spotify!
     •    Oct. 17- Untitled (Cut) @theTarble from 1-6 pm at the Tarble
     •    Oct. 17- Women's Soccer vs. Tennessee Tech at 3 pm
     •    Oct. 17- Jazz Combos in the Black Box at 7:30 pm
     •    Oct. 18- Eastern Symphony Orchestra in the Dvorak Concert Hall at 7:30 pm
     •    Oct. 19- Volleyball vs Tennessee Tech in Groniger Arena at 4 pm
     •    Oct. 20- Women's Soccer vs UT Martin at Lakeside field starts at 1 pm
     •    Oct. 20- Flute Studio Recital in the Doudna recital hall at 4 pm
     •    Oct. 21- Faculty Chamber Recital in the Doudna recital hall at 7:30 pm
     •    Oct. 22- Trans*formation Station Ribbon Cutting and Fashion Show at 7 pm
     •    Volleyball standings: 4-11 on the season (0-5 in conference)

                                                                                                     Page 2 of 7
                               Student government discusses fees, approves RSO

    •   Soccer standings: Women's at 5-6-5 (3-2-2), Men's at 1-9-1 (0-5)
    •   Football standings: 1-6 on the season (0-4 in conference)
    •   Check out our newsletters on Overlooked!

The Ticker
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

Student government discusses fees, approves RSOThe geological Avenger on EIU's campus On-campus
enrollment down 7%, administration feeling positiveConstruction happening all around EIUEIU student government
swears in new senatorEIU women's soccer wins two in a rowCharleston prepares for must-win game against
TaylorvilleJunior outside hitter talks about support system in Sweden in Q&AEIU athletic director responds to House
v. NCAA preliminary approvalEIU volleyball wins first conference gameAnderson reflects on Yankees career during
9/11EIU Baseball's path through OVC TournamentEIU Baseball honors seniors, win over MSUEIU Baseball drops
second game against MSUEIU Baseball loses fifth straight gameBollant leaves EIU basketball programDavis, Luers
enter transfer portalPanthers of the Year: MJ Flowers, Macy McGlone, Sara ThomasPanthers of the Semester:
Tiger Booker, Macy McGlone, Tara ArchibaldSTAFF PICKS: NBA finals winnerCOLUMN: What went wrong with
EIU football?COLUMN: Female athletes are just as capable as maleCOLUMN: Court storming should be a thing of
the pastCOLUMN: Court storming needs to stayCOLUMN: EIU should move on from swim programPanthers of the
Week: Joe Stoddard, Alex TettehFall 2024 athletes to watchPanthers of the Week: Joe Stoddard, Taris
ThorntonPanthers of the Week: Macy McGlone, Isai MoralesCOLUMN: Why you should watch running
sportsCharleston prepares for must-win game against TaylorvillePanthers hope for first conference win against
TigersCharleston loses 42-10 at homecomingCharleston looks to break losing streak against Mount
ZionTakeaways from the Coles County ClashEIU women's soccer wins two in a rowFormer EIU soccer coach
returns for first game since departureEIU men's soccer loses 3-0 to Houston Christian UniversityEIU women's
soccer wins 4-0 on senior nightPanthers of the Week: Alex Tetteh, Abby ReinlGrover, Oslanzi, Archibald win OVC
AwardsPanthers of the Week: McKenzie Oslanzi, Joe StoddardPanthers of the Semester: Tiger Booker, Macy
McGlone, Tara ArchibaldCatcher talks about being a black belt in Q&AEIU softball loses nine-game winning streak
to Tennessee TechThrough 40 years of coaching: Scott TeetersCOLUMN: EIU should move on from swim
programEIU swim competes for first time in 2024EIU Swim competes as wholeAthletes to watch in the winterFall
2024 athletes to watchPanthers of the Week: William Hays, Danny InfanteEIU men's tennis gets second straight
victory with win against USIEIU tennis siblings' journey from AustraliaEIU tennis coach with varied past: Robin
CambierJunior outside hitter talks about support system in Sweden in Q&AEIU volleyball wins first conference
gameTakeaways from EIU volleyballSouthern Indiana's runs trample EIU volleyballEIU volleyball loses close match
against Southern IndianaCOLUMN: 'Lars and the Real Girl:' a very, very different type of rom-comFitness,
followers, family: Monica AlifantisCOLUMN: 'Beast:' a narratively dull, sporadic filmRadius and local A cappella
groups light up DoudnaCOLUMN: 'Flight:' What can't Denzel do?COLUMN: Future educators: get
organizedCOLUMN: Boo! Get off the stage!EDITORIAL: Ranked choice voting is the way to goCOLUMN: 'Beast:' a
narratively dull, sporadic filmCOLUMN: 'Megalopolis:' the art of insisting upon yourselfTwo Dudes Talk Movies Ep.
70: Joker: Folie à Deux and the Horrible, No Good, One Bad DayTwo Dudes Talk Movies Ep. 69: Rebel Ridge:
Every Ridge Has A PlateauTwo Dudes Talk Movies Ep. 68: Whiplash: Aggression vs. PassionPanther Playbook
Ep.5: Football in a hurricane, The Coles County Clash, EIU teams begin OVC playThe Overton Window: Ep. 6:
Under the Radar RacesTHROUGH THE LENS: Tour De CharlestonTHROUGH THE LENS: Camp New Hope

                                                                                                 Page 3 of 7
                               Student government discusses fees, approves RSO

celebrates 50th anniversaryTHROUGH THE LENS: Something's cooking in Klehm HallTHROUGH THE LENS:
Glow Foam Party lights up South QuadTHROUGH THE LENS: Fresh produce at the Charleston Farmer's Market

Search this site

Submit Search

Open Navigation Menu

The Daily Eastern News
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The Daily Eastern News

Open Search Bar

Search this site

Submit Search

Open Navigation Menu

The Daily Eastern News
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The Daily Eastern News

Open Search Bar

Search this site

Submit Search

Categories:
    •   News

                                                                                                           Page 4 of 7
                                 Student government discusses fees, approves RSO

Student government discusses fees, approves RSO

Jason Coulombe, Student Government Reporter

·

October 18, 2024

Jason Coulombe A major point in discussion from the weekly Student Senate meeting on Wednesday was the
transparence of fees in the billing of students. Speaker of the senate Madison Veatch (left) senate parliamentarian
Megan Fox (middle) and VPSA Mason Tegeler (right) discuss with fellow senate members at the senate
weekly meeting on Wednesday

The weekly student senate meeting saw the approval of a new registered student organization and a discussion on
the transparency and allocation of student fees on Wednesday.

The student senate heard from turn the page journaling at EIU RSO member Lizzie Tomko.

"The purpose of our club is to introduce, educate, explain and assist on how journaling can be helpful for reflection
tools and outlets," Tomko said.

Journaling can include both writing and visual aspects to it.

Meetings are held on Tuesdays and Wednesdays, though it is only required for students to attend one meeting
every two weeks, Tomko said.

The RSO was approved with ten in favor with no opposing votes and one abstention.

The meeting saw a speech by Senior Diversity and Inclusion Officer John Blue about the EIU climate survey.

"The results of the climate survey will be used to assist the belonging access and equity council to write the
diversity strategic plan," Blue said.

The survey will be open until Nov. 5. Students, faculty and staff who take the survey can choose to be included in a
drawing for EIU merchandise.

A key point of discussion and questioning for the members of the student senate came from the student fees
committee report from speaker of the senate Madison Veatch.

"An overview of the committee task force is how fees should appear on the bill," Veatch said.

There were three questions posed by Veatch on what to do about fees.

The first question was on whether student fees should be listed individually or as one lump sum, which is what is
currently in place.

"Within the student activity fee, there is all those fees but on your bill, you are only seeing one fee," Veatch said.

The second question which caused the main point of discussion was should the athletic fee be moved from the
grant in aid fee.

"78% of that fee goes to athletics," Veatch said. "Should athletics be moved from [grant and aid] to intercollegiate
athletics?"

The third question was whether there should be flat rates of fees or fees based around credit hours.

"I think that all athletic fees should be consolidated. I think the one under the GIA shouldn't be there," student
senator Preston Siewert said.

                                                                                                     Page 5 of 7
                                Student government discusses fees, approves RSO

VPSA Mason Tegeler raised the question to Veatch of changing where the funds go.

"Would moving athletics out of GIA fix the problem of 78% of it going to athletics?" Tegeler said. "If not, then it
doesn't change which bill item is charging you this amount of money."

In response to Tegeler, Veatch explained moving the fees.

"It would not change the allocation. What it would do was change the transparency," Veatch said. "It would be one
fee, and every athlete would come out of that fee."

Parliamentarian Megan Fox raised the question on whether there is a breakdown of student fees.

"There seems to be a lack of transparency when it comes to fees," Fox said. "Is there a way for students to find a
breakdown of this?"

"On eiu.edu there is a breakdown of some of the fees, not all of them," Veatch said in response.

Overall, the discussion led to the senate wanting to have the Office of Financial aid and the Athletic department
present fees to gain a better understanding of where funds are going and how the funds are disclosed.

Jason Coulombe can be reached at 581-2812 or at jmcoulombe@eiu.edu

View Story Comments

0

Like This Story

Share on Facebook

Share on X

Email this Story

Print this Story

Leave a Comment

Tags:
    •    2024-2025 student government
    •    Student senate

More to Discover

More in News

The geological Avenger on EIU's campus

On-campus enrollment down 7%, administration feeling positive

Construction happening all around EIU

EIU student government swears in new senator

"The Thinking Game" screening discusses AI

Health and Wellness Fair provides resources to students

                                                                                               Page 6 of 7
                                 Student government discusses fees, approves RSO

About the Contributor

Jason Coulombe, Student Government Reporter

Jason Coulombe is a freshman sports media relations major and can be reached at 581-2812 or
jmcoulombe@eiu.edu

The Daily Eastern News

The student news site of Eastern Illinois University in Charleston, Illinois.

Facebook

Instagram

X

Tiktok

YouTube

RSS Feed
      •   News
      •   Sports
      •   Arts & Entertainment
      •   Opinions
      •   Podcasts
      •   Through the Lens
      •   About

The Daily Eastern News · © 2024 · FLEX Pro WordPress Theme by SNO · Log in

Comments (0)

Commenting on the Daily Eastern News web site is a privilege, not a right. We reserve the right to remove
comments that contain obscene, vulgar, lewd, racist or sexually-oriented language. Also, comments containing
personal attacks or threats of harming another person will not be tolerated.

Share your thoughts...

All

The Daily Eastern News Picks

Reader Picks

Sort: Newest

Close

Close Modal Window

Close

                                                                                Page 7 of 7
                              Student government discusses fees, approves RSO


Load-Date: October 18, 2024


  End of Document

                                                                                          Page 1 of 7
                                            Construction happening all around EIU




                                Construction happening all around EIU
                                        Daily Eastern News: Eastern Illinois University
                                                      October 14, 2024 Monday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1816 words

Body

content"class="skip-to-content">Skip to Content

The Daily Eastern News

Facebook

Instagram

X

Tiktok

YouTube

RSS Feed
     •    Welcome back to the Daily Eastern News!
     •    Check out our podcasts on Spotify!
     •    Oct. 14- Corey Durham in the Doudna recital hall at 6 pm
     •    Oct. 15- Volleyball vs. SIUE in Groniger Arena at 6 pm
     •    Oct. 15- Songwriter showcase in the Doudna Black Box at 7:30 pm
     •    Oct. 16- Para la Cultura: Talent Night in 7th street underground at 6 pm
     •    Oct. 17- Untitled (Cut) @theTarble from 1-6 pm at the Tarble
     •    Oct. 17- Women's Soccer vs. Tennessee Tech at 3 pm
     •    Oct. 17- Jazz Combos in the Black Box at 7:30 pm
     •    Oct. 18- Eastern Symphony Orchestra in the Dvorak Concert Hall at 7:30 pm
     •    Oct. 19- Volleyball vs Tennessee Tech in Groniger Arena at 4 pm
     •    Volleyball standings: 4-11 on the season (0-5 in conference)

                                                                                                     Page 2 of 7
                                      Construction happening all around EIU

    •   Soccer standings: Women's at 3-6-5 (1-2-2), Men's at 1-9-1 (0-5)
    •   Football standings: 1-6 on the season (0-3 in conference)
    •   Check out our newsletters on Overlooked!

The Ticker
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

Construction happening all around EIUEIU student government swears in new senator"The Thinking Game"
screening discusses AIHealth and Wellness Fair provides resources to studentsEIU GSD hosts National Coming
Out DayEIU men's soccer loses 3-0 to Houston Christian UniversityEIU women's soccer wins 4-0 on senior
nightPanthers of the Week: Alex Tetteh, Abby ReinlPanthers hope for first conference win against TigersCharleston
loses 42-10 at homecomingAnderson reflects on Yankees career during 9/11EIU Baseball's path through OVC
TournamentEIU Baseball honors seniors, win over MSUEIU Baseball drops second game against MSUEIU
Baseball loses fifth straight gameBollant leaves EIU basketball programDavis, Luers enter transfer portalPanthers
of the Year: MJ Flowers, Macy McGlone, Sara ThomasPanthers of the Semester: Tiger Booker, Macy McGlone,
Tara ArchibaldSTAFF PICKS: NBA finals winnerCOLUMN: What went wrong with EIU football?COLUMN: Female
athletes are just as capable as maleCOLUMN: Court storming should be a thing of the pastCOLUMN: Court
storming needs to stayCOLUMN: EIU should move on from swim programPanthers of the Week: Joe Stoddard,
Alex TettehFall 2024 athletes to watchPanthers of the Week: Joe Stoddard, Taris ThorntonPanthers of the Week:
Macy McGlone, Isai MoralesCOLUMN: Why you should watch running sportsPanthers hope for first conference win
against TigersCharleston loses 42-10 at homecomingCharleston looks to break losing streak against Mount
ZionTakeaways from the Coles County ClashPanthers of the Week: Abby Reinl, Quenton RogersEIU men's soccer
loses 3-0 to Houston Christian UniversityEIU women's soccer wins 4-0 on senior nightPanthers of the Week: Alex
Tetteh, Abby ReinlEastern loses 4-1 to Incarnate WordJunior defender shares season goals in Q&AGrover,
Oslanzi, Archibald win OVC AwardsPanthers of the Week: McKenzie Oslanzi, Joe StoddardPanthers of the
Semester: Tiger Booker, Macy McGlone, Tara ArchibaldCatcher talks about being a black belt in Q&AEIU softball
loses nine-game winning streak to Tennessee TechThrough 40 years of coaching: Scott TeetersCOLUMN: EIU
should move on from swim programEIU swim competes for first time in 2024EIU Swim competes as wholeAthletes
to watch in the winterFall 2024 athletes to watchPanthers of the Week: William Hays, Danny InfanteEIU men's
tennis gets second straight victory with win against USIEIU tennis siblings' journey from AustraliaEIU tennis coach
with varied past: Robin CambierTakeaways from EIU volleyballSouthern Indiana's runs trample EIU volleyballEIU
volleyball loses close match against Southern IndianaHieb returns to volleyball program after one year
awayPanthers of the Week: Kaelin Drakeford, Sylvia HaszCOLUMN: 'Lars and the Real Girl:' a very, very different
type of rom-comFitness, followers, family: Monica AlifantisCOLUMN: 'Beast:' a narratively dull, sporadic filmRadius
and local A cappella groups light up DoudnaCOLUMN: 'Flight:' What can't Denzel do?COLUMN: Boo! Get off the
stage!EDITORIAL: Ranked choice voting is the way to goCOLUMN: 'Beast:' a narratively dull, sporadic
filmCOLUMN: 'Megalopolis:' the art of insisting upon yourselfCOLUMN: Fall is the best time of yearTwo Dudes Talk
Movies Ep. 70: Joker: Folie à Deux and the Horrible, No Good, One Bad DayTwo Dudes Talk Movies Ep. 69: Rebel
Ridge: Every Ridge Has A PlateauTwo Dudes Talk Movies Ep. 68: Whiplash: Aggression vs. PassionPanther
Playbook Ep.5: Football in a hurricane, The Coles County Clash, EIU teams begin OVC playThe Overton Window:
Ep. 6: Under the Radar RacesTHROUGH THE LENS: Tour De CharlestonTHROUGH THE LENS: Camp New
Hope celebrates 50th anniversaryTHROUGH THE LENS: Something's cooking in Klehm HallTHROUGH THE

                                                                                                 Page 3 of 7
                                      Construction happening all around EIU

LENS: Glow Foam Party lights up South QuadTHROUGH THE LENS: Fresh produce at the Charleston Farmer's
Market

Search this site

Submit Search

Open Navigation Menu

The Daily Eastern News
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The Daily Eastern News

Open Search Bar

Search this site

Submit Search

Open Navigation Menu

The Daily Eastern News
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The Daily Eastern News

Open Search Bar

Search this site

Submit Search

Categories:
    •   News

                                                                                                       Page 4 of 7
                                       Construction happening all around EIU

    •   Showcase

Construction happening all around EIU

Jacob Hamm, News Editor

·

October 14, 2024

Jacob Hamm Construction workers replace the roof on Buzzard Hall at Eastern Illinois University in Charleston, Ill.

Roof shingle palettes and a dumpster have sat in front of Buzzard Hall for the past several weeks.

The EIU board of trustees approved Buzzard's roof replacement at its Sept. 4 meeting. Construction began in the
middle of September. The nearly $250,000 project is likely to be completed within the next week.

Other roof replacements on campus include the Booth Library and the Physical Science building, among several
others. The total cost for all roof replacements will be approximately $7 million, according to documents from the
board of trustees.

The roof replacement comes after storm damage due to hail and strong winds that occurred this past spring
combined with deterioration over time. Several rooms within Buzzard experienced leaks and water damage to the
ceiling.

The roof on the dorms are originally from the rehabilitation of Buzzard that occurred in 1996, according to Eastern's
maintenance department. Asphalt shingle roofs can last between 15 and 30 years, depending on the shingle and
layering type, according to Roof Doctor's website.

Alongside the roof, Buzzard's satellite and cell phone tower are under repair.

Other campus improvements include Lakeside Field being recently renovated. Both field houses' roofs are also
being replaced, with the replacements also being approved at last month's board of trustees meeting.

Additional planned upgrades include nearly $8 million in fire alarm upgrades in several buildings on campus,
including in Old Main, said the board of trustees.

 Due to Old Main being a historical structure, the university will work with a consulting agency advising the
university on what can be altered and where to discreetly wire the upgrades, according to the plan. Other buildings
receiving fire alarm upgrades include Klehm and Coleman halls.

Coleman Hall currently has no fire protection or sprinkler system, and the upgrades will include installing fire
protection systems. However, some lighting and ceiling tiles will have to be replaced due to some of the building
materials containing asbestos, according to the board.

The university is requesting approximately $253 million for other campus construction, the board of trustees
documents found. This includes the rehabilitation of Klehm Hall, Coleman Hall and the Physical Science Building.
The three projects are estimated to cost approximately $144 million. No concrete plans or architectural concepts
have been released yet.

The other $109 million in the board plans will cover renovating the Student Services Building and potentially
relocating it to an underutilized building of campus. The documents did not specify where student services would
potentially be relocated.

The university plans to demolish two buildings on campus deemed obsolete or underutilized. However, the plans,
which are apart of Project 2028, did not specify what buildings would be demolished currently.

                                                                                                       Page 5 of 7
                                        Construction happening all around EIU

Another $5 million will be spent on replacing and retrofitting the windows at McAfee Gym, along with necessary
brick repairs. Approximately $90,000 of the cost will be dedicated to asbestos removal, the board said.

Due to McAfee being built by the Works Progress Administration during the Great Depression, the university will be
working with the Illinois Historic Preservation Agency to preserve the aesthetic of the building and not to adversely
affect public spaces in McAfee.



Jacob Hamm can be reached at 581-2812 or at jmhamm@eiu.edu

View Story Comments

0

Like This Story

Share on Facebook

Share on X

Email this Story

Print this Story

Leave a Comment

Tags:
    •    Buzzard Hall
    •    campus
    •    campus renovation
    •    Coleman Hall
    •    Construction

More to Discover

More in News

EIU student government swears in new senator

"The Thinking Game" screening discusses AI

Health and Wellness Fair provides resources to students

EIU GSD hosts National Coming Out Day

How to deal with time management issues

Rodeo Round-Up brings bull riding to Library Quad

More in Showcase

EIU women's soccer wins 4-0 on senior night

Fitness, followers, family: Monica Alifantis

                                                                                               Page 6 of 7
                                        Construction happening all around EIU

What EIU takes away from Coles County Clash

Late goal gives EIU women's soccer first OVC win

Homecoming court crowned for 2024

The history of the Coles County Clash

About the Contributor

Jacob Hamm, News Editor

Jacob Hamm is a senior journalism major and can be reached at 581-2812 or jmhamm@eiu.edu He previously
served as a campus reporter.

The Daily Eastern News

The student news site of Eastern Illinois University in Charleston, Illinois.

Facebook

Instagram

X

Tiktok

YouTube

RSS Feed
      •   News
      •   Sports
      •   Arts & Entertainment
      •   Opinions
      •   Podcasts
      •   Through the Lens
      •   About

The Daily Eastern News · © 2024 · FLEX Pro WordPress Theme by SNO · Log in

Comments (0)

Commenting on the Daily Eastern News web site is a privilege, not a right. We reserve the right to remove
comments that contain obscene, vulgar, lewd, racist or sexually-oriented language. Also, comments containing
personal attacks or threats of harming another person will not be tolerated.

Share your thoughts...

All

The Daily Eastern News Picks

Reader Picks

Sort: Newest

                                                                      Page 7 of 7
                              Construction happening all around EIU

Close

Close Modal Window

Close


Load-Date: October 14, 2024


  End of Document

                                                                                          Page 1 of 7
                                          The geological Avenger on EIU's campus




                             The geological Avenger on EIU's campus
                                        Daily Eastern News: Eastern Illinois University
                                                  October 17, 2024 Thursday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1996 words

Body

content"class="skip-to-content">Skip to Content

The Daily Eastern News

Facebook

Instagram

X

Tiktok

YouTube

RSS Feed
     •    Welcome back to the Daily Eastern News!
     •    Check out our podcasts on Spotify!
     •    Oct. 14- Corey Durham in the Doudna recital hall at 6 pm
     •    Oct. 15- Volleyball vs. SIUE in Groniger Arena at 6 pm
     •    Oct. 15- Songwriter showcase in the Doudna Black Box at 7:30 pm
     •    Oct. 16- Para la Cultura: Talent Night in 7th street underground at 6 pm
     •    Oct. 17- Untitled (Cut) @theTarble from 1-6 pm at the Tarble
     •    Oct. 17- Women's Soccer vs. Tennessee Tech at 3 pm
     •    Oct. 17- Jazz Combos in the Black Box at 7:30 pm
     •    Oct. 18- Eastern Symphony Orchestra in the Dvorak Concert Hall at 7:30 pm
     •    Oct. 19- Volleyball vs Tennessee Tech in Groniger Arena at 4 pm
     •    Volleyball standings: 4-11 on the season (0-5 in conference)

                                                                                                        Page 2 of 7
                                     The geological Avenger on EIU's campus

    •   Soccer standings: Women's at 3-6-5 (1-2-2), Men's at 1-9-1 (0-5)
    •   Football standings: 1-6 on the season (0-3 in conference)
    •   Check out our newsletters on Overlooked!

The Ticker
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The geological Avenger on EIU's campus               On-campus enrollment down 7%, administration feeling
positiveConstruction happening all around EIUEIU student government swears in new senator"The Thinking Game"
screening discusses AIJunior outside hitter talks about support system in Sweden in Q&AEIU athletic director
responds to House v. NCAA preliminary approvalEIU volleyball wins first conference gameFormer EIU soccer
coach returns for first game since departureEIU men's soccer loses 3-0 to Houston Christian UniversityAnderson
reflects on Yankees career during 9/11EIU Baseball's path through OVC TournamentEIU Baseball honors seniors,
win over MSUEIU Baseball drops second game against MSUEIU Baseball loses fifth straight gameBollant leaves
EIU basketball programDavis, Luers enter transfer portalPanthers of the Year: MJ Flowers, Macy McGlone, Sara
ThomasPanthers of the Semester: Tiger Booker, Macy McGlone, Tara ArchibaldSTAFF PICKS: NBA finals
winnerCOLUMN: What went wrong with EIU football?COLUMN: Female athletes are just as capable as
maleCOLUMN: Court storming should be a thing of the pastCOLUMN: Court storming needs to stayCOLUMN: EIU
should move on from swim programPanthers of the Week: Joe Stoddard, Alex TettehFall 2024 athletes to
watchPanthers of the Week: Joe Stoddard, Taris ThorntonPanthers of the Week: Macy McGlone, Isai
MoralesCOLUMN: Why you should watch running sportsPanthers hope for first conference win against
TigersCharleston loses 42-10 at homecomingCharleston looks to break losing streak against Mount
ZionTakeaways from the Coles County ClashPanthers of the Week: Abby Reinl, Quenton RogersFormer EIU
soccer coach returns for first game since departureEIU men's soccer loses 3-0 to Houston Christian UniversityEIU
women's soccer wins 4-0 on senior nightPanthers of the Week: Alex Tetteh, Abby ReinlEastern loses 4-1 to
Incarnate WordGrover, Oslanzi, Archibald win OVC AwardsPanthers of the Week: McKenzie Oslanzi, Joe
StoddardPanthers of the Semester: Tiger Booker, Macy McGlone, Tara ArchibaldCatcher talks about being a black
belt in Q&AEIU softball loses nine-game winning streak to Tennessee TechThrough 40 years of coaching: Scott
TeetersCOLUMN: EIU should move on from swim programEIU swim competes for first time in 2024EIU Swim
competes as wholeAthletes to watch in the winterFall 2024 athletes to watchPanthers of the Week: William Hays,
Danny InfanteEIU men's tennis gets second straight victory with win against USIEIU tennis siblings' journey from
AustraliaEIU tennis coach with varied past: Robin CambierJunior outside hitter talks about support system in
Sweden in Q&AEIU volleyball wins first conference gameTakeaways from EIU volleyballSouthern Indiana's runs
trample EIU volleyballEIU volleyball loses close match against Southern IndianaCOLUMN: 'Lars and the Real Girl:'
a very, very different type of rom-comFitness, followers, family: Monica AlifantisCOLUMN: 'Beast:' a narratively dull,
sporadic filmRadius and local A cappella groups light up DoudnaCOLUMN: 'Flight:' What can't Denzel
do?COLUMN: Future educators: get organizedCOLUMN: Boo! Get off the stage!EDITORIAL: Ranked choice voting
is the way to goCOLUMN: 'Beast:' a narratively dull, sporadic filmCOLUMN: 'Megalopolis:' the art of insisting upon
yourselfTwo Dudes Talk Movies Ep. 70: Joker: Folie à Deux and the Horrible, No Good, One Bad DayTwo Dudes
Talk Movies Ep. 69: Rebel Ridge: Every Ridge Has A PlateauTwo Dudes Talk Movies Ep. 68: Whiplash:
Aggression vs. PassionPanther Playbook Ep.5: Football in a hurricane, The Coles County Clash, EIU teams begin
OVC playThe Overton Window: Ep. 6: Under the Radar RacesTHROUGH THE LENS: Tour De

                                                                                                 Page 3 of 7
                                    The geological Avenger on EIU's campus

CharlestonTHROUGH THE LENS: Camp New Hope celebrates 50th anniversaryTHROUGH THE LENS:
Something's cooking in Klehm HallTHROUGH THE LENS: Glow Foam Party lights up South QuadTHROUGH THE
LENS: Fresh produce at the Charleston Farmer's Market

Search this site

Submit Search

Open Navigation Menu

The Daily Eastern News
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The Daily Eastern News

Open Search Bar

Search this site

Submit Search

Open Navigation Menu

The Daily Eastern News
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The Daily Eastern News

Open Search Bar

Search this site

Submit Search

Categories:

                                                                                                        Page 4 of 7
                                      The geological Avenger on EIU's campus

    •   News
    •   Showcase

The geological Avenger on EIU's campus

Luke Brewer, Reporter

·

October 17, 2024

Luke Brewer Jake Crandall moving analog samples in the lab located in the Physical Sciences building at Eastern
Illinois University on Oct 4, 2024.

An Eastern Illinois University professor and NASA contractor is researching Venus from EIU's backyard.

Geology professor Jake Crandall, with the help of an EIU student, is utilizing analog sites, radar and remote sensing
techniques to study the potential geologic activity of Venus.

Crandall joined the Analogs for Venus' Geologically Recent Surfaces Initiative (Avengers), a group of thirty experts
across the world studying Venus, two years ago to provide his expertise helping the group look for terrestrial analog
sites.

Analog sites are locations on one planet that are similar to another location in space. For example, Utah has sulfur
deposits similar to the deposits found on Mars, Crandall said.

Venus is a volcanic planet, meaning the best site for Crandall to find analog sites on Earth is near active
volcanoes.

So far, the primary analog sites for the Avengers' research are Mount Etna off the coast of Sicily, Italy, and lava
flows in Hawaii, according to Crandall. These sites are comparable to Idunn Mons, a shield volcano on Venus.
Shield volcanoes are the largest type of volcano on Earth.

To determine what is a good analog site or not, samples of rocks are brought back to labs and cut into very thin
portions by researchers, Crandall said. One of these labs is EIU's Physical Science Building.

Jasper Tyner, a senior geology major, helps Crandall research these sites in hopes of finding new data that can
help the Avengers. Tyner also helps use radar and remote sensing techniques to "see through" Venus' harsh
atmosphere to learn more about how the rocks on the planet's surface have changed over time, he said.

Any data found is then presented at the Lunar and Planetary Science Conference held each year in Houston,
Texas, to help understand how Venus formed, Crandall said.

Jake Crandall sampling a volcanic rock as part of our ongoing Mars/Venus analog projects near Green River, Utah
in the fall of 2018. (Submitted photo)

New information could go on to influence the theory of how the solar system was formed as well.

Currently, Tyner said he is helping create a poster to take to LPSC where he will be the first student from EIU to
attend the conference.

This research effort is not only based in the United States, as the project is an international effort. It features the
likes of NASA, the European Space Agency, the India Space Agency, the China National Space Administration and
the State Corporation for Space Activities based in Russia.

Crandall said the project has been, "a major international bridge in the volcanic and planetary society," as everyone
gets along with each other...mostly.

                                                                                                         Page 5 of 7
                                        The geological Avenger on EIU's campus

Only a few missions are selected to move into the creation and deployment phases, resulting in, as Crandall said,
"very vigorous debates" between the different international teams on whose project deserved to go forward. At
LPSC, there has been debate regarding if Venus is or isn't geologically active, he said.

One reason only a few missions are selected is due to the cost. According to Crandall, it's highly expensive to
create and deploy missions to Venus. The landers and probes sent to the planet don't last long and cost millions.

For example, the Soviet Union launched the Venera 13 lander to Venus that only lasted 127 minutes on the
surface, or two hours and seven minutes, according to NASA.

Currently regarding Venus, the VERITAS and DAVINCI+ missions, both designed to test the surface and
atmosphere of Venus respectively, were given the green light to proceed and are currently in the creation progress
following the funding phase. Both missions are owned by NASA.

Another issue resulting in limited missions is due to contracting issues with high-value contractors, like Boeing.

Crandall said there are other various factors to account for that could hinder missions like the math and science
behind the project taking too long and the possibility of helium and hydrogen leaks due to the small particles being
hard to contain.

"People forget that space is really difficult," said Crandall.

To mend this, both Crandall and Tyner believe that interest in space exploration and research deserves to go up.
Tyner also mentioned how when he was younger, a lot of kids wanted to be astronauts, but that isn't the case
nowadays.

"It's going to be slow progress if interest in space doesn't increase," said Tyner.

Luke Brewer can be reached at 581-2812 or at lsbrewer@eiu.edu

View Story Comments

0

Like This Story

Share on Facebook

Share on X

Email this Story

Print this Story

Leave a Comment

Tags:
    •    Avengers
    •    Geology
    •    Jake Crandall
    •    NASA
    •    Venus

More to Discover

                                                                                                Page 6 of 7
                                       The geological Avenger on EIU's campus

More in News

On-campus enrollment down 7%, administration feeling positive

Construction happening all around EIU

EIU student government swears in new senator

"The Thinking Game" screening discusses AI

Health and Wellness Fair provides resources to students

EIU GSD hosts National Coming Out Day

More in Showcase

EIU athletic director responds to House v. NCAA preliminary approval

EIU women's soccer wins 4-0 on senior night

Fitness, followers, family: Monica Alifantis

What EIU takes away from Coles County Clash

Late goal gives EIU women's soccer first OVC win

Homecoming court crowned for 2024

About the Contributor

Luke Brewer, Reporter

Luke Brewer is a freshman journalism major and can be reached at 581-2812 or lsbrewer@eiu.edu

The Daily Eastern News

The student news site of Eastern Illinois University in Charleston, Illinois.

Facebook

Instagram

X

Tiktok

YouTube

RSS Feed
    •    News
    •    Sports
    •    Arts & Entertainment
    •    Opinions
    •    Podcasts
    •    Through the Lens

                                                                                               Page 7 of 7
                                  The geological Avenger on EIU's campus

      •   About

The Daily Eastern News · © 2024 · FLEX Pro WordPress Theme by SNO · Log in

Comments (0)

Commenting on the Daily Eastern News web site is a privilege, not a right. We reserve the right to remove
comments that contain obscene, vulgar, lewd, racist or sexually-oriented language. Also, comments containing
personal attacks or threats of harming another person will not be tolerated.

Share your thoughts...

All

The Daily Eastern News Picks

Reader Picks

Sort: Newest

Close

Close Modal Window

Close


Load-Date: October 17, 2024


  End of Document

                                                                                              Page 1 of 8
                              On-campus enrollment down 7%, administration feeling positive




           On-campus enrollment down 7%, administration feeling positive
                                        Daily Eastern News: Eastern Illinois University
                                                      October 15, 2024 Tuesday



University Wire
Copyright 2024 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 2441 words

Body

content"class="skip-to-content">Skip to Content

The Daily Eastern News

Facebook

Instagram

X

Tiktok

YouTube

RSS Feed
     •    Welcome back to the Daily Eastern News!
     •    Check out our podcasts on Spotify!
     •    Oct. 14- Corey Durham in the Doudna recital hall at 6 pm
     •    Oct. 15- Volleyball vs. SIUE in Groniger Arena at 6 pm
     •    Oct. 15- Songwriter showcase in the Doudna Black Box at 7:30 pm
     •    Oct. 16- Para la Cultura: Talent Night in 7th street underground at 6 pm
     •    Oct. 17- Untitled (Cut) @theTarble from 1-6 pm at the Tarble
     •    Oct. 17- Women's Soccer vs. Tennessee Tech at 3 pm
     •    Oct. 17- Jazz Combos in the Black Box at 7:30 pm
     •    Oct. 18- Eastern Symphony Orchestra in the Dvorak Concert Hall at 7:30 pm
     •    Oct. 19- Volleyball vs Tennessee Tech in Groniger Arena at 4 pm
     •    Volleyball standings: 4-11 on the season (0-5 in conference)

                                                                                                      Page 2 of 8
                          On-campus enrollment down 7%, administration feeling positive

    •   Soccer standings: Women's at 3-6-5 (1-2-2), Men's at 1-9-1 (0-5)
    •   Football standings: 1-6 on the season (0-3 in conference)
    •   Check out our newsletters on Overlooked!

The Ticker
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

On-campus enrollment down 7%, administration feeling positiveConstruction happening all around EIUEIU student
government swears in new senator"The Thinking Game" screening discusses AIHealth and Wellness Fair provides
resources to studentsFormer EIU soccer coach returns for first game since departureEIU men's soccer loses 3-0 to
Houston Christian UniversityEIU women's soccer wins 4-0 on senior nightPanthers of the Week: Alex Tetteh, Abby
ReinlPanthers hope for first conference win against TigersAnderson reflects on Yankees career during 9/11EIU
Baseball's path through OVC TournamentEIU Baseball honors seniors, win over MSUEIU Baseball drops second
game against MSUEIU Baseball loses fifth straight gameBollant leaves EIU basketball programDavis, Luers enter
transfer portalPanthers of the Year: MJ Flowers, Macy McGlone, Sara ThomasPanthers of the Semester: Tiger
Booker, Macy McGlone, Tara ArchibaldSTAFF PICKS: NBA finals winnerCOLUMN: What went wrong with EIU
football?COLUMN: Female athletes are just as capable as maleCOLUMN: Court storming should be a thing of the
pastCOLUMN: Court storming needs to stayCOLUMN: EIU should move on from swim programPanthers of the
Week: Joe Stoddard, Alex TettehFall 2024 athletes to watchPanthers of the Week: Joe Stoddard, Taris
ThorntonPanthers of the Week: Macy McGlone, Isai MoralesCOLUMN: Why you should watch running
sportsPanthers hope for first conference win against TigersCharleston loses 42-10 at homecomingCharleston looks
to break losing streak against Mount ZionTakeaways from the Coles County ClashPanthers of the Week: Abby
Reinl, Quenton RogersFormer EIU soccer coach returns for first game since departureEIU men's soccer loses 3-0
to Houston Christian UniversityEIU women's soccer wins 4-0 on senior nightPanthers of the Week: Alex Tetteh,
Abby ReinlEastern loses 4-1 to Incarnate WordGrover, Oslanzi, Archibald win OVC AwardsPanthers of the Week:
McKenzie Oslanzi, Joe StoddardPanthers of the Semester: Tiger Booker, Macy McGlone, Tara ArchibaldCatcher
talks about being a black belt in Q&AEIU softball loses nine-game winning streak to Tennessee TechThrough 40
years of coaching: Scott TeetersCOLUMN: EIU should move on from swim programEIU swim competes for first
time in 2024EIU Swim competes as wholeAthletes to watch in the winterFall 2024 athletes to watchPanthers of the
Week: William Hays, Danny InfanteEIU men's tennis gets second straight victory with win against USIEIU tennis
siblings' journey from AustraliaEIU tennis coach with varied past: Robin CambierTakeaways from EIU
volleyballSouthern Indiana's runs trample EIU volleyballEIU volleyball loses close match against Southern
IndianaHieb returns to volleyball program after one year awayPanthers of the Week: Kaelin Drakeford, Sylvia
HaszCOLUMN: 'Lars and the Real Girl:' a very, very different type of rom-comFitness, followers, family: Monica
AlifantisCOLUMN: 'Beast:' a narratively dull, sporadic filmRadius and local A cappella groups light up
DoudnaCOLUMN: 'Flight:' What can't Denzel do?COLUMN: Boo! Get off the stage!EDITORIAL: Ranked choice
voting is the way to goCOLUMN: 'Beast:' a narratively dull, sporadic filmCOLUMN: 'Megalopolis:' the art of insisting
upon yourselfCOLUMN: Fall is the best time of yearTwo Dudes Talk Movies Ep. 70: Joker: Folie à Deux and the
Horrible, No Good, One Bad DayTwo Dudes Talk Movies Ep. 69: Rebel Ridge: Every Ridge Has A PlateauTwo
Dudes Talk Movies Ep. 68: Whiplash: Aggression vs. PassionPanther Playbook Ep.5: Football in a hurricane, The
Coles County Clash, EIU teams begin OVC playThe Overton Window: Ep. 6: Under the Radar RacesTHROUGH
THE LENS: Tour De CharlestonTHROUGH THE LENS: Camp New Hope celebrates 50th anniversaryTHROUGH

                                                                                                 Page 3 of 8
                         On-campus enrollment down 7%, administration feeling positive

THE LENS: Something's cooking in Klehm HallTHROUGH THE LENS: Glow Foam Party lights up South
QuadTHROUGH THE LENS: Fresh produce at the Charleston Farmer's Market

Search this site

Submit Search

Open Navigation Menu

The Daily Eastern News
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The Daily Eastern News

Open Search Bar

Search this site

Submit Search

Open Navigation Menu

The Daily Eastern News
    •   News
    •   Sports Baseball Basketball Columns Cross Country Football Soccer Softball Swimming Tennis Volleyball
    •   Arts & Entertainment
    •   Opinions
    •   Podcasts
    •   Through the Lens
    •   About Staff Advertising Privacy Policy
    •   More

The Daily Eastern News

Open Search Bar

Search this site

Submit Search

Categories:
    •   News

                                                                                                          Page 4 of 8
                           On-campus enrollment down 7%, administration feeling positive

    •    Showcase

On-campus enrollment down 7%, administration feeling positive

Alli Hausman, Managing Editor

·

October 15, 2024

EIU's on-campus enrollment fell by over 7% this semester, but administration said they have plans like direct
admission and increasing out-of-state marketing to fix it. (File)

EIU's on campus enrollment is down 7.35% for fall 2024, marking the biggest percent drop since 2018.

Despite this drop, Eastern Illinois University's administration is feeling largely positive because enrollment actually
ended better than anticipated, according to Vice President for Enrollment Management Josh Norman.

"I feel really good about where we landed because of all of the market factors that we had to endure," Norman
said.

Overall, Eastern's enrollment fell 3.40% this year. However, in the past eight years, enrollment has trended upward.


This is the lowest overall enrollment has been since 2021.

EIU's fall semester on-campus and overall enrollment from the past eight years.

EIU's fall semester on-campus and overall enrollment from the past eight years. (Alli Hausman)

Enrollment fell this year, Norman said, because of three primary factors: delayed Free Application for Federal
Student Aid, visa denial for prospective international students and an abnormally large graduating class in 2023.

Last year, FASFA released three months late on Dec. 30 rather than the typical Oct. 1, due largely to issues related
to a Congress mandated simplification process.

"When you go from a cycle where you open up the FASFA in February and you package aid in December, and the
FASFA doesn't open until December and you don't package aid until May, that pushes everything back," Norman
said.

While Eastern pushed back grant and scholarship deadlines to make up for the lost time, Norman said it wasn't
enough to maintain enrollment.

In total, the number of students nationally who completed FASFA dropped 11.6% from 2023, according to data from
the National College Attainment Network.

According to Director of Marketing and Communications Christy Kilgore, FASFA being delayed as long as it was
came as a surprise last year.

Both Norman and Kilgore said the university began preparing for lower enrollment as soon as word on extended
delays started.

This year, she said, EIU is anticipating FASFA opening late and are starting to prepare for it early in financial aid.

Alongside the FASFA issues, Norman said international student enrollment was well below what was expected.

He said there were some major issues including visa denial and a lack of visa appointments being made and
followed through with.

                                                                                                        Page 5 of 8
                          On-campus enrollment down 7%, administration feeling positive

Many prospective international students were denied this year, he said, with international students down around
200 less than anticipated.

Norman also pointed to last year's graduating class as part of the reason EIU's numbers dropped.

Over 1,270 students graduated last year, larger than any incoming fall freshman class since 2017, according to past
tenth day reports.

This year, the reported freshman class including on- and off-campus students was 1,040. There were 1,093
freshmen in total in 2023 and 1,201 in 2022.

"Despite this sub optimal outcome from the lower-than-expected international student enrollments and overall
enrollment, because we planned for it, we're in pretty good shape," said Norman. "We're just going to have to be
continually mindful of the future."

He said EIU is going into the next fiscal year with a balanced budget.

Eastern has put out a number of plans to wrangle in enrollment at both the marketing and administrative level for
the spring semester and fall of next year.

According to Norman, there are over 100 strategic action plans in place with 55 people in administration working on
them, in connection to President Jay Gatrell's Plan 2028, ranging from direct admission projects to a new marketing
kit.

One of the biggest, he said, was a new direct admissions program. Under the new program, EIU's partnered high
schools will send lists of directory information for students with a minimum of 3.0 grade point average. Then, EIU
will reach out to the students and offer direct admission to the university.

Currently, Norman said over 2,000 students have been identified for direct admission within the region.

Happening next year, the freshman connection program will be mandatory in some form for all incoming freshman,
he said.

According to Norman, freshmen will have the option of being in both university foundation class and freshman
connections, just freshman connections with mandatory lunches with mentors or can opt to just have a mentor.

"This isn't just about enrolling new incoming students," he said. "This is about better serving our current students as
well."

There have been many changes over in marketing as well, Kilgore said.

This year, EIU is focused on bigger scale out-of-state marketing.

After last year's in-state tuition change, removing out-of-state tuition from EIU, a larger avenue has been opened to
the marketing department.

The EIU marketing department is exploring sending more direct mail instead of emails to students in lieu of the
enrollment drop. (File)

Kilgore said that marketing is looking to focus in on those areas, especially for the St. Louis, Missouri, and Terra
Haute, Indiana, areas.

The out-of-state tuition removal, she said, was a change made specifically with enrollment in mind.

Additionally, EIU is starting early on updated financial aid calculators with more features. Kilgore said. Last year,
Kilgore said they were scrambling to update the calculator at the last minute.

Direct mail will also be making a comeback in marketing this year, Kilgore said.

                                                                                                         Page 6 of 8
                            On-campus enrollment down 7%, administration feeling positive

Where historically mass letters through mail have been ignored, quite literally coining the term junk mail, according
to Kilgore, this isn't the case anymore.

"It feels fun to get something in the mail as opposed to digitally now," she said.

She said she believes letters will garner more attention and bring in students more than an email can.

Overall, Kilgore said that marketing has become a lot more "intentional" as the years have gone by.

"Way back, I mean like old days old days, you made a viewbook and then people [would] come to our school," she
said.

Marketing's biggest long-term shift, Kilgore said, has been trying to reframing how students look at college debt.

"I think a lot of students growing hearing those kinds of narratives and assume if you go to college, you're going to
be eleventy billion dollars in debt forever," she said.

EIU's prime demographic is middle to lower income students, being ranked seventh in the region for best value
recently.

Marketing is seeking to show high school seniors that college doesn't have to come with steep debt, she said.

Looking forward, according to Norman, freshman applications for fall 2025 are up 17% compared to last year at this
time.

He said spring 2025 is already looking up on admissions and expects spring enrollment to fill in some of the gaps
from fall.

Kilgore is also confident for the future.

"I will never think a place like Eastern doesn't have a place in the world," she said.



Alli Hausman can be reached at 581-2812 or at athausman@eiu.edu

View Story Comments

0

Like This Story

Share on Facebook

Share on X

Email this Story

Print this Story

Leave a Comment

Tags:
    •    Christy Kilgore
    •    enrollment
    •    Josh Norman

                                                                                                    Page 7 of 8
                           On-campus enrollment down 7%, administration feeling positive

    •    Tenth Day enrollment

More to Discover

More in News

Construction happening all around EIU

EIU student government swears in new senator

"The Thinking Game" screening discusses AI

Health and Wellness Fair provides resources to students

EIU GSD hosts National Coming Out Day

How to deal with time management issues

More in Showcase

EIU women's soccer wins 4-0 on senior night

Fitness, followers, family: Monica Alifantis

What EIU takes away from Coles County Clash

Late goal gives EIU women's soccer first OVC win

Homecoming court crowned for 2024

The history of the Coles County Clash

About the Contributors

Alli Hausman, Managing Editor

Alli Hausman is a junior journalism major and can be reached at 581-2812 or athausman@eiu.edu She previously
served as the copy chief.

Mackenzie Fehrenbacher, Photographer

Mackenzie Fahrenbacher is a sophomore public relations major. This is her first year at The News.

The Daily Eastern News

The student news site of Eastern Illinois University in Charleston, Illinois.

Facebook

Instagram

X

Tiktok

YouTube

RSS Feed
    •    News

                                                                                               Page 8 of 8
                          On-campus enrollment down 7%, administration feeling positive

      •   Sports
      •   Arts & Entertainment
      •   Opinions
      •   Podcasts
      •   Through the Lens
      •   About

The Daily Eastern News · © 2024 · FLEX Pro WordPress Theme by SNO · Log in

Comments (0)

Commenting on the Daily Eastern News web site is a privilege, not a right. We reserve the right to remove
comments that contain obscene, vulgar, lewd, racist or sexually-oriented language. Also, comments containing
personal attacks or threats of harming another person will not be tolerated.

Share your thoughts...

All

The Daily Eastern News Picks

Reader Picks

Sort: Newest

Close

Close Modal Window

Close


Load-Date: October 15, 2024


  End of Document

                                                                                                        Page 1 of 3
                                                      No Headline In Original




                                               No Headline In Original
                                           The Columbian (Vancouver, Washington)
                                                     March 16, 2024 Saturday



Copyright 2024 The Columbian Publishing Co. All Rights Reserved

Section: LETTERS TO EDITOR; Pg. A12
Length: 959 words
Highlight: Republicans embrace ignorance

In offering an explanation for measles, which was considered eliminated a quarter-century ago, The Columbian
("Misinformation to blame for measles comeback," In Our View, March 7) wrote: "The situation reflects absurdly
willful ignorance from large segments of the population."

Unfortunately, absurdly willful ignorance is a hallmark of America's Republican voters. Millions of these voters:

n Continue to believe that the 2020 election was stolen from their man despite a plethora of evidence that it was not
and none that it was;

n View Jan. 6, 2021, as a reasonable exercise of their dissatisfaction with the outcome of the 2020 election as do
many of their congressional representatives (who probably don't believe that but realize that they couldn't hold
office without their support). This, after most of them watched the insurrection on live television (like their
designated hero);

n Will actually support their main guy in November even if he's convicted of all 91 charges against him.

Norm Krasne

VANCOUVER

Explore benefits of AI

I was pleased to see a productive - and civilized - discussion about the benefits and challenges posed by artificial
intelligence ("It's just complicated math: Columbian's Economic Forecast event zooms in on AI," The Columbian,
March 5). Another aspect of AI that should be considered when discussing the technology's role in our local
economy is how the technology is already shaping the future of other top industries in the region.

Body

Republicans embrace ignorance
In offering an explanation for measles, which was considered eliminated a quarter-century ago, The
Columbian ("Misinformation to blame for measles comeback," In Our View, March 7) wrote: "The situation
reflects absurdly willful ignorance from large segments of the population."

Unfortunately, absurdly willful ignorance is a hallmark of America's Republican voters. Millions of these
voters:

                                                                                             Page 2 of 3
                                          No Headline In Original

n Continue to believe that the 2020 election was stolen from their man despite a plethora of evidence that
it was not and none that it was;
n View Jan. 6, 2021, as a reasonable exercise of their dissatisfaction with the outcome of the 2020
election    as do many of their congressional representatives (who probably don't believe that but realize
that they couldn't hold office without their support). This, after most of them watched the insurrection
on live television (like their designated hero);
n Will actually support their main guy in November even if he's convicted of all 91 charges against him.
Norm Krasne
VANCOUVER

Explore benefits of AI

I was pleased to see a productive - and civilized - discussion about the benefits and challenges posed by
artificial intelligence ("It's just complicated math: Columbian's Economic Forecast event zooms in on AI,"
The Columbian, March 5). Another aspect of AI that should be considered when discussing the technology's
role in our local economy is how the technology is already shaping the future of other top industries in
the region.

Take health care, for example, which was cited by economist Scott Bailey as one of the top drivers of job
growth in Clark County. AI is being deployed across numerous applications to improve health care delivery
across the U.S., and it holds exciting potential for reducing health disparities in Washington's
underserved communities.

AI's health care applications should be at the forefront of policymakers' minds as they look to develop
rules of the road for this emerging technology. With Attorney General Bob Ferguson and members of the
Legislature working to establish a new AI Task Force, it is critical that our elected leaders take a
measured approach to AI regulation that addresses legitimate issues while not derailing the benefits this
technology offers Washington residents.
Susannah Hardesty
VANCOUVER
Support carbon dividend plan
It can be disheartening to see an environmental policy fail. Luckily, failure is often just an opportunity
for improvement. That's the message I took away from a recent article ("California's war on plastic bag
use seems to have backfired. Lawmakers are trying again," Los Angeles Times, Feb. 18).
Similarly, we can look to other countries to learn about their climate change solutions. Putting a price
on carbon - a carbon fee and dividend - is successful in countries like Canada. These programs collect
fees from companies as they extract and release carbon emissions, and the money is cycled back to citizens
in checks similar to economic stimulus checks.
Putting a price on carbon is a proven win-win that the U.S. needs to get in the game on. I encourage our
Sens. Maria Cantwell and Patty Murray, and Oregon Sens. Ron Wyden and Jeff Merkley, to support a carbon
fee and dividend for a livable future.
Jessica Lang
PORTLAND
Pending loss of Vanco golf is sad
The city of Vancouver has decided to build apartments in the place of Vanco driving range ("After more
than 50 years, Vanco Golf Range to close in October," The Columbian, March 8). It's clear someone made
this decision from their desk in some office away from this site.
The city would never build on one of their many parks would they? Some of these parks I assume don't get
as many visitors per day as Vanco. I started going to Vanco about two years ago. This is my and many other
people's city park. I've met many amazing people at this establishment. It has a feel of community and
friendship.
On only the third visit, the owner and I were on a first-name basis as well as some of the employees. You
are taking away all these employees' and owner's livelihood. You're taking away something that has been
there for decades and decades. A place where people go to make their day better and hopefully their golf
game better as well.
I get that Vancouver needs more housing. I don't get the location that you have chosen. It's been around
longer than most city of Vancouver employees. It's very sad.
Brandon Schouviller
VANCOUVER
A win-win for can scavengers
For years, I have seen people going through recycling containers in my Vancouver neighborhood to get out
the aluminum cans ("Can collectors' rummaging rankles Clark County residents," The Columbian, Feb. 21). I

                                                                                             Page 3 of 3
                                          No Headline In Original

admire them for working that hard to get 10 cents per can, and I doubt they would do so if they had a
better source of income.
Several months ago, I started putting my cans into a separate container and setting it out along with the
recycling bins the night before the truck comes. Someone picks up the cans and doesn't have to go through
the Waste Connections recycling container with the cardboard and metal to look for them. The cans are mine
and I can choose to recycle them myself or give them to someone else to do so.
This is one simple way to cope with the problem of people going through official recycling containers and
irritating homeowners.
Tom Paulu
VANCOUVER
Legislator makes a difference
Thank you Sen. Lynda Wilson for your tireless work on three important issues: Domestic violence against
women, hospital patient rights and most recently your leadership on a bill that passed regarding police
pursuits. You show that legislators can have an impact ("Washington state Sen. Lynda Wilson to step down
from Legislature to spend time with family," The Columbian, March 6).
Greg Flakus
VANCOUVER



Load-Date: April 9, 2024


  End of Document

