
Cerebrospinal fluid leaks, caused by tears or holes in the spinal cord, are rare and difficult to identify. Because the symptoms aren't uncommon - including nausea, neck pain, ringing in the ears and debilitating positional headaches - patients can spend years without a proper diagnosis. Some have been told they have allergies. 
As in a growing number of medical fields, artificial intelligence may upend the way such maladies are detected and treated - boosting accuracy, saving money and in many cases drastically improving lives. While most AI-enabled devices approved by U.S. regulators today are diagnostic, the potential uses of the technology in health care are vast, from automating tedious administrative tasks to accelerating drug discovery. By some estimates, broad adoption of AI could save up to $360 billion in annual health spending. 
Spinal fluid leaks may offer a glimpse of what's ahead. While an MRI can show changes in the brain that suggest a leak, finding the source - often a teeny, irregularly dribbling tributary, which can occur anywhere along the spine - requires the higher spatial resolution of a CT scanner. Yet the core technology running such machines hasn't meaningfully improved in decades. 
Now that's changing. So-called photon-counting CT scanners use AI and advanced semiconductors to detect previously invisible spinal leaks, enabling treatment and often leading to full recovery. Patients have described the technology as life-changing. 
Beyond neurology, such scanners can identify small irregularities before they become major health threats - from unruptured aneurysms to dangerous amounts of arterial plaque. Their ability to screen for cardiovascular disease and stroke, two of the top causes of death globally, could revolutionize preventive care. 
A key challenge for AI-reliant medical devices is the amount of data needed to train their models. In the U.S., such information is often siloed in provider and hospital databases. The government has invested billions of dollars to encourage data sharing. Yet more than 60% of hospitals reported at least one major barrier to information exchanges last year - roughly 70% are still using fax machines. 
Improving this picture should be a priority. The accuracy and usefulness of AI models depend on innovators gaining access to vast troves of data - optimally from multiple health systems and countries, in various formats and languages. Encouragingly, the private sector is in the early stages of building other AI tools that can process "unstructured" data. But while U.S. health agencies have shown interest, they haven't fully embraced such products for regulatory purposes - an important first step toward wider adoption. 
Lawmakers, too, can do their part. With funding from Congress, agencies can collaborate to develop a large dataset of high-quality and anonymized patient information for AI training. Models trained on "regulatory grade data," as former Food and Drug Administration Commissioner Scott Gottlieb puts it, would improve diagnostic accuracy and could be granted streamlined approvals. Last week, the FDA and Department of Veterans Affairs announced one such plan - a joint "health AI lab" - to test AI tools using VA data. Narrowing the FDA's mission - to focus on ensuring data quality and precision, and preventing bias - might also make better use of limited resources. 
Relying on AI for diagnoses and preventive screenings isn't without drawbacks. In addition to cost, there's a risk of unnecessary or harmful interventions. Ultimately, though, faster, more accurate scans will become more affordable and increase access, especially for high-risk patients. It's worth noting the initial skepticism of preventive CT scans for smokers quickly dissipated once research showed screenings drastically reduced the risk of lung cancer. 
The ability for AI to improve the lives of patients is no longer theoretical. With increased access to data, AI-driven treatment can become the standard of care. 


