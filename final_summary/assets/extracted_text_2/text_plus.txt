User Name: =
Date and Time: = 2024-12-07
Job Number: = 240314555



Documents (297)

  Client/Matter: -None-
  Search Terms: AI, health
  Search Type: NaturalAnd
  Content Type                       Narrowed by
  news                               : Newspapers Timeline: Jan 01, 2020 to Dec 31, 2023
                                     Source Location: North America Source Location: United
                                     States Source Language: English


  1. UW HEALTH USING AI IN EPIC MEDICAL RECORDS


  2. Local health systems leverage AI for better outcomes, efficiency


  3. Health care leaders seek regulation, transparency for AI in health industry


  4. 'The potential is unbelievable': First chief data scientist of Duke Health talks
  intersection of AI and healthcare


  5. Hackers target health care AI amid coronavirus pandemic


  6. Improving Kupuna Health Through 'Ai Pono


  7. Emory launches institute focused on AI use to promote health equity


  8. Faculty Assembly addresses Plan for Pitt, health care and AI in monthly meeting - The
  Pitt News


  9. TOO MUCH HEALTH TECH AI MAY BE BAD FOR YOUR HEALTH




              | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

10. Is your health insurer using AI to deny you services? Lawsuit says errors harmed
elders.


11. UF , Jacksonville propose new graduate campus focused on health administration and
AI


12. Montreal start-up Aifred Health is applying AI to mental healthcare


13. AI can help combat health misinformation, White House cancer research head says


14. What do experts say about AI in health care?


15. SUNY , UAlbany to Research AI for Mental Health Treatment


16. Experts weigh role of AI in health care's future From filling out forms to creating a
treatment plan, professionals are eager to use new technologies


17. AI'S POTENTIAL IN HEALTH CARE DOMINATES EVENT


18. AI biases could worsen health disparities Experts: Technology could lead to
advancements but brings biased algorithms


19. Telehealth Week @ TTUHSC Conference to highlight digital healthcare


20. Biovista Personalized Medicine and Diginova to deliver next generation AI-driven
doctor/patient support in a deal that can generate over $5 Billion.


21. Point-counterpoint: ChatGPT's role as therapy alternative


22. Ad agencies rethink mental health policies Amid layoffs, AI fears and an uncertain
economy, shops are prioritizing employee well-being and preventative care


23. Possibilities, concerns rise as artificial intelligence breaks into health care


24. U. expert discusses AI bias in research studies


25. Walla Walla students' mental health app and AI idea wins State of Innovation
Challenge award



            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

26. BU artificial intelligence symposium explores intersection between AI and public
health


27. UC Berkeley researcher argues artificial intelligence cannot replace human empathy


28. Mercy looks to AI to relieve burden on health care workers, answer patients'
questions


29. HIGHMARK HEALTH DIPPING A TOE IN AI POOL


30. Arunachal Minister Alo Libang launches AI-driven technology intervention at institutes


31. U Receives $100 Million for Responsible AI Initiative


32. Free-market health care innovations should be used to make lives better, not expand
government power


33. Duke Health to partner with Microsoft on development and use of generative AI, cloud
technology


34. Retirement health costs a concern for many


35. 'Improve health for all': Dr. Ziad Obermeyer named to TIME100 AI


36. AI helps detect heart disorder


37. Man Hung AI is saving lives and improving health care systems


38. Mount Sinai Launches Dept Of Artificial Intelligence And Human Health


39. Revolutionizing medicine: Aimon Rahman on enhancing health care with deep
learning


40. AI Impact On Mammograms, Breast Health & The OBGYN Field


41. Biden signs executive order to guide AI safety




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

42. Biden signs executive order to guide AI safety


43. Parkland school shooting survivor develops Joy, an app built on AI that helps people
heal


44. Mayo Clinic explores use of artificial intelligence. Is it hype or help?


45. Experts discuss AI use across fields at conference


46. Health care artificial intelligence gets biased data creating unequal care


47. Most Patients Have Positive Views About AI in Medicine


48. Exploring how artificial intelligence could redefine health care


49. Most Patients Have Positive Views About AI in Medicine


50. Can AI help improve outcomes for cancer patients?


51. The US Executive Order on artificial intelligence is out.


52. AI HELPING UPMC DOCTORS WITH TRANSCRIPTION


53. Renowned health scholar joins Emory School of Medicine amid artificial intelligence
research expansion


54. BRIEFLY


55. Penn State students, alumnus develop Reach.AI to address health disparities within
marginalized communities


56. S. Korean startup HoneyNaps' sleep diagnostic software Somnum earns U.S. approval


57. Does AI or ChatGPT provide accurate medical advice?


58. Surgalign receives FDA clearance for surgical guidance system




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

59. President signs executive order for guardrails on AI


60. Parkland survivor creates wellness app Parkland school shooting survivor develops
Joy, an app built on AI that helps people heal


61. School of Public Health kicks off 10-year anniversary celebrations with reception - The
Brown Daily Herald


62. AI is too biased to be trusted in the medical field


63. AI is too biased to be trusted in the medical field


64. AI tools are keeping hospital patients alive and well Opinions


65. AI tools are keeping hospital patients alive and well Opinions


66. Software developer (and other coding careers) Blockchain jobs Virtual reality jobs Big
data analyst Content creator AI jobs Mental health jobs Data broker Augmented reality
developer Drone expert/pilot Entrepreneur


67. AI May Be On Its Way To Your Doctor's Office, But It's Not Ready To See Patients


68. Dr. Jamal Lawrence Announced As GRIT 2024 Keynote


69. Vietnam well-positioned to benefit from AI: website


70. UF to use $23.5 million grant to build AI infrastructure to improve critical care
HEALTHY LIVING


71. From the Community | Stanford Medicine is taking the step toward better Native
health care Login or create an account


72. AI mission control center for medical care eyed UC San Diego Health will use $22
million given by Joan and Irwin Jacobs


73. UK, NHS hospitals want to partner with PH on health care


74. Artificial Intelligence Outperforms Doctors in Breast Cancer Diagnosis



            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

75. Young ‘surprised’ by bipartisan agreement on AI


76. Medical chatbots developed to speed medical research, alleviate privacy worries


77. Democrats urge FDA to include civil rights, disability and ethics advocates on digital
health committee


78. GATC Health Investor Conference to Feature First Public Demonstration of Its AI
Platform's Drug Discovery Capabilities


79. Artificial Intelligence, Public Trust, and Public Health


80. PNC PILOTS AI-POWERED TOOL FOR DOCTORS, HOSPITALS


81. Social chatbots are abetting the loneliness epidemic


82. Parkland school shooting survivor develops Joy, an app built on AI that helps people
heal Kai Koerber was a junior at Marjory Stoneman Douglas High School when a gunman
murdered 14 students and three staff members on Valentine's Day in 2018


83. Nassau must take a proactive approach to regulating AI


84. Nassau must take a proactive approach to regulating AI


85. Nassau must take a proactive approach to regulating AI


86. Nassau must take a proactive approach to regulating AI


87. Nassau must take a proactive approach to regulating AI


88. Nassau must take a proactive approach to regulating AI


89. Nassau must take a proactive approach to regulating AI


90. Nassau must take a proactive approach to regulating AI




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

91. Nassau must take a proactive approach to regulating AI


92. Nassau must take a proactive approach to regulating AI


93. Nassau must take a proactive approach to regulating AI


94. Nassau must take a proactive approach to regulating AI


95. Nassau must take a proactive approach to regulating AI


96. Nassau must take a proactive approach to regulating AI


97. Nassau must take a proactive approach to regulating AI


98. Nassau must take a proactive approach to regulating AI


99. Regulating AI: Is AI a threat to humanity? | Opinion


100. TALK TO ME THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD, WITH
POWERFUL POTENTIAL IN HEALTH CARE SETTINGS


101. TALK TO ME THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD, WITH
POWERFUL POTENTIAL IN HEALTH CARE SETTINGS


102. Biden seeks guardrails on AI use Biden: President signs order tackling AI issues


103. Biden seeks guardrails on AI use


104. The AI Bill of Rights Is 'Mile One of a Long Marathon'


105. ChatGPT is poised to change medical care AI technology can empower patients, but
glitches make some wary


106. Sen. Mitt Romney says he is 'terrified about AI ' at Senate hearing


107. White House Executive Order Threatens to Put AI in a Regulatory Cage




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

108. UW System schools would develop AI majors under $32 million workforce
development proposal. Here's what they might look like


109. UW System schools would develop AI majors under $32 million workforce
development proposal. Here's what they might look like


110. Electronic Caregiver breaks top 1,000 on Inc. list


111. Microsoft Summit Addresses AI in a Time of Upheaval


112. Researchers: 319K covid deaths could have been avoided


113. Area hospitals using AI to improve processes, patient outcomes Predictive software
is providing doctors with risk assessments for patients prior to procedures being done.


114. AI is gaining attention of state lawmakers Legislators try to guard against
discrimination as technology evolves


115. ChatGPT is poised to change medical care AI technology can empower patients, but
glitches make some wary


116. Healthcare decisions are about to get easier


117. AI makes MRIs 4 times faster, NYU and Meta researchers find


118. Who Should Be Regulating AI Classroom Tools?


119. ChatGPT is poised to upend medical information. For better and worse.


120. WPI Establishes Master's Degree in Artificial Intelligence to Prepare Students for
Growing Field


121. Artificial intelligence is gaining state lawmakers' attention, and they have a lot of
questions


122. WPI Establishes Master's Degree in Artificial Intelligence to Prepare Students for
Growing Field


123. Biden signs executive order to guide AI safety


            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

124. Boulder-based Boomtown goes virtual with help from Shark Tank star


125. Boulder-based Boomtown goes virtual with help from Shark Tank star


126. Researchers find puberty onset associated with racial, economic privilege


127. A case for health care stocks


128. National Science Foundation launches artificial intelligence center at Duke


129. A case for health care stocks


130. A case for health care stocks


131. A case for health care stocks


132. Home State Health and Babylon Partner to Bring App-based, 24/7 Healthcare to
Southeast Missouri


133. Arunachal Pradesh gets second Yolo Health ATM


134. NSF grant funding to support health monitoring system for elderly


135. Apple , Fitbit should use all that data they collect from you to protect public health


136. 2022 Underwriters Laboratories-ASEAN- U.S. Science Prize for Women


137. Local woman awarded Pillars of Strength Scholarship


138. Create introductory AI flag requirement


139. Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges


140. Involta 's Idaho employees use AI to detect COVID-19




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

141. Google CEO Sundar Pichai promises to invest Rs 75,000 Crore in India


142. Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth, Status,
and Forecast | Admera Health LLC , Advinow Inc - The Courier


143. NaturaLawn welcomes new franchise owners


144. Lead into the future with clean energy - The Independent Florida Alligator


145. Mind-boggling implications of AI


146. Will Artificial Intelligence ever live up to its hype?


147. THE CONVERSATION Michigan Medicine CTO is engineering health care's efficiency
transformation


148. How Europe is leading the world in the push to regulate AI


149. PEZA approvals jump 107% to P33-B in Jan-April


150. Children Who Escaped Boko Haram Captivity Are Tortured In Detention Amnesty
International


151. Biden administration focuses on AI Action comes amid public wariness


152. White Paper Offers Ethics Advice for Government Use of AI


153. Pausing AI development would be a mistake. Congress shouldn't meddle – for now.


154. European leaders OK first comprehensive rules for AI


155. Helping vets. Finding tax cheats and illegal rhino horns. How AI could transform
government


156. UMaine hosts webinar on artificial intelligence and its applications for healthcare


157. Goat Reproduction Clinic to be held on Sept. 25



            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

158. Talking Tech : The biggest tech stories of 2023 (so far)


159. Baltimore competes to be national tech hub Officials hoping to generate an
economic boost - upward of $3.2B - to add 52,000 jobs by 2030


160. UChicago expands relationship with Weizmann Institute of Science in Israel


161. BofA acquisition makes its health care payments business more nimble


162. Southeast Texas hospitals employ new stroke technology


163. New CEO at Black Girls Code


164. Algorithms used in tracking OD risk rating AI may influence whether one can receive
pain meds


165. Algorithms used in tracking OD risk rating AI may influence whether one can receive
pain meds


166. Algorithms used in tracking OD risk rating AI may influence whether one can receive
pain meds


167. AI and work 7 jobs that don't exist today but will in the next 5 years


168. AI and work 7 jobs that don't exist today but will in the next 5 years


169. AI and work 7 jobs that don't exist today but will in the next 5 years


170. AI and work 7 jobs that don't exist today but will in the next 5 years


171. Chatbots Bring Buzz, but the Real Money Will Come From APIs


172. BofA acquisition makes its health care payments business more nimble


173. BofA acquisition makes its health care payments business more nimble




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

174. Mobile health care brings home visits to North County residents Partnership provides
nonemergency medical care


175. TECH ROLE GROWS IN DIABETES CARE


176. A Room With a View: Will artificial intelligence send us to hell or create it?


177. How Europe is leading the world in the push to regulate AI


178. Ripping the band-aid off: Why Canadians resist health care reforms


179. Amazon 's creepy new health wearable analyzes your voice and body


180. Former New York City Mayor Bill de Blasio talks AI and urban technology at Ford


181. IU faculty to help shape the future at Luddy School's new artificial intelligence center


182. How is AI changing the world?


183. Groupon co-founder Lefkofsky's Tempus raises more funding The precision medicine
company said it raised $275M in a combination of equity and debt financing


184. Ishrak-led firm seeks $750M IPO


185. "Even if you can do it, should you?" Researchers talk combating bias in artificial
intelligence


186. NYSOFA brings ELLiQ Proactive Care Companion Technology to older adults


187. NYSOFA brings ELLiQ Proactive Care Companion Technology to older adults


188. 40 UNDER FORTY Eric Schwartz


189. MACHINES CAN LEARN HOW TO HEAL YOU


190. Rising health care reformer charts a path for young professionals and policy reforms




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

191. From the Future: AI


192. From the Future: AI - Philosophical, political and practical issues


193. Deals may be down, but the city's tech industry is still up


194. Helping older adults combat loneliness, social isolation


195. FDA-approved algorithms can inform clinicians of heart abnormalities


196. Professor on using AI to detect medical errors, the future of AI in medicine


197. What will the U.S. look like in 2030?


198. Wearable tech may someday cloak us in greater public health Data could aid larger
swath of society beyond users


199. Candidate Q&A: Walla Walla School District Position 4


200. What will the U.S. look like in 2030?


201. Wearable tech may someday cloak us in greater public health Data could aid larger
swath of society beyond users


202. Educators embrace usefulness of artificial intelligence, note potential problems


203. HEALTH TRACKERS LOOK TO AI TOOLS


204. Study finds 8,500 COVID deaths may have been avoided if more Missourians were
vaccinated


205. Smart Machines: AI technology's impact on Florida 's business sectors Arificial
intelligence hasn't quite replaced humans, but the technology is making business better.


206. Regulatory Comments Before the U.S. Copyright Office Library of Congress In the
Matter of Artificial Intelligence and Copyright


207. 'Doing the right thing' Americas International tops Best Places to Work list


            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

208. Leidos and Clarify Health Announce Strategic Alliance to Deliver Innovative Analytics
Solutions to Healthcare Partners


209. Leidos and Clarify Health Announce Strategic Alliance to Deliver Innovative Analytics
Solutions to Healthcare Partners


210. School Safety Index Predicts K-12 COVID Policy Effectiveness


211. Meet the new vice dean and executive director of the Duke Clinical Research
Institute


212. PhysIQ Elects Former Vice Admiral Raquel C. Bono, M.D. to Advisory Board


213. 4 retirement trends for the coming decade


214. UC Berkeley community talks artificial intelligence


215. Great American Smokeout aims to reduce smoking rates, increase lung cancer
screenings


216. Great American Smokeout aims to reduce smoking rates, increase lung cancer
screenings


217. Great American Smokeout aims to reduce smoking rates, increase lung cancer
screenings


218. Artificial Intelligence in Medical Imaging Market to Watch: Spotlight on Firms Like
OrCam , Babylon , Freenome, Clarify Health Solutions, BioXcel Therapeutics - The Courier


219. AI Is Learning to Read Mammograms


220. COVID-19 booster shot available for high-risk, elderly individuals


221. COVID-19 booster shot available for high-risk, elderly individuals


222. Big tech startups falling fast Collapsing firms show how venture-backed darlings ran
out of time, money, support




           | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

223. Big tech startups falling fast Collapsing firms show how venture-backed darlings ran
out of time, money, support


224. Governments Consider Ethics, Transparency in Cutting-Edge Tech


225. Governments Consider Ethics, Transparency in Cutting-Edge Tech


226. The 'PodoSighter' uses AI to identify a key indicator of early kidney disease


227. The 'PodoSighter' uses AI to identify a key indicator of early kidney disease


228. The 'PodoSighter' uses AI to identify a key indicator of early kidney disease


229. Big Tech swallows most of the hot AI startups


230. Adventist nurses receive a gift of gratitude


231. Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference


232. USC to open new campus in Washington, D.C.


233. A Robot Wrote This Book Review Nonfiction


234. NYSOFA brings ElliQ Proactive care companion to older adults, reducing social
isolation, supporting independence, connection & engagement


235. Teachers Need More Than Just Pay Raises, Secretary Cardona Says


236. NYSOFA brings ElliQ Proactive care companion to older adults, reducing social
isolation, supporting independence, connection & engagement


237. NYSOFA brings ElliQ Proactive care companion to older adults, reducing social
isolation, supporting independence, connection & engagement


238. Artificial intelligence may influence whether you can get pain medication


239. Adventist Health Bakersfield celebrates new designation for its AIS Cancer Center



           | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

240. Case Study: Saving Employers $6M Annually Through Machine Learning + Value-
Based Care Management


241. A Robot Wrote This Review


242. Review: A Fierce Clarity of Vision in ‘J’ai Pleuré Avec les Chiens’ Critic’s Pick


243. Indonesia striving to solve shortage of specialists doctors


244. Pushing the Extremes Toward a Kind of Healing


245. Blockchain for Healthcare Market Future Outlook | IBM Corporation , Microsoft ,
Guardtime, PokitDok, Gem, Hashed Health, Chronicled, iSolve - The Courier


246. AI TO DETECT HEART ATTACKS? PITT AND UPMC DEVELOP A TOOL TO BETTER
ANALYZE EKGS


247. AI TO DETECT HEART ATTACKS? PITT AND UPMC DEVELOP A TOOL TO BETTER
ANALYZE EKGS


248. IN SCHOOLS, AI IS TRACKING MENTAL HEALTH


249. Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South
Korea and Strategic Opportunities for Canada


250. Hard to track virus impact on Indigenous Inconsistent data masks Native American
deaths


251. Jabi Concert: FG Suspends Airline For Flying Naira Marley To Abuja


252. Recruiting Through Computers - Upcoming Virtual Career Events


253. Computer Science Department expands as student interest grows


254. Medical errors kill thousands of people each year. But are hospitals getting any
safer?




            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

255. Stanford Medicine [email protected] Concert segment celebrates Asian
grandmothers, youth activism


256. AIS Cancer Center gets $10 million shot in the arm in state funding


257. Boeing gives $3M for Franklin Institute SPACE exhibit


258. THAT'S OUT OF THIS WORLD! Boeing gives $3 million for new Franklin Institute
Space Center


259. Stressed about the election? You're not alone. How to stay calm.


260. Global Blockchain for Healthcare Market by : Complete Analysis of Key Players,
Growth Rate, Opportunities, Challenges - The Courier


261. Pharma Clinical Trial Digitization Market 2027 Overview, Scope, Growth Trends,
Manufacturers- Antidote Technologies , Aparito, Clinerion - The Courier


262. Aggies facilitate a 24-hour hacking event at Huntsman Hall


263. Translation tech has just scratched the surface


264. DEC seeking public comment on Unit Management Plan


265. Liberty + Leadership News: December 1


266. DEC announces finalization of campground and day-use area unit management plan
to help combat aquatic invasive species


267. DEC announces finalization of campground and day-use area unit management plan
to help combat aquatic invasive species


268. Artists, researchers pair up for exhibit


269. Artificial Intelligence In Healthcare Diagnosis Market 2021 Growth Opportunities and
Future Scope Till 2027: Aidoc, Arterys Inc., Icometrix, IDx Technologies Inc - The Courier


270. DEC announces finalization of campground and day-use area unit management plan
to help combat aquatic invasive species


            | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

271. DEC announces finalization of campground and day-use area unit management plan
to help combat aquatic invasive species


272. DEC announces finalization of campground and day-use area unit management plan
to help combat aquatic invasive species


273. Top headlines in major S. Korean newspapers


274. Valadao takes early lead over Salas


275. Valadao takes early lead over Salas


276. Valadao takes early lead over Salas


277. DEC announces release of draft amendment to campground and day-use area unit
management plan to help combat aquatic invasive species


278. 'Chasing Butterflies' | A Penn State alumna's Manhattan journey as a daughter of
9/11


279. Four days, 90 speakers, no charge. St. Pete forum tackles global issues. This year's
Conference on World Affairs reaches out to include high school students and more
conservative voices.


280. Prostate cancer support group in Tehachapi has been helping men for 20 years


281. Penn State NSO leaders contemplate 2nd summer of online orientation


282. PITTSBURGH REGION READY FOR SUPPLY CHAIN INVESTMENT


283. NOTABLE IN HEALTH CARE


284. How Tech Dreams Go Up in Smoke


285. From Unicorns to Zombies: Tech Start-Ups Run Out of Time and Money


286. EFCC Arraigns Former Attorney General, Mohammed Adoke , On Fresh Charges



           | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

287. NE India 's relation with ASEAN on trade & investment: Post COVID-19


288. Global Pharma Clinical Trial Digitization Market by : Complete Analysis of Key
Players, Growth Rate, Opportunities, Challenges - The Courier


289. The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems


290. No Headline In Original


291. 22nd Congressional District: Valadao-Salas race may come down to political loyalties


292. 22nd Congressional District: Valadao-Salas race may come down to political loyalties


293. THE COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's


294. The COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's - The
Brown Daily Herald


295. No Headline In Original


296. NOTABLE DIVERSE LEADERS IN LAW


297. No Headline In Original




           | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

Failed Documents (3)

1. Lee Health using new technology to prevent heart disease



2. UF to use $23.5 million grant to build AI infrastructure to improve critical care



3. Medical chatbots developed to speed medical research, alleviate privacy worries




               | About LexisNexis | Privacy Policy | Terms & Conditions | Copyright © 2020 LexisNexis

                                                                                                           Page 1 of 2
                                   UW HEALTH USING AI IN EPIC MEDICAL RECORDS




                     UW HEALTH USING AI IN EPIC MEDICAL RECORDS
                                        Wisconsin State Journal (Madison, Wisconsin)
                                                      April 18, 2023 Tuesday
                                                              ALL EDITION



Copyright 2023 Madison Newspapers, Inc. All Rights Reserved

Section: LOCAL; Pg. A3
Length: 222 words

Byline: DAVID WAHLBERG , dwahlberg@madison.com

Body


UW Health is among three health care providers using artificial intelligence developed by Microsoft Corp. to draft
message responses in electronic medical records by Verona-based Epic Systems Corp., the companies said
Monday.

"A good use of technology simplifies things related to workforce and workflow," Chero Goswami, chief information
officer at UW Health, said in a statement. "Integrating generative AI into some of our daily workflows will increase
productivity for many of our providers, allowing them to focus on the clinical duties that truly require their attention."

Microsoft and Epic said they are expanding their strategic collaboration to integrate AI into health care by
combining Microsoft's Azure AI platform with Epic's software.

UW Health, along with UC San Diego Health and Stanford Health Care, are among the first organizations to use
the technology to automatically draft message responses.

Another AI program will bring natural language queries and interactive data analysis to SlicerDicer, Epic's self-
service reporting tool, the companies said.

That should make it easier for health care organizations "to identify operational improvements, including ways to
reduce costs and to find answers to questions locally and in a broader context," said Seth Hain, senior vice
president of research and development at Epic.



Graphic


STATE JOURNAL ARCHIVES

                                                                         Page 2 of 2
                            UW HEALTH USING AI IN EPIC MEDICAL RECORDS


Load-Date: April 18, 2023


  End of Document

                                                                                                       Page 1 of 2
                              Local health systems leverage AI for better outcomes, efficiency




           Local health systems leverage AI for better outcomes, efficiency
                                                   Crain's New York Business
                                                          July 24, 2023
                                                          Print Version



Copyright 2023 Crain Communications All Rights Reserved




Section: Pg. 19; Vol. 39
Length: 879 words
Byline: JACQUELINE NEBER

Body


Local organizations are taking their own bets on how to best deploy artificial intelligence as the technology takes
root within the health care system at large.

Crain's spoke with health systems in the area to understand how they are experimenting and investing in AI and
found that using the technology to predict patient outcomes, expedite analysis of medical images and lighten the
load of administrative tasks for physicians are some major use cases.

Medical imaging lends itself to using AI because the technology can help doctors interpret images faster and detect
issues sooner, according to Dr. James Tsai, president of the New York Eye and Ear Infirmary of Mount Sinai.

Tsai is the founding director of the Center for Ophthalmic Artificial Intelligence and Human Health at the Icahn
School of Medicine at Mount Sinai, which launched on July 3. The center's goal is to use AI to diagnose eye
diseases such as glaucoma, macular degeneration and diabetic retinopathy faster, which can help prevent vision
loss, according to Sinai. Researchers will work with Icahn students and Sinai's Windreich Department of Artificial
Intelligence and Human Health to build the infrastructure for using AI in critical care, which will let the system
incorporate tools quickly as they are approved, Tsai said.

AI can also help health systems move patients out of the hospital faster by streamlining physicians' work. At New
York-Presbyterian, leaders have experimented with AI since 2017 to accomplish that goal. Leo Bodden, the group
vice president and chief digital and technology officer at NYP, said tools help track which tasks need to be done for
patients, such as lab work, and "nudge" physicians to complete them.

The system has launched several initiatives recently to tighten workflow, Bodden said, with predictive machine
learning, imaging, robotic process automation, conversational AI and general robotics. Some pilot programs strive

                                                                                                       Page 2 of 2
                           Local health systems leverage AI for better outcomes, efficiency

to reduce the amount of documentation doctors must complete and help radiologists interpret images faster, for
example.

NYU Langone, too, is using generative AI to read patient notes and tackle administrative tasks. The technology can
help detect gaps in care, said Dr. Jonathan Austrian, associate chief medical information officer of inpatient
informatics at NYU Langone Health.

If a physician notes that a patient needs blood clot prevention medication, for example, but the technology doesn't
see an order for that prescription, the system will alert the physician of the discrepancy, he said. NYU is beginning
to deploy more sophisticated general language AI models in these cases.

Comb through data

Additionally, AI can be used to interact with patients, educate them during vulnerable periods and improve
outcomes. On Long Island, Northwell Health is using AI to improve maternal health outcomes through a chatbot
product called Pregnancy Chats, which aims to reduce maternal mortality rates by communicating with patients
about their symptoms. The chatbot can encourage patients to go to the hospital or connect them with Northwell
physicians. The tool is one of the health system's Center for Maternal Health initiatives to address maternal health
risks.

Northwell developed the chatbot in collaboration with Conversa Health, a software company based in Portland,
Oregon. Northwell invested $5.5 million into Conversa before Conversa was acquired by Amwell, a virtual care
company in Boston, according to Richard Mulry, president and chief executive of Northwell Holdings.

More broadly, AI can be used to comb through patient data to identify which individuals are at a higher risk for
negative health outcomes and close care gaps. At Ascertain, Northwell's joint venture with Aegis Ventures,
scientists are using data from more than 100,000 records to help providers better understand patients' maternal
mortality risks and help patients better understand dangerous symptoms of conditions such as preeclampsia, said
Dr. Michael Nimaroff, senior vice president of Northwell's obstetrics and gynecology service line.

Northwell and Aegis committed to investing $100 million in launching Ascertain, Mulry said.

While the wealth of available medical data means the health care industry is ripe to benefit from AI, utilizing the
data comes with watchouts.

Exposing sensitive data, such as patient and billing information, to new tools opens up already-vulnerable hospitals
to data breaches, according to Marion Lewis, chief executive of Govenda, a governance management firm that
works with several New York health systems. She noted patients' privacy concerns and AI's potential for bias when
it comes to care disparities among underserved patients that already exist in the industry.

Additionally, despite AI's potential benefits, doctors also warned of their concerns around the technology. Tsai
called some potential AI algorithms a "black box" that makes it impossible for doctors to understand why they're
getting certain results.

He also has concerns about the technology's limitations, how the health system will be reimbursed for using it, its
financial sustainability and patient acceptance, he said.

To combat these concerns, Tsai said, human specialists will have to remain involved, checking AI's conclusions at
every step of the process.


Load-Date: July 27, 2023


  End of Document

                                                                                                       Page 1 of 2
                      Health care leaders seek regulation, transparency for AI in health industry




  Health care leaders seek regulation, transparency for AI in health industry
                                                        TheHill.com
                                             November 29, 2023 Wednesday



Copyright 2023 NEXSTAR MEDIA INC. All Rights Reserved

Section: HEALTH CARE INDUSTRY NEWS & HEALTHCARE MANAGEMENT NEWS
Length: 460 words
Byline: Lydia McFarlane

Body


Health care sector leaders urged Congress to pass regulations on the use of artificial intelligence (AI) in the
industry based on experiences facing issues in the AI programming such as implicit bias and patient privacy.

Wednesday’s hearing on the use of AI in health care comes after tools such as ChatGPT made waves in the
health care space.

Witnesses expressed concern about implicit bias in AI used in health care that could potentially discriminate
against patients based on demographics.

“Generative [large language models] must be ‘trained’ on massive volumes of written language — the ultimate
compendium of human experience,” said Benjamin Nguyen, senior product manager at health care company
Transcarent. “It therefore inherits the inherent biases of that experience through the data used to train the model.”

House Energy and Commerce Chair Rep. Cathy McMorris Rodgers (R-Wash.) echoed Nguyen’s concerns, voicing
fears about “the possibility of human biases to be implicitly baked into AI technologies.”

When considering legislation, witnesses said Congress must consider the training procedures that could result in
bias to ensure equitable use of AI in medicine.

Dr. David Newman-Toker, director of the division of neurovisual and vestibular disorders at Johns Hopkins
University School of Medicine neurology department, said AI systems should be trained on “gold-standard data
sets” to ensure health care professionals aren’t “converting human racial bias into hard and fast AI-determined
rules.”

Also discussed between witnesses and members of the subcommittee on health were concerns about how the use
of AI in medicine could compromise transparency and patient privacy.

“It is critical that safeguards are put in place to protect the privacy and security of patient’s data,” Rep. Frank
Pallone Jr. (D-N.J.), said.

                                                                                                        Page 2 of 2
                     Health care leaders seek regulation, transparency for AI in health industry

Peter Shen, head of digital health in North America for health care company Siemens Healthineers, said it is
critical to work together and build “ethical, transparent and accessible AI in health care.”

Witnesses encouraged telling patients when and how AI is being used, in the interest of transparency.

“I think it’s of the most paramount importance that patients understand who is treating them. And if AI is being used,
there needs to be transparency,” Nguyen said.

As with AI use in other industries, lawmakers are tasked with balancing innovation and regulation when considering
the use of AI in health care.

“[With the] absence [of] carefully crafted regulations, innovative payment incentives, and new research resources
directed to overcome key barriers to successful deployment of high-quality AI systems, risks will dominate,”
Newman-Toker said.

For the latest news, weather, sports, and streaming video, head to The Hill.


Load-Date: January 11, 2024


  End of Document

                                                                                                            Page 1 of 2
    'The potential is unbelievable': First chief data scientist of Duke Health talks intersection of AI and healthcare




 'The potential is unbelievable': First chief data scientist of Duke Health talks
                       intersection of AI and healthcare
                                             The Duke Chronicle: Duke University
                                               September 20, 2023 Wednesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 533 words

Body


As artificial intelligence takes the world by storm, Duke sees it as an opportunity to transform healthcare.

Michael Pencina, vice dean for data science, was recently named Duke Health's chief data scientist, a leadership
role created in the midst of rapid developments and intense discussions around AI technology.

"I want Duke Health to be synonymous with trustworthy health AI," Pencina said. "When people think about
developing or evaluating algorithms, I want them to look at what we develop, come to us for guidance."

Merging data and health

Pencina, a professor of bioinformatics and biostatistics at the School of Medicine, said that his role was to facilitate
a "partnership between the research side - the University's School of Medicine - and the health delivery side."

Duke's creation of the new position was motivated by the potential benefits to medicine that the University's
research and education in data science could bring, according to Pencina.

Duke Health also recently formed a major partnership with Microsoft to "redefine the health care landscape"
through collaborative work on generative artificial intelligence and cloud technology.

According to Pencina, Microsoft saw Duke Health as a partner that could work to evaluate the development of
trustworthy AI. With established governance for the use of AI in healthcare, Duke was also viewed as a national
leader of AI applications.

Road to chief data scientist

The role of chief data scientist is new for Pecina, whose career spans decades as well as multiple campuses and
organizations.

The School of Medicine regards Pencina as "an internationally recognized authority in risk prediction model
development and evaluation," especially in the field of cardiovascular disease risk prediction.

                                                                                                           Page 2 of 2
   'The potential is unbelievable': First chief data scientist of Duke Health talks intersection of AI and healthcare

In the past, Pencina has contributed to the Framington Heart Study, which is recognized by the National Heart,
Blood and Lung Institute for "transformative discoveries related to the treatment of heart disease." Pencina praised
the Institute as having "pioneered risk prediction algorithms."

With over 400 publications in peer-reviewed journals that have been cited over 111,000 times, Pencina brings
experience and expertise to the ever-evolving fields of AI and medicine.

Ethical and equitable AI

Duke AI Health, an initiative that Pencina directs, has ethical and equitable data science as its core, he said.

In the face of advancements as well as worrying possibilities in the field of AI technology, these values are a
cornerstone of Pencina's vision.

"In 2019, a colleague of mine published this really important paper showing racial bias in an algorithm that was
supposed to determine which patients need preventive health," Pencina said. "Then the pandemic hit and what
came to the forefront were major racial inequities in healthcare."

These instances of inequity motivated Pencina to prevent misuse of AI and ensure ethics in its implementation
within health care.

Pencina has since committed himself to actions such as hiring a health ethicist in February, as well as forming the
Algorithm Based Clinical Decision Support Oversight to consistently evaluate whether newly introduced technology
is equitable and safe.

The future of healthcare


Load-Date: September 21, 2023


  End of Document

                                                                                                         Page 1 of 3
                                   Hackers target health care AI amid coronavirus pandemic




                 Hackers target health care AI amid coronavirus pandemic
                                                                   The Hill
                                                       March 31, 2020 Tuesday



Copyright 2020 Capitol Hill Publishing Corp. All Rights Reserved

Section: Pg. 12
Length: 1181 words
Byline: By Maggie Miller

Body


The health care sector has increasingly turned to artificial intelligence to aid in everything from performing surgeries
to helping diagnose and predict outcomes of patient illnesses.

But as the coronavirus crisis ramps up, and hackers turn their eyes toward the health sector, experts warn these
systems and the patients they support are increasingly at risk.

"Obviously any disruption or denial of service of any type of medical health technology which interrupts patient care
is definitely a significant issue," said John Riggi, the senior adviser for cybersecurity and risk at the American
Hospital Association (AHA). "Worst-case scenario, life-saving medical devices may be rendered inoperable."

AI systems have gradually been integrated into health care in the United States, often used to help speed
diagnoses, such as reading X-rays, and for determining risks to patients. But with the increase in AI use comes an
increase in risks to the networks they rely on.

John Frownfelter, the chief medical information officer for health care-focused AI group Jvion, told The Hill that he
believes that, as it stands, hospitals are "losing the battle" against hackers.

"Cybersecurity is getting more and more sophisticated where for hospitals, it's not their core business, but the bar is
getting higher for them to match the efforts to breach them essentially," Frownfelter said. "I think this trend is going
to continue until some paradigm shift occurs."

Jvion currently provides clinical insights for therapy through AI to about 5 to 10 percent of U.S. hospitals, according
to Frownfelter. The coronavirus pandemic is providing new opportunities for companies to deploy AI resources.
Jvion recently built a map that uses AI technology to analyze the communities most at risk in the United States from
the spread of coronavirus, using factors such as income and employment rates.

But Frownfelter cautioned that if hackers were to target AI systems amid the coronavirus crisis, it could lead to
delayed care for patients at a time when every moment counts.

                                                                                                       Page 2 of 3
                             Hackers target health care AI amid coronavirus pandemic

"There are [some] radiologists that are much faster and more efficient at reading imaging stories," Frownfelter said.
"Radiologists can glance at it and confirm that and take a fraction of the time ... if you took that away, you would
have delays in getting images read and interpreted and getting back to physicians."

AI capabilities have made a major difference in the ability to treat patients. Ray Page, a Texas-based oncologist
and fellow at the American Society of Clinical Oncology, told The Hill that he uses AI to track his patients
throughout their cancer treatment.

He noted that the use of these systems has been integrated into "comprehensive" treatments and was
apprehensive about the implications of AI systems being compromised by hackers.

"If this gets hacked, or we lose access to those tools, then basically we are going back to the way of using clinical
judgment," Page said.

Hospitals have long been a tempting target for hackers, particularly for ransomware attacks, in which a system is
locked out and hackers ask for money to unlock it. Hospitals and health care centers, where access to networks
can mean the difference between life and death for patients, are seen as more likely to pay those ransoms.

There have already been worrying signs of malicious actors stepping up their game against hospitals and health
care organizations during the coronavirus pandemic.

The website of the Champaign-Urbana Public Health District in Illinois, which serves about 200,000 people, was
taken down by hackers for several days, while both the Department of Health and Human Services (HHS) and the
World Health Organization were targeted by cyberattacks. Earlier this month, the second largest hospital in the
Czech Republic was hit by a cyberattack that led to canceled surgeries and rerouted ambulances.

Riggi told The Hill that AHA, which consists of about 5,000 hospitals and health care groups, was aware of another
attempted ransomware attack on an American hospital and ongoing attempts to probe the websites of HHS and
state hospitals.

He noted that he would also not be surprised if a nation state such as China attempted to steal AI algorithms as
part of intellectual property theft.

"Unfortunately, they are not taking a break," Riggi said. "The bad guys are using the COVID-19 pandemic to exploit
and conduct further frauds ... a despicable and heinous crime."

But concerns over hacking are not the only problem facing AI systems during the coronavirus pandemic.

The Association of American Physicians and Surgeons put out an alert earlier this month warning its members to be
wary of AI-powered chatbots being used for diagnosing potential symptoms of coronavirus.

The Association of American Physicians and Surgeons detailed a report from STAT in which the reporter asked
multiple chatbots for organizations, including the Centers for Disease Control and Prevention and other established
medical groups, whether his symptoms pointed toward coronavirus. The chatbots all gave different answers.

"There are many unknowns," the group warned members. "The established experts could be mistaken. Use good
judgment. Help your neighbor, and don't panic."

On Capitol Hill, concerns over the cybersecurity of the health care sector have also not gone unnoticed.

Sen. Mark Warner (D-Va.), the vice chairman of the Senate Intelligence Committee, sent letters to top health care
groups including the AHA in 2019 asking questions about what the federal government could do to counter
cyberattacks on systems.

Warner told The Hill earlier this month that his concerns around the cybersecurity of hospitals were only heightened
by the coronavirus pandemic.

                                                                                                         Page 3 of 3
                              Hackers target health care AI amid coronavirus pandemic

"While we've seen the sector make some strides in recent months, we're still operating from a unnecessarily low
security baseline compared to other critical infrastructure sectors, and I fear any weaknesses could be magnified
during a crisis such as this," Warner said.

While it may be some time before the impact of the coronavirus pandemic across the health care sector is known,
the crisis is certain to open more doors to using AI in health care. And there are ways AI could help counter
broader cyber threats.

Riggi predicted that AI, while still used by hackers to create malware and seen as another route into vulnerable
systems, could also speed up the identification of cybersecurity risks to hospitals.

"AI is being deployed in hospitals to identify in a dynamic process all the connected devices ... and continuously
monitor those medical devices for anomalous behavior that might indicate a potential cyberattack on those devices
and highlight potential risk to patient care and safety," Riggi said.

Frownfelter, of Jvion, predicted that the crisis may also lead to more dependence on AI than ever before.

"I think this is the first time that AI will be recognized as adding value," Frownfelter said. "The season is now for AI
to come into its own, and when you've got health systems that are overwhelmed or processes that are
overwhelmed, then the power becomes more appreciated."


Load-Date: April 13, 2020


  End of Document

                                                                                                        Page 1 of 2
                                           Improving Kupuna Health Through 'Ai Pono




                              Improving Kupuna Health Through 'Ai Pono
                                           The Molokai Dispatch (Kaunakakai, Hawaii)
                                                       August 26, 2020



Copyright 2020 Molokai Dispatch, Inc.
Distributed by Newsbank, Inc. All Rights Reserved

Section: COMMUNITY
Length: 560 words
Byline: layout@themolokaidispatch.com

Body


By Dr. Landon Opunui, ND and Miki Wong, RD, Na Pu'uwai

There are multiple social and health disparities Native Hawaiian kupuna face such as high rates of life-threatening
diseases, financial hardship, disability, shorter life expectancies and underutilization of services. As a result, it
should be no surprise that data suggests the health care needs of Native Hawaiian kupuna far exceed that of their
non-Hawaiian counterparts. This leads to health equity problems.

 Hawaiian culture emphasizes care for kupuna. However, many adult caregivers are less available to care for their
aging loved ones because of competing work and 'ohana responsibilities.

 Several studies have reported on the health benefits associated with a return to a precontact Hawaiian diet.
Although this may be an ideal dietary approach for many Hawaiians, food access and cost limitations may not
always allow this a practical option, especially for some of our kupuna who rely on complimentary meal assistance.
In addition, the high concentration of complex carbohydrates found in native starches along with high glycemic rich
tropical fruits may still be problematic for kupuna challenged with metabolic diseases such as diabetes.

 One of N Pu'uwai's flagship programs is our KUpuna Program, the only adult day care offered on the island of
Molokai. The program provides kupuna with a safe and structured environment to enjoy daily activities with other
kupuna and staff while 'ohana caregivers are at work. The program supports kupuna to help them remain active
and healthy, so they can remain at home as long as possible. With a previous capacity of 20 kupuna, safety
guidelines have reduced our capacity to 10 during the COVID-19 pandemic.

 On July 1, we launched our kupuna nutrition program, which redesigned meals with the goal of providing high-
quality nutrition using flavorful, locally inspired recipes with locally sourced ingredients. The program was launched
under the direction of cook Neil Gonzalez, registered dietitian/nutritionist Miki Wong, and volunteer chef coach
consultant, Ikaika Molina.

 Menus were designed to support the health and well-being of our kupuna, many of whom have chronic health
conditions. Gonzalez was inspired to change the menu after making improvements to his own diet. In addition, he
developed daily themes to add creativity and fun to meal planning. "Mostly Molokai Mondays," for example,

                                                                                                        Page 2 of 2
                                     Improving Kupuna Health Through 'Ai Pono

showcase locally sourced ingredients from the island —and the kupuna enjoy their meals. Many of them already
avoided rice, citing health concerns. Since introducing cauliflower rice, kupuna are finishing their plates, with
compliments to the cook. Recipe highlights include egg white frittatas, almond-flour waffles, venison stir fry and beef
short ribs with cauliflower mash. Providing delicious and familiar meals also provides comfort to our kupuna who
have been isolated with limited access to socialization.

 This helped Na Pu'uwai forge partnerships with local organizations committed to ensuring the health of the
community such as Sustainable Molokai, which provides reduced pricing on produce.

 We hope to inspire other organizations who have the resources and opportunities to feed our kupuna to consider
consulting with nutrition experts to curate 'ai pono meals that can be used to combat many of the chronic health
challenges our kupuna face today.


Load-Date: August 27, 2020


  End of Document

                                                                                                        Page 1 of 2
                            Emory launches institute focused on AI use to promote health equity




       Emory launches institute focused on AI use to promote health equity
                                                  The Atlanta Journal-Constitution
                                                   November 18, 2023 Saturday
                                                           Main Edition



Copyright 2023 The Atlanta Journal-Constitution




Section: MAIN; Pg. 14A
Length: 648 words

Byline: Donovan J. Thomas - , donovan.thomas@ajc.com


Staff
Highlight: Emory Empathetic AI for Health Institute is first of its kind in Ga.

Body


HEALTHEmory University has launched an institute focused on the use of artificial intelligence in the prevention,
treatment and diagnosis of diseases in Georgia and across the globe.

The Emory Empathetic AI for Health Institute is the first effort of its kind in Georgia, with a mission of using AI to
address inequities in health care. AI is an emerging and rapidly expanding technology in the field of medicine.

Researchers hope to work collaboratively with other institutions and providers in the metro area and around the
state to implement tools with a goal of enhancing care while lowering costs.

Scientists have used AI to identify differences in appearances of prostate cancer between Black and white patients,
to better visualize and understand blood vessels and to better diagnose patients with cancer and other diseases.
With the institute, Emory researchers look to use the technology to better treat prostate cancer, breast cancer,
diabetes, heart disease and more.

Dr. Anant Madabhushi, a research scientist and professor of biomedical engineering at Emory and the Georgia
Institute of Technology, will lead the initiative.

He says that his experiences growing up in India and as an immigrant in the U.S. drive his commitment to improving
health outcomes for all.

                                                                                                       Page 2 of 2
                        Emory launches institute focused on AI use to promote health equity

“I grew up in a lower-middle-income country and I’ve seen firsthand the challenges of access to health care and
access to technologies,” he said. “When you talk about places like India and Africa, you have to develop
technologies that are affordable.”

Madabhushi said that the institute has secured nearly $70 million in institutional and grant funding, with an overall
goal of achieving $300 million in funding over the next two to three years with the help of philanthropic donations.

With the Empathetic AI for Health Institute, Madabhushi and his team will develop affordable AI tools that are both
accessible and equitable to provide personalized care for patients. He says use of the word “empathetic” in the title
was intentional because of the focus on fixing global health problems without burdensome costs, which he says is
unique to the work of the institute.

He said AI has to be empathetic, taking into account the experiences of a range of diverse populations, to
effectively address health disparities.

Madabhushi acknowledged reservations about the use of AI in health, particularly from communities of color.

“If you don’t have data representative of populations of color as you’re developing these technologies, they’re
simply not going to work in underrepresented populations or populations of color,” he said. “So, that’s something
that we are very focused on.”

Given Georgia’s current health care landscape, where access to care can be a challenge and a lack of Medicaid
expansion has left hundreds of thousands without coverage, the team wants to improve patient outcomes in the
state.

“One of the other things that we need to consider is the large rural population that we have in Georgia. A rural
population that has been largely cut off from the innovations and technology development,” he said, pointing out the
gaps in rural health outcomes.

In Georgia, 120 of the state’s 159 counties are considered rural. Madabhushi said the institute intends to work with
other health partners around the state, sharing tools that can benefit rural patients.

“Ultimately it all comes down to transparency. If you cannot explain how technology works, there are always going
to be reservations and skepticism,” Madabhushi explained.

“We are going to focus on technology that is transparent and understandable, so that both our physicians and
patients are going to be able to understand how the AI is making its predictions.”

The Atlanta Journal- Constitution and Report for America are partnering to add more journalists to cover topics
important to our community. Please help us fund this important work at ajc.com/give


Load-Date: November 18, 2023


  End of Document

                                                                                                       Page 1 of 2
           Faculty Assembly addresses Plan for Pitt, health care and AI in monthly meeting - The Pitt News




    Faculty Assembly addresses Plan for Pitt, health care and AI in monthly
                          meeting - The Pitt News
                                The Pitt News: University of Pittsburgh - Pittsburgh Campus
                                                      October 6, 2023 Friday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 806 words

Body


Faculty Assembly President Robin Kear opened Wednesday's Faculty Assembly meeting by introducing Chancellor
Joan Gabel, who announced the start of the next phase of Plan for Pitt.

The Faculty Assembly meeting took place on Wednesday afternoon in Posvar Hall and over Zoom. Topics
discussed included Plan for Pitt, student health insurance and AI implementation on campus.

The Plan for Pitt identifies areas in which the University can improve and creates an institutional strategy, Gabel
said.

"It's time to do the next phase of Plan for Pitt that was already in the works," Gabel said. "But because of timing, it
will also reflect the lens of a change in leadership, and I'm really excited about that. I think it's a great opportunity for
the entire institution, but also [a] really important moment around shared governance where there's a lot of
consultation around how we would take things into the next chapter."

Gabel said the second phase of the Plan for Pitt includes assessing measures and outcomes of the first phase. She
said the plan focuses on increasing student success, creativity, scholarship and innovation.

"When we talk about student success, I mean, there are some very standard measures of how we would assess
whether our students are successful," Gabel said. "Are they advancing from first year to second year? Are they
graduating? Are they well? Are they able to have access to what they need in order to have the kinds of academic,
personal and professional experiences to set them up for a life well lived?"

Kear shared that the graduate student health network is proceeding with shared governance on the short-term
student health insurance task force, and student representatives are the driving force of the initiative.

"This task force is discussing the needs of students benchmarking with peer institutions, providing
recommendations to the university and ultimately receiving approval by the state of Pennsylvania because their
approval by the state is a requirement for student health insurance," Kear said.

                                                                                                      Page 2 of 2
          Faculty Assembly addresses Plan for Pitt, health care and AI in monthly meeting - The Pitt News

Nancy Glynn, associate professor and director of Pitt's master's degree programs in epidemiology, said the scope
of problems concerning student health insurance is getting larger for students. She said students are having to pay
co-pays, and they're witnessing the gap in costs between what is and isn't covered by insurance.

"Some of my other students have said that the cost for counseling visits and mental health visits have gone up like
400% from five bucks to like 20 bucks or 25 bucks," Glynn said. "So, I think

the students are getting more distressed as they're using the services right in the first month of the term."

Glynn questioned whether students are actively aware of the Student Emergency Fund, which helps students who
are facing financial hardships cover funds. Glynn's daughter is one of many people impacted by mounting co-pays.

"My daughter happens to be one of them who is a Type 1 diabetic," Glynn said. "Just one of her insulin supplies
went from a $60 co-pay to a $105 co-pay for three months. That's only one of five meds."

Although students receive information about their student health insurance plans, many are not aware of the
details. Bridget Keown, a teaching assistant professor in the gender, sexuality and women's studies program, said
Pitt should find new ways of informing students about resources available to them.

"I don't see the harm in finding new ways to make sure that people know about [the Student Emergency Fund],"
Keown said. "Because especially if you're talking about issues that could compromise people's emotional health or
put them in distress or stuff like that, they are not necessarily thinking productively about where an email is."

The Assembly also addressed the growing prominence of artificial intelligence on campus. Kear said it's important
to discuss AI implementation because several conversations are occurring related to its impact on research
agendas and individual learning.

"There's deep individual learning going on," Kear said. "There are class discussions, there are guidelines on our
syllabi now, there are department-level discussions, and of course there's the formal ad hoc committee from the
provost and research office."

Kear emphasized the importance of choosing AI vendors with privacy and ethical boundaries as the University uses
the technology more. Members of the Senate Council were involved in the discussion as informal and formal
mechanisms of AI are taking shape around campus.

"There are so many unknowns and yet, there are so many ways for us to influence the development of AI
implementation here at Pitt," Kear said. "A quick issue that I see forming is around the procurement of AI software.
It's how to purchase, integrate and use AI, whether generative or not, responsibly and ethically in our everyday
operations."


Load-Date: October 6, 2023


  End of Document

                                                                                                        Page 1 of 2
                            TOO MUCH HEALTH TECH AI MAY BE BAD FOR YOUR HEALTH




           TOO MUCH HEALTH TECH AI MAY BE BAD FOR YOUR HEALTH
                                              Pittsburgh Post-Gazette
                                               May 21, 2022 Saturday
                                                 SOONER EDITION



Copyright 2022 P.G. Publishing Co.

Section: OPINION; Pg. WB-3
Length: 857 words

Body


Without much fanfare, some of the biggest names in tech have been pulling back on once-enthusiastic efforts to
disrupt healthcare. Within the past nine months, Alphabet Inc. has dismantled its healthcare division Google Health
while IBM sold its Watson Health data and analytics business to a private equity firm, having struggled to turn a
profit. It turns out healthcare is a highly complex industry and much of the hype around the transformative promise
of artificial intelligence may have been overblown.

That reality has hit hard in the U.K, whose influx of investment into health tech comes thanks to the internationally
respected, centralized National Health Service that has tested new technology through a special department called
NHSX.

Health tech refers to a market in which companies use technology to solve healthcare problems. These range from
chatbots to help patients triage symptoms of an illness to fitness trackers to monitor a patient's vital signs with a
fitness tracker to machine-learning algorithms to make hospital waiting rooms more efficient. A growing cohort of
mental health apps for consumers offers to help people manage stress or sleep better.

Many of these systems say they use artificial intelligence, which can give them a funding boost in private markets. It
has in England. Funding for health-tech startups has soared in the U.K. from $420 million in 2016 to approximately
$3.8 billion in 2021 according to data from database management firm Dealroom and London promotional agency
London&Partners. That put Britain in third place behind the U.S. and China for health-tech investment last year.

But some of the country's more mature health-tech firms, which got into this game early, are going through
something of a midlife crisis, exacerbated by the wider loss of momentum in the pandemic health-tech boom in the
U.S.

Part of the problem, according to staff and entrepreneurs from multiple health-tech firms, has been a clash of
cultures between the ambitious and iterative world of engineering - where problems can be solved with the right
algorithm - and the world of medicine, which calls for a more cautious approach. Medical researchers at health-tech
firms have complained of being steamrolled by the move-fast-and-break-things approach of highly paid software
engineers. The techies, for their part, complain of being unable to experiment freely in a world obsessed with
patient safety and regulation.

                                                                                                         Page 2 of 2
                        TOO MUCH HEALTH TECH AI MAY BE BAD FOR YOUR HEALTH

The resulting stumbles from this culture clash not only hurts company profits, it also threatens to corrode patient
trust in the National Health System and other healthcare systems.

Among the more affected British players is Sensyne Health Plc, which uses artificial intelligence to analyze patient
records to help pharmaceutical companies develop new medicines. To get that data, Sensyne has signed
agreements with a handful of NHS trusts, such as Great Ormond Street Hospital for Children and Exeter NHS
Trust; together they own a 16.2% stake in the firm in return for sharing patient data the company says is
anonymized.

But Sensyne found itself on the brink of collapse last month, after the company said it was on the verge of running
out of cash and cutting the majority of its staff, according to Sky News. The company had been fined Â£400,000
($495,000) by the London Stock Exchange in November for failing to disclose bonus payments to its chief executive
officer, a former British science minister who stepped down last month.

Publicly, the company said it suffered contract delays because of the COVID-19 pandemic. But its shift away from
developing algorithms to selling access to an analytics platform, as described on its website, also speaks to the
challenge of applying cutting edge AI to complex challenges in medicine.

Another high flying health-tech startup, Babylon Health, has seen its shares fall by nearly 87% since it went public
last October through a blank-check company merger that valued it at $4.2 billion. It's now worth about $528 million.
The company has heavily marketed its use of artificial intelligence to give diagnostic advice to patients through a
symptom-checker on its app, but doctors have warned it has given unsafe information through the checker.
Babylon, in response, publicly criticized an oncologist who criticized its symptom checker as a "troll" who "tweeted
defamatory content about us."

Signs are pointing to artificial intelligence falling short of its promise more generally in medicine. Multiple clinical
studies published last year showed nearly all artificial intelligence tools used to try and predict a diagnosis of
COVID-19 made no real difference or were potentially harmful. A separate study published in the British Medical
Journal last year also found 94% of AI systems that scanned for signs of breast cancer were less accurate than the
analysis of a single radiologist.

"This is not an AI problem," said Booth. "It's technology coming into healthcare thinking it can outperform expert
human beings at treating other human beings."

It seems when technology fails in that regard, humans pay the price.

Parmy Olson is a Bloomberg Opinion columnist.



Graphic


PHOTO: Courtesy of UPMC: UPMC is using new technology designed to help patients get faster stroke treatment.
When a patient has stroke symptoms and gets an MRI or CT scan, the Viz.ai app uses artificial intelligence to
determine if the patient is having a stroke.


Load-Date: May 21, 2022


  End of Document

                                                                                                          Page 1 of 3
               Is your health insurer using AI to deny you services? Lawsuit says errors harmed elders.




   Is your health insurer using AI to deny you services? Lawsuit says errors
                                 harmed elders.
                                                        USA Today Online
                                                        November 19, 2023



Copyright 2023 Gannett Media Corp All Rights Reserved

Section: INSURANCE INDUSTRY NEWS, INSURANCE INDUSTRY NEWS, INSURANCE INDUSTRY NEWS &
LAWSUITS NEWS
Length: 1384 words
Byline: Ken Alltucker, USA TODAY

Body


For years, vital decisions about who got medical care coverage took place in back offices at health insurance
companies. Now, some of those life-altering decisions are being made by artificial intelligence programs.

At least that's the contention of the two families who sued UnitedHealth Group this week, saying the insurance giant
used emerging technology to deny or shorten rehabilitation stays for two elderly men in the months before they
died.

They say that UnitedHealth's artificial intelligence, or AI, is making "rigid and unrealistic" determinations about what
it takes for patients to recover from serious illnesses and denying them care in skilled nursing and rehab centers
that should be covered under Medicare Advantage plans, according to a federal lawsuit filed in Minnesota by the
estates of two elderly Wisconsin patients. The lawsuit, which seeks class-action status, says it is illegal to let AI
override doctors' recommendations for these men and patients like them. The families say assessments like that
should be done by medical professionals.

The families note in the suit that they believe the insurance company is denying care to elderly patients who won't
fight back even though evidence shows the AI is doing a lackluster job of assessing people's needs. The company
used algorithms to determine coverage plans and override doctors' recommendations despite the AI program's
astonishingly high error rate, they say.

More than 90% of patient claim denials were overturned through internal appeals or a federal administrative law
judge, according to court documents. But in reality, few patients challenged the algorithms' determinations. A tiny
percentage of patients − .2% − choose to fight claim denials through the appeals process. The vast majority of
people insured by UnitedHealth's Medicare Advantage plans "will either pay out-of-pocket costs or forgo the
remainder of their prescribed post-acute care," the lawsuit says.

Attorneys representing the families suing the Minnesota-based insurance giant said the high rate of denials is part
of the insurance company's strategy.

                                                                                                         Page 2 of 3
              Is your health insurer using AI to deny you services? Lawsuit says errors harmed elders.

"They're placing their own profits over the people that they are contracted with and then legally bound to cover,"
said Ryan Clarkson, a California attorney whose law firm has filed several cases against companies using AI. "It's
that simple. It's just greed."

UnitedHealth told USA TODAY in a statement naviHealth's AI program, which is cited in the lawsuit, isn't used to
make coverage determinations.

"The tool is used as a guide to help us inform providers, families and other caregivers about what sort of assistance
and care the patient may need both in the facility and after returning home," the company said.

Coverage decisions are based on the Centers for Medicare & Medicaid Services' criteria and the consumer's
insurance plan, the company said.

"This lawsuit has no merit, and we will defend ourselves vigorously,” the company said.

Lawsuits of this type are not new. They are part of a growing body of litigation.

In July, the Clarkson law firm filed a case against CIGNA Healthcare alleging the insurer employed AI to automate
claims rejections. The firm also has pursued cases against ChatGPT maker OpenAI and Google.

Families pay for expensive care that the insurer denies

The plaintiffs in the suit this week are the relatives of two deceased Wisconsin residents, Gene B. Lokken and Dale
Henry Tetzloff, who were both insured by UnitedHealth's private Medicare plans.

In May 2022, Lokken, 91, fell at home and broke his leg and ankle, requiring a brief hospital stay followed by a
month in a rehab facility while he healed. Lokken's doctor then recommended physical therapy so he could regain
strength and balance. The Wisconsin man spent less than three weeks in physical therapy before the insurer
terminated his coverage and recommended he be discharged and sent to recover at home.

 A physical therapist described Lokken's condition as "paralyzed" and "weak," however his family appeals for
continued therapy coverage were rejected, according to the lawsuit.

His family opted to continue with treatment despite the denial. Without coverage, the family had to pay $12,000 to
$14,000 per month for about a year of therapy at the facility. Lokken died at the facility in July 2023.

The other man's family also raised concerns that necessary rehabilitation services had been denied by the AI
algorithm.

Tetzloff was recovering from a stroke in October 2022, and his doctors recommended the 74-year-old be
transferred from a hospital to a rehab facility for at least 100 days. The insurer initially sought to end his coverage
after 20 days, but the family appealed. The insurer then extended Tetzloff's stay another 20 days.

The man's doctor had recommended additional physical and occupational therapy, but his coverage ended after 40
days. The family spent more than $70,000 on his care during the next 10 months. Tetzloff spent his final months in
an assisted living facility, where he died on Oct. 11.

10 appeals to rehab a broken hip

The legal action comes after Medicare advocates began raising concerns about the routine use of AI technology to
deny or reduce care for older adults on private Medicare plans.

In 2022, the Center for Medicare Advocacy examined multiple insurers' use of artificial intelligence programs in
rehabilitation and home health settings. The advocacy group's report concluded that AI programs often made
coverage decisions that were more restrictive than what Medicare would have allowed and the decisions lacked the
level of nuance necessary to evaluate the unique circumstances of each case.

                                                                                                         Page 3 of 3
              Is your health insurer using AI to deny you services? Lawsuit says errors harmed elders.

"We saw more care that would have been covered under traditional Medicare denied outright or prematurely
terminated," said David Lipschutz, associate director and senior policy attorney for the Center for Medicare
Advocacy.

Lipschutz said some older adults who appeal rejections might win a reprieve only to be shut down again. He cited
the example of a Connecticut woman who sought a three-month stay at a rehab center as she recuperated from a
hip replacement surgery. She filed and won 10 appeals after an insurer repeatedly attempted to terminate her
coverage and limit her stay.

Importance of having 'human in the loop'

Legal experts who are not involved in these cases said artificial intelligence is becoming a fertile target for people
and organizations seeking to rein in or shape the use of emerging technology.

Gary Marchant, faculty director at the Center for Law, Science and Innovation at Arizona State University's Sandra
Day O'Connor College of Law, said an important consideration for health insurers and others deploying AI
programs is making sure that humans are part of the decision-making process.

While AI systems can be efficient and complete rudimentary tasks quickly, programs on their own can also make
mistakes, Marchant said.

"Sometimes AI systems aren't reasonable and they don't have common sense," said Marchant. "You have to have
a human in the loop."

In cases involving insurance companies using AI to guide claim decisions, Marchant said a key legal factor might
be how much a company defers to an algorithm.

The UnitedHealth lawsuit states that the company limited workers' "discretion to deviate" from the algorithm.
Employees who deviated from the AI program's projections faced discipline or termination, the lawsuit said.

Marchant said one factor to track in the UnitedHealth cases and similar lawsuits is how closely employees are
required to follow an AI model.

"There, clearly, has to be an opportunity for the human decider to override the algorithm," Marchant said. "That's
just a huge issue in AI and healthcare."

He said it's important to consider the consequences of how companies set up their AI systems. Companies should
think about how much deference they give to an algorithm, knowing that AI can digest huge amounts of data and
be"incredibly powerful" as well as "incredibly accurate," he said, and leaders should also keep in mind that AI
"sometimes can just be completely wrong."

Ken Alltucker is on X, formerly Twitter, at @kalltucker, or can be emailed at alltuck@usatoday.co m.

This article originally appeared on USA TODAY: Is your health insurer using AI to deny you services? Lawsuit says
errors harmed elders.


Load-Date: November 20, 2023


  End of Document

                                                                                                      Page 1 of 1
                  UF, Jacksonville propose new graduate campus focused on health administration and AI




         UF, Jacksonville propose new graduate campus focused on health
                               administration and AI
                                          The Spinnaker: University of North Florida
                                                      February 7, 2023 Tuesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 220 words

Body


The City of Jacksonville and the University of Florida announced a new partnership on Tuesday that would bring a
new graduate facility specializing in medicine, business and engineering to the city.

Courses at this new facility would be offered nowhere else, providing new graduate education programs aimed at
supporting the region's growing workforce needs, specifically in biomedical technology and focus on pioneering
technology related to simulation, health application and artificial intelligence, patient quality and safety, health
administration and fintech, officials explained.

Mayor Lenny Curry said that Jacksonville is proud to be home to major health institutions and specialty clinics,
specifically drawing attention to UF's proton therapy institute and looks forward to expanding on those roots.

"Drawing on our robust network of fortune 500 companies and cutting-edge health facilities, we have pushed the
boundaries of what is possible in the healthcare and tech fields," he said. "To keep up with this growth, we must
continue to invest in the infrastructure and talent pipelines that drive these industries."

Gallery|4 Photos

Jacksonville Mayor Lenny Curry held a press conference Tuesday morning to announce a new partnership with the
University of Florida. (Photo courtesy of the City of Jacksonville)


Load-Date: February 7, 2023


  End of Document

                                                                                                        Page 1 of 2
                            Montreal start-up Aifred Health is applying AI to mental healthcare




         Montreal start-up Aifred Health is applying AI to mental healthcare
                                             The McGill Tribune: McGill University
                                                  February 18, 2020 Tuesday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: SCI-TECH; Pg. 1
Length: 621 words
Byline: Margaret Wdowiak

Body

Mental health treatments for conditions such as depression are currently based on an arduous 'trial and error'
process. Matching people with the right care is difficult: An individual experiencing depression might consult
different specialists who may recommend various different kinds of treatment, none of which could actually work.

Aifred Health, a Montreal-based healthcare company, has perhaps found a better way. The company is developing
a treatment-agnostic artificial intelligence model that helps make personalized treatment more widely available and
match patients with the best care. Specifically, it is a machine learning model, a mathematical algorithm trained on
sample data to make predictions about the most effective treatment.

"Once the clinician has made a diagnosis, we assist in the process of treatment selection," Dr. David Benrimoh
(M.D, C.M, 2016), Aifred Health's Chief Science Officer and a Resident in McGill's Department of Psychiatry, said
in an interview with The McGill Tribune.

Medical professionals collect a number of data when a patient visits the doctor, including symptoms and
sociodemographic information. Aifred Health's job starts with assembling this data using an AI model to predict the
probability of remission with different treatments. Afterward, the clinician receives a report that helps them make a
more informed decision with the patient about their treatment.

"The clinician still makes the choice with the patient, but we help give them more information to make a better
choice that is more likely to work than without the tool," Benrimoh said.

Currently, the treatment-agnostic AI model is only intended for one condition.

"Right now, [it is designed] for depression, with plans to expand to other conditions such as anxiety and
schizophrenia in the future," Benrimoh said.

At the moment, there are no widely accessible methods of personalizing treatment for patients. Aifred Health's
model's main advantage is that it tailors treatment to the individual, increasing the chance that patients will receive
the right medical care. What's more, the new tool does not need huge amounts of time-consuming data collection,
as it only requires patients to fill out a questionnaire.

                                                                                                          Page 2 of 2
                          Montreal start-up Aifred Health is applying AI to mental healthcare

Despite the huge potential of this technology, the model still poses many challenges to the Aifred Health team.
According to Benrimoh, the biggest obstacle they face is adoption of the technology. Thus, it is essential that the
tool they build is one that doctors and patients actually want to employ.

"If no one uses it, it could be the best model ever, but it's not going to do anything," Benrimoh said.

Still, Aifred Health has a few steps to complete before worrying about consumer reactions. The company is
currently conducting a feasibility study in which they are using the technology for the first time in real clinics.
Computer simulations and tests at McGill's Arnold and Blema Steinberg Medical Simulation Centre have already
yielded promising results. The Steinberg Medical Simulation Centre simulates authentic health care settings using
the latest technologies to enhance the skills of healthcare professionals. Indeed, most doctors that participated in
tests at the Simulation Centre found that the AI model was useful and were willing to use it in their practice, though
they will have to wait a few years.

"Within roughly two to three years, the full AI tool will be market ready," Benrimoh said.

Aifred Health's treatment-agnostic AI model has the potential to revolutionize mental health treatment. Although
still currently in the testing stages, they will soon be providing millions of individuals with more effective treatment.
    •   aifred health
    •   Artificial Intelligence
    •   Medicine
    •   mental health


Load-Date: February 18, 2020


  End of Document

                                                                                                         Page 1 of 2
                 AI can help combat health misinformation, White House cancer research head says




   AI can help combat health misinformation, White House cancer research
                                 head says
                                                        TheHill.com
                                               December 7, 2023 Thursday



Copyright 2023 NEXSTAR MEDIA INC. All Rights Reserved

Section: CANCER NEWS, US news & US POLITICS NEWS
Length: 440 words
Byline: Nathaniel Weixel

Body


The head of the White House cancer moonshot initiative said artificial intelligence (AI) can be used to help combat
health misinformation.

In a conversation with The Hill’s Bob Cusack on Thursday, cancer moonshot coordinator Danielle Carnival said
patients and caregivers need trusted and accurate information to drive the care they need. There’s a significant
opportunity for artificial intelligence to help with that, she said.

“There are lots of risks with artificial intelligence … but one of the opportunities I think is going to make a huge
impact in health care is the ability for people to get targeted information in a language or a culturally appropriate
way that they can receive and act on,” Carnival said during The Hill’s “U.S. Healthcare’s Annual Checkup” event.

She added that for AI to succeed in health settings, it needs to be used to improve equity.

“As we build these AI systems, it’s not good enough just not to introduce new bias through AI, but to use AI in
health care to improve equity, improve the ability for people to get the information and knowledge they need to
make preventive health care decisions, to get access to early screening and detection and make decisions,”
Carnival said.

President Biden said he wants to build on the bipartisan progress in the fight against America’s No. 2 killer, and he
has made fighting cancer a priority of his administration by relaunching the “cancer moonshot.”

The first iteration of the moonshot was created in 2016, at the tail end of the Obama administration, when Biden
was vice president.

Now, the Biden administration is aiming not only to decrease the number of deaths from the disease, but improve
the lives of those who are living with or have survived cancer. One of the initiative’s goals is to cut the cancer death
rate by at least 50 percent over the next 25 years.

Carnival said the best way to achieve national progress toward prevention, detection and treatment must increase.

                                                                                                       Page 2 of 2
                AI can help combat health misinformation, White House cancer research head says

“It’s not just about driving cures or treatments that can get people back to their lives … it’s about making sure we
prevent more cancers, we detect them early, and I think we can do that. There’s a huge bipartisan support for these
goals,” Carnival said.

The federal government needs to work together across all agencies to emphasize prevention, she added.

“We know that that’s how we save money in the long run, is preventing disease in the first place. I think if we could
come together around a really preventive mindset and do the work we need to do, that would be a huge benefit,”
Carnival said.

For the latest news, weather, sports, and streaming video, head to The Hill.


Load-Date: January 11, 2024


  End of Document

                                                                                                         Page 1 of 3
                                         What do experts say about AI in health care?




                            What do experts say about AI in health care?
                                                        The Deseret News
                                                     March 20, 2023 Monday



Copyright 2023 The Deseret News Publishing Co. All Rights Reserved

Section: HEALTH CARE INDUSTRY NEWS & HEALTHCARE MANAGEMENT NEWS
Length: 1274 words
Byline: Gabrielle Shiozawa

Body


Editor's note: This is part of a KSL.com series looking at the rise of artificial intelligence technology tools such as
ChatGPT, the opportunities and risks they pose and what impacts they could have on various aspects of our daily
lives.

In the 1992 movie "Wayne's World," the character Garth is working on a robotic arm when Benjamin comes to ask
him about making a change to his show.

"We fear change," Garth says. He then looks down at the mechanical hand and begins to repeatedly smash it with
a hammer.

Many Americans have a similar reaction to change and technology, especially when it comes to using artificial
intelligence in health care.

In fact, 60% of U.S. adults say they would be uncomfortable with a doctor using AI in their treatment, according to a
Pew Research Center study released in December.

Medical professionals see it differently. Mark Fotheringham, vice president of communications at the Utah Medical
Association, said the association views AI as a natural progression of the medical industry.

"To us, AI just seems to be another tool in the medicine bag," he said. "No one has brought it up as an issue of
concern."

Richard H. Wiggins, associate dean at the University of Utah School of Medicine, explained that most people's
concerns come from a lack of education surrounding AI.

"AI is going to help us bring better, more precise medicine and practical care," Wiggins said. "For us, it's like having
a good assistant. It's going to be helping us, not replacing us."

An AI a day keeps the doctor away

One misconception about AI in health care is that automated technology will eventually replace doctors.

                                                                                                               Page 2 of 3
                                      What do experts say about AI in health care?

Wiggins said this isn't a new fear. Thirty years ago when he was being trained as a radiologist, there were many
people who told Wiggins not to study mammography because they thought new diagnostic technology would
replace mammographers.

"Of course, we still have mammographers - they just do different things, and we've seen examples of this over and
over throughout history," he said.

Matt Hollingsworth, CEO and co-founder of Carta Healthcare, compared today's fears to past concerns that
architecture jobs would disappear with the invention of computer-aided drafting software.

"What actually happened is that the bar for quality coming out of an architecture firm increased unilaterally because
everyone had access to the same tools," he said. "It became a productivity tool. So I think (AI) is going to be like
that."

Hollingsworth sees this same improvement in his work. Carta software, which creates AI tools to replace manual
data collection in doctors' offices, doesn't replace medical professionals, he said. It simply streamlines their work by
improving the speed and accuracy of filling out forms during medical visits. Those data entries still have to be
checked by a doctor for accuracy.

"It's not going to be cutting anybody out of a job, it's just going to keep them from having to do boring stuff in their
job," Hollingsworth said. "As long as we're working with these algorithms, we're going to need a babysitter, and that
babysitter is going to need to be a human."

Speed of change

Seventy-five percent of Americans are afraid medical providers will implement AI in healthcare too quickly without
fully understanding the risks involved.

But Hollingsworth said people probably think AI advancements are moving much faster than they actually are
because people are discussing AI more than they used to.

"It feels like it's coming out of nowhere, but really this is just the first time it's been more accessible to the public," he
said.

Neural networks, an early conception of machine learning and artificial intelligence, were first proposed in 1944.
Seventy-nine years later, we have not developed AI nearly as greatly as researchers projected we would have by
this time, Hollingsworth said.

Wiggins added that inaccuracies in movie portrayals of technological advances also contribute to the public
perception that things are advancing much quicker than they are.

"After 'Star Wars' came out, everyone assumed that we had holograms, but we still don't know how to make
holograms," Wiggins said. "We're not at 'The Terminator.' That's so far away."

Hollingsworth added that the slow rate at which advancements are being made, along with being comforting to
those intimidated by technological progress, is a good sign that AI developers are putting great consideration into
their work.

"We don't even have line of sight into generalized AI. Not even close," he said. "And that's not to denigrate; it's
actually the opposite. This is hard work."

Educating the next generation

Wiggins said even though AI won't be replacing doctors, health care professionals still have to adapt to the
evolving medical field to stay relevant.

                                                                                                         Page 3 of 3
                                    What do experts say about AI in health care?

"The people who are thinking about how to use AI and machine learning to help them with their jobs may be
replacing the people who are not," he said.

This mindset has driven many changes at the University of Utah Medical School, where Wiggins and his team are
evolving their teaching methods to better prepare the next generation of doctors.

"We're totally redoing the curriculum," Wiggins said. "Artificial intelligence is definitely going to change health care
... so we can't teach (students) the same way anymore."

The most successful doctors used to be the ones who could memorize the most facts, Wiggins said. Now, because
of constant technological evolution, he said it is more important to focus on critical thinking.

"It's impossible to know everything because there's so much more knowledge coming out all the time," Wiggins
said. "If I can teach my students how to use logic and rationality to effectively solve a problem, that's a much bigger
deal."

Part of that education includes getting students out of the classroom and into clinics sooner, to work hands-on with
patients and technology.

"I'll have a class about the heart ... and then they go into a clinic and see a guy with that heart issue they were just
talking about," Wiggins said. "You're putting together what you're learning about right away."

He also projected that cancer treatments will be aided by AI tools in the near future.

Despite the public's general skepticism about AI, 65% of U.S. adults say they would definitely or probably want AI
to be used when they were screened for skin cancer, and 55% believe AI would improve accuracy in skin cancer
diagnoses.

"That's going to be an amazing thing, so we have to change the way that we educate our students to prepare them
for that," he said.

'A lot to be excited about'

Medical error was the third leading cause of death in 2016, according to the British Medical Journal. Hollingsworth
said the improvements AI makes in speed and accuracy will be instrumental in changing this statistic.

He said people are only right to be concerned about AI when it is not used correctly or when people leave AI
unchecked. Medical professionals should be held to a high standard in how they use the technology, Hollingsworth
said.

"As long as everyone is incentivized to make sure that the quality of care remains high, then applying these tools is
a really good thing for everyone," Hollingsworth said. "It's not something that we should fear; it is something to be
welcomed."

Wiggins is optimistic about how AI can be used to personalize medicine, including pinpointing warning signs for
later health problems and helping to recommend preventive measures.

"I think the primary emotion people ought to feel out of this is just excitement that there is a new thing in the world
that could make their jobs easier and more effective," Hollingsworth said. "There is a lot to be excited about here."


Load-Date: March 20, 2023


  End of Document

                                                                                                        Page 1 of 2
                                SUNY , UAlbany to Research AI for Mental Health Treatment




               SUNY, UAlbany to Research AI for Mental Health Treatment
                                                Government TechNology
                                                July 19, 2023 Wednesday



Copyright 2023 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 692 words
Byline: Aaron Gifford, Government Technology

Body


Jul. 19—Researchers at State University of New York at Albany (UAlbany) and SUNY Downstate Health Sciences
University are studying artificial intelligence-powered solutions for treating mental illness around the globe.

The initiative was announced in a recent news release after representatives from both schools returned from a
global Health Innovation Exchange (HIEx) meeting in Switzerland to formalize plans with various international
partners. UAlbany Vice President for Research and Economic Development Thenkurussi "Kesh" Kesavadas told
Government Technology on Tuesday that much of the future research will involve an AI supercomputer currently
under construction at UAlbany that's expected to go online next spring.

Kesavadas said supercomputers develop the next generation of AI and deep learning technology using trillions of
data points. At UAlbany, he said, this technology will map and analyze the human brain. The long-term goal is to
improve mental health-care capabilities globally to the point where technology can detect conditions earlier and
doctors can monitor patients more efficiently, somewhat lessening the impact of shortages of health-care workers.
UAlbany's AI supercomputer will be one of the largest in the nation located in a university setting, and the biggest
within the SUNY system, Kesavadas said.

Although specific research projects within this massive initiative have not been specified yet, and the partners are
still seeking additional funding from public and private sources, Kesavadas said faculty and staff across various
UAlbany departments, to include public health, psychology, nanotechnology and engineering, have already
committed to future efforts. SUNY Downstate will conduct clinical research on underserved patient populations.

"Bringing in people from different backgrounds and combining our expertise is important," Kesavadas said.
"Collaboration is the key."

HIEx is particularly interested in providing better mental health care in Asian and African countries, according to the
news release. Biju Jacob, the organization's chief technology officer, said economic problems, climate change,
disasters and health emergencies are contributing factors to the 25 percent increase in mental disorders in Africa
and Asia.

                                                                                                     Page 2 of 2
                           SUNY , UAlbany to Research AI for Mental Health Treatment

"We need a radical shift in mental health-care delivery, as the current approach has failed to address this silent
pandemic," Jacob said in a public statement. "That shift is possible only through digital technologies and AI-based
community-centric care. This partnership is particularly aimed at creating a technology framework and backbone to
quickly translate cutting-edge technologies to practice."

David Christini, SUNY Downstate senior vice president for research, said the partnership between the two SUNY
campuses and HIEx is aiming at "substantive global advancements in mental health care."

"Identifying and treating mental health and wellness has grown increasingly important as our global society faces
challenges that dominate everyday living," Christini said in a public statement. "We are excited to redouble our
mental health research efforts and see tremendous potential in utilizing AI to advance diagnosis and treatment."

While AI-powered research is developing new methods for treating mental health, Kesavadas said, existing virtual
reality or augmented reality (VR/AR) could be deployed around the globe in the meantime to treat patients. He said
these low-cost tools can be customized to work with different health-care systems, languages and customs, adding
that advocating for increased mental health screening around the world and reducing the stigma of mental health
disorders are important tasks that the partners in this initiative can get working on right away.

"We have plenty to get started with to analyze different conditions," Kesavadas said. "There are various domains.
You can monitor people's actions through the tracking of Apple watches and social media — especially in student
environments. You can see how moods are changing."

___ (c)2023 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: July 20, 2023


  End of Document

                                                                                                           Page 1 of 3
  Experts weigh role of AI in health care's future; From filling out forms to creating a treatment plan, professionals
                                         are eager to use new technologies




  Experts weigh role of AI in health care's future; From filling out forms to
 creating a treatment plan, professionals are eager to use new technologies
                                                   Crain's Cleveland Business
                                                          December 11, 2023
                                                            Print Version



Copyright 2023 Crain Communications All Rights Reserved




Section: Pg. 1; Vol. 44
Length: 922 words
Byline: Paige Bennett

Body


As interest grows around artificial intelligence, experts believe emerging technologies could lead to big changes in
health care. Developments in AI could provide assistive tools to busy caregivers and allow for medicine to be
tailored to a patient's specific needs.

Conversations around the potential of AI in health care have gained momentum in recent years, but the concept
has been around for some time.

"Everything gets packaged as completely new, but, really, creating algorithms that do more consistent, better
medicine has been with us for decades," Dr. Paul Ford, who works in the Cleveland Clinic's Department of
Neurology. "It really has ramped up in the last five to 10 years, given our electronic medical record and the
increasing abilities of computer hardware to process things faster for large data sets."

Dr. Daniel Spratt, chair of the Department of Radiation Oncology at UH Cleveland Medical Center, said that
historically most hardware and software used in health care has been operated by humans, but that certain areas
have the potential to be standardized using technology.

"There are aspects of healthcare that should be very evidence-based, very algorithmic, very standardized," he said.
"That may not be a nuanced clinical decision whether to treat or not, but it may be once you've decided to treat or
you've decided to get a scan or to order, there should be very set processes and standards for some stuff to be
done safely and reproducibly and efficiently."

A lot of the recent buzz has been around generative AI, a type of technology that can produce images, text and
audio in seconds. This describes algorithms such as ChatGPT, an AI-powered chatbot that generates conversation-
like responses to user-inputted questions.

                                                                                                           Page 2 of 3
  Experts weigh role of AI in health care's future; From filling out forms to creating a treatment plan, professionals
                                         are eager to use new technologies

Dr. Nicholas Schiltz, an assistant professor at Case Western Reserve University's Frances Payne Bolton School of
Nursing, said generative AI has the potential to simplify routine processes in health care.

"Nurses, doctors, the thing that they're lacking the most is time," he said. "And so, I think this technology has a lot of
promise to automate some of the tasks that they do in terms of documenting."

For example, a doctor or nurse could use generative AI to create a lay summary of a patient's electronic health
record. Rather than having to search through a clunky electronic medical record system, the caregiver would have
immediate access to the patient's important information.

Ford said assistive AI technology could act as a sort of scribe for doctors, filling out electronic forms so they don't
have their faces plastered on computer screens during appointments. These technologies are the closest to being
ready to apply and implement, he said.

"I think that where AI and generative AI play a role is in being able to standardize and automate many things that
are done inefficiently right now, in a lot of different people's hands on various processes, a lot of handoffs," Spratt
said. "That should improve the quality, you know, reduce mistakes."

Schiltz said one of the key potentials for AI is precision medicine, an emerging model that uses a patient's genes,
environmental factors and lifestyle to curate disease treatment and prevention to a specific patient. Medications are
tested based on what works for the average patient, but that doesn't mean they work for everyone. Precision
medicine aims to eliminate that one-size-fits-all approach and get patients the right medicine at the right time.

"In order to do that, you really need large databases and representative databases so you can actually say 'This
particular treatment should work well for this patient because their genetic profile works well with this. They're a
good metabolizer of this medication, whereas some other patients, because they have this other gene mutation,
they cannot metabolize that drug,'" Schiltz said.

The National Institutes of Health has an ongoing research program called "All of Us" that looks to collect and study
data from one million people living in the U.S. in an effort to improve health research and individualized prevention,
but many groups continue to be underrepresented in this area of research.

There is also concern among experts that biased algorithms could worsen health disparities if not properly
addressed. Experts say it's important for researchers to evaluate their models for biases and not assume that a new
form of technology will work for an entire population simply because it has worked for one group.

If researchers can develop effective technology, AI may be able to help diagnose rare or hard-to-detect conditions,
Schiltz said. Some chronic conditions, like fibromyalgia, can be difficult to diagnose because they can appear as
different symptoms. Schiltz said AI may be able to help detect patterns that may otherwise go unnoticed.

In addition, Spratt said trained generative AI chatbots could potentially help patients move their appointment times
or answer basic questions about treatments or side effects. The technology could also flag questions that need to
be answered by a caregiver.

New forms of AI could serve as effective tools for the health care industry, but experts don't expect any new
technologies to replace or eliminate the need for caregivers.

"I do think AI will be an assist," Spratt said. "I view it analogous to the typewriter versus Microsoft Word. It's going to
be an assistant for a lot of things to improve efficiency, accuracy. I don't see it removing physicians, nurses. I think
there's still huge value of the human connection."


Load-Date: December 14, 2023

                                                                                                         Page 3 of 3
Experts weigh role of AI in health care's future; From filling out forms to creating a treatment plan, professionals
                                       are eager to use new technologies


End of Document

                                                                                                       Page 1 of 2
                                 AI'S POTENTIAL IN HEALTH CARE DOMINATES EVENT




                  AI'S POTENTIAL IN HEALTH CARE DOMINATES EVENT
                                        Wisconsin State Journal (Madison, Wisconsin)
                                                  August 23, 2023 Wednesday
                                                              ALL EDITION



Copyright 2023 Madison Newspapers, Inc. All Rights Reserved

Section: LOCAL; Pg. A7
Length: 494 words

Byline: KIMBERLY WETHAL , kwethal@madison.com

Body


ChatGPT-style software could order medication mid-doctor's visit just by listening in, and your genetics could
predict the best medication for you, Epic Systems Corp. says as it continues to focus on automating health care
processes and alleviating clinician workloads.

Epic talked about these advancements as part of its annual User Group Meeting that brings about 14,000 people
from hundreds of Epic customer organizations to its sprawling Verona campus. The three-day convergence of
health care administrators and staff gives Epic's customers insight into new features in development and offers
breakout sessions centered on the health care industry's largest hurdles.

This year, the topic of generative AI and its ability to automate some of health care's most time-consuming tasks
was king. Epic founder and CEO Judith Faulkner hinted at a few upcoming features during her executive address
Tuesday morning in a nearly full Deep Space auditorium.

The conference's theme, Castaway - which also happens to be the moniker of Epic's newest office building within
its "Storybook" cluster of buildings on campus - represents where the health care industry is now, Faulkner said.
After surviving the shipwreck and being flung out to sea - a thinly veiled metaphor for how the COVID-19 pandemic
upended the health care industry - the industry has washed ashore and must find a way to move forward.

"It's been tumultuous: Things have washed away, health care staff have left, hospitals have closed. And important
services, such as maternity, have closed," she told health care workers. "The storm was grueling ... not everyone
has made it. We're still having to throw life buoys to those in jeopardy. But we're going to make our new health care
world better than it was before."

Through a partnership with Microsoft, Epic launched its own generative AI technology earlier this year, four months
after the debut of ChatGPT. With it, Epic hopes to add AI to some of its most recognizable platforms, including
MyChart and the patient management app Rover, to reduce administrative tasks for clinicians and allow patients to
schedule appointments with just a few text messages from a chatbot.

                                                                                                        Page 2 of 2
                             AI'S POTENTIAL IN HEALTH CARE DOMINATES EVENT

And while machine-based learning isn't new to Epic - there are already nearly 2,200 functions within its software -
the company hopes it'll decrease worker burnout and decrease administrative costs.

Epic's enterprises also will focus on improving health care outcomes through its Cosmos platform, which allows for
210 million de-identified electronic health records to serve as a database for human health.

At the doctor's office level, expanded genomic testing could mean your doctor picks a certain medication based on
what's in your DNA.

"When you're prescribing a med for a patient whose genetic test results are available, we might be able to tell you if
the medication will work for the patient, or what would the best dose be based on the patient's genetic information,"
Faulkner said.


Load-Date: August 23, 2023


  End of Document

                                                                                                     Page 1 of 3
    AI biases could worsen health disparities Experts: Technology could lead to advancements but brings biased
                                                     algorithms




AI biases could worsen health disparities; Experts: Technology could lead to
                advancements but brings biased algorithms
                                                   Crain's Cleveland Business
                                                          December 4, 2023
                                                            Print Version



Copyright 2023 Crain Communications All Rights Reserved




Section: Pg. 2; Vol. 44
Length: 1154 words
Byline: Paige Bennett

Body


Diagnosing chronic illnesses. Personalizing medicine. Improving staff efficiency.

Health care professionals see a number of potential uses for artificial intelligence in the industry, but as new
technology develops, there also is the risk of biases infiltrating algorithms and worsening health disparities.

"It's not just to create the technology and then throw it in the hands of clinicians," said Dr. Paul Ford, who works in
the Cleveland Clinic's Department of Neurology. "You constantly go back and evaluate how efficient it is and what
any untoward side effects are and if you need to go back and revisit the algorithm or the training data or whether
there's systemic bias, societal bias, some built in assumption."

The rise of AI could lead to huge advancements in health care, but experts say the industry must take a methodical
approach to adopting new technologies to ensure bias stays out of these models.

A big reason for the growing conversation around AI has been advancements in genomic data science, an
interdisciplinary field that uses statistics and computational biology to analyze data created by modern genomics
technologies.

Many researchers believe genomics could revolutionize health care through precision medicine, a type of care that
uses molecular biomarkers to evaluate a patient's risks and prognosis, and tailor treatment and prevention to their
specific genes. But relying on these biomarkers to make accurate assessments of a patient's health could be a
problem for diverse populations.

"A lot of genomic data tend to be mostly in northern European ancestry," said Dr. Nicholas Schiltz, an assistant
professor in Case Western Reserve University's Frances Payne Bolton School of Nursing. "When you're building

                                                                                                    Page 2 of 3
   AI biases could worsen health disparities Experts: Technology could lead to advancements but brings biased
                                                    algorithms

models on those, the models are trained specifically for that data, so when you go to try to apply it to other
populations, it might not actually perform well or be relevant to them."

Bias problems have been detected within some of the predictive algorithms that health care systems have used for
years. A 2019 study published in Science found that an algorithm used by many hospitals to decide which patients
need care was determining that Black patients had to be much sicker than white patients to be recommended for
the same treatment. The algorithm had been designed using past data on health care spending, which did not
consider that wealth and income disparities also play a role in the health care spending habits of Black patients.

Dr. Daniel Spratt, chair of the Department of Radiation Oncology at UH Cleveland Medical Center, said there are
three main forms of bias: data-driven, algorithmic and human. Data-driven biases emerge when researchers
assume an algorithm that works for a certain group can be applied to the entire population without further validation.
Algorithmic bias happens when a dataset doesn't contain fair representation of a particular group. Human bias
comes from issues that already exist in society, such as structural racism.

Ford, who works with the Clinic's AI team to identify potential biases or ethical concerns in projects before they
move forward, said it's important for researchers to be mindful about biases and the harm they can inflict in the
early stages of design.

"Really it needs to be a thoughtful process at the beginning to say we know some traditional biases around
economics, equity, access, things like gender," he said. "We're obligated to make sure that we have assessed for
those, then to run algorithms alongside to say, 'Are there other things, patterns that we need to evaluate to see
whether they contain some of the biases we hadn't thought of?'"

Spratt said transparency is key to preventing unintentional negative consequences.

For instance, if a model is designed based on a dataset of mostly white patients from Wisconsin, researchers
should not automatically assume it will work for patient populations in Cleveland. It's crucial that researchers are
open about where their data is coming from, he said, and that they gather information from diverse patients if they
plan on applying their algorithms to larger populations.

"I think data sharing is now probably more important than ever to make sure that you are enriching and including
either, whether it's rare cancers or minority populations, different socioeconomic factors," Spratt said. "Data sharing
will enable (researchers) to have enough data on potentially underrepresented data to make sure that AI algorithms
that are meant to be applied to those less common things to prove that they work or don't work in those settings."

Ford said clinicians and patients who use AI or other forms of machine learning must be empowered to recognize
when something seems amiss. The end user of any technology should know how to look for problems and report
anything that needs further review, he said.

"The reality is, AI can be harmful," said Dr. Yasir Tarabichi, medical director of the virtual care enterprise and
director of clinical research informatics at MetroHealth. "AI can be biased. It can bring out the worst tendencies that
arise from what we already know in this world to be a lot of inequity and structural racism and bias. So, if you just
hold AI up as a mirror, it's just going to reflect all the bias that exists in our world today."

Tarabichi said researchers should treat algorithms like new medications and put them through robust evaluations.
It's also important not to assume that every algorithm is going to be fair and representative simply because it's
based on data, he said.

Another way to reduce bias is to ensure that diverse populations are involved with building algorithms, Schiltz said.

"A lot of people who build these models tend to be white males, so trying to be more inclusive in terms of diversity
of gender, race, ethnicity (is important)," he said. "Get people hired into these positions to build these models. Bring
diversity of perspective."

                                                                                                    Page 3 of 3
   AI biases could worsen health disparities Experts: Technology could lead to advancements but brings biased
                                                    algorithms

From 2006 to 2016, bachelor's degree recipients in biological sciences, computer sciences, mathematics and
statistics were only 8.7% Hispanic or Latinx, 7.8% Black or African American and 1.9% multiracial or indigenous
American, according to a 2022 journal published by the National Library of Medicine.

Experts agree the health care industry should take a slow and deliberate approach to rolling out new technology.
Ford said it was "heartening" to see the U.S. set guidelines for AI development. In October, President Joe Biden
signed an executive order on AI that the White House says will establish new standards for safety, protect citizens'
privacy and advance equity and civil rights.

Spratt said the appropriate guardrails must be in place before new technologies are implemented.

"All this AI stuff is not going to redefine health care overnight," Tarabichi said. "It has to be put through its paces,
and we have to make sure that we are helping and not harming the community that we serve."


Load-Date: December 7, 2023


  End of Document

                                                                                                       Page 1 of 2
                          Telehealth Week @ TTUHSC Conference to highlight digital healthcare




     Telehealth Week @ TTUHSC Conference to highlight digital healthcare
                                                     Odessa American (Texas)
                                                      August 7, 2023 Monday



Copyright 2023 The Odessa American (Odessa, Texas)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 639 words
Byline: Odessa American, Texas

Body


Aug. 7—Telehealth Week @ TTUHSC, a conference about digital innovation, will offer an immersive experience in
digital health using technology for access to care. The free conference, which takes place Sept. 19-21 at the
TTUHSC Academic Event Center located at 3601 Fourth St., is open to all clinicians, administrators, health care
providers and stakeholders.

The conference aims to demonstrate how digital health enhances access to care and solves rural health
disparities. Three goals of the conference include:

>> Exposing stakeholders to the broader goals of digital health at TTUHSC

>> Motivating stakeholders to go beyond telehealth and embrace the fullness of digital health

>> Celebrating and launching the Institute of Telehealth and Digital Innovation

"Health care in this region is a collaboration of many stakeholders," TTUHSC President Lori Rice-Spearman said in
a news release. "We're proud to be among those preparing the providers and delivering excellent research-backed
care, but we also want to identify and implement innovative initiatives that truly transform health care."

TTUHSC Executive Director for the Institute of Telehealth and Digital Innovation John Gachago said digital health
is all-encompassing and includes a variety of current and emerging digital tools to improve health care delivery.

"When we look at digital health, it includes all tools to leverage technology not only to improve access, but also to
improve health care as a whole," Gachago said in the release. "Some of these technologies are current while
others are emerging, such as artificial intelligence (AI), the internet of things and blockchain technology. If
leveraged strategically, these technologies have the capacity to enhance health care outcomes and lower the cost
of care."

TTUHSC's telehealth programs continue to bridge the barriers in the 108-county service area of West Texas
through new projects and innovations to expand telemedicine into most rural areas.

                                                                                                     Page 2 of 2
                       Telehealth Week @ TTUHSC Conference to highlight digital healthcare

TTUHSC experts and telemedicine professionals from across the country will serve as presenters. Gachago said
the conference will educate, motivate and jumpstart stakeholders around digital health.

Telehealth Week @ TTUHSC will focus on three tracks that include: an introduction to telehealth; rural health care;
and AI in health care.

Panel discussions will include: How Digital Health Can Help Overcome Rural Health Challenges; Telehealth and
Organ Delivery Drone Project; and a TTUHSC Telehealth Poster Showcase.

Other presentations will include: Leveraging Technology for Access to Care; AI Can Help Rural and Urban; Mayo
Clinic and The Role of AI in Health Care; and Opportunities for AI in Health Care and Related Challenges.

Conference participants will have vendor opportunities that will be interactive.

To         register    for       the       Telehealth    Week     @                TTUHSC    conference,       visit
https://tthsclubbock.co1.qualtrics.com/jfe/form/SV_3juOAINoanOD52K.

In support of improving patient care, TTUHSC is jointly accredited by the Accreditation Council for Continuing
Medical Education (ACCME), the Accreditation Council for Pharmacy Education (ACPE), and the American Nurses
Credentialing Center (ANCC), to provide continuing education for the health care team.

For the Credit Designation statements, please visit the conference website.

Separate registration is required for continuing medical education credits at

https://cmetracker.net/TTUHSC/Publisher?page=pubOpen#/EventID/37523/

Additional details, including speakers and agenda will be provided at https://www.ttuhsc.edu/president/telehealth-
week/.

The Telehealth Week @ TTUHSC conference is in conjunction with the American Telemedicine Association
Telehealth Awareness Week Sept. 18-21.

___ (c)2023 the Odessa American (Odessa, Texas) Visit the Odessa American (Odessa, Texas) at www.oaoa.com
Distributed by Tribune Content Agency, LLC.


Load-Date: August 8, 2023


  End of Document

                                                                                                       Page 1 of 2
     Biovista Personalized Medicine and Diginova to deliver next generation AI-driven doctor/patient support in a
                                      deal that can generate over $5 Billion.




  Biovista Personalized Medicine and Diginova to deliver next generation AI-
   driven doctor/patient support in a deal that can generate over $5 Billion.
                                            The Breeze: James Madison University
                                               September 15, 2021 Wednesday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 569 words

Body


CHARLOTTESVILLE, Va. and DUBAI, UAE, Sept. 15, 2021 /PRNewswire/ -- Biovista Personalized Medicine and
Diginova Health Solutions today announced their deal to deliver augmented intelligence -driven personalized
medicine analytics to over a quarter of a billion patients in Asia, starting in the MENA region. Diginova will offer
Biovista Personalized Medicine's market-leading AI Health ShieldTM analytics direct-to-consumer, where the
consumers are doctors, patients, their family caregivers, and national/regional health systems.

"We are excited to partner with Diginova on bringing our AI Health ShieldTM to a major part of the world," said Aris
Persidis, Biovista Personalized Medicine's Managing Director. "Diginova is excellent at integrating the right health
solutions for patients and doctors and has an innovation-led vision for the future of healthcare that is aligned with
ours," he continued.

"Outside of cancer, there were no AI-based solutions that could deeply understand patient data, including the use
of data to understand existing therapies versus unanticipated ones, until the arrival of Biovista Personalized
Medicine's AI Health ShieldTM," said Sarper Tanli, CEO of Diginova. "Biovista Personalized Medicine helps us
deliver high quality-analytics to our consumers for any real-world clinical scenarios they may be facing. We see the
AI Health ShieldTM as a real disruptor in the delivery of data-driven healthcare services," he added.

"We see this deal as generating potentially over $5 billion in new AI-driven service revenues over its current
iteration and lifetime," said Persidis, "helping us continue to engineer better healthcare for everybody's future," he
added.

About Biovista Personalized Medicine's AI Health ShieldTM: It compares a patient's current diagnosis and
treatment program against the many millions of evidence-based research reports published annually in scientific
journals. It then recommends either extensions or replacements of the standard of care when the latter fails. Such
augmented intelligence-supported analytics help physicians to adjust treatment plans and medications as well as
pro-actively "think differently" for patients in need. Going beyond AI-based systems focused primarily in cancer as
offered by competing personalized medicine companies, Biovista Personalized Medicine's AI Health ShieldTM was
designed from the start to be disease/therapy agnostic.

                                                                                                      Page 2 of 2
    Biovista Personalized Medicine and Diginova to deliver next generation AI-driven doctor/patient support in a
                                     deal that can generate over $5 Billion.

About Biovista Personalized Medicine: The company is a wholly-owned subsidiary of Biovista, Inc., the award-
winning pioneer in AI-driven drug repositioning and personalized medicine. Biovista Personalized Medicine's focus
is the delivery of the class-leading AI-Health ShieldTM to consumers, patients, caregivers, doctors and health
systems.

About Diginova: Based in the UAE, Diginova advances evidence-based technologies and digital care models to
treat a broad spectrum of conditions, both chronic and otherwise. Diginova's multi-functional digital health platforms
include, but are not limited to therapeutic care, diagnostics, HCP upskilling and more.

Further information:

For BPM: info@biovista.com

For Diginova: info@diginovahealth.com

View original content to download multimedia:https://www.prnewswire.com/news-releases/biovista-personalized-
medicine-and-diginova-to-deliver-next-generation-ai-driven-doctorpatient-support-in-a-deal-that-can-generate-over-
5-billion-301376963.html

SOURCE Biovista


Load-Date: September 16, 2021


  End of Document

                                                                                                       Page 1 of 3
                                 Point-counterpoint: ChatGPT's role as therapy alternative




                  Point-counterpoint: ChatGPT's role as therapy alternative
                                      Badger Herald: University of Wisconsin - Madison
                                                      May 4, 2023 Thursday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: OPINION; Pg. 1
Length: 1395 words
Byline: Fiona Hatch and Emily Otten

Body

CONTENT WARNING: Discussion of suicide and/or self harm. If you have are experiencing thoughts of suicide or
self harm, dial 988 to reach the Suicide & Crisis Lifeline. View options for mental health services on campus
through University Health Services.

Since the technology's launch in late 2022, ChatGPT is quickly becoming one of the fastest-growing apps of all
time. The new technology has several uses though recently, some have been exploring it as a fast, accessible
alternative to therapy. Could ChatGPT serve as a therapy alternative, or are there too many risks in addressing
complexities of mental health?

Point: AI can be an accessible solution to the therapist shortage

In the first two months of its release, ChatGPT gained over 100 million users, compared to the nine months it took
for TikTok to cross that same threshold. The app was developed by the company OpenAI as a chatbot that can
process and respond to prompts given by users.

Most news surrounding ChatGPT has been with respect to how the technology has been used by students.
Northern Illinois University's research into the capabilities of ChatGPT shows the app can craft essays, write emails
and solve relatively complex equations when prompted.

But, the app could have uses beyond the classroom. There are now conversations regarding AI's future role in
society, namely in the medical field and mental health. With technology adapting to provide quick and increasingly
human-like responses to users' prompts, many are now wondering if it could be the solution to the world's mental
health professional shortage.

Point-counterpoint: Platforming controversial speakers60 Minutes recently aired an episode featuring an interview
with U.S. Rep. Marjorie Taylor Greene (R-Ga.). The controversial piece gave Read...

There is a clear shortage of therapists in the U.S. and around the world. A map released by the Rural Health
Information Hub shows that the majority of counties in the U.S. are facing a mental health professional shortage.
Over 150 million Americans live in a federally designated mental health professional shortage area, leaving many
without reliable access to help.

                                                                                                        Page 2 of 3
                              Point-counterpoint: ChatGPT's role as therapy alternative

This is an even more prominent issue when expanded to the international level. According to the World Health
Organization, there has been a 13% increase in mental health issues worldwide over the last decade, with 20% of
the world's child and adolescent population struggling with some form of mental health condition.

AI technology like ChatGPT presents an opportunity to broaden access and definitions of mental health support in
an increasingly necessary way.

This is not to say that apps like ChatGPT are prepared to handle every mental health condition or situation. Mental
health is a broad and extensive issue that requires a nuanced system of resources for struggling individuals. For
some, the ease of access and instantaneous responses that AI offers could be very beneficial if the software was
programmed with adequate medical information.

But, AI inherently lacks certain things that only a face-to-face connection with a medical professional can provide -
such as reading clients' behavioral or social cues, gathering important life or medical contexts that might go
unnoticed by a bot and displaying compassion or empathy in a way that no technological alternative could replicate.

Along these lines, there are some mental health crises that AI technology like ChatGPT should never be in charge
of handling. Technological therapy is more often than not a lesser alternative for individuals struggling with mental
health, but for those facing an immediate crisis, on-the-ground human judgment might be critical.

But, with mental health issues on the rise worldwide and a critical shortage of qualified professionals, the world
needs new and innovative solutions to combat the current mental health crisis. AI could be the best way to ease
the burden for medical workers by tending to those with concerns that can be addressed quickly and without
person-to-person communication.

Fiona Hatch ([email protected]) is a senior studying political science and international studies.

Point-counterpoint: Decison to appoint new Wisconsin secretary of stateAfter longtime Wisconsin Secretary of State
Doug LaFollette stepped down from his position, Gov. Tony Evers appointed Sarah Godlewski, the Read...

Counterpoint: The risks of using ChatGPT are too great

The utilization of ChatGPT as a source of therapy should be used very sparingly, if at all, because of the danger it
presents to users. After texting with an AI chatbot for a few weeks, a Belgian man died by suicide. Though this is
likely not a widespread experience with AI chatbots, it does show the potential dangers of turning to an unreliable
AI bot for support.

ChatGPT is not a trained therapist and can give individuals inaccurate information, especially about emotional
issues. ChatGPT creators specially designed policies to not diagnose people with health conditions or provide
medical information.

Additionally, ChatGPT is not always accurate in its responses to objective questions. As AI, it cannot truly
comprehend the questions people are asking. AI doesn't always understand the meaning or intent behind a user's
words. So when it comes to complex issues of mental health and therapy, AI can't be fully accurate or offer the
best advice.

Getting therapy over the Internet became incredibly popular during the pandemic. Apps like BetterHelp aided
individuals in getting mental health assistance for a fraction of the cost in the comfort of their own homes. But, even
BetterHelp had its issues.

Users called "therapists" who operated on BetterHelp unprofessional, claiming they gave them bad advice that
harmed their mental health instead of improving it. Additionally, the app came under fire for sharing customers'
personal data on social media apps, according to the Federal Trade Commission. These issues with BetterHelp,
which uses real people to communicate with customers, could happen with AI chatbots used for therapy like
ChatGPT.

                                                                                                         Page 3 of 3
                              Point-counterpoint: ChatGPT's role as therapy alternative

Point-Counterpoint: News414, the future of journalismNews414 is a new journalism initiative launched through the
collaboration of three Wisconsin newsrooms - Milwaukee Neighborhood News Service, Wisconsin Read...

There is no promise that ChatGPT can keep users' information confidential, especially information that could be
considered incredibly private. Also, AI chatbots can be less professional than BetterHelp therapists because they
aren't real people. There is no promise that ChatGPT will give people good advice that will actually help them cope
with trauma or other mental health issues.

There are certainly areas where ChatGPT could be used in a therapeutic-like setting. For example, a quick question
about how to respond to a difficult text or asking for examples of coping mechanisms could be helpful. When a full
therapy session is not needed, AI could be used for issues that a person could address later with more detail in a
therapy session. Using ChatGPT for continual therapeutic advice, however, could be dangerous.

Therapy is incredibly personal and needs to be well-tailored to an individual to be effective. Therapists and their
clients form intense personal relationships, and that relationship simply cannot be mimicked with ChatGPT or even
over text with a real human with BetterHelp. Mental health treatment can be incredibly expensive in America, but
that treatment is effective.

ChatGPT could have its benefits in certain situations with a quick question, but for long-term, complex mental
health support, ChatGPT should not be used. The AI chatbot is not designed to be used for mental health
treatment, so individuals should stay clear of communicating with ChatGPT in that way.

Emily Otten ([email protected]) is a junior majoring in journalism.

Resources regarding suicide prevention and mental health:

    •   988 Suicide & Crisis Lifeline: 988 https://988lifeline.org/help-yourself/loss-survivors/
    •   Crisis Text line: Text HOME to 741741 https://www.crisistextline.org/

    •   Survivors of Suicide support group: https://www.uhs.wisc.edu/prevention/suicide-prevention/
    •   Trevor Lifeline: https://www.crisistextline.org/ crisis intervention and suicide prevention services to lesbian,
        gay, bisexual, transgender, queer and questioning young people under 25
    •   24/7 crisis support 608-265-5600 (option 9)


Load-Date: May 4, 2023


  End of Document

                                                                                                      Page 1 of 5
       Ad agencies rethink mental health policies; Amid layoffs, AI fears and an uncertain economy, shops are
                              prioritizing employee well-being and preventative care




   Ad agencies rethink mental health policies; Amid layoffs, AI fears and an
     uncertain economy, shops are prioritizing employee well-being and
                              preventative care
                                                          Advertising Age
                                                           May 22, 2023
                                                           Print Version



Copyright 2023 Crain Communications All Rights Reserved




Section: Pg. 1; Vol. 94
Length: 2230 words
Byline: Lindsay Rittenhouse

Body


The pandemic sparked a focus on mental health in the ad business, an industry known for its churn-and-burn
nature. But now with the shaky economy and increase in agency layoffs, along with the emergence of generative AI
creating new concerns around job security, shops are once again reevaluating how they're taking care of their
people.

Some are deploying AI into their mental health programs while others are offering on-call specialists including
psychologists for employees to chat with whenever they need.

"The business that I grew up in was: 'Shut up, keep your head down, plow through the work and if you've got
problems, go home and tell your wife your troubles, don't talk about it at work,'" said Jeff Graham, president and
chief marketing officer at Denver ad agency Cactus. "The difference is now we're talking about it. As a dad of a
young copywriter in Los Angeles, I am so grateful that she works in the business today with dedication to balance
and mental well- being of employees."

For Cactus, mental health has been at its core since its founding in 1990 by CEO Joe Conrad, who started the
shop to build brands and causes he believes in. It's a passion point for Conrad, who also founded a platform for
college students to access health and well-being solutions.

Cactus built out a version of the platform in 2021 for its employees to access mental health resources whenever
they need and, in honor of Mental Health Awareness Month, the agency is now expanding that platform to give out
free to any ad agency that wants it.

                                                                                                     Page 2 of 5
      Ad agencies rethink mental health policies; Amid layoffs, AI fears and an uncertain economy, shops are
                             prioritizing employee well-being and preventative care

Conrad said Cactus will customize the platform for agencies, as well, so a company's specific health benefits and
programs can be included on its site for its employees to access.

The Cactus platform includes resources for managing everything from stress to substance abuse. It was built with a
clinical psychologist who is on staff and splits time between the platforms and the agency and who is available for
employees to talk to at any time as well.

On call professionals

Similar to Cactus, agencies are increasingly bringing on mental health professionals, including psychologists and
other individuals, for employees to talk to as needed.

Independent ad agency RPA works with FZ Coaching's Felicia Zigman, an outsourced HR professional, to give its
employees mental health support.

Zigman said she started working originally with RPA's leadership four years ago, but recently started offering office
hours to the agency's employees to give them space to come to her to talk about anything-personal or career-
related-without fear of repercussions.

"I'm intended to be a resource for people," Zigman said. "I'm external so it's completely confidential. You can air
grievances, talk about next steps in your career."

She dedicates about two days a week to RPA and works with other tech companies, as well. Zigman said
employees in the ad and tech spaces are particularly stressed because of the layoffs that have hit those industries
and the emergence of generative AI that has caused concerns about apps like ChatGPT taking jobs such as
copywriting.

"There's an added layer of 'is AI going to take my job?' That's a big issue I see across the board," she said.

Holding company WPP expanded its "Mental Health Allies" program, a collective of more than 130 trained
volunteers who can support colleagues in times of need, to the U.S. in 2021 after a successful pilot in the U.K.

"They're not counselors, so they don't diagnose or give clinical advice, but they do give people a space to be heard
when they need it," a WPP spokesperson said.

WPP's GroupM also has its "Employee Assistance Program," which workers can call into confidentially to get
support, guidance and referrals for a variety of needs.

Interpublic Group of Cos.-owned McCann pays to give its employees access to Talkspace, an online and mobile
therapy company that lets people communicate through text or video with a therapist.

Megan Streba, senior director of people experience for The Variable, said the agency provides eight free, face-to-
face counseling visits through its employee assistance program. "We believe it's important to remove financial
barriers when it comes to accessing mental health services," Streba said.

Jonathan Schoenberg, executive creative director and partner of independent agency TDA Boulder, said the shop
"provides employees with free, confidential, mental health support," with around-the-clock access to therapists.

Accenture's "Mental Well-being Hub" also includes access to more than 12,000 mental health "allies" across the
world.

AI-powered programs

Generative AI may be fueling some of the anxiety that's out there right now, but artificial intelligence is also helping
some agencies provide better mental health programs.

                                                                                                     Page 3 of 5
      Ad agencies rethink mental health policies; Amid layoffs, AI fears and an uncertain economy, shops are
                             prioritizing employee well-being and preventative care

Publicis Groupe said it began working with Arianna Huffington's Thrive Global, a behavior change technology
provider, via its global AI connectivity platform, Marcel.

"This partnership works to address burnout with sustainable, science-based solutions that unlock employee
performance and enhance well-being for the entire Groupe via workshops, guides and micro-learning experiences
across five key focus areas: Thriving Performance, Working Families, Thriving Parenthood, Thriving Across Our
Differences, Thriving Together," Publicis said.

Some of the programs within Thrive Global and Marcel include 60-second breathing and focus exercises, according
to the holding company.

Also through Marcel, Publicis launched a dedicated "Working With Cancer" hub with resources, manager trainings
and services for Publicis employees to share their workspace with people with cancer and their caregivers. Publicis
Groupe Chairman-CEO Arthur Sadoun revealed he had surgery to remove a cancerous tumor in his neck last year
and has discussed how many testimonials he received from people in the industry who also have been touched by
cancer and the stress it causes not only in their personal lives, but professional as well.

Programs for specific needs and groups

Some agencies have additional resources dedicated to specific groups, including parents, the LGBTQ+ community,
Black employees and people with disabilities or battling certain diseases, as Publicis did through its "Working with
Cancer" hub.

Just as the pandemic shone a light on the stresses the ad business places on people's well-being, the murder of
George Floyd and the rise of the Black Lives Matter movement in 2020 also revealed just how intertwined social
issues and diversity, equity and inclusion are with mental health.

GroupM said it started offering a session this month on inclusive family-building benefits for the LGBTQ+
community.

Independent agency Big Spaceship partners with The Adversity Group (TAG), a diversity, equity and inclusion
consultancy, "to facilitate agency-wide trainings and discussions around current events and diversity-related topics
to offer crew a safe space to have conversations," said Kristin Daversa, senior VP of people and culture.

WPP's VMLY&R partners with Bright Horizons to provide backup child, adult, elder and even pet care to its
employees in need of those services, as having to find family care is another big weight on people's shoulders.

For backup child care, for example, VMLY&R said it offers 10 days of care, plus 10 additional days within the first
year of birth or adoption, for between $15 and $25 a day per child. If care is unavailable within the Bright Horizons
network, employees get reimbursed up to $100 a day for finding their own childcare, according to the agency.

OMG's Global Chief Talent Officer Kate King said the company has been particularly focused on expanding
resources for parents and caregivers. It partners with Peace at Home Parenting Solutions and the Working Parents
Network to host "safe space discussions" for its working parents around events such as school shootings.

"Today's environment and recent events have created new challenges and concerns for caregivers and parents,"
King said. "We recognize the emotions of our employees and do not expect it to be just another day at work. In
addition to these sessions, resources are provided including handouts and videos on how to help your children feel
safe in an unpredictable world, access to our EAP assistance and tips to manage distress from a traumatic event."

With rising inflation causing financial stress, some agencies also introduced additional monetary perks for
employees.

TDA Boulder said it increased its employee healthcare insurance coverage to cover 100% of costs. The Variable
invested in Pocketnest, a financial wellness platform for employees struggling with economic hardships amid the

                                                                                                     Page 4 of 5
      Ad agencies rethink mental health policies; Amid layoffs, AI fears and an uncertain economy, shops are
                             prioritizing employee well-being and preventative care

shaky economy. OMG said it also has specific apps focused on the struggles facing Black workers as well as
parents and their kids, and some that provide financial guidance for cultivating better saving habits and dealing with
debt.

Rise in meditation and sleep apps

Meditation and sleep apps such as Calm and Headspace soared in popularity at the start of the pandemic, and
many agencies are continuing to give their employees access to these platforms for free.

Independent ad agencies such as RPA and Giant Spoon, as well as holding companies including Stagwell, offer
employees memberships to Calm. OMG recently partnered with Headspace to offer its employees access to that
meditation and sleep app, which also provides kid-friendly content for parents and caregivers. McCann and
experiential agency Giant Spoon also pay for employee access to Headspace. GroupM gives its employees free
access to Ginger, an app that offers counseling and coaching via texts and video, as well as other means.
Independent agency Pereira O'Dell said it offers various apps such as Talkspace, Ginger and Happify.

Giant Spoon said it also reimburses employees for certain wellness experiences they take up including fitness
classes, massages and acupuncture. The Variable recently added free employee access to the Bright Wellness
app, which provides classes for exercises like meditation, stretching, yoga and strength. Streba said the agency
"highly encourages employees to make use of this app during the workday as a way to decompress."

Time off

It may seem obvious, but one of the biggest ways agencies can take care of their people is by giving them
adequate paid time off.

Some agencies including VaynerMedia, TDA Boulder, Mekanism and McCann's North American and APAC offices
offer unlimited PTO-although, there is an ongoing debate over whether doing so motivates or deters (because of
the lack of structure) people from taking as many days as they should.

Maren Reed, founder of ad industry HR strategy firm Hatch Consulting, said companies must have a strong culture
to have unlimited PTO.

"What I've seen is that people actually take less time off with an unlimited PTO plan unless there is a policy in place
that requires employees to take at least X days off [per] quarter," Reed said. "I know of examples where unlimited
PTO has been helpful and it is when companies have policies to encourage employees to actually use the PTO.
This could be requiring employees to use a certain number of days/quarter or managers following up with
employees on their time off plans."

Some agencies are also allowing for more flexibility in letting people take chunks of time off during the work day, or
offering sporadic company-wide PTO days.

"On a day-to-day basis, we openly encourage each other to step away from important tasks to take a walk or grab
coffee with a coworker as this allows for a reset and the ability to regain a healthy state," said Becky Stevenson,
chief operating officer of independent ad agency Two By Four.

Suzanne Barbosa, managing director of independent agency Atlantic New York, said her shop goes one step
further by mandating the use of PTO.

"Those who do not use all of their PTO by end of the year are submitted to do 'community service' at the agency's
headquarters-a boat in Red Hook," Barbosa said. "People (at all levels) are forbidden to contact a team member
when that person is on vacation. The only vacation shaming at Atlantic is if someone disrupts other people's
vacations."

The Atlantic's PTO policy may seem extreme, but the boundaries-setting aspect is critical.

                                                                                                     Page 5 of 5
      Ad agencies rethink mental health policies; Amid layoffs, AI fears and an uncertain economy, shops are
                             prioritizing employee well-being and preventative care

Reed said regardless of how much PTO an employee is given, it is of utmost importance for companies to urge
their employees to set boundaries when they are off and for managers to respect those boundaries.

"This can range from blocking time to walk their dog to leaving early to see kids' sporting events to spending time
with parents," Reed said. "Managers should take time to learn what their employees care about outside of work and
support them in creating space and time to nurture those passions."

Safe space

All in all, many agency executives said it's especially important for leaders to be vulnerable and open about talking
about their own mental health struggles to encourage team members to do so as well.

Ellie Lloyd, executive creative director of independent agency Glow, said being vulnerable with her team has always
been a priority.

"I have found that as a leader if you open up, your team feels comfortable enough to do the same. There's no piece
of work that is more important than your health," Lloyd said. "I make sure that my team knows the resources that
are available to them should they need to step away to take care of their mental health."


Load-Date: May 25, 2023


  End of Document

                                                                                                           Page 1 of 2
                        Possibilities, concerns rise as artificial intelligence breaks into health care




  Possibilities, concerns rise as artificial intelligence breaks into health care
                                                  The Lariat: Baylor University
                                                  December 5, 2023 Tuesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 369 words
Byline: Caleb Wheeler

Body


By Caleb Wheeler | Staff Writer

Artificial intelligence has officially entered health care in an effort to reduce demands on health care professionals.
Recently, ChatGPT joined the field to produce reports, process images and message patients.

Dr. Pablo Rivas, assistant professor of computer science at Baylor, said there are numerous ways AI can be
beneficial in medicine.

"If there's an illness or an epidemic and it fits a genetic profile, certain people are affected by that," Rivas said. "AI
can help me identify people at risk much faster than any human. There are files of people; AI can mine all that data
and identify people who are much faster than a doctor, so the doctor can focus on actually reaching out to people.
Making searches and imaging is also pretty good for an MRI or CAT scan."

While the use of AI in health care has spread across the nation, Baylor medical director Dr. Sharon Stern said
there are some concerns about the use of AI in such fields.

"AI is actually helpful in report-writing and reading X-rays, but you have to have a human there for several reasons,"
Stern said. "AI is educated by a database, so it depends on what that database is. If they just put [AI] on the
internet, they're going to pull up erroneous information; they're going to pull up a lot of biased, prejudiced
information."

Rivas and Stern both said they see the value of speed, although a person should be monitoring the work of AI to
ensure it is producing accurate information.

"AI can make a lot of decisions much faster, but I think as a society, we're not yet willing to accept the cost of our
decision because of liability if a doctor makes the wrong decision," Rivas said. "If AI is making decisions, who is
responsible for that?"

Stern said she is also concerned about the future of the medical field if it starts relying on AI for basic health care
tasks.

                                                                                                       Page 2 of 2
                     Possibilities, concerns rise as artificial intelligence breaks into health care

"Let's say AI starts doing all this radiology work, and it's great and there are humans and they're learning and
everything," Stern said. "But what if we get to the point where all of our young residents and medical students don't
know how to read a report without the AI? And what if the system goes down one day? They're going to have to
close the shop."


Load-Date: December 6, 2023


  End of Document

                                                                                                          Page 1 of 2
                                       U. expert discusses AI bias in research studies




                          U. expert discusses AI bias in research studies
                                               Daily Targum: Rutgers University
                                                      April 17, 2023 Monday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 741 words
Byline: Samantha Marshak

Body


U. expert discusses AI bias in research studies

SMSamantha MarshakApr 17, 2023, 4:00 AM

Photo by Irwan @tweetbyirwan / UnsplashArtificial intelligence technology in the medical field may hold biases.

In a recent study, researchers determined that the field of studying fairness and bias in healthcare-related artificial
intelligence is largely dominated by white and male researchers.

The study concluded that white and male researchers' scholarly works are cited disproportionately more often than
other races and sexes, mainly in first and last authorship.

The order of authorship indicates their contribution to the study, with the last author being the primary contributor to
the research. The study also found that authors from wealthier countries were more often referenced in major
journals than their peers.

Charles Senteio, an author of the study and an associate professor in the School of Information and
Communication, said the study aimed to measure the diversity of authorship in health AI research.

The study compiled 1,614 articles related to AI fairness to analyze the diversity of authorship and filtered the
articles for eligibility. Articles examined in this study discussed machine learning fairness, were related to healthcare
and included the clinical applications of their findings.

For the 1,984 authors studied, the researchers created distributions of each author's ethnicity and gender,
nationality, citations and funding received. Sixty-four percent of the total authors were white, 60 percent of the total
authors were male and white male last authors accounted for 58.3 percent of the total citations, according to the
study.

Additionally, only .5 percent of all authors came from low-income countries, according to the study.

                                                                                                         Page 2 of 2
                                   U. expert discusses AI bias in research studies

Senteio said the study itself faced limitations and is yet to be peer-reviewed. Additionally, he said that measuring
diversity in the context of research can be fraught with complications.

"Even collecting the race of patients today is not always straightforward because it's not done in a uniform way. For
example, sometimes, it's already in the record. We don't know necessarily how it got there," he said. "So simply
asking a patient their race and to indicate it. That's the simplest, the most common way, but there are many
reasonable patients who would rather not disclose that."

Additionally, Senteio said that having diverse teams does not inherently guarantee that the research conducted will
have no bias.

Despite these limitations, he said that researchers will not understand how bias negatively impacts health AI until
they start measuring aspects like the research's authorship.

"I wouldn't say necessarily that mandating racial equity among authors for all work in AI bias regarding health care
is a solution. But we don't even know what a problem is right now. So let's start somewhere and see what we get ...
and see what researchers think and see where it goes," Senteio said.

He said an issue recently found relating to health AI bias involves the pulse oximeter device. The technology,
which measures the level of oxygen in the blood, was found to read dark skin differently than light skin.

Additionally, Senteio said that AI bias had been found in radiology, where X-rays traveling through darker skin look
different than X-rays that do not, which can affect how radiologists examine these scans.

In terms of working with these medical devices, Senteio said that developers should factor in the potential
differences between patients' skin color when designing this technology.

"How do we know that when we develop guidelines from these algorithms that they'll actually be appropriate for the
patients who are going to be subjected to some of these recommendations? Maybe having diverse teams will put
us in a better position to act," he said.

Regarding the Rutgers community, he said that he hopes he and his co-authors' research will inspire people to
think of diversity as a method of producing better research, not just as a quota to hit.

"Diverse teams, which doesn't just mean representation, but empowerment and safe spaces to actually speak up
and put forth points of view that might not be aligned with the mainstream. That might not be aligned with what
leaders or (principal investigators) of projects are putting forward," Senteio said. "I think that that kind of thinking
and realization would go a long way to some of the very noble DEI efforts that we see almost everywhere."


Load-Date: April 18, 2023


  End of Document

                                                                                                     Page 1 of 2
            Walla Walla students' mental health app and AI idea wins State of Innovation Challenge award




Walla Walla students' mental health app and AI idea wins State of Innovation
                             Challenge award
                                             Walla Walla Union-Bulletin (Washington)
                                                       April 22, 2021 Thursday



Copyright 2021 Walla Walla Union-Bulletin (Walla Walla, Wash.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 632 words
Byline: Jeremy Burnham, Walla Walla Union-Bulletin, Wash.

Body


Apr. 22—Three Garrison Middle School students are innovating technology to address mental health of teenagers
during the pandemic.

"Lots of teens are more isolated from their peers during this pandemic, and they might feel like they have no control
over what is happening in their lives," eighth grader Miriam Hutchens said. "Teens also have to deal with online
school, which can be really stressful. Social media can also influence teens' view of themselves or the world, which
can be really confusing."

The students teamed up and were honored at a state STEM contest for a smart phone app proposal that addresses
mental health for teenagers. The project by Huchens, Hanen Mohamed and Mia Roughton was chosen as a State
of Innovation Challenge honoree.

The student project was one of eight out of nearly 90 submitted projects that earned the award, Garrison STEM
teacher Michael Bertram said.

Bertram coached the students in the project along with 21st Century Program director William Hammond.

The State of Innovation Challenge is funded by Washington state and sponsored by the Office of the
Superintendent of Public Instruction.

"They ask kids to solve real world problems," Bertram said.

This year, one category to address was "Responding to COVID-19."

The students started by examining what mental health services were offered in the Walla Walla area.

They were looking for gaps that could be filled by a service they could create. That's not, however, what they found.

"[We] found, if anything, there were lots of overlaps," Hutchens said.

                                                                                                    Page 2 of 2
           Walla Walla students' mental health app and AI idea wins State of Innovation Challenge award

So, the students shifted their focus. Rather than create a new service, which they felt would be redundant, they
wanted to focus on an easier way of finding existing services.

"They decided it would be interesting to create a way kids could connect with mental health services without having
to pick up a phone to call someone," Bertram said. "That's when they decided to develop an app."

While an actual, working app, was not developed, students came up with a proposal, including a design for the app
and what it would feature.

The app's home screen would have buttons such as "Learn," where teens could read about mental health issues
they may be facing, and "Find a Therapist."

Teen would also have the option of communicating with a virtual assistant-like bot named Zen.

So what exactly is Zen?

"Zen is a chat bot that teens or other app users can 'talk' to," Hutchens said. "It is there for when you can't or don't
want to talk to a real person about a problem or question you have."

Hutchens said many teens would feel more comfortable talking with a bot than a person because they will feel less
judged.

"A computer can't make fun of them," Hutchens said. "The computer also can't start rumors or degrade a person for
asking legitimate questions."

Zen can also help teens determine what other help may be available to them.

Bertram said he presented the State of Innovation Challenge to his students while in-person instruction was closed
due to the COVID-19 pandemic.

He said it was a good project students could tackle that would allow collaboration during distance learning.

"We did everything on Zoom," Bertram said. "I offered this challenge to them and three students took me up on it."

Hutchens said the experience was very educational.

"I learned a lot about teamwork and communication, especially since we started the project before going to school
in person," she said. "I also learned about the process of designing apps and how ideas that start as one thing can
end as something completely different."

Jeremy Burnham can be reached at jeremyburnham@wwub.com or 509-526-8321.

___ (c)2021 Walla Walla Union-Bulletin (Walla Walla, Wash.) Visit Walla Walla Union-Bulletin (Walla Walla, Wash.)
at union-bulletin.com Distributed by Tribune Content Agency, LLC.


Load-Date: April 23, 2021


  End of Document

                                                                                                            Page 1 of 2
                  BU artificial intelligence symposium explores intersection between AI and public health




  BU artificial intelligence symposium explores intersection between AI and
                                 public health
                                           The Daily Free Press: Boston University
                                                 October 20, 2021 Wednesday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: FEATURES; Pg. 1
Length: 736 words
Byline: Casey Choung

Body


Artificial intelligence and social media have many useful applications, but their use may affect and accentuate
inequalities and disparities, and add to the spread of health-related misinformation, as discussed at an event
hosted by the Rafik B. Hariri Institute for Computing and Computational Science and Engineering Monday.

The Rafik B. Hariri Institute hosted a virtual symposium Monday where scholars from various fields discussed the
significance and underlying concerns of the intersection of artificial intelligence and healthcare. COURTESY OF
THE RAFIK B. HARIRI INSTITUTE

The event - "Artificial Intelligence in Healthcare Symposium: Mitigating Disparities, Biases and Misinformation" -
was an opportunity for scholars across a myriad of disciplines to discuss this critical intersection between
healthcare and artificial intelligence.

The symposium was held over Zoom, with two panel discussions and presentations in the morning, and two more in
the afternoon.

The event was spearheaded by Yannis Paschaldis, a professor at the College of Engineering at Boston University,
and Gianluca Stringhini, an assistant professor in the department of electrical and computer engineering.

"Our objective was not only to discover how biases affect health and health care ... but also to explore how AI and
algorithmic methods can help mitigate these biases and these effects," Paschaldis said in his opening remarks.

Stringhini said plans for the event began about six months ago and originated from a focus research group that the
Hariri Institute created. Stringhini said they opted for a fully virtual event to allow anyone to join the all-day event.

"The Hariri community would identify important topics that research was needed on and then we would work
together for a year, to basically build connections and collaborations across the entirety of BU," Stringhini said in an
interview.

                                                                                                        Page 2 of 2
              BU artificial intelligence symposium explores intersection between AI and public health

Rich Caruana, a senior principal researcher at Microsoft, spoke later in the morning at the panel discussion, "AI in
Healthcare, Algorithmic & Data Bias, and Mitigation Strategies." He explained how machine learning models could
work well, or be "dangerous" for certain patients.

"If you've got a very effective treatment it's very easy for the model to learn that someone is low risk, when in fact
they're high risk and the only reason they're low risk is because there's an effective treatment, and that's really
tragic."

Biases can also develop from drawing data from non-diverse populations, said Derry Wijaya, an assistant professor
in the department of computer science who spoke at the panel "The Challenges, Risks, and Opportunities of AI in
Healthcare."

Wijaya said when predicting baldness in a certain population, for example, the AI will not be as accurate or safe
when predicting outside of that population.

"One of the ways we can improve equity is to have more diverse perspectives so that when we develop programs
and systems, it will be something that can address the needs of a diverse set of people, not just a proportion of the
population." Wijaya said.

Following the morning discussions and presentations, attendees were invited to join a virtual platform called Gather,
which created a unique experience for attendees with the platform's customizable avatars and rooms. Event
attendees could navigate through different virtual rooms, examine research and interact with researchers.

The virtual platform allowed researchers, like Samad Amini - a third year doctoral student in ENG under the
department of electrical and computer engineering - to share their work and interact with event attendees.

Amini shared his research on detecting dementia, which showed how a simple interview and drawing test can be
used in tandem with a deep neural network to produce a prediction that is more accessible and cost-effective.

"I learned a lot from the symposium here, and now it's my turn to present my poster and work, and I will get some
feedback from others to kind of improve my work later on," Amini said.

Sandro Galea, dean and professor at the BU School of Public Health, spoke during the healthcare panel. He said
while there's a potential for AI to improve healthcare, there will be challenges.

"We should lean into it [AI]," Galea said. "We should be having these conversations, and the mountain of
challenges, to my mind, are really large that we'll have to overcome before this makes a real contribution to
healthcare."


Load-Date: October 20, 2021


  End of Document

                                                                                                       Page 1 of 2
                  UC Berkeley researcher argues artificial intelligence cannot replace human empathy




 UC Berkeley researcher argues artificial intelligence cannot replace human
                                empathy
                                     Daily Californian: University of California - Berkeley
                                                      June 15, 2021 Tuesday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 437 words
Byline: Riley Cooke

Body


In a paper published May 26, Jodi Halpern, professor of bioethics and medical humanities at UC Berkeley and
UCSF, argued that artificial intelligence, or AI, is not a substitute for human empathy in health care.

Halpern wrote the paper with authors Carlos Montemayor and Abrol Fairweather from San Francisco State
University. In the paper, they claim that simulating empathy with AI is both impossible and immoral - impossible
because AI cannot experience emotion and immoral because patients deserve human empathy during times of
distress.

Halpern said the paper is a response to the growth of AI in health care, especially concerning mental health.

"Just as we deployed actual humans to do contact tracing because of the relational aspects and the need for trust,
we can deploy actual humans to provide mental health support," Halpern said in an email.

However, Halpern notes in the paper that she is not against AI in health care as a whole and there are many
places where AI can be useful.

According to Niloufar Salehi, an assistant professor at the UC Berkeley School of Information, AI is a great tool for
diagnosis and helping patients track their own health. She said the problem arises when people in health care treat
AI as more than what it is - a pattern finder.

"We have to be very, very careful here," Salehi said. "You don't want to trick people into thinking that AI or a
computer is sympathizing or empathizing with you."

Salehi focuses on human-centric AI, which identifies gaps in human work that AI can fill or supplement. According
to Salehi, it aims to develop AI around people's needs, rather than the other way around.

Salehi agreed with Halpern's paper, noting that people need to continue to draw a distinction between what is
impossible versus what is unethical with regard to AI.

                                                                                                       Page 2 of 2
               UC Berkeley researcher argues artificial intelligence cannot replace human empathy

Halpern emphasized another distinction, specifically between simulated empathy and human empathy: the ability to
have experiences. This allows humans to resonate with other people in a way that a computer cannot, according to
her paper.

Both Salehi and Halpern said they see a future for AI in health care, but they agreed that it cannot substitute
interactions that require empathy.

Halpern added that she is currently working on a book titled "Engineering Empathy," which will delve deeper into
the role of AI in interpersonal relationships. In the meantime, she hopes that her paper might shift the general
consensus of AI use in health care.

"We provided a conceptual argument that we hope will show that it is not only technical limitations but the nature of
empathy that limits AI going forward," Halpern said in an email.


Load-Date: June 16, 2021


  End of Document

                                                                                                           Page 1 of 3
                  Mercy looks to AI to relieve burden on health care workers, answer patients' questions




Mercy looks to AI to relieve burden on health care workers, answer patients'
                                 questions
                                                  St. Louis Post-Dispatch (Missouri)
                                                        October 1, 2023 Sunday
                                                             FIRST EDITION



Copyright 2023 St. Louis Post-Dispatch, Inc. All Rights Reserved

Section: ; Pg. C1
Length: 980 words
Byline: By Annika Merrilees St. Louis Post-Dispatch

Body


CHESTERFIELD - The Mercy health system plans to roll out a series of artificial intelligence-based tools in the
coming months, in partnership with Microsoft.

Their efforts are still in the early stages, but if they succeed, officials believe the technology could help patients
navigate the health care system, reduce burden on medical staff and monitor for errors.

They aim to get a few programs up and running sometime next year, but officials are already looking at dozens of
other potential uses for AI within the health system over the longer term.

Joe Kelly, Mercy's executive vice president and chief transformation and business development officer, said the
health system is treading carefully, with an eye toward ethical considerations like data privacy. The health system
is developing its own AI "code of conduct."

"We're not going to rush," Kelly said. "I think it's really important to make sure that we do have the right safeguards
in place before we just deploy technology like this into the wild."

Dr. Lee Schwamm, professor of biomedical informatics and data sciences at Yale School of Medicine, said AI is
already used in many parts of the U.S. health care system. Machine learning and automation are used widely in
financial transactions. "Conversational AI," often used in retail to monitor satisfaction during customer service calls,
is beginning to spread into health care. Schwamm think's there is potential to use AI to write clinical notes, and to
offer doctors suggestions of possible diagnoses that line up with patient symptoms.

People working on AI programs in health care, Schwamm said, need to ensure that there is human supervision of
what the technology is doing or recommending. And they need to consider how transparent they are with patients.

"I think that the bigger question here is really not whether it's going to be part of health care. It's gonna be part of
health care, just like it's part of everything else. The biggest question will be: Will you know it when you're
interacting with it? And will you know when it has been used in your care?" Schwamm said.

                                                                                                          Page 2 of 3
               Mercy looks to AI to relieve burden on health care workers, answer patients' questions

One of the first programs Mercy plans to introduce is a chatbot where patients would be able to ask questions and
get help understanding their lab results, which often hit patients' online medical portals before medical staff have a
chance to reach out and explain what the findings mean, Kelly said. The program should be able to cut back on
calls over basic questions, he said, and patients will always be able to reach out to medical staff for more
discussion if they want to.

Another program will take patients' calls and schedule appointments. A third is an internal chatbot tool, where staff
can find information about policies and procedures and answer HR-related questions.

Those first programs are just a few of the roughly 50 ideas Mercy leaders presented to Microsoft, as possible uses
for AI in the health system.

Kelly said these tools aren't expected to come at the expense of jobs. In an industry struggling with staffing
shortages, the hope is to reduce the time workers spend on tedious tasks, and give them more time to spend with
patients.

It wouldn't be Mercy's first time adopting this type of technology. Kelly said that for about a year now, Mercy has a
machine learning model that predicts roughly when a patient might be discharged, in hopes of preventing people
from spending more time in the hospital than they need to.

In the past, when a doctor determined a patient was ready for discharge, a staff member would then begin calling
around, looking for available space at a skilled nursing facility, rehabilitation hospital, or wherever the patient may
go next. It may take an extra day or two to find an available slot, which means the patient stayed longer in the
hospital than they wanted to, and the hospital would have one less available bed for new admissions.

Doctors always have the ability to overrule the technology, Kelly said, adding, "We don't want to have (AI) models
performing patient care." But in some cases, the prediction model meant that staff could start calling facilities and
say, "''Hey, four-and-a-half days from now, I will have a patient in need of a slot,'" Kelly said.

People working in this field are having conversations with regulators about appropriate safeguards, said Peter Lee,
corporate vice president of research and incubations at Microsoft. They are also discussing how to mitigate
potential biases that can be introduced by AI.

Kelly said the health system is taking a measured pace, despite the inclination to adopt AI tools soon.

"Health care has a massive staffing shortage, so there's a big desire to move quickly," he said. "But it's
counterbalanced by the desire to do this the right way and protect patient safety and privacy."

Lee said he sees potential to use AI to cut back on the time health care workers normally spend on paperwork -
from clinical notes, to notes referring patients to specialists, and notes justifying that lab tests or prescriptions
should be covered by insurance. It could also be used to inform doctors when there is a clinical trial that a patient
could participate in.

He also thinks the technology can be used as a backstop, to check for errors.

"I'm a big believer in using AI as a second set of eyes," Lee said. "Just make sure that any errors, any biases are
spotted, and that people are given a chance to rethink a decision or a calculation."

"Generative AI turns out to be incredibly good at reviewing, and evaluating, and critiquing, and spotting errors," Lee
said.

One company that provides electronic medical record software, Epic, has an AI-based tool with Microsoft that helps
doctors respond to patient emails more quickly. Lee said he's found that some patients sometimes like the AI-
assisted letters more, because they can add empathetic flourishes that doctors may not have time to.

                                                                                                       Page 3 of 3
              Mercy looks to AI to relieve burden on health care workers, answer patients' questions



Graphic


 The entrance to Mercy Hospital on Ballas Road in Creve Coeur is seen on Thursday, July 7, 2022. Forbes has
reported that Generative AI could soon become a key weapon in the fight against cancer. An Oxford-based biotech
firm has created an immunotherapy drug with the help of generative AI. Veuer's Chloe Hurst has the story!


Load-Date: October 1, 2023


  End of Document

                                                                                                              Page 1 of 3
                                     HIGHMARK HEALTH DIPPING A TOE IN AI POOL




                         HIGHMARK HEALTH DIPPING A TOE IN AI POOL
                                                 Pittsburgh Post-Gazette
                                              October 11, 2023 Wednesday
                                                   SOONER EDITION



Copyright 2023 P.G. Publishing Co.

Section: ASECTION; Pg. A-1
Length: 986 words
Byline: Kris B. Mamula Pittsburgh Post-Gazette

Body


Visit your Allegheny Health Network doctor to talk over your medical problems and soon a machine may be
listening in, adding its own advice to what the physician tells you about staying healthy - stuff that may have been
missed in the conversation.

The "machine" is new software Highmark Health has been road testing - released for commercial use Monday by
Alphabet subsidiary Google - that carries the promise of dramatically improving health care and streamlining
Highmark's insurance operations. Google's Vertex AI Search is being introduced in virtually every aspect of
Highmark's business, Highmark Health's Chief Analytics Officer Richard Clarke said Tuesday.

"We are frankly deploying it across our enterprise," he said.

Ambient listening in doctors' offices may be a couple years off at Highmark Health's 14-hospital system of 2,600
physicians, but for now, Highmark is exploring whether the software's contributions to the doctor-patient
conversation will be in real time - like a third person sitting in the room - or sent to the patient after the visit by text,
email or patient portal message.

"We really see this as a multi-modality," Mr. Clarke said. "The current focus is really on actual medical
documentation," a physician chore that eats up hours a day and leads to caregiver burnout.

It's also expensive: Administrative costs rose $18 billion or 30% to $60 billion in 2022, according to the Council for
Affordable Healthcare, a Washington D.C.-based nonprofit.

Vertex AI Search is a generative artificial intelligence search platform that's tailored to health care and the life
sciences. It can also be tailored specifically to Highmark's purposes, Mr. Clarke said.

"We're teaching it how to speak Highmark," he said. "It's going to have a vey meaningful impact in the clinical
setting."

Google announced Monday that Highmark Health, the corporate parent of the Downtown-based $26 billion health
insurance and hospital system, had been among the U.S. health systems piloting Vertex AI Search. What

                                                                                                         Page 2 of 3
                                 HIGHMARK HEALTH DIPPING A TOE IN AI POOL

differentiates the search engine is its heft in quickly answering questions from vast stores of internal information,
including doctor's notes, medical records and scans.

Mr. Clarke said the new software would be rolled out gradually systemwide, which patients and health plan
members might begin to notice in doctor visits and other interactions with the company in 2024 or 2025.

A small pilot involving automated medical documentation after the patient visit was underway using Vertex AI
Search, Mr. Clarke said.

Before Vertex AI Search, there was ChatGPT, a widely hailed artificial intelligence chatbot introduced in 2022 by
San Francisco-based OpenAI that can answer complex questions, and write poetry and answer user queries by
searching the entire web. ChatGPT ignited an industry rush to find commercial uses for the technology, with
medicine leading the way.

The technology harnesses immense power, providing transformative potential to change medicine.

"A single AI program can write as much text as all of humanity," former Google Health employee and serial
entrepreneur Mustafa Suleyman wrote in "The Coming Wave: Technology, Power and the 21st Century's Greatest
Dilemma," a book published in September.

Google's new search platform is designed to make medical information immediately available that otherwise would
be slow or nearly impossible to retrieve. The technology promises to reduce administrative burden and improve
physician efficiency, which Mr. Clarke said was a focus at Highmark.

Vertex AI Search uses an easy to use, conversational search format with machine learning that frames answers to
the individual user, with the software "learning" from each question. The tool will be specifically tailored to Highmark
needs.

At Highmark, Vertex AI Search was first tested in its strategy to transform health care, which it calls Living Health,
but Mr. Clarke said Tuesday that virtually every aspect of the organization will eventually benefit from the software,
including such far-flung departments as marketing.

"Artificial intelligence, including generative AI, plays a key role in how we are enabling Living Health and we are
interested in how Vertex AI Search could help us simplify the experience and make it more personal, accessible
and helpful for providers and patients," Mr. Clarke said in a prepared statement Monday.

Highmark Health has been a Google Cloud partner since 2020 when the nonprofit introduced Living Health. In
January, Highmark began rolling out the My Highmark app, which provides patients with access to information
about bills, insurance deductibles and health savings account balances along with medical history and treatment
information, which is the kind of streamlined access to patient information Living Health envisions.

Generative AI search tools have been tested elsewhere in drug discovery, breast cancer detection, surgery and
other areas, sometimes with notable results.

Among the more intriguing uses for generative AI has been in retinal scans, which have revealed not only eye
diseases such as glaucoma, but stroke, Parkinson's disease and heart attack. AI-assisted studies of chest X-rays,
the most commonly obtained medical image in the world, have detected Type 2 diabetes, measured heart function
and identified valve disease.

Rochester, Minn.-based Mayo Clinic, another health system trying out the Vertex AI Search engine, has been
using it to answer questions from large volumes of internally generated medical research, according to Dedaimia
Kozlovsky, a solution architect at Mayo Clinic.

Back at Highmark, Mr. Clarke said the new software would transform operations.

                                                                                                      Page 3 of 3
                                HIGHMARK HEALTH DIPPING A TOE IN AI POOL

"These are things that are going to continuously rolled out," he said. "We're just going to keep adding - every
quarter, every six months - we're going to just keep adding. Our focus is on creating remarkable experiences for our
patients."

Kris B. Mamula kmamula@post-gazette.com



Graphic


PHOTO: Pittsburgh Post-Gazette: Highmark Health has been road testing a new Google search platform - now
released for general use - that carries the promise of transforming health care.


Load-Date: October 11, 2023


  End of Document

                                                                                                           Page 1 of 2
                  Arunachal Minister Alo Libang launches AI-driven technology intervention at institutes




Arunachal Minister Alo Libang launches AI-driven technology intervention at
                                 institutes
                                                              The Sentinel
                                                         June 23, 2023 Friday



Copyright 2023 Omega Printers & Publishers Pvt Ltd, distributed by Contify.com All Rights Reserved

Length: 522 words
Byline: Our Correspondent

Body


ITANAGAR: In a revolutionary initiative that will transform the health and agriculture sectors of the state and
facilitate immersive learning in health care education through 5G AI-driven technology intervention, Arunachal
Pradesh Health and Family Welfare Minister Alo Libang launched the project '5G Applications in the Northeast
Region at various institutes in Pasighat in East Siang district on Thursday. The NEC-funded project, with a hub at
the Guwahati-based Assam Electronics Development Corporation Ltd. (AMTRON), was launched at the
Government Nursing College, Bakin Pertin General Hospital (BPGH), and College of Agriculture under the Smart
City mission. The minister was accompanied by NEC Secretary K Moses Chalai, MLAs Ninong Ering and Kaling
Moyong, state industries secretary Hage Tari, East Siang DC Tayi Taggu, joint director of health services (BPGH)
Dr T Tali, PMC Chief Councillor Okiam Moyong Borang, among others.

Terming the initiative as the first of its kind, Libang said that the NEC-funded initiative would immensely help in
facilitating remote patient monitoring and consultation, telemedicine, and screening through mobile AI App-based
solutions and devices, through which patients could access speedy, affordable, specialized and best of breed
healthcare services in an easy and seamless manner, even in rural areas, through 5G AI solutions. "The project will
be replicated in all districts, including community health centres (CHCs) and primary health centres (PHCs), with a
special focus on rural areas," the health minister added. While visiting the nursing college, which is the first to be
equipped with a virtual reality-powered immersive human anatomy learning model under the project, Libang
interacted and took the feedback of the students on their enhanced learning experiences through the AR and VR
applications.

The minister also visited the BPGH, where the project is being implemented, for exposure to the practical
deployment of 5G health AI solutions in the OPD of the hospital and their benefits to patients and healthcare
professionals. At the College of Agriculture, the Minister visited the 5G lab and was apprised by the Dean, Dr. A K
Tripathi, of the 5G use case applications of IoT and Technology in the agriculture sector and its benefits to the
farmers in smart farming ranging from irrigation, livestock monitoring, precision farming, agricultural drones, etc.
The NEC secretary said that the council is committed to adopting future technologies to have a positive impact in
various development sectors for the speedy socio-economic development of the northeastern states.

The project, funded by NEC under the union DoNER ministry, is jointly executed by AMTRON, the Design
Innovation Centre of Punjab University, the School of Planning and Architecture under the union telecom

                                                                                                       Page 2 of 2
              Arunachal Minister Alo Libang launches AI-driven technology intervention at institutes

department, and the Telecom Skill Sector Council. The focus will be on medical and health care applications as
computing speeds up the internet through artificial intelligence (AI) enabling technologies ensuring reliability,
affordability, and speed being implemented in the eight northeastern states.


Load-Date: June 23, 2023


  End of Document

                                                                                                           Page 1 of 2
                                    U Receives $100 Million for Responsible AI Initiative




                     U Receives $100 Million for Responsible AI Initiative
                                         The Daily Utah Chronicle: University of Utah
                                                November 22, 2023 Wednesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 580 words
Byline: Jamie Faux

Body


The University of Utah recently received a $100 million investment for a new initiative on responsible artificial
intelligence. Led by the Scientific Computing and Imaging Institute, this initiative will focus on improving aspects of
civil rights, privacy and civil liberties. It will also be used to address important challenges in the community including
sustainability, health, society, teaching and learning.

What is responsible AI?

Manish Parashar, director of the SCI Institute, said responsible AI is the simultaneous recognition of both the
importance of AI in tackling societal and environmental challenges as well as understanding and getting rid of the
issues this technology poses.

"However, AI has many important challenges around areas of bias, fairness, ethics and responsibility," Parashar
said. "We started thinking about how we can leverage this technology in a responsible way that considers these
aspects while simultaneously addressing important challenges to our region."

For example, Parashar brought up the possibility of using AI to tackle mental health crises. He said AI can gather
and analyze data to vastly improve an individual's mental health, but that this project will inevitably raise issues of
bias and privacy. The purpose of the Responsible AI Initiative is to solve these problems.

"Think of the issues of mental health ... There are many dimensions to the issue, including lifestyle and behavior,
and previous life incidences," Parashar said. "AI allows us to take our understanding of these different modalities
and use them collectively to address the problem. But you also want to make sure it's doing it in a fair way so that it
respects privacy and is not biased."

Why is the Responsible AI Initiative important?

"AI is a rapidly growing industry that will soon be involved in every aspect of our lives," said James Anderson,
researcher at the U's musculoskeletal research laboratory. "Even though I'm in biomedical engineering, AI is
already becoming a big part of my department."

                                                                                                          Page 2 of 2
                                 U Receives $100 Million for Responsible AI Initiative

Whether it's at work or home, for an individual or for a community, AI has the "potential to transform lives," Parashar
said.

As an example, he brought up the issue of environmental sustainability surrounding wildfires in Utah. He said AI
has the potential to mitigate fire damage by combining data from the past and present to create the best plan of
action.

"You can use a combination of architectural aspects when fire intensifies, smoke behavior and local temperature,
combine these together and find which area the fire will impact the most and how to address it," he said. "The
potential with responsible AI is to minimize impact, create the right early warning systems, and know what
resources will be impacted the most quickly so we can tackle the problem early on and efficiently."

Who will be involved?

Parashar said the initiative is a huge project that will involve experts in multiple fields of work. These experts will
work together with students and the community to create efficient and responsible AI to address important
challenges.

"We will bring in the best experts as visitors, faculty and researchers," Parashar said. "They will create structures for
the students in different academic units and work as a team to address a problem."

Parashar said the initiative is geared towards the population as a whole, and he wants everyone to have the
opportunity to contribute.

For students wanting to be involved in the research, Parashar said "stay tuned".


Load-Date: November 22, 2023


  End of Document

                                                                                                   Page 1 of 2
      Free-market health care innovations should be used to make lives better, not expand government power




Free-market health care innovations should be used to make lives better, not
                         expand government power
                                                    Washington Policy Center
                                                 September 28, 2023 Thursday



Copyright 2023 Content Engine, LLC.
All Rights Reserved
Copyright 2023 Washington Policy, USA All Rights Reserved

Length: 661 words
Byline: Elizabeth Hovde

Body


From improving diagnosis accuracy and alleviating burdens on health care providers to helping along the creation
of new, lifesaving drugs and expanding patient access to care, the integration of artificial intelligence has the
potential to transform health care.

The Biden Administration and Congress, however, are considering regulations that could stifle AI innovation in
health care. We need lawmakers to carefully weigh the trade-offs between regulation and medical advancement.

The following principles for any government regulatory action concerning AI in health care are urged by a group of
federal and state policy experts, including Washington Policy Center. (See the full letter and organizations on
board here.)

1. No new regulatory agency: We advocate against creating a dedicated AI regulatory agency in healthcare.
Instead, existing regulatory bodies should adapt their current authorities, such as the FDA's approval and
certification of AI-driven medical products, to accommodate AI innovations. Congress should ensure that these
agencies avoid regulatory overreach and, instead, focus on developing modern and agile regulatory approaches.

2. Safeguarding American sovereignty and intellectual capital: While international collaboration can be
beneficial, maintaining regulatory independence is vital to protect national sovereignty. Robust intellectual property
(IP) frameworks for AI should spur research and investments in healthcare advancements and bolster investment
while safeguarding American intellectual capital.

3. Cost-saving and resource efficiency: Government-deployed AI systems in healthcare agencies and programs
should prioritize cost reduction, operational efficiency, and the elimination of duplicative activities. Targeting waste,
fraud, and abuse in taxpayer-funded healthcare delivery and administration can yield significant resource savings.

4. Prohibition of government authority to dictate results or limit ideas and scientific debate: Governments
should not have the authority to dictate AI-generated outcomes in healthcare. To combat bias, comprehensive
datasets are vastly preferable to governmental intervention in algorithmic decision-making. AI should not be used to
stifle intellectual freedom, hinder scientific discourse, or suppress dissenting opinions. The ultimate authority for

                                                                                                  Page 2 of 2
     Free-market health care innovations should be used to make lives better, not expand government power

medical decisions should remain in the domain of the practice of medicine, upholding the principle of medical
autonomy.

5. Regulatory clarity and simplicity for fostering innovation: Modern and agile AI regulations in healthcare
should prioritize clarity and simplicity. They should support innovation and AI technology development while
providing for patient safety, privacy, and ethical standards. These regulations should resist the influence of large
market incumbents and avoid creating artificial barriers to entry.

6. Embrace innovation in healthcare: The integration of AI in healthcare has the potential to create a dynamic
and patient-centered experience. It harnesses AI technologies to expand healthcare access, enhance outcomes,
improve the patient experience, reduce costs, alleviate the burdens on our healthcare providers, and drive
advancements in medicine. To achieve these goals, lawmakers and policymakers should meticulously assess the
boundaries of regulatory action, weigh the trade-offs between regulation and medical advancement, and consider
the consequences of stifling innovation, which would further limit healthcare access.

Congressional and state policymakers need to find constructive solutions to concerns over new technologies in
health care. If regulation is deemed necessary, it should be limited in scope, protecting patient safety and privacy
while promoting competition and medical innovation that can make people's lives better. Patient-centered health
care needs to be front and center.
  Sign up for the WPC Newsletter      Please enter full name      Please enter e-mail address




Load-Date: September 29, 2023


  End of Document

                                                                                                      Page 1 of 2
           Duke Health to partner with Microsoft on development and use of generative AI, cloud technology




Duke Health to partner with Microsoft on development and use of generative
                            AI, cloud technology
                                             The Duke Chronicle: Duke University
                                                      August 1, 2023 Tuesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 479 words

Body


A new five-year partnership between Duke Health and Microsoft will work to "redefine the health care landscape"
through collaborative work on generative artificial intelligence and cloud technology, according to a Tuesday
announcement.

Microsoft will help establish a Duke AI Innovation Lab to explore new AI technologies and solutions and a Center of
Excellence, which will work to refine and scale the AI applications "across diverse clinical and research domains."

"Duke Health's commitment to delivering the next generation of medicine is unwavering," said Craig Albanese,
chief executive officer of Duke Health. "Through this collaboration, we aim to bring the future of health care into the
present, crafting a new normal that is not merely innovative but transformative."

Generative AI technology is AI that can create new content and not simply operate using pre-existing data. The
most well-known example is ChatGPT, the AI chatbot that has recently exploded in popularity. Microsoft has been
rapidly expanding its presence in the AI sector, having announced an additional $10 billion investment in ChatGPT
owner OpenAI earlier this year.

The partnership will focus on four critical areas: modernized infrastructure, innovation, transformation and emerging
technology. Duke Health plans to utilize Microsoft's Azure Cloud and Cloud for Healthcare, while also taking
advantage of other digital tools and "early access to new technologies" provided by Microsoft.

According to an email from Duke Health leadership obtained by The Chronicle, the partnership will aim to
"empower evolution toward a data-centric, digital-first academic healthcare system."

The email further reads that generative AI technology will be used "to redefine the healthcare experiences for
providers and patients alike." Microsoft's support in upgrading Duke Health's cloud infrastructure would also "assist
in diagnosis and treatment decisions through advanced data analysis, create personalized patient education, and
reduce administrative tasks via automation."

Microsoft will also provide Duke with training to "foster a cloud-savvy IT workforce and construct a secure cloud
environment to simplify and modernize IT operations."

                                                                                                    Page 2 of 2
         Duke Health to partner with Microsoft on development and use of generative AI, cloud technology

"Microsoft is excited to collaborate with Duke Health to operationalize responsible AI principles, helping to ensure
that AI is deployed safely, effectively, and in an unbiased and transparent manner," said David Rhew, global chief
medical officer and vice president of healthcare at Microsoft. "Together we will apply the latest Microsoft
technologies to expedite and scale Duke Health's nationally recognized model of AI governance. By sharing best
practices and lessons learned, we hope other organizations will benefit from our experience."

Further details about the partnership are still in progress and will be communicated once finalized, according to the
email.


Load-Date: August 1, 2023


  End of Document

                                                                                                      Page 1 of 2
                                           Retirement health costs a concern for many




                              Retirement health costs a concern for many
                                               The Daily Reporter (Columbus, Ohio)
                                                    October 26, 2023 Thursday



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 The Daily Reporter

Section: NEWS
Length: 539 words
Byline: KEITH ARNOLD The Daily Reporter, THE DAILY REPORTER

Body


Persistent inflation and rising health-care costs have left the majority of respondents of a recent Harris Poll with
diminishing confidence in their ability to afford health expenses and maintain physical and financial wellbeing in
retirement.

Columbus-based Nationwide commissioned the poll for its annual Health Care Cost in Retirement survey, which is
utilized by the company's financial services arm.

The survey detailed that during the past year, 18 percent of respondents have postponed health-care actions such
as a medical procedure, physical exam or renewing prescriptions as a means to save money, while 10 percent also
reported considering a downgrade in their health insurance plan to counter higher costs resulting from inflation.

A news release noted the generational breakdown of individuals who were considering such a reduction 19 percent
and 14 percent of Gen Z and Gen X respondents, respectively, and 11 percent of millennials.

Three-fifths of the survey's respondents said they have chosen or would choose a health insurance policy with a
lower premium but higher deductible for a cheaper monthly payment.

Company officials said in the release that the economic uncertainty has resulted in consumers having to make
tough decisions with likely long-term implications.

"While Americans are trading more comprehensive health coverage for lower monthly premiums, many do not
have the means to cover an emergency health-care expense," the release provided, noting that 51 percent of
respondents said they could not pay off an unexpected $5,000 health-care expense.

Nationwide Retirement Institute Senior Vice President Kristi Rodriguez said financial services providers are able to
work with consumers to develop a financial plan to meet health-care costs without compromising their overall
financial wellbeing.

                                                                                                        Page 2 of 2
                                    Retirement health costs a concern for many

The survey found that two-thirds of adults are terrified of the impact health-care costs may have on their retirement
plans, with 72 percent of respondents reporting that a top fear is health-care costs rising to an out-of-control level
during their retirement.

Sixty-nine percent of Americans with chronic conditions reported that they do not have a written financial plan that
includes how to pay for the health-care costs related to their health condition in retirement, the survey provided.

The survey also considered the impact that artificial intelligence, or AI, may have on health-care cost planning in
retirement.

"Advances in AI and health-care technology in general are moving faster than ever and may help treat many of
today's chronic diseases, as well as other health issues," Rodriguez said. "While this is good news, longevity
requires more planning."

One in four of respondents said they expect AI advancements in health care to add more than a decade to their
lifespan, with Gen Xers expecting an additional eight years and baby boomers another nine years.

The online survey was conducted Aug. 28 through Sept. 11 among 1,260 adults age 18 years and older who reside
in the United States, including 301 Gen Z participants, 310 millennials, 307 Gen Xers and 342 boomers.

The sample data is accurate to within + 3.7 percentage points using a 95 percent confidence level, the release
detailed.


Load-Date: October 26, 2023


  End of Document

                                                                                                    Page 1 of 2
                            'Improve health for all': Dr. Ziad Obermeyer named to TIME100 AI




           'Improve health for all': Dr. Ziad Obermeyer named to TIME100 AI
                                     Daily Californian: University of California - Berkeley
                                                 September 12, 2023 Tuesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 622 words
Byline: Kelsey McIvor

Body


UC Berkeley associate professor of health policy and management Dr. Ziad Obermeyer was named to the 2023
TIME100 AI list, the media company's annual award for top professionals in the artificial intelligence sector.

Obermeyer's extensive research primarily focuses on the intersection of machine learning and health, such as
aiding doctors' decision-making process and extensive data analysis. TIME's announcement Sept. 7, however,
highlighted Obermeyer's work in the dissemination of racial bias in widely-used algorithms.

In a recent study, Obermeyer found that due to Black patients' unequal access to healthcare, there is a cost
disparity between Black and white patients with similar needs - a disparity that algorithms accurately detect and
"thus deprioritize Black patients relative to their needs," he noted.

To address these exacerbated racial biases and pave the way toward access to more equitable care, Obermeyer
aimed to fix this biased proxy mechanism known as "label choice bias."

"Retraining algorithms to predict less biased proxies can turn algorithms into a force for good, redistributing
resources to those who need them and reducing disparities rather than perpetuating them," Obermeyer said in an
email.

This is one of the many technological advances Obermeyer has contributed to as a renowned research fellow and
emergency doctor. He believes the greatest problem facing health research is the insurance of safe, ethical access
to data - so he founded two organizations addressing this need.

Nightingale Open Science, a nonprofit that connects researchers with medical datasets, and Dandelion, an AI
innovation platform for health, both work toward making public health data available for researchers and patients
while also maintaining patient privacy.

Dr. Michael Lu, dean of UC Berkeley's School of Public Health, fervently praised Obermeyer's contributions to
addressing accessibility and equity issues within the public health sector.

                                                                                                         Page 2 of 2
                         'Improve health for all': Dr. Ziad Obermeyer named to TIME100 AI

"What sets Professor Obermeyer's work apart from the rest is its focus on advancing the social good - how do we
leverage AI and new technologies to improve healthcare and not deepen systemic bias, advance health equity and
not widen health disparities, improve health for all and not benefit only the wealthy few," Lu said in an email.

Kimberly MacPherson, co-director of Berkeley Center for Health Technology and faculty director of the School of
Public Health, emphasized the importance of recognizing public health professionals within the field of artificial
intelligence.

With only about 4% of American healthcare spending allocated to public health, she believes this award will shed
light on artificial intelligence as a viable solution to issues, such as doctor shortages and clinical burnout.

"There is so much data out there that could support helping make better decisions on things like equitable resource
allocation and spreading best practices," MacPherson said in an email. "We need thoughtful and balanced
approaches to the use of AI in public health and (Obermeyer's) lens as a practicing physician and data scientist in
public health."

Aware of the potential ramifications of AI-driven solutions, Obermeyer is still "cautiously optimistic" about its effect
on public health.

Through continued work in reducing bias and equity issues, he believes artificial intelligence could be key to
healthcare advancements and treatment decision making.

"By working to solve real health problems, we can learn a lot about how AI works in general; what it's great at,
where it goes wrong, and how to do better," Obermeyer said in the email. "Looking at (TIME's 2023 AI awards) list,
there are so many people building for a future where AI helps everyone, and that's really exciting."


Load-Date: September 13, 2023


  End of Document

                                                                                                   Page 1 of 2
                                                  AI helps detect heart disorder




                                         AI helps detect heart disorder
                                           The Columbian (Vancouver, Washington)
                                                    August 22, 2023 Tuesday



Copyright 2023 The Columbian Publishing Co. All Rights Reserved

Section: HEALTH; Pg. B3
Length: 599 words
Byline: Ed Stannard Hartford Courant
Highlight: It can find structural problem that's hard to diagnose

For people who have a serious structural problem in their heart but no symptoms, there has not been a practical
way to detect the disorder.

A researcher at the Yale School of Medicine, however, has developed a way to find the seemingly invisible problem
using artificial intelligence.

Body

It can find structural problem that's hard to diagnose
For people who have a serious structural problem in their heart but no symptoms, there has not been a
practical way to detect the disorder.
A researcher at the Yale School of Medicine, however, has developed a way to find the seemingly invisible
problem using artificial intelligence.

Dr. Rohan Khera, clinical director of the medical school's Center for Health Informatics and Analytics,
said a simple electrocardiogram can be analyzed using AI, which can detect what a basic reading of an ECG
cannot.
Khera's paper about his research appeared in the July 25 issue of the journal Circulation. The work is
centered in the Cardiovascular Data Science Lab, where Khera is the principal investigator.

"Many people, up to one in 20, have structural heart disorder, so their heart function is down, but they
don't know that until they develop symptoms and go to the hospital       or (suffer) adverse effects of a
certain sort that trigger health care needs," Khera said.
The disorder is known as left ventricular systolic dysfunction, which reduces the ability of the heart to
pump blood. It develops before symptoms appear and medical attention is required, Khera said. The problem
can lead to more than an eightfold increase in heart failure and double the risk of premature death,
according to Khera's study.
There are "very inexpensive treatments" for the dysfunction, he said.
"However, we just don't have a way to know who had this. The way to diagnose it is actually getting
cardiac imaging, which is an ultrasound of the heart, or an MRI," he said. "But those tests are not
something you can do with everyone in the community, so this is not feasible."

Using AI and deep learning, "which are very exciting domains in medicine, we developed a technology that
actually uses ECG data," Khera said.

                                                                                            Page 2 of 2
                                       AI helps detect heart disorder

ECGs, which register electrical activity in the heart, are routinely done during physical exams. They can
now be taken on a wearable device such as an Apple Watch, Khera said. About 100 million ECGs are done in
the United States each year, he said.
"We have now identified ways to find signatures of structural heart disorders from these very inexpensive
and widely available tests," Khera said. "And that's the key observation and we are able to do that with
accuracy in the 90 to 95 percent range."
The Yale study has been repeated in California, Missouri and Texas, and validated in a Brazilian
longitudinal study. "So (we've) kind of shown that our approach to identifying those with disease really
works across the board," he said.
"Before, when we were doing echocardiograms, when we were only relying on cardiac imaging, there was not
infrastructure in place to do that at scale for the population," Khera said. "But now with these
technologies, you can actually get people without any expense or challenge       a diagnosis that is very
treatable."
ECGs, which measure a number of different electrical signals in the heart, are printed out on paper. "We
can use the photos of those ECGs and we use computer vision algorithms," Khera said.
"These are tools built to infer deep signatures of disease from photos. So we take photos of ECGs and
identify areas within an ECG that may actually be suggestive of a diagnosis of low heart function.   It's
a hidden feature inside that photo of an ECG that none of us as clinicians can pick up on."

While the ECG is used to measure the electrical signals, AI can pick up structural abnormalities in the
heart by examining the photo. The following fields overflowed: REFERENCE = 08-22 B3 HEALTH-AI-HEART-
PROBLEMSHC_B03



Load-Date: September 21, 2023


  End of Document

                                                                                                          Page 1 of 2
                               Man Hung AI is saving lives and improving health care systems




            Man Hung AI is saving lives and improving health care systems
                                                       The Salt Lake Tribune
                                                       August 25, 2023 Friday



Copyright 2023 The Salt Lake Tribune All Rights Reserved

Length: 761 words
Byline: Man Hung | For The Salt Lake Tribune

Body

Artificial intelligence (AI) has gained significant attention worldwide due to its potential to revolutionize healthcare.
During the past decade, AI has already been applied rapidly to numerous areas in healthcare, including medical
imaging analysis, health information management, real-time decision support monitoring and disease diagnosis
and treatment.

For example, AI has been integrated in cataract management to serve as a telemedicine platform for screening,
diagnosing and classifying patients with cataracts, and to augment cataract surgical skill training as well as predict
the duration of surgical procedures and disease progression.

AI has also shown promise in
    •     The diagnosis, prognosis and treatment selection for cancer patients,
    •     Clinical decision support and monitoring for musculoskeletal diseases and conditions,
    •     Detection of colorectal cancer liver metastases on computed tomography similar to or better than some
          expert radiologists,
    •     Personalized robotic medical treatment for removing tumors with accuracy and precision anywhere in the
          body without using invasive surgical procedures,
    •     Diagnostic prediction of dental root caries with high accuracy and precision, and
    •     Screening for cardiovascular diseases in asymptomatic individuals to enable early detection and treatment.

These and many other advancements in AI applications are very exciting. Scientific studies have demonstrated the
efficient use of AI algorithms in analyzing electrocardiograms for the detection of cardiovascular diseases, and
these algorithms have shown improved performance in identifying patterns and predicting events, leading to more
accurate diagnoses and treatment decisions.

Additionally, AI has been utilized in precision oncology to analyze genomic sequencing data and medical imaging,
and its algorithms can identify biomarkers, predict disease risk and aid in the development of targeted therapies.

It can also be used to address issues facing medical education, such as judicious information and knowledge
management, and improve customer relationship management capability in healthcare by enhancing service
innovation and providing access to data and health information.

                                                                                                     Page 2 of 2
                          Man Hung AI is saving lives and improving health care systems

AI can also design clinical trials for medical device and drug development and beyond.

These many applications of AI in improving efficiency and accuracy in diagnosis and management of diseases are
fascinating and are poised to have a transformative impact on healthcare. They underscore the potential for AI to
improve healthcare and services; enhance treatment outcomes and quality of life; and provide better experiences
for medical professionals and patients.

Nonetheless, there are implementation barriers. Concerns over security and privacy, regulatory approval, poor
generalizability of AI models, trust and explainability issues, unfavorable end-user perceptions and uncertain
economic value contribute to the challenges in translating AI algorithms into clinical settings.

Additional challenges, such as the need for standardized protocols and regulations; adequate financial resources
and investment; and efficient algorithms and models should be addressed for a successful transition to the real-
world implementation of AI.

Furthermore, even though many medical workers had a relatively high acceptance level towards implementation of
AI in healthcare, there are concerns regarding medical ethics in AI and concerns over AI partly replacing doctors.
These are legitimate concerns and they highlight the challenges and need for further examination and discussion
on the ethical, social and economic implications of AI in healthcare. By overcoming these challenges, AI has the
potential to greatly benefit health care providers, healthcare systems and patients alike.

Overall, the application of AI in healthcare shows great promise for improving disease detection and diagnosis, as
well as enhancing the efficiency and effectiveness of healthcare systems. It is expected to continue to be of great
interest around the globe in the coming years. However, it also presents challenges that must be addressed.

Future direction should focus on developing robust and reliable AI models, addressing barriers and challenges and
ensuring the ethical and responsible use of AI in healthcare.Man Hung

Dr. Man Hung is the senior associate dean for research and graduate education at Roseman University of Health
Sciences College of Dental Medicine, and adjunct faculty at the University of Utah School of Medicine. She
specializes in artificial intelligence, global business management and leadership.


Load-Date: August 27, 2023


  End of Document

                                                                                                         Page 1 of 2
                           Mount Sinai Launches Dept Of Artificial Intelligence And Human Health




     Mount Sinai Launches Dept Of Artificial Intelligence And Human Health
                                                    The Queens Gazette (New York)
                                                          October 13, 2021



Copyright 2021 The Service Advertising Group Inc.
Distributed by Newsbank, Inc. All Rights Reserved

Section: FEATURES
Length: 726 words

Body


The Icahn School of Medicine at Mount Sinai has launched a new department dedicated to advancing artificial
intelligence (AI) to transform health care, further positioning the Mount Sinai Health System as a leader in
providing patient care through pioneering innovations and technologies. The Department of Artificial Intelligence
and Human Health is the first department of its kind within a medical school in the United States.

The department's mission is to lead the artificial intelligence-driven transformation of health care through innovative
research, apply that knowledge to treatment in hospital and clinical settings, and provide personalized care for each
patient, which will expand Mount Sinai's impact on human health across the Health System and around the world.

 "Mount Sinai's AI enterprise and its collective entities will be the connective fabric linking and integrating our work
throughout the entire Health System, as we robustly collaborate with all our institutes, departments, and centers to
provide phenomenal patient care," said Thomas J. Fuchs, Dr.sc, Dean for Artificial Intelligence and Human Health,
Co-Director of the Hasso Plattner Institute for Digital Health at Mount Sinai, and Professor of Computational
Pathology and Computer Science in the Department of Pathology at Icahn Mount Sinai. "The overarching goal of
the Department for AI and Human Health is to impact patients' health with AI. We will accomplish this by building
AI systems at scale from data representing Mount Sinai's diverse patient population. These systems will work
seamlessly across all hospitals and care units to support physicians, foster research, and most importantly help
patients' care and well-being."

 Dr. Fuchs, who will lead the Department, is a prominent scientist in the groundbreaking field of computational
pathology, with decades of experience in machine learning and artificial intelligence in health care. Together with
his team, he will guide the department in creating an "AI Fabric" that will integrate machine learning and AI-driven
decision-making throughout the Health System's eight hospitals. This effort will include creating a hub-and-satellite
model to make new tools and techniques available to all Mount Sinai physicians, and building an infrastructure for
high-performance computing and data access to improve Mount Sinai's diagnostic and treatment capabilities.

 "Mount Sinai has been on the forefront of the artificial intelligence revolution," said Dennis S. Charney, MD, Anne
and Joel Ehrenkranz Dean of Icahn Mount Sinai and President for Academic Affairs of the Mount Sinai Health
System. "We've made bold steps in recruiting the brightest minds, invested in leading-edge technology, and created
an infrastructure where discoveries are quickly translated to benefit patients and change practice. This Department

                                                                                                       Page 2 of 2
                      Mount Sinai Launches Dept Of Artificial Intelligence And Human Health

cements our commitment to further developing this field, charting new avenues, and making this bold future a
reality."

 As part of Mount Sinai's ongoing commitment to expand AI, the department will be located on four floors in a
completely redesigned and renovated space at 3 East 101st Street that includes areas for computational work and
advanced imaging modalities such as virtual and augmented reality. The Department of AI and Human Health is
also launching a campaign to recruit talented researchers, scientists, physicians, and students in the field.

 The new department continues to build on Mount Sinai's expertise and early adaptation of various forms of artificial
intelligence, including machine learning to develop novel diagnostics and treatments for diseases. Earlier this year,
Icahn Mount Sinai announced it will offer a new PhD concentration in Artificial Intelligence and Emerging
Technologies in Medicine as part of its PhD in Biomedical Sciences program starting in the fall of 2022. The
concentration will train future scientists in cutting-edge technologies, including AI, medical devices, robotic
machines, and sensors. The Hasso Plattner Institute for Digital Health at Mount Sinai—a collaboration between the
Hasso Plattner Institute for Digital Engineering in Potsdam, Germany, and the Mount Sinai Health System—formed
in 2019 to expand capabilities and create new tools of data science, biomedical and digital engineering, machine
learning, and AI, including wearable technology.


Load-Date: October 30, 2021


  End of Document

                                                                                                        Page 1 of 2
                  Revolutionizing medicine: Aimon Rahman on enhancing health care with deep learning




   Revolutionizing medicine: Aimon Rahman on enhancing health care with
                               deep learning
                                The Johns Hopkins News-Letter: Johns Hopkins University
                                                      November 10, 2023 Friday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: SCIENCE-TECHNOLOGY; Pg. 1
Length: 756 words
Byline: ANNIE HUANG

Body


Aimon Rahman, a third-year doctoral student in the Vision & Image Understanding Lab in the Electrical and
Computer Engineering Department, is making significant contributions to the field of medical artificial intelligence .
In her Hopkins Engineering Applications and Research Tutorials course titled "Introduction to Deep Learning for
Medical Imaging," Rahman introduces students to the practical applications of computer vision in medical image
analysis.

In an interview with The News-Letter, Rahman shared insights on her recent publications, as well as opinions
regarding the opportunities and challenges associated with medical AI.

Deep learning is a method of creating AI relying on neural networks, with many independent modeling layers. Their
ability to handle large and intricate datasets makes them well-suited for tasks like medical imaging analysis.

Rahman's work centers on training deep learning models to detect anomalies such as tumors and lesions across
various modalities, including ultrasound, CT and MRI scans.

One of Rahman's recent publications trains diffusion models to replicate the ''collective insights'' of doctors. Her
paper, titled "Ambiguous medical image segmentation using diffusion models," includes an algorithm that can
detect tumors given a set of images.

What sets Rahman's work apart is her approach of countering the deterministic nature of AI by using a probabilistic
model to mirror the diagnostic results of multiple doctors as collective insights.

"Let's say you have a segmentation model that analyzes medical images and segments out tumors. Whenever you
have this kind of model, it's always deterministic, meaning you input an image, and it will provide a segmentation
specific to that image. However, in a hospital setting, multiple radiologists may each have their unique diagnosis
and segmentation for the same image," she explained. "This is what I worked on last summer, where I developed a
probabilistic model. When you input an image, the network will produce a variety of segmentation maps, mimicking
the diagnostic results of different doctors."

                                                                                                        Page 2 of 2
               Revolutionizing medicine: Aimon Rahman on enhancing health care with deep learning

Rahman also shed light on the potential applications of her work in health care. She emphasized the timely
importance of AI and the abundance of resources available at Hopkins.

"Right now is a favorable time to delve into AI, and Hopkins offers extensive resources," she said. "My goal is to
leverage computer vision to make a meaningful impact in health care. For instance, incorporating AI into health
care can significantly reduce costs, which can be particularly beneficial for countries with limited resources and in
point-of-care scenarios."

Rahman underscored the technology's relevance in situations like wartime, refugee crises or natural disasters,
where makeshift hospitals may lack health care professionals. Computer vision and deep learning can provide
rapid and accurate diagnosis in such critical circumstances.

Looking toward the future, Rahman hopes that medical AI will make health care better and more affordable for all.

"Medical AI will be integrated in point-of-care architecture so that patients do not have to wait a long time in
hospitals. The overarching aim is to use this technology to cut the health care cost and make standard health care
more affordable in countries with few resources," she said.

However, Rahman acknowledges the challenges she faces, primarily concerning the scarcity of training data and
the generalizability of the models, an issue compounded by the unavailability of private datasets.

"The biggest challenge in the medical domain is the limited dataset availability, as medical data are not publicly
accessible," she said. "Obtaining data involves navigating ethical concerns and obtaining permissions. Moreover,
data collection by medical professionals is time-consuming."

One possible solution to these issues is the use of synthetic data - which itself is created by a neural network.
However, when asked about the possibility of using synthetic datasets for medical training, Rahman expressed
caution.

"To use a synthetic dataset, we need to have a bunch of data to begin with and train the model first, which is hard
due to the aforementioned reasons. Furthermore, relying on healthy patient data to mimic severe cases can
introduce bias into the dataset, as AI can only generate based on what it has seen before,'' she said. "We don't
want to give AI too much creative freedom so that it would create something that is impossible to occur in real life."

Have a tip or story idea?

Let us know!


Load-Date: November 13, 2023


  End of Document

                                                                                                         Page 1 of 2
                               AI Impact On Mammograms, Breast Health & The OBGYN Field




            AI Impact On Mammograms, Breast Health & The OBGYN Field
                                              Glendale Register (Queens, New York)
                                                         February 2, 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Glendale Register (Queens, NY), Queens Ledger/Greenpoint Star Inc.

Section: HEALTH
Length: 611 words
Byline: web

Body


Artificial intelligence (AI) has invaded our daily lives, and in the last decade, there have been very promising
applications of AI in the field of medicine, including medical imaging, in vitro diagnosis, intelligent rehabilitation,
Gynecology and prognosis. Artificial intelligence (AI) is commonly defined as "a system's ability to correctly interpret
external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through
flexible adaptation".

Over the past 50 years, the dramatic growth of computer functions related to big data intrusion has pushed AI
applications into new areas. Breast cancer is one of the common malignant tumors in women and seriously
threatens women's physical and mental health. Early screening for breast cancer via mammography, ultrasound
and magnetic resonance imaging (MRI) can significantly improve the prognosis of patients. AI has shown excellent
performance in image recognition tasks and has been widely studied in breast cancer screening. This paper
introduces the background of AI and its application in breast medical imaging (mammography, ultrasound and
MRI), such as in the identification, segmentation and classification of lesions; breast density assessment; and
breast cancer risk assessment. In addition, we also discuss the challenges and future perspectives of the
application of AI in medical imaging of the breast.

Mammography, a breast exam, is one of the most widely used methods for breast cancer screening.
Mammography is a non-invasive detection method associated with relatively low pain, easy operation, high
resolution, and good repeatability. The retained image can be compared before and after and is not limited by age
or body shape. Mammography can detect breast masses that cannot be palpated by doctors and can reliably
identify benign lesions and malignant tumors of the breast. Mammograms are currently acquired with full-field digital
mammography (DM) systems and are provided in both for-processing (the raw imaging data) and for-presentation.
To date, AI has been used to analyze mammography images in most studies mainly for the detection and
classification of breast mass and microcalcifications, breast mass segmentation, breast density assessment, breast
cancer risk assessment and image quality improvement.

Breast Cancer Risk Assessment

                                                                                                        Page 2 of 2
                          AI Impact On Mammograms, Breast Health & The OBGYN Field

The high incidence and mortality of breast cancer are seriously threatening women's physical and mental health. At
present, there are many known risk factors for breast cancer. These include aging, family history, reproductive
factors (early menarche, late menopause, late age at first pregnancy and low parity), estrogen (endogenous and
exogenous estrogens), lifestyle (excessive alcohol consumption, too much dietary fat intake, smoking) are all risk
factors for breast cancer. The early detection and prevention of breast cancer can be promoted by increasing the
overall understanding and recognition of breast cancer risk.

Relevant literature shows that the research of AI in breast cancer risk prediction is also very extensive. As a result,
AI predicts breast cancer risk with higher accuracy than other methods, which in turn helps physicians guide high-
risk populations to conduct appropriate interventions to reduce the incidence of breast cancer.

------------

Contributed with help from our Glendale Register & Queens Ledger Featured Gynecologist: EMU Breast Surgery,
Exams & Mammograms Center of Queens 8340 Woodhaven Blvd Ste 6, Queens, NY 11385 (929) 299-6124
https://www.emuhealth.com/womens-health/mammography/.

You May Also Be Interested In Reading About: OBGYN Trends Going Into 2023 Post Roe V Wade


Load-Date: February 17, 2023


   End of Document

                                                                                                       Page 1 of 2
                                        Biden signs executive order to guide AI safety




                          Biden signs executive order to guide AI safety
                                                       The Baltimore Sun
                                                  October 31, 2023 Tuesday
                                                           First Edition



Copyright 2023 The Baltimore Sun Company All Rights Reserved

Section: MAIN; A; Pg. 10
Length: 334 words
Byline: Josh Boak and Matt O'Brien Associated Press

Body


WASHINGTON - President Joe Biden on Monday signed a sweeping executive order to guide the development of
artificial intelligence - requiring industry to develop safety and security standards, introducing new consumer
protections and giving federal agencies an extensive to-do list to oversee the rapidly progressing technology.

The order reflects the government's effort to shape how AI evolves in a way that can maximize its possibilities and
contain its perils.

AI has been a source of deep personal interest for Biden, with its potential to affect the economy and national
security.

White House chief of staff Jeff Zients recalled Biden giving his staff a directive to move with urgency on the issue,
having considered the technology a top priority.

In Biden's view, the government was late to address the risks of social media and now U.S. youth are grappling with
related mental health issues. AI has the positive ability to accelerate cancer research, model the impacts of climate
change, boost economic output and improve government services, among other benefits.

But it also could warp basic notions of truth with false images, deepen racial and social inequalities, and provide a
tool to scammers and criminals.

The order builds on voluntary commitments already made by technology companies. It's part of a broader strategy
that administration officials say also includes congressional legislation and international diplomacy.

Using the Defense Production Act, the order will require leading AI developers to share safety test results and other
information with the government. The National Institute of Standards and Technology is to create standards to
ensure AI tools are safe and secure before public release.

The Commerce Department is to issue guidance to label and watermark AI-generated content to help differentiate
between authentic interactions and those generated by software. The order touches on matters of privacy, civil
rights, consumer protections, scientific research and worker rights.

                                                                               Page 2 of 2
                              Biden signs executive order to guide AI safety


Load-Date: October 31, 2023


  End of Document

                                                                                                       Page 1 of 2
                                         Biden signs executive order to guide AI safety




                           Biden signs executive order to guide AI safety
                                                          The Morning Call
                                                     October 31, 2023 Tuesday
                                                            FIRST Edition



Copyright 2023 Capital Gazette Communications, Inc. All Rights Reserved

Section: MAIN; A; Pg. 7
Length: 334 words
Byline: Josh Boak and Matt O'Brien Associated Press

Body


WASHINGTON - President Joe Biden on Monday signed a sweeping executive order to guide the development of
artificial intelligence - requiring industry to develop safety and security standards, introducing new consumer
protections and giving federal agencies an extensive to-do list to oversee the rapidly progressing technology.

The order reflects the government's effort to shape how AI evolves in a way that can maximize its possibilities and
contain its perils.

AI has been a source of deep personal interest for Biden, with its potential to affect the economy and national
security.

White House chief of staff Jeff Zients recalled Biden giving his staff a directive to move with urgency on the issue,
having considered the technology a top priority.

In Biden's view, the government was late to address the risks of social media and now U.S. youth are grappling with
related mental health issues. AI has the positive ability to accelerate cancer research, model the impacts of climate
change, boost economic output and improve government services, among other benefits.

But it also could warp basic notions of truth with false images, deepen racial and social inequalities, and provide a
tool to scammers and criminals.

The order builds on voluntary commitments already made by technology companies. It's part of a broader strategy
that administration officials say also includes congressional legislation and international diplomacy.

Using the Defense Production Act, the order will require leading AI developers to share safety test results and other
information with the government. The National Institute of Standards and Technology is to create standards to
ensure AI tools are safe and secure before public release.

The Commerce Department is to issue guidance to label and watermark AI-generated content to help differentiate
between authentic interactions and those generated by software. The order touches on matters of privacy, civil
rights, consumer protections, scientific research and worker rights.

                                                                               Page 2 of 2
                              Biden signs executive order to guide AI safety


Load-Date: October 31, 2023


  End of Document

                                                                                                        Page 1 of 3
                Parkland school shooting survivor develops Joy, an app built on AI that helps people heal




    Parkland school shooting survivor develops Joy, an app built on AI that
                              helps people heal
                                                  St. Louis Post-Dispatch (Missouri)
                                                    September 28, 2023 Thursday
                                                             FIRST EDITION



Copyright 2023 St. Louis Post-Dispatch, Inc. All Rights Reserved

Section: ; Pg. A12
Length: 877 words
Byline: BARBARA ORTUTAY Associated Pres

Body


Kai Koerber was a junior at Marjory Stoneman Douglas High School when a gunman murdered 14 students and
three staff members there on Valentine's Day in 2018. Seeing his peers - and himself - struggle with returning to
normal, he wanted to do something to help people manage their emotions on their own terms.

While some of his classmates at the Parkland, Florida, school have worked on advocating for gun control, entered
politics or simply took a step back to heal and focus on their studies, Koerber's background in technology - he'd
originally wanted to be a rocket scientist - led him in a different direction: to build a smartphone app.

The result was Joy: AI Wellness Platform, which uses artificial intelligence to suggest bite-sized mindfulness
activities for people based on how they are feeling. The algorithm Koerber's team built is designed to recognize how
a person feels from the sound of their voice - regardless of the words or language they speak.

"In the immediate aftermath of the tragedy, the first thing that came to mind after we've experienced this horrible,
traumatic event - how are we going to personally recover?" he said. "It's great to say OK, we're going to build a
better legal infrastructure to prevent gun sales, increased background checks, all the legislative things. But people
really weren't thinking about … the mental health side of things."

Like many of his peers, Koerber said he suffered from post-traumatic stress disorder for a "very long time" and only
recently has it gotten a little better.

"So when I came to Cal, I was like, let me just start a research team that builds some groundbreaking AI and see if
that's possible," said the 23-year-old, who graduated from the University of California, Berkeley earlier this year.
"The idea was to provide a platform to people who were struggling with, let's say sadness, grief, anger … to be able
to get a mindfulness practice or wellness practice on the go that meets our emotional needs on the go."

He said it was important to offer activities that can be done quickly, sometimes lasting just a few seconds, wherever
the user might be. It wasn't going to be your parents' mindfulness practice.

                                                                                                     Page 2 of 3
             Parkland school shooting survivor develops Joy, an app built on AI that helps people heal

"The notion of mindfulness being a solo activity or something that's confined to sitting in your room breathing is
something that we're very much trying to dispel," Koerber said.

Mohammed Zareef-Mustafa, a former classmate of Koerber's who's been using the app for a few months, said the
voice-emotion recognition part is "different than anything I've ever seen before."

"I use the app about three times a week, because the practices are short and easy to get into. It really helps me
quickly de-stress before I have to do things like job interviews," he said.

To use Joy, you simply speak into the app. The AI is supposed to recognize how you are feeling from your voice,
then suggest short activities.

It doesn't always get your mood right, so it's possible to manually pick your disposition. Yet another activity helps
you practice making an effective apology. Another has you write a letter to your future self, with a pen and a paper -
remember those? Feeling sad? A suggestion pops up asking you to track how many times you've laughed over a
seven-day period and tally it up at the end of the week to see what moments gave you a sense of joy, purpose or
satisfaction.

The iPhone app is available for a $8 monthly subscription, with a discount if you subscribe for a year. It's a work in
progress, and as it goes with AI, the more people use it, the more accurate it becomes.

"Kai is a leader of this next generation who are thinking intentionally and with focus about how to use technology to
meet the mental, physical, and climate crises of our times," said Dacher Keltner, a professor at UC Berkeley and
Koerber's faculty adviser on the project. "It comes out of his life experience, and, unlike past technologists, he
seems to feel this has to be what technology does, make the world healthier."

A plethora of wellness apps on the market claim to help people with mental health issues, but it's not always clear
whether they work, said Colin Walsh, a professor of biomedical informatics at Vanderbilt University who has studied
the use of AI in suicide prevention. According to Walsh, it is feasible to take someone's voice and glean some
aspects of their emotional state.

"The driver is there's a huge demand there, or at least the perception of a huge demand there" Walsh said of the
explosion of wellness and mental health apps in the past few years. "Despite the best of intentions with our current
system - and it does a lot of good work - obviously, there's still gaps. So I think people see technology as a tool to
try to bridge that."

Koerber said people tend to forget, after mass shootings, that survivors don't just "bounce back right away" from the
trauma they experienced. It takes years to recover.

"This is something that people carry with them, in some way, shape or form, for the rest of their lives," he said.

His work has also been slower and deliberate than tech entrepreneurs of the past.

"I guess young Mark Zuckerberg was very ‘move fast and break things,'" he said. "And for me, I'm all about building
quality products that, you know, serve social good in the end."



Graphic


 With the fall school semester having already started or soon to get under way in most of the U.S., school safety is
top of mind, with what to do in the case of a school shooting becoming a regular part of planning.Last year, there
were 47 school shootings. That's just shy of the previous year's 52 and significantly higher than the two years
before that. However, those numbers are lower, in part due to students being in virtual learning due to the

                                                                                                     Page 3 of 3
             Parkland school shooting survivor develops Joy, an app built on AI that helps people heal

pandemic. The deadliest school shooting from last school year was at a private Christian school in Nashville where
the gunman shot through glass to be able to get access inside.SEE MORE: Shots again fired at site of Parkland
school massacre in reenactmentSince the Nashville shooting in March, Tennessee lawmakers approved $230
million for enhanced safety and mental health. In Denver, armed officers are returning to public schools in the
fall.And in Florida, dozens of state laws are focused on school safety.Districts in other states are allowing certain
staff members to carry guns on campus or installing collapsible bulletproof rooms, and in some places, resource
officers are back to walking school grounds.Scripps News reporters nationwide have been closely following safety
changes like this in recent years. They explain the changes their local community schools are making to address
safety concerns this year. Kai Koerber, seen July 27 in Berkeley, Calif., was a junior at Marjory Stoneman Douglas
High School when a gunman murdered 14 students and three staff members on Valentine's Day in 2018. Kai
Koerber, seen July 27 in Berkeley, Calif., was a junior at Marjory Stoneman Douglas High School when a gunman
murdered 14 students and three staff members on Valentine's Day in 2018. In response, he created Joy, an app
that helps people struggling with sadness, grief or anger. The Joy: AI Wellness Platform app uses artificial
intelligence to suggest bite-sized mindfulness activities for people based on how they are feeling. The algorithm is
designed to recognize how a person feels from the sound of their voice.


Load-Date: September 28, 2023


  End of Document

                                                                                                        Page 1 of 3
                             Mayo Clinic explores use of artificial intelligence. Is it hype or help?




        Mayo Clinic explores use of artificial intelligence. Is it hype or help?
                                             Post-Bulletin (Rochester, Minnesota)
                                                  February 4, 2023 Saturday



Copyright 2023 The Post-Bulletin

Distributed by Tribune Content Agency

Section: LIFESTYLE
Length: 1362 words
Byline: Jeff Kiger, Post-Bulletin, Rochester, Minn.

Body


Feb. 4—ROCHESTER — Artificial intelligence can now act as an artist or a writer. After years of hype, does that
mean AI is ready to play doctor?

Many institutions like Mayo Clinic, Google and venture capital firms believe that AI's potential in medicine is ready
to mature into truly useful tools to help patients and doctors.

The Mayo Clinic Platform is working with Google and other technology giants as a number of startup firms to
combine AI and Mayo's more than a century of medical records and data. In early December, the Mayo Clinic
Platform hosted its inaugural Health FWD conference to spotlight AI and life science entrepreneurship.

Dr. John Halamka, president of the Mayo Clinic Platform initiative, pointed out in his keynote address at the event
that health care needs improvement.

"Despite many best efforts, care is still disconnected, reactive, late stage, confusing, expensive," he said,
referencing his mother's recent experiences.

Halamka said that AI has the potential to improve the patient experience in many ways.

That's the same message that many were expressing 12 years ago when IBM's Watson supercomputer competed
against and defeated human contestants on the game show "Jeopardy!" In the years that followed, hundreds of
headlines described how AI would transform every aspect of medical care.

However, those breathless predictions faded away as many of the early applications failed to live up to those
expectations.

Frank Jaskulke, vice president of intelligence at Minnesota's Medical Alley organization, believes that AI is on the
upswing following the traditional trajectory of technology.

Using AI is less expensive than in its early days, he said, and that is one factor spurring the acceleration of the
number of AI-related startups appearing in the health care industry.

                                                                                                           Page 2 of 3
                         Mayo Clinic explores use of artificial intelligence. Is it hype or help?

Medical Alley, which works closely with entrepreneurs in health care, has an estimated 100 to 150 members who
are using AI in some fashion, according to Jaskulke. And that number is growing.

Jaskulke cited Gartner's Hype Cycle, which includes five phases: Technology Trigger, Peak of Inflated
Expectations, Trough of Disillusionment, Slope of Enlightenment and Plateau of Productivity.

"Every technology goes through this where there's a huge amount of hype and people say that it's gonna change
the world forever. And then there's the Trough of Disillusionment when it doesn't quite work out that way. But then
the real applications develop and it becomes a real thing," he said. "AI, I think, is in that phase. It's never universal,
but more and more companies are using real AI technology to solve real clinical problems. It's definitely
accelerating."

Jeff Clement, a doctoral candidate at the University of Minnesota who researches how clinicians and patients
evaluate AI recommendations, also believes that AI is starting to make a real impact in health care.

"I think that we're at the stage where everybody sees that this could do some good and a lot of people are using AI
in their personal lives. They're using AI to help them with traffic directions...They're talking to Alexa at home, but
they're still very wary," he said. "So we're still very early in actually deploying and developing algorithms that would
make a big impact on problems in patient care. And we're still seeing huge advancements in AI technology."

While AI in health care hasn't had a big breakout application or company yet, artificial intelligence has seen some
success in the medical realm in the past 10 years.

In Rochester, Mayo Clinic helped launch Ambient Clinical Analytics in 2013 under the leadership of well-known
Rochester entrepreneur Al Berning.

Ambient provides clinical decision tools designed for use at a patient's bedside or a nurse's station. It was approved
for medical use by the U.S. Food and Drug Administration in 2015. Ambient has found success in helping doctors
and nurses detect and treat sepsis with its AWARE Sepsis DART system.

Many AI systems in health care use algorithms to compare a patient's test results to large databases of patient
records.

Halamka explained at the Health FWD conference that Mayo Clinic's patient records are not enough and more are
needed to include more patients of different demographics.

"The challenge, of course, is that we're going to try to make these models generalizable to the globe using Mayo
Clinic. Ten million patient records aren't sufficient," he said. "You know that machine learning is math, not magic.
And if you have the wrong clinical context to the wrong data, inputs and outputs, you can generate some pretty
compelling and utterly worthless algorithms."

In 2022, Mayo Clinic signed a 10-year contract with a southern hospital system called Mercy. That agreement adds
15 million patient records from Arkansas, Missouri and Oklahoma to the mix. Halamka added that Mayo Clinic also
is working with centers in Canada to add more variety to the patient database.

"They want to make sure that when they build models they are appropriately representative... This is the thing that I
very much appreciate about Mayo Clinic's involvement. They're starting not from the tech side. They're starting from
the needs of the patient and asking 'How do we build tech tools that achieve that goal," said Jaskulke.

One challenge for developing AI algorithms is trying to keep racial or gender bias out of the results.

Referencing the old technology adage of "garbage in, garbage out," Jaskulke pointed out that "You have to have
really good data on the front end, to get an effective tool on the back end."

Clement said bias is a major issue that developers need to address when working with AI in health care.

                                                                                                        Page 3 of 3
                         Mayo Clinic explores use of artificial intelligence. Is it hype or help?

"If we train an algorithm just on the way we've always been doing things, we may be just replicating human bias.
Human biases show up in the data as it exists now. So if we train an algorithm on that data, a lot of those biases will
be captured in the algorithm," he said. "That's when you work with the developer and basically fine tune it on your
patient data. So rather than a sort of a general solution, you're able to customize it on your patient data."

Referencing the old technology adage of "garbage in, garbage out," Jaskulke pointed out that, "You have to have
really good data on the front end, to get an effective tool on the back end."

While artificial intelligence appliances are being developed in every aspect of health care from pharmaceuticals to
diagnosis to monitoring, AI is already a standard tool being used in areas like radiology or electrocardiography

"Image processing is sort of an easier task for AI," said Clement. "If you're doing something with radiology, there's a
good chance that your radiologist has access to what's called a CAD tool, Computer Aided Diagnosis."

When it comes to businesses and economic development, is AI in health care on the upswing to the Plateau of
Productivity?

"It depends on the sector. There are parts of health care health technology that are doing well. There are parts that
are struggling. There are some that are in between. I feel good about the ecosystem. Rochester is growing. We're
seeing innovations in St. Cloud," said Jaskulke. "We've had a very strong five years in the startup community,
including 2022. Those innovations take five to 10 years for stuff to develop. I think those things we are seeing in the
early stages now will pay off in 2024 or 2025 in major job creation, major patient impact and major wealth creation."

While AI has potential to improve health care, experts said that doesn't mean a computer program will be
diagnosing and treating patients on its own. AI in health care is about augmenting the knowledge of a doctor or
nurse.

"How many patient cases can a doctor see over their entire career? Many thousand, but not 100 million," said
Clement. "I've heard this phrase that by reading books you gain a 1,000-year-old mind, because you gain the
knowledge. This is the same idea. There are rare diseases and conditions that might only come up a handful of
times in a physician's whole career, even at a place like Mayo Clinic."

___ (c)2023 the Post-Bulletin Visit the Post-Bulletin at www.postbulletin.com Distributed by Tribune Content
Agency, LLC.


Load-Date: February 4, 2023


  End of Document

                                                                                                          Page 1 of 2
                                     Experts discuss AI use across fields at conference




                      Experts discuss AI use across fields at conference
                                              The Dartmouth: Dartmouth College
                                                      October 5, 2023 Thursday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 752 words
Byline: Connor Perrotta

Body


On Sept. 29, Dartmouth held its annual Artificial Intelligence Conference, hosting experts in art, banking, business,
health and investment who discussed the applications of artificial intelligence and popular arguments against its
use.

Saeed Hassanpour - the Dartmouth Center for Precision Health and AI director - said at the event that artificial
intelligence can aid health-related initiatives. He noted that AI "can sift through ... a large amount of data in a small
amount of time," to predict outcomes of potential treatment options. Hassanpour added that he is currently working
with AI to research cancer treatments.

Lisa Marsch, Dartmouth Center for Technology and Behavioral Health director, discussed at the conference the
benefits of AI in helping patients who are anxious to seek help.

"Not everybody's going to go seek a prescriber," Marsch said.

Marsch said that patients appreciate digital therapeutics, a term that refers to delivering a medical-grade
intervention entirely through software, adding that FDA-approved prescriptions of software are now available in the
U.S. She stressed the need for these low-stigma services and the "widespread availability of these devices."

Jasmine Lombardi - Chief customer officer at Locus Robotics - spoke toward the end of the conference on the
impact of AI on the workforce, specifically in warehouses. Lombardi said that the average worker in a warehouse
has a "tough life," walking miles a day in hot temperatures and doing manual labor. Locus makes robots that act as
moving platforms, carrying heavier items to which carry heavier items to minimize the risk of worker injuries.

"[Locus robots are] going to help you, not take away your job," Lombardi said.

Aditya Bhasin, chief technology and information officer for Bank of America, spoke about working to minimize AI's
bias in the world of finance.

"Our models actually have to have explainability," Bhasin said. "If a model's not explainable, you can't say to
somebody, 'We didn't make you a loan because the computer said no.'"

                                                                                                           Page 2 of 2
                                  Experts discuss AI use across fields at conference

Bhasin talked about the ethical dilemma of "[AI] augmenting human capability."

"No matter how artificially intelligent the creation of something was ... the human accountability cannot be lost," he
added.

Film and Media studies and digital humanities professor Mary Flanagan said that she thinks that creative integrity
will be preserved in the era of AI, and that she often creates her own pieces of art after feeding a prompt to an AI
software and then using the generated image as reference.

"I have my own voice," Flanagan said. "[I] know what I'm looking for."

Flanagan also spoke about the controversial aspects of AI, specifically with the arts. She noted that AI did not have
a dataset trained on women's art, until she undertook the effort herself.

"Which things do we value?" Flanagan asked the audience. "[I] started thinking about how biased our systems are
... Whose work is valued?"

In an interview with The Dartmouth following the event, 401 Ventures partner Graham Brooks said he feels
concerned about AI from an "academic" standpoint, rather than a "Terminator ... who's gonna take over the world?"
perspective.

"The way that these [AI] models work, they don't understand facts," Brooks said. "They process information in a
very different way. That said, they do it in a pattern-matching way... fundamentally, one could argue that humans do
[this just] as well."

When asked about his opinions on AI in academia, Brooks said that AI is "similar to calculators and the internet ...
They are tools that are gonna be available." He said that we should be "figuring out how to teach with [AI] in a very
open way."

"You go back down to elementary school," Brooks added, "that's where it gets a little bit harrier ... There is a level of
... basic understanding that needs to be done."

Brooks spoke about how age differences can influence the extent to which students use AI.

"[Young children] don't have that level of maturity and responsibility to use it in a positive way," Brooks said. "But ...
if you're in college, and you can use [Chat] GPT to write an essay, let's say ... if you were gonna write that essay in
12 hours ... now you can ... actually do the writing in an hour, or two hours. You're gonna spend 10 more hours on
the critical thinking and the outlining."

For all his insistence on the benefits and relative public acceptance of AI, he clarified that AGI (artificial general
intelligence) is "not going to be a cure-all," providing the example of global warming.


Load-Date: October 5, 2023


  End of Document

                                                                                                         Page 1 of 2
                         Health care artificial intelligence gets biased data creating unequal care




    Health care artificial intelligence gets biased data creating unequal care
                                 Michigan Independent: University of Michigan - Ann Arbor
                                                      September 30, 2022 Friday



University Wire
Copyright 2022 UWIRE via U-Wire All Rights Reserved

Section: NEW; Pg. 1
Length: 865 words

Body


FACULTY Q&A

Like many sectors, health care has benefited from the rising use of artificial intelligence, but it has sometimes
happened at the expense of minority patients.

Nicholson Price

In fact, health care AI might amplify and worsen disparities (racial/ethnic and others) because the data sources that
"teach" AI are not representative and/or are based on data from current unequal care, says University of Michigan
law professor Nicholson Price, who also is a member of U-M's Institute for Healthcare Policy & Innovation.

In a recent Science article, Price and colleagues Ana Bracic of Michigan State University and Shawneequa Callier
of George Washington University say these disparities are happening despite efforts in medicine by physicians and
health systems trying strategies focused on diverse workforce recruitment or implicit bias training.

Science article: Health care artificial intelligence gets biased data creating unequal care

What is an example of anti-minority culture?

There are depressingly many examples of cultures that include deeply embedded biases against minoritized
populations (that is, populations constructed as minorities by a dominant group). We focus on Black patients in
medicine in the article (who are stereotyped as being less sensitive to pain, among a host of other pernicious
views), but we could just as easily have focused on Native American patients, transgender patients, patients with
certain disabilities or even women in general (who, even though they're a numerical majority, are often still
minoritized).

So this influences research participation/recruitment and AI, such as Black participants declining participation?

Exactly. We start the piece by describing patterns of clinical care that involve self-reinforcing cycles of exclusion,
but then step back to show how these dynamics also occur in patient recruitment for big data and then AI. The
research participation story actually relies a lot on an earlier study (that) showed different rates of consent for big-
data research participation (in the Michigan Genomics Initiative) for members of different minority groups.

                                                                                                        Page 2 of 2
                       Health care artificial intelligence gets biased data creating unequal care

In this project, we build on that work (and other work on research participation by Shawneequa Callier, the third co-
author of this piece) to lay out cyclical dynamics, where bias leads to inadequate recruitment, leads to lessened
engagement, resulting in perceptions of minoritized patients as less interested in research, and a repeating,
strengthening cycle. And the same sort of pattern shows up in medical AI.

Describe the AI and anti-minority culture/discrimination interaction.

AI isn't sentient; it can't "think less" of members of minoritized groups. But AI systems are trained on data that
reflect many decades of entrenched bias in clinical care, and they're also trained on inadequately representative
data sets (for the reasons just described). This means that AI systems "learn" from biased data, and the patterns
they learn-and which they then use to predict, classify and recommend-are biased, so those outputs are likely to be
biased and discriminatory, too. And when patients resist or react poorly to bad recommendations, the AI systems
learn from those new data, too, and the cycle repeats again.

What are the policy implications of this study?

Basically, there are three main policy takeaways. First, exclusion can be self-reinforcing, whether in medical
practice, research data collection or medical AI. Hopes that these processes will improve over time (especially for
AI) as they just learn more are likely to be fruitless unless those hopes are accompanied by focused study and
effort.

Second, these different exclusion cycles aren't only self-reinforcing, they can also reinforce each other. AI systems
learned from biased care, and biased AI recommendations can feed back into more biased care. A totally unbiased
physician working with an AI trained on biased data will likely end up making biased decisions.

Third, and related: Trying to fix these issues at the policy level will require understanding and taking account of
these interweaving and reinforcing dynamics. Trying to fix just one bit of bias in the system is like trying to cure a
systemic infection by focusing on one organ: It's just going to get reinfected by other parts of the system.

How can biases be determined from any data set or AI? Who is going to take the lead in changing what is
happening with the algorithms?

This is a tough one. We think multidisciplinary, diverse teams are the way to go, but it's far from clear who those
teams might be or how they can meaningfully implement change. It would be nice if we had a really clear,
straightforward solution, but really, we see our role here as doing more to point out the complexity and the
dynamics of the problem, hopefully while it's still early enough to tackle it more effectively.

In fact, health care AI might amplify and worsen disparities (racial/ethnic and others) because the data sources that
"teach" AI are not representative and/or are based on data from current unequal care, says University of Michigan
law professor Nicholson Price, who also is a member of U-M's Institute for Healthcare Policy & Innovation.


Load-Date: September 30, 2022


  End of Document

                                                                                                        Page 1 of 1
                                  Most Patients Have Positive Views About AI in Medicine




                  Most Patients Have Positive Views About AI in Medicine
                                            The Breeze: James Madison University
                                                      May 12, 2022 Thursday



University Wire
Copyright 2022 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 302 words

Body


THURSDAY, May 12, 2022 (HealthDay News) -- Most patients have positive views about the ability of artificial
intelligence to improve care but have concerns about unintended consequences, according to a research letter
published online May 4 in JAMA Network Open.

Dhruv Khullar, M.D., M.P.P., from Weill Cornell Medical College in New York City, and colleagues administered a
survey between Dec. 3 and 18, 2019, to a hybrid probability-based, nationally representative online panel to
examine public perceptions of the use of AI in diagnosis and treatment; 926 participants completed the survey.

The researchers found that most patients believed that AI would make health care much or somewhat better (10.9
and 44.5 percent, respectively), while few believed AI would make health care somewhat or much worse (4.3 and
1.9 percent, respectively); 19 percent indicated that they did not know. Overall, 66 and 29.8 percent said that being
informed if AI played a big role in their diagnosis or treatment was very and somewhat important, respectively. A
total of 31 and 40.5 percent, respectively, of respondents reported being very and somewhat uncomfortable
receiving a diagnosis from an AI algorithm that was accurate 90 percent of the time but incapable of explaining its
rationale. Most respondents were very or somewhat concerned about unintended consequences of AI, including
misdiagnosis, privacy breaches, less time with clinicians, and higher health care costs (91.5, 70.8, 69.6, and 68.4
percent, respectively).

"Patients may benefit from education on how AI is being incorporated into care and the extent to which clinicians
rely on AI to assist with decision-making," the authors write.

Several authors disclosed financial ties to the pharmaceutical, legal, health care, and insurance industries.

Abstract/Full Text


Load-Date: May 13, 2022


  End of Document

                                                                                                          Page 1 of 2
                               Exploring how artificial intelligence could redefine health care




             Exploring how artificial intelligence could redefine health care
                                             The McGill Tribune: McGill University
                                                      October 6, 2020 Tuesday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: SCI-TECH; Pg. 1
Length: 663 words
Byline: Namrata Rana

Body

Before Siri and Alexa, programmers created Eliza. Developed in 1964, Eliza was the first chatbot capable of
recreating conversations between a psychotherapist and a patient. This chatbot pushed the boundaries of artificial
intelligence , a still-emerging field at the time, into the domain of health care. Despite researcher's best efforts, the
integration of AI into medicine was slow in the following decades. This slow progress accelerated, however, when
the global COVID-19 pandemic challenged health care systems' abilities to treat larger populations in need of
immediate attention. AI-augmented care has emerged as the leading solution to efficiently manage patients and
apply the ever-growing collection of data to diagnostic medicine.

Dr. Samira Rahimi, a professor in the Department of Family Medicine at McGill, is using AI to monitor senior
residents in long term care facilities in Montreal and Toronto. Her ongoing project, AiCoV19, funded by Roche
Canada's COVID-19 Open Innovation challenge, uses biosensors in smartwatches to continuously track potential
COVID-19 symptoms in elderly patients.

"The goal is to integrate data from these sensors into an algorithm that can detect abnormalities in vital signs and
predict an infection earlier," Rahimi said in an interview with The McGill Tribune. "The biggest advantage of AI-
based, real-time monitoring is how quickly a health care professional can be alerted upon detection of concerning
signals."

AI is often glorified as a solution to numerous problems, however it is not yet capable of spontaneous
consciousness. Instead, AI learns within the algorithms it is given.

"What makes AI so powerful is its capacity to translate big data into an automated algorithm that captures complex
relationships and trends," Rahimi said.

One of the most challenging obstacles facing doctors and nurses on the front-lines of COVID-19 is the inability to
process the magnitude of data constantly being collected and updated worldwide. Deep learning is a specialized
category of AI that loosely resembles networks of neurons in an attempt to mimic human intelligence and complete
tasks that require layers of information processing. AI has become the basis of multiple global tools being used to
tackle the pandemic. One such tool was created by MIT data scientists to forecast infections and deaths. Leaving
computers to the task of reading research papers on COVID-19 as well as collecting and predicting future trends
provides physicians more time to look after patients.

                                                                                                       Page 2 of 2
                             Exploring how artificial intelligence could redefine health care

With mounting evidence supporting the benefits of AI in diagnostic support, patient monitoring, and personalized
care, its strongest proponents still wonder why it has yet to be embraced on a wider scale. The answer to that
question is complex, but for many, this hesitation can be attributed to open debates surrounding the right to
information security and the further questions of ethics that come with big data projects.

"Data access continues to be a barrier in AI adoption in health care," Rahimi said. "AI project proposals undergo [a]
rigorous process to seek approval. There is a lack of open-source data available to researchers, which is the most
valuable asset for any developer. AI continues to be part of the few scientific fields where the practice of open-
science is still heavily debated.

Although the global pandemic has revealed the necessity of AI in health care, it is important to reflect on the long
term opportunities for AI-augmentation in tackling health-related problems. According to the World Health
Organization, the expected shortage of health care workers in North America is projected to exceed 14.5 million by
2030. Rahimi points out that the incorporation of AI technology can resolve some of these anticipated issues by
expanding health care access, improving administrative efficiency, and providing insight into selecting the most
appropriate treatment paths for each patient.
    •   Artificial Intelligence
    •   covid-19
    •   healthcare


Load-Date: October 6, 2020


  End of Document

                                                                                                        Page 1 of 2
                                  Most Patients Have Positive Views About AI in Medicine




                  Most Patients Have Positive Views About AI in Medicine
                                     The Griffon News: Missouri Western State College
                                                      May 12, 2022 Thursday



University Wire
Copyright 2022 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 317 words

Body


THURSDAY, May 12, 2022 (HealthDay News) -- Most patients have positive views about the ability of artificial
intelligence to improve care but have concerns about unintended consequences, according to a research letter
published online May 4 in JAMA Network Open.

Dhruv Khullar, M.D., M.P.P., from Weill Cornell Medical College in New York City, and colleagues administered a
survey between Dec. 3 and 18, 2019, to a hybrid probability-based, nationally representative online panel to
examine public perceptions of the use of AI in diagnosis and treatment; 926 participants completed the survey.

The researchers found that most patients believed that AI would make health care much or somewhat better (10.9
and 44.5 percent, respectively), while few believed AI would make health care somewhat or much worse (4.3 and
1.9 percent, respectively); 19 percent indicated that they did not know. Overall, 66 and 29.8 percent said that being
informed if AI played a big role in their diagnosis or treatment was very and somewhat important, respectively. A
total of 31 and 40.5 percent, respectively, of respondents reported being very and somewhat uncomfortable
receiving a diagnosis from an AI algorithm that was accurate 90 percent of the time but incapable of explaining its
rationale. Most respondents were very or somewhat concerned about unintended consequences of AI, including
misdiagnosis, privacy breaches, less time with clinicians, and higher health care costs (91.5, 70.8, 69.6, and 68.4
percent, respectively).

"Patients may benefit from education on how AI is being incorporated into care and the extent to which clinicians
rely on AI to assist with decision-making," the authors write.

Several authors disclosed financial ties to the pharmaceutical, legal, health care, and insurance industries.

Abstract/Full Text

Originally published on consumer.healthday.com, part of the TownNews Content Exchange.


Load-Date: May 13, 2022

                                                                           Page 2 of 2
                  Most Patients Have Positive Views About AI in Medicine


End of Document

                                                                                                     Page 1 of 2
                                     Can AI help improve outcomes for cancer patients?




                      Can AI help improve outcomes for cancer patients?
                                               Daily Record, The (Baltimore, MD)
                                                 September 12, 2023 Tuesday



Copyright 2023 BridgeTower Media All Rights Reserved

Section: NEWS
Length: 804 words
Byline: Christine Tobar

Body


Nawar Shara, chief of research data science at the MedStar Health Research Institute, has high hopes for artificial
intelligence (AI) and other technologies in the medical field.

Shara and her team have been awarded $3 million from the National Institutes of Health to study how AI can
improve outcomes for patients recovering from gastrointestinal cancer surgery.

Using a voice-assisted, remote patient symptom monitoring system (VARSMS) developed through artificial
intelligence and natural language processing technology, patients can be monitored remotely for post-recovery.
With the goal of improving communication with health care providers and, in turn, improving post-surgical recovery
outcomes, the system is designed to recognize accents and a variety of speaking cadences, providing real-time,
proactive encouragement and discharge recommendations.

The grant expands Shara’s prior research that examined how voice-assisted devices like Amazon Alexa can
improve care management for ethno-racial minority patients with heart failure. The previous study successfully
showed that AI technologies can be utilized to improve patient engagement.
“This grant builds upon the work that we have done in the past using Alexa. Instead of a canned survey where
patients are asked questions, we have incorporated language models to have explainable symptoms to act in real-
time. It allows us to intervene if the situation necessitates that,” Shara said.

Shara and her team believe that remote patient symptom monitoring tools can help prevent post-discharge
complications, especially among patient populations who historically experience worse outcomes. Black and
Hispanic patients are twice as likely as white patients to experience complications after gastrointestinal cancer
surgery. Factors including socioeconomic conditions, poor provider communication and low health literacy can
contribute to post-surgical complications. Shara and her team will use BERT, a language representation model from
Google, and ChatGPT to enhance comprehension of patient feedback.
In her previous study, the remote voice-assisted technologies helped patients remember to take their medicine or
modify their care plan based on symptoms. Providers were also able to intervene when symptoms recorded put the
patient at risk of heart failure.
“We were able to look at the dashboard as they were recovering in their homes, and in some instances, were able
to intervene to have patients come to the clinic to be seen immediately to prevent a heart attack,” she said.

                                                                                                          Page 2 of 2
                                 Can AI help improve outcomes for cancer patients?

The new grant will fund the study of a randomized clinical trial of patients from high-risk populations in urban,
suburban and rural settings. Patients who have had surgery for gastrointestinal cancer will be assigned the
standard of care that includes traditional follow-up communication with their provider, or with the VARSMS system
for a 40-day period after their discharge. Shara and her team will then analyze how the VARSMS system impacts
patient outcomes and compliance with treatment plans. It will also evaluate the surgical team’s experiences.
The team is currently in the first phase of the study, which includes fine-tuning the tool, conducting interviews and
developing a system that understands the clinical flow, Shara said.

“It’s one of the most important things in health care. The clinical flow needs to be accounted for. There are steps
that the health care team follows, and we cannot just come in and interrupt. We want to ensure this tool is not
interrupting, but rather complementing,” Shara said.
The next phase will include enrolling patients and official testing will begin.

Shara believes that this is just the beginning of using AI in healthcare.

“Health care has historically lagged behind in technology because of the intricacies of the field and the sensitive
information of the patient. This is just the beginning, and the sky is the limit. But before we can say it is safe, we
really need to be confident. With big data we can identify patients who may be vulnerable and deploy preventative
measures. I think the future is really bright, but any change brings angst to us, patients and the field. If we do things
with care, these tools can be used for good,” she said.

Shara has partnered with Dr. Waddah Al-Refala, Chair of the Department of Surgery at Creighton University and
Chair of Surgery at CHI Health for the study. The research team is also comprised of experts in human-centered
design and evaluation, including Dr. Guodong (Gordon) Gao and Dr. Rita Agarwal from the Johns Hopkins Carey
School of Business and Co-Directors of the Center for Digital Health and Artificial Intelligence, and Dr. Dakuo Wang
from Northeastern University.
The five-year study is expected to conclude in 2028 or sooner.

Copyright © 2023 BridgeTower Media. All Rights Reserved.


Load-Date: September 25, 2023


  End of Document

                                                                                                         Page 1 of 2
                                      The US Executive Order on artificial intelligence is out.




                      The US Executive Order on artificial intelligence is out.
                                                             R Street Institute
                                                      October 30, 2023 Monday



Copyright 2023 Content Engine, LLC.
All Rights Reserved
Copyright 2023 R Street Institute, USA All Rights Reserved

Length: 595 words

Body

But some perceive a coming "regulatory cage."

That's the viewpoint the R Street Institute published this morning, Adam Thierer, a senior fellow for the R Street
Institute's technology and innovation team and AI expert, sees an incipient "regulatory cage." He summarized five
key points from his assessment:
          •       "While some will appreciate the whole-of-government approach to AI required by the order, if taken
          too far, unilateral and heavy-handed administrative meddling in AI markets could undermine America's
          global competitiveness and even the nation's geopolitical security. AI is a critical new technology with the
          potential to fundamentally expand productivity and economic growth, with benefits accruing across many
          sectors and for all consumers. AI has particularly important implications for advancing public health. AI
          and computational science also have national security ramifications, which is why a strong and secure
          domestic technology base is essential to countering challenges or threats from China and other nations.
          Excessive preemptive regulation of AI systems could impede the growth of these technologies or limit their
          potential in various ways."
    •     "The new executive order highlights how the administration is adopting an everything-and-the-kitchen-sink
          approach to AI policy that is, at once, extremely ambitious and potentially over-zealous. The
          implementation details on all the matters here are mostly left to the various federal agencies to work out,
          and it remains unclear how far they can stretch their statutory authority to enforce many of these
          stipulations. Even so, taken together with other recent administration statements, the order represents a
          potential sea change in the nation's approach to digital technology markets as federal policymakers appear
          ready to shun the open innovation model that made American firms global leaders in almost all computing
          and digital technology sectors."
    •     "There are some positive and much-needed elements to the EO, however, including its call 'to expand the
          ability of highly skilled immigrants and nonimmigrants with expertise in critical areas to study, stay, and
          work in the United States by modernizing and streamlining visa criteria, interviews, and reviews.' For some
          time, there has been a pressing need to expand efforts to retain skilled immigrant workers, with many
          technology companies and experts worried about losing top-notch talent to other nations. But most of the
          order focuses on broader and extremely amorphous calls for expanded government oversight across many
          other issues and agencies, raising the risk of a 'death by a thousand cuts' scenario for AI policy in the US."

                                                                                                        Page 2 of 2
                              The US Executive Order on artificial intelligence is out.

   •    "Of greater concern is the executive order's green light for the Federal Trade Commission (FTC) to expand
        its focus on AI policy. While the FTC does possess broad powers to police unfair and deceptive practices
        for all markets, the danger of preemptive overreach exists with the EO's call for the FTC to exercise greater
        regulatory authority over the AI ecosystem in particular."
   •    "With the administration's recent actions, one can't help but worry that the Biden administration is looking to
        follow in the E.U.'s footsteps on AI policy with more comprehensive controls on computation and meddling
        in digital tech markets. There is still time to pursue a more enlightened path. To balance innovation and
        safety, AI governance must be focused on flexible, collaborative, iterative, bottom-up governance
        solutions through risk-based policies that are focused on system outcomes, not on system inputs or
        design."


Load-Date: October 31, 2023


  End of Document

                                                                                                          Page 1 of 2
                                     AI HELPING UPMC DOCTORS WITH TRANSCRIPTION




                    AI HELPING UPMC DOCTORS WITH TRANSCRIPTION
                                                 Pittsburgh Post-Gazette
                                                November 17, 2023 Friday
                                                   SOONER EDITION



Copyright 2023 P.G. Publishing Co.

Section: BUSINESS; Pg. A-14
Length: 429 words
Byline: Kris B. Mamula Pittsburgh Post-Gazette

Body


Transcribing physician notes about care provided to patients was once a $12 billion business, with doctors' voice
recordings even sent abroad for conversion into written form that eventually made its way into patient medical
records.

That's all gone now with the advent of artificial intelligence in medicine, which has turned the industry inside out with
real-time capabilities of summarizing and structuring doctor-patient conversations into medical records and
diagnostic codes needed for billing insurers.

"We built generative AI in health care," said Shivdev Rao, non-invasive cardiologist at UPMC and co-founder of
Abridge AI Inc., a startup that converts voice into structured medical records. "It improves the care experience."

Creating medical notes after meeting with a patient has been a headache for doctors since there were medical
records. Abridge software saves doctors up to three hours a day in administrative chores, Dr. Rao said, giving them
more time to spend with patients.

"At this point in time, they need technologies to augment clinical care and improve the patient's experience," he
said.

The company, which employs about 50 people and generates undisclosed revenue, has offices in Lawrenceville,
New York, Boston and San Francisco. Abridge recently closed on a $30 million Series B funding round, bringing the
total amount raised by the company to $62.5 million since its start in 2018.

Some two dozen UPMC physicians in Eastern Pennsylvania have used Abridge to create structured medical
records from 10,000 doctors' office interactions with patients as the technology continues to roll out to other
hospitals in the system. In addition to UPMC, Abridge software is being used by the University of Kansas Health
System and Emory Healthcare as part of a partnership with Epic Systems, an electronic medical records system
outfit based in Verona, Wis.

                                                                                                        Page 2 of 2
                             AI HELPING UPMC DOCTORS WITH TRANSCRIPTION

The big advantage of the software is the time it saves doctors, said Salim Saiyed, chief medical information officer
at UPMC Pinnacle in Harrisburg.

"It frees them up mentally," he said. "That gives them time to really focus on the patient. That's just phenomenal."

Health care has been a tantalizing target for generative AI because of the mark the technology is expected to make
in everything from new drug research to primary medical care. In October, Highmark announced a deal with
Alphabet's Google subsidiary for Vertex AI Search software, which the hospital and health insurance giant said
would be used in every facet of its business, including doctors' offices.

Kris B. Mamula: kmamula@post-gazette.com



Graphic


PHOTO: Jessie Wardarski/Post-Gazette: A computer used at the West Penn Hospital School of Nursing in
Bloomfield.


Load-Date: November 17, 2023


  End of Document

                                                                                                      Page 1 of 2
       Renowned health scholar joins Emory School of Medicine amid artificial intelligence research expansion




    Renowned health scholar joins Emory School of Medicine amid artificial
                      intelligence research expansion
                                                Emory Wheel: Emory University
                                                      May 13, 2022 Friday



University Wire
Copyright 2022 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 591 words
Byline: Meredith Salzinger

Body


Donnell Institute Professor of Biomedical Engineering Anant Madabhushi. Photo courtesy of Emory University

Artificial intelligence savant Anant Madabhushi will join the Emory University School of Medicine in July, where he
will establish an institute that researches AI to improve patient outcomes and address health inequities.

Madabhushi's recruitment comes as the University expands its research into AI. The Office of the Provost's artificial
intelligence initiative, AI.Humanity, plans to hire 50 to 60 faculty members over the next three to five years to enrich
the University's interdisciplinary exploration of AI through lenses of health, social justice, business, economics and
entrepreneurship, the humanities and arts and beyond.

Working at Case Western Reserve University (Ohio) since 2012, Madabhushi has served as both the Donnell
Institute Professor of Biomedical Engineering as well as the founding director of Case Western's Center for
Computational Imaging and Personalized Diagnostics. Madabhushi has authored hundreds of peer-reviewed
articles and holds hundreds of patents.

At Emory, Madabhushi will hold a primary appointment in the department of biomedical engineering and secondary
appointments in the departments of radiology and imaging sciences, biomedical informatics and pathology.

"I am really excited about this opportunity and am hoping to make an impact," Madabhushi said. "I have been
touched by the huge support and reaction [from Emory] I have already seen. I am getting the platinum level service
of southern hospitality here."

Madabhushi develops artificial intelligence to inform diagnosis, treatment and prognosis for patients with cancer and
other diseases. He specifically works to identify and tackle racial health disparities by studying and applying data
from minority populations, which have been historically left out of medical studies.

In 2020, Madabhushi gained recognition for his use of AI analysis to find cellular differences in the cancer tissue of
white and Black prostate cancer patients.

                                                                                                    Page 2 of 2
     Renowned health scholar joins Emory School of Medicine amid artificial intelligence research expansion

"If there are differences [in disease phenotype between different races], then taking an AI model that was
developed using a majority white population is not going to translate very well to a Black man with prostate cancer
because there is not enough representation of those patients," Madabhushi said.

Looking ahead, Madabhushi wants to collaborate with clinicians at Emory to utilize the technologies developed by
his team.

"To me, the 'what next' is about impact," Madabhushi said. "You can do all the research in the world but unless you
are deliberately thinking about how the technology can move forward into clinical deployment, it is not really that
satisfying."

In addition to potentially collaborating with Emory Healthcare, Madabhushi said he is impressed by Emory's
commitment to social justice and diversity. Madabhushi also plans to collaborate with Morehouse School of
Medicine (Ga.), a historically Black college, in addressing health inequities.

"The big vision is to establish a mecca for AI in health," Madabhushi said. "There is a great opportunity in Emory
and Atlanta."

In a Feb. 17 press release, Provost and Executive Vice President for Academic Affairs Ravi V. Bellamkonda wrote
that the University is "delighted" to welcome Madabhushi.

"Anant Madabhushi is an innovative scholar and doer, a true visionary whose bold ideas in the use of AI to improve
human health will be foundational to our goals of expanding Emory's education and research community in this
arena," Bellamkonda said.


Load-Date: May 14, 2022


  End of Document

                                                                                                          Page 1 of 2
                                                             BRIEFLY




                                                           BRIEFLY
                                                 The San Diego Union-Tribune
                                                  March 15, 2023 Wednesday
                                                            Final Edition



Copyright 2023 The San Diego Union-Tribune All Rights Reserved

Section: BUSINESS; Part C; Pg. 1
Length: 433 words

Body


Markets

Markets climb: Stocks ended broadly higher on Wall Street Tuesday, as some of the most breathtaking moves from
a manic Monday reversed course. See story, C3.

BRIEFLY

Tyson closures: Tyson Foods is closing two facilities that employ more than 1,600 people in an effort to streamline
its U.S. poultry business. The company said Tuesday it plans to close its processing, broiler and hatching
operations in Glen Allen, Va., and a plant in Van Buren, Ark. Both closures are scheduled for May 12. Tyson said
the closures will help it better use all available capacity at remaining plants.

Eye on app: Britain's security minister said Tuesday he has asked the country's National Cyber Security Center to
review threats posed by TikTok amid calls for the U.K. to impose a ban on the Chinese-owned social media app.
Security Minister Tom Tugendhat said he was waiting for a review from the government's cybersecurity experts
before deciding on the "hugely important question." Prime Minister Rishi Sunak hinted a day earlier that the U.K.
could follow the U.S. and the European Union in banning the app from government-issued mobile phones and
devices.

AI inclusion: Alphabet Inc.'s Google unveiled plans to integrate artificial intelligence into health-related initiatives,
including an update on the use of language-generating technology in medical exams and AI-assisted research,
ways to help consumers find information faster via Internet searches, and tools to help developers build health
apps around the world. Google's health-related AI announcements come more than a year after the company
shifted strategy for its health efforts, moving to embed health care research and other functionality in its core
products.

Xbox game deal: Microsoft said Tuesday that it has struck a deal to make Xbox PC video games available on the
Boosteroid cloud gaming platform, its latest move to appease antitrust regulators scrutinizing its purchase of
gamemaker Activision Blizzard. The U.S. tech giant said the 10-year agreement would also include Activision
Blizzard titles like the popular Call of Duty franchise if or when the acquisition gets approved. Microsoft has been

                                                                                                    Page 2 of 2
                                                    BRIEFLY

announcing new partnerships as it tries to persuade regulators to allow the $69 billion all-cash transaction to go
through.

Digits

$8.1B

Amount the deal between private equity firm Apollo Global Management and Univar Solutions is worth.
Shareholders of Univar, which deals with specialty chemicals and ingredients distribution, will receive $36.15 per
share in cash. Univar will continue to operate under its name and brand.

U-T NEWS SERVICES


Load-Date: March 17, 2023


  End of Document

                                                                                                    Page 1 of 3
   Penn State students, alumnus develop Reach.AI to address health disparities within marginalized communities




         Penn State students, alumnus develop Reach.AI to address health
                   disparities within marginalized communities
                                        Daily Collegian: Pennsylvania State University
                                                      July 7, 2021 Wednesday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 959 words
Byline: Olivia Estright

Body


Recent Penn State alumnus Kareem Jelks said he spent his childhood homeless in an "impoverished area" in
Washington D.C. From discrimination to food insecurities, Jelks said he understood what it felt like to be in need of
help.

Since earning a bachelor's degree in cybersecurity analytics and operations in 2021, Jelks said he's continued to
work on Reach.AI - an artificial intelligence software that incorporates different data sets to determine and address
various health disparities Hispanic and Latino communities in rural Pennsylvania are facing.

"I understood what it was like from a firsthand perspective to be overlooked and underrepresented in regards to
having certain issues addressed," Jelks said.

Jelks said he has focused on his education most of his life and was able to "navigate through [his] life" with hard
work.

During the coronavirus pandemic, Jelks found a new hobby - machine learning.

"I was really intrigued by machine learning applications and its application to different industries," Jelks said.

Jelks wasn't alone with his intrigue for machine learning. Kalp Patel, another member of the Reach.AI team, said
machine learning is a tool used with AI that aims to train a computer to learn data and algorithms to identify patterns
within the data.

Patel (junior-computer science) said he and John Keeling have been working to make Reach.AI "more user-
friendly."

"We're currently in the process of beginning to publish the website," Patel said. "We will hopefully have the website
up in the next week or so, and then [Jelks] will have to take some final looks at it."

                                                                                                   Page 2 of 3
  Penn State students, alumnus develop Reach.AI to address health disparities within marginalized communities

The project was co-created by Jelks and Keeling at the beginning of the pandemic after they saw how different
communities reacted to the coronavirus pandemic, Patel said.

"For Reach.AI, I tried to think about how we can incorporate healthcare into the machine learning industry because
that's a pressing need for vulnerable populations," Jelks said. "I saw it as a way to give back. Not necessarily right
now, but that's what the software's supposed to do."

The team was one of 20 teams to compete in the Prototype Phase of the Nittany AI Challenge, according to Penn
State Outreach. Each team received $500 to begin crafting their prototypes.

However, Jelks said he doesn't want Reach.AI to end at the university level.

"I want Reach.AI to be more than something that was in a competition," Jelks said. "I want to implement this idea
into society."

Courtesy of Kalp Patel

The newest team member who has been working on the "backend of the website," Punya Shah, said he's excited to
see what Reach.AI can teach him and where the software can go.

"The main goal for me is to gain experience that I can eventually take into the real world," Shah (junior-computer
science) said. "The second thing for me is Reach.AI can be made bigger with a push in the right direction."

Shah and Jelks said the team relies heavily on the planning portions for the development of the software.

"Time is of the essence, so I try to think of what we can do in the next 30 days to take this project to the next level,"
Jelks said.

Although the team has made it this far, Patel said it hasn't always been easy - the process is more complex than it
seems.

"A major issue we ran into was while displaying the models and showing the different data that [Jelks] collected, [we
realized] all of the data was distinctly similar," Patel said. "We had to find other determinants to differentiate the data
- otherwise it all looks the same."

The team gathers its data from programs like Feeding America to track food insecurities, the Centers for Disease
Control and Prevention for flu vaccinations and areas impacted by certain viruses, and the census to determine a
better demographic, according to Jelks.

MORE CAMPUS COVERAGE

Jelks said the goal of Reach.AI is to show some correlation between every aspect of the data. For example, Jelks
explained how the data will one day uncover how one area's susceptibility toward the flu relates to the coronavirus,
food insecurity, employment rates and education.

Currently, Patel said the team has enough data to focus on most counties in Pennsylvania.

"I would like to see Reach.AI become a sort of solution-oriented business," Patel said. "Once you find a determinant
that makes a county lesser, we want to provide them tools to actually [grow to] be above average."

The team is in the process of developing different visuals - different types of graphs, displays and lists of resources
- that will be accessible to users "during rough times," according to Patel.

As the project continues to develop, Jelks said they are trying to ensure community members the necessary
support so they won't have to "suffer."

                                                                                                      Page 3 of 3
     Penn State students, alumnus develop Reach.AI to address health disparities within marginalized communities

While Jelks' process does include networking with industry experts to gain their input on the project, he said his
belief in service is a driving factor for his work.

"There's always going to be someone out there in a far worse situation than what you're in. Even if you're having a
bad day, someone's having a worse day," Jelks said. "That's what motivates me the most. We're the next leaders of
the free world."

Jelks said his key to getting where he is today revolves around the idea of writing everything out.

"I have a dream journal, so a lot of my ideas come from being asleep, waking up and then writing that stuff down
and making sense of it," Jelks said.

Jelks said his one piece of advice for Penn State students is to "focus on how you can make the most out of your
Penn State story."

"How can you really stand out and make a difference in your community?"

MORE CAMPUS COVERAGE

+2

Penn State alumnus Robert Boyce publishes Western adventure novel he began 34 years ago

Penn State alumnus Robert Boyce always wanted to write a Western novel complete with action ...


Load-Date: July 7, 2021


  End of Document

                                                                                                       Page 1 of 1
                S. Korean startup HoneyNaps' sleep diagnostic software Somnum earns U.S. approval




    S. Korean startup HoneyNaps' sleep diagnostic software Somnum earns
                               U.S. approval


                                                       ASEAN Tribune
                                                   August 21, 2023 Monday



Copyright 2023 ASEAN Tribune All Rights Reserved




Length: 227 words

Body


 21 Aug 2023 (Yonhap News Agency) South Korean digital health care startup HoneyNaps Co. said Monday its
artificial intelligence-based sleep diagnostic software, Somnum, has won approval for sale from U.S. drug
authorities.

The U.S. Food and Drug Administration (FDA) granted Section 510(k) clearance, or premarket notification, to
Somnum, demonstrating that the medical device is safe and effective. The cleared device does not need to win
premarket approval before hitting the shelves.

It is the first FDA approval won by a sleep analysis solution developed by a South Korean company. Two U.S.
companies -- EnsoData's EnsoSleep and Cerebra Medical's Cerebra Sleep System -- have received FDA
clearance.

"The FDA has strengthened its review process of AI-based health care products," HoneyNaps said in a release.
"We have carried out clinical trials in the U.S. for the past three years to meet the FDA criteria."

Somnum is software with an AI algorithm that collects and analyzes sleep data, mainly the vital signs of its user,
and predicts disease by applying it to a clinical data set. Its AI has been trained with more than 18 million sets of
related data over the past eight years.

HoneyNaps said the FDA approval will help the company go public in South Korea and put more effort into
expanding its business horizons to include cerebral and cardiovascular diseases.


Load-Date: August 22, 2023


  End of Document

                                                                                                        Page 1 of 2
                                   Does AI or ChatGPT provide accurate medical advice?




                   Does AI or ChatGPT provide accurate medical advice?
                                                        The Deseret News
                                                  December 11, 2023 Monday



Copyright 2023 The Deseret News Publishing Co. All Rights Reserved

Length: 721 words
Byline: Lois M. Collins

Body

For people used to searching online for medical information, consulting artificial intelligence may be more of a skip
than a leap. But be warned: A new study from Long Island University found that ChatGPT answered three dozen
medication-related questions correctly or completely only a quarter of the time.

The questions, which had actually been asked of the university's College of Pharmacy drug information service,
suggest that Dr. ChatGPT leaves a lot to be desired.

The findings were presented last week at the annual meeting of the American Society for Health-Systems
Pharmacists in Anaheim, California.

As CNN reported, the queries "often yielded inaccurate - or even dangerous - responses."

Of the 29 questions the chatbot missed, researchers said the artificial intelligence did not directly answer 11 of them
and 10 were inaccurate. A dozen of the answers were incomplete, as well.

Sometimes, the artificial intelligence response was dangerous, as when ChatGPT was asked if it was OK to take
COVID-19 antiviral Paxlovid with the blood pressure medication verapamil. Although ChatGPT said there would be
no ill effects, adverse interactions have been documented - including significant drops in blood pressure, causing
fainting and dizziness.

"Using ChatGPT to address this question would put a patient at risk for an unwanted and preventable drug
interaction," study co-author Sara Grossman, an associate professor of pharmacy practice at Long Island
University, told CNN.

The researchers asked ChatGPT to provide scientific references for its responses. It could do so only for about 20%
of them - and each of those contained well-formatted fake references. Past studies have shown the AI "even
includes the names of actual authors who have published in journals," as Firstpost.com reported.

Per CNN, "The Long Island University study is not the first to raise concerns about ChatGPT's fictional citations.
Previous research has also documented that, when asked medical questions, ChatGPT can create deceptive
forgeries of scientific references, even listing the names of real authors with previous publications in scientific
journals."

                                                                                                     Page 2 of 2
                               Does AI or ChatGPT provide accurate medical advice?

In this study, the chatbot also made a potentially dangerous mistake. Asked to convert doses of a muscle relaxant
that's injected into the spine, the software calculation was off by a "factor of 1,000."

Related

    •     The future is here

    •     Chatbot's AI hits 77% for correct medical diagnosis in Boston study

OpenAI, which developed ChatGPT, tells users not to rely on the artificial intelligence for medical advice or for
"diagnostic or treatment services for serious medical conditions."

The recommendation is echoed by health experts and others.

"AI-based tools have the potential to impact both clinical and operational aspects of care, said Gina Luchen,
pharmacist and director of digital health and data for the American Society of Health-System Pharmacists, told Fox
Business. "Pharmacists should remain vigilant stewards of patient safety by evaluating the appropriateness and
validity of specific AI tools for medication-related uses and continuing to educate patients on trusted sources for
medical information.

"According to the study's findings, anyone considering using ChatGPT for drug-related information - including
patients and health care professionals - should proceed with caution. They should speak with professionals directly
for any medical advice, whether utilizing the paid or free version with access to real-time data," Firstpost.com
reported.

ChatGPT has broad appeal elsewhere. According to CNBC, "ChatGPT broke records as the fastest-growing
consumer app in history, and now has about 100 million weekly active users, along with more than 92% of Fortune
500 companies using the platform, according to OpenAI. Earlier this year, Microsoft invested an additional $10
billion in the company, making it the biggest AI investment of the year, according to PitchBook, and OpenAI is
reportedly in talks to close a deal that would lead to an $86 billion valuation."

As for diagnosis, a study published in August in the Journal of Medical Internet Research, found that ChatGPT was
roughly 72% accurate when it came to general decision-making, "from coming up with possible diagnoses to
making final diagnoses and care management decisions," per a Mass General Brigham news release.


Load-Date: December 11, 2023


  End of Document

                                                                                                          Page 1 of 1
                               Surgalign receives FDA clearance for surgical guidance system




            Surgalign receives FDA clearance for surgical guidance system
                                                   Chicago Daily Herald
                                               January 19, 2022 Wednesday
      WEB EditioneBlast EditionCLFM EditionMC1 EditionMC3 EditionMD1 EditionMF12 EditionML2 EditionNC
     EditionNC1 EditionNC14 EditionNC14C EditionNC2 EditionNC3 EditionNC4 EditionNL1 EditionNM1 Edition



Copyright 2022 Paddock Publications, Inc.

Section: BUSINESS; Pg. 0
Length: 213 words

Body


Surgalign receives FDA clearance for surgical guidance system Surgalign receives FDA clearance for surgical
guidance system DEERFIELD — Surgalign Holdings Inc. said Tuesday it has received initial U.S. Food &amp; Drug
Administration clearance for its HOLO Portal surgical guidance system for use within lumbar spine procedures.
"Receiving the initial clearance for the HOLO Portal system is a significant milestone and represents a critical step
toward building the foundation of the digital surgery of the future," said Terry Rich, Surgalign's president and chief
executive officer. "With clearance in hand for our guidance application, our near-term focus is getting the platform
into the hands of surgeons as we work toward a market release." The HOLO Portal system is the world's first
artificial intelligence-driven, augmented reality guidance system for spine surgery and the first clinical application of
Surgalign's HOLOTM AI digital health platform, the company said. "While the current capabilities of the HOLO
Portal system have the potential to offer a quantum leap in the way surgical procedures are performed, we have a
much larger vision for our HOLO AI digital health platform across a variety of health care specialties and
throughout the care continuum," Rich said.


Load-Date: January 19, 2022


  End of Document

                                                                                                    Page 1 of 2
                                     President signs executive order for guardrails on AI




                      President signs executive order for guardrails on AI
                                           The Columbian (Vancouver, Washington)
                                                    October 31, 2023 Tuesday



Copyright 2023 The Columbian Publishing Co. All Rights Reserved

Section: NATION; Pg. A5
Length: 430 words
Byline: JOSH BOAK and MATT O'BRIEN Associated Press
Highlight: Associated Press files

President Joe Biden speaks about artificial intelligence in the Roosevelt Room of the White House on July 2 in
Washington. Biden on Monday signed a sweeping executive order to guide the development of artificial intelligence.

Body

Biden seeks to balance tech needs with protections
WASHINGTON - President Joe Biden on Monday signed an ambitious executive order on artificial intelligence
that seeks to balance the needs of cutting-edge technology companies with national security and consumer
rights, creating an early set of guardrails that could be fortified by legislation and global agreements.

Before signing the order, Biden said AI is driving change at "warp speed" and carries tremendous potential
as well as perils.

"AI is all around us," Biden said. "To realize the promise of AI and avoid the risk, we need to govern
this technology."

The order is an initial step that is meant to ensure that AI is trustworthy and helpful, rather than
deceptive and destructive. The order - which will likely need to be augmented by congressional action -
seeks to steer how AI is developed so that companies can profit without putting public safety in jeopardy.

Using the Defense Production Act, the order requires leading AI developers to share safety test results
and other information with the government. The National Institute of Standards and Technology is to create
standards to ensure AI tools are safe and secure before public release.

The Commerce Department is to issue guidance to label and watermark AI-generated content to help
differentiate between authentic interactions and those generated by software. The order touches on matters
of privacy, civil rights, consumer protections, scientific research and worker rights.
White House chief of staff Jeff Zients recalled Biden giving his staff a directive when formulating the
order to move with urgency.
"We can't move at a normal government pace," Zients said the Democratic president told him. "We have to
move as fast, if not faster, than the technology itself."

In Biden's view, the government was late to address the risks of social media and now U.S. youth are
grappling with related mental health issues. AI has the positive ability to accelerate cancer research,
model the impacts of climate change, boost economic output and improve government services, among other

                                                                                             Page 2 of 2
                              President signs executive order for guardrails on AI

benefits. But it could also warp basic notions of truth with false images, deepen racial and social
inequalities and provide a tool to scammers and criminals.

With the European Union nearing final passage of a sweeping law to rein in AI harms and Congress still in
the early stages of debating safeguards, the Biden administration is "stepping up to use the levers it can
control," said digital rights advocate Alexandra Reeve Givens, president of the Center for Democracy &
Technology.



Load-Date: February 5, 2024


  End of Document

                                                                                                    Page 1 of 3
  Parkland survivor creates wellness app; Parkland school shooting survivor develops Joy, an app built on AI that
                                                helps people heal




 Parkland survivor creates wellness app; Parkland school shooting survivor
           develops Joy, an app built on AI that helps people heal
                                                Richmond Times Dispatch (Virginia)
                                                    September 28, 2023 Thursday
                                                             01 Edition



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Richmond Times-Dispatch, Richmond, VA

Section: MAIN; Pg. 15A
Length: 881 words
Byline: BARBARA ORTUTAY Associated Pres

Body


Kai Koerber was a junior at Marjory Stoneman Douglas High School when a gunman murdered 14 students and
three staff members there on Valentine's Day in 2018. Seeing his peers - and himself - struggle with returning to
normal, he wanted to do something to help people manage their emotions on their own terms.

While some of his classmates at the Parkland, Florida, school have worked on advocating for gun control, entered
politics or simply took a step back to heal and focus on their studies, Koerber's background in technology - he'd
originally wanted to be a rocket scientist - led him in a different direction: to build a smartphone app.

The result was Joy: AI Wellness Platform, which uses artificial intelligence to suggest bite-sized mindfulness
activities for people based on how they are feeling. The algorithm Koerber's team built is designed to recognize how
a person feels from the sound of their voice - regardless of the words or language they speak.

"In the immediate aftermath of the tragedy, the first thing that came to mind after we've experienced this horrible,
traumatic event - how are we going to personally recover?" he said. "It's great to say OK, we're going to build a
better legal infrastructure to prevent gun sales, increased background checks, all the legislative things. But people
really weren't thinking about ... the mental health side of things."

Like many of his peers, Koerber said he suffered from post-traumatic stress disorder for a "very long time" and only
recently has it gotten a little better.

"So when I came to Cal, I was like, let me just start a research team that builds some groundbreaking AI and see if
that's possible," said the 23-year-old, who graduated from the University of California, Berkeley earlier this year.
"The idea was to provide a platform to people who were struggling with, let's say sadness, grief, anger ... to be able
to get a mindfulness practice or wellness practice on the go that meets our emotional needs on the go."

                                                                                                    Page 2 of 3
  Parkland survivor creates wellness app; Parkland school shooting survivor develops Joy, an app built on AI that
                                                helps people heal

He said it was important to offer activities that can be done quickly, sometimes lasting just a few seconds, wherever
the user might be. It wasn't going to be your parents' mindfulness practice.

"The notion of mindfulness being a solo activity or something that's confined to sitting in your room breathing is
something that we're very much trying to dispel," Koerber said.

Mohammed Zareef-Mustafa, a former classmate of Koerber's who's been using the app for a few months, said the
voice-emotion recognition part is "different than anything I've ever seen before."

"I use the app about three times a week, because the practices are short and easy to get into. It really helps me
quickly de-stress before I have to do things like job interviews," he said.

To use Joy, you simply speak into the app. The AI is supposed to recognize how you are feeling from your voice,
then suggest short activities.

It doesn't always get your mood right, so it's possible to manually pick your disposition. Yet another activity helps
you practice making an effective apology. Another has you write a letter to your future self, with a pen and a paper -
remember those? Feeling sad? A suggestion pops up asking you to track how many times you've laughed over a
seven-day period and tally it up at the end of the week to see what moments gave you a sense of joy, purpose or
satisfaction.

The iPhone app is available for a $8 monthly subscription, with a discount if you subscribe for a year. It's a work in
progress, and as it goes with AI, the more people use it, the more accurate it becomes.

"Kai is a leader of this next generation who are thinking intentionally and with focus about how to use technology to
meet the mental, physical, and climate crises of our times," said Dacher Keltner, a professor at UC Berkeley and
Koerber's faculty adviser on the project. "It comes out of his life experience, and, unlike past technologists, he
seems to feel this has to be what technology does, make the world healthier."

A plethora of wellness apps on the market claim to help people with mental health issues, but it's not always clear
whether they work, said Colin Walsh, a professor of biomedical informatics at Vanderbilt University who has studied
the use of AI in suicide prevention. According to Walsh, it is feasible to take someone's voice and glean some
aspects of their emotional state.

"The driver is there's a huge demand there, or at least the perception of a huge demand there" Walsh said of the
explosion of wellness and mental health apps in the past few years. "Despite the best of intentions with our current
system - and it does a lot of good work - obviously, there's still gaps. So I think people see technology as a tool to
try to bridge that."

Koerber said people tend to forget, after mass shootings, that survivors don't just "bounce back right away" from the
trauma they experienced. It takes years to recover.

"This is something that people carry with them, in some way, shape or form, for the rest of their lives," he said.

His work has also been slower and deliberate than tech entrepreneurs of the past.

"I guess young Mark Zuckerberg was very 'move fast and break things,'" he said. "And for me, I'm all about building
quality products that, you know, serve social good in the end."



Graphic

                                                                                                    Page 3 of 3
  Parkland survivor creates wellness app; Parkland school shooting survivor develops Joy, an app built on AI that
                                                helps people heal

With the fall school semester having already started or soon to get under way in most of the U.S., school safety is
top of mind, with what to do in the case of a school shooting becoming a regular part of planning.Last year, there
were 47 school shootings. That's just shy of the previous year's 52 and significantly higher than the two years
before that. However, those numbers are lower, in part due to students being in virtual learning due to the
pandemic. The deadliest school shooting from last school year was at a private Christian school in Nashville where
the gunman shot through glass to be able to get access inside.SEE MORE: Shots again fired at site of Parkland
school massacre in reenactmentSince the Nashville shooting in March, Tennessee lawmakers approved $230
million for enhanced safety and mental health. In Denver, armed officers are returning to public schools in the
fall.And in Florida, dozens of state laws are focused on school safety.Districts in other states are allowing certain
staff members to carry guns on campus or installing collapsible bulletproof rooms, and in some places, resource
officers are back to walking school grounds.Scripps News reporters nationwide have been closely following safety
changes like this in recent years. They explain the changes their local community schools are making to address
safety concerns this year. Newsy Kai Koerber, seen July 27 in Berkeley, Calif., was a junior at Marjory Stoneman
Douglas High School when a gunman murdered 14 students and three staff members on Valentine's Day in 2018.
Godofredo A. Vásquez, Associated Press Kai Koerber, seen July 27 in Berkeley, Calif., was a junior at Marjory
Stoneman Douglas High School when a gunman murdered 14 students and three staff members on Valentine's
Day in 2018. Godofredo A. Vásquez, Associated Press Kai Koerber, seen July 27 in Berkeley, Calif., was a junior at
Marjory Stoneman Douglas High School when a gunman murdered 14 students and


Load-Date: September 28, 2023


  End of Document

                                                                                                      Page 1 of 3
     School of Public Health kicks off 10-year anniversary celebrations with reception - The Brown Daily Herald




     School of Public Health kicks off 10-year anniversary celebrations with
                       reception - The Brown Daily Herald
                                          The Brown Daily Herald: Brown University
                                               September 27, 2023 Wednesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: UNIVERSITY-NEWS; Pg. 1
Length: 761 words
Byline: Ryan Doherty

Body


Ashish Jha, dean of SPH, wants to change the face of American public health leadership by expanding diversity.
"While the public health workforce is quite diverse, the leadership of public health has not really reflected the
experiences of people across America," he said.

Media by Ryan Doherty

| The Brown Daily Herald

By Ryan Doherty Senior Staff Writer

September 27, 2023 | 10:02pm EDT

With clinking glasses and fizzing champagne, the School of Public Health celebrated its 10-year anniversary in
Alumnae Hall on Wednesday with a toast for its past, present and future.

Public health at Brown has a history that spans longer than 10 years - the Corporation, the University's highest
governing body, recommended a graduate program in public health over a century ago. "We could be celebrating
the 107th anniversary of public health," SPH Dean Ashish Jha said during his speech at the reception.

Governor Dan McKee, who worked closely with Jha during the COVID-19 pandemic, also spoke at the event. He
issued a proclamation expressing "gratitude for (Jha and SPH's) mission towards improving the health of all
populations, especially those most vulnerable, by producing world-class public health scholarships, forging strong
community partnerships and educating the next generation of diverse public health leaders."

The reception featured what Chancellor Samuel Mencoff '78 P'11 P'15 described as an "all-star cast" while
introducing the keynote event: a conversation between Jha and President Christina Paxson P'19 P'MD'20.

ADVERTISEMENT

                                                                                                     Page 2 of 3
    School of Public Health kicks off 10-year anniversary celebrations with reception - The Brown Daily Herald

During the discussion, the pair delved into the past and future of public health as SPH works to address the next
wave of public health threats.

Paxson reflected on the creation of SPH, which she said "was not a hard decision ... because of all the work that
went into developing the plans" by previous faculty members.

Paxson and Jha both applauded SPH's commitment to teaching at all levels, from undergraduates to Ph.D.
students. They also praised the interdisciplinary nature of SPH, noting the many dual appointments held by its
faculty members.

"Everybody talks about being multidisciplinary and interdisciplinary, (but) in most places it's extremely hard," Jha
said. At Brown, however, interdisciplinary connections and dual appointments "are second nature."

"If you think about the big, pressing problems, they are not going to be solved by people who work inside the classic
structure of public health," he added. "They are going to require people working across disciplines - between
economics, sociology, human behavior, psychology, et cetera. We do that effortlessly."

As SPH reaches a double-digit age, pressing and emerging public health threats remain a crucial focus.

"Climate change (is) probably the biggest public health threat over the next decade (and) next century," Jha said.
With the advent of climate-change-related threats, "we are going to see a lot more novel outbreaks regionally and
globally" and they will require greater preparation, Jha added. In 2022, SPH opened the Pandemic Center to
improve pandemic preparedness.

Jha also discussed misinformation and evidence, warning that the arrival of artificial intelligence could reshape
public health. "AI is going to change the practice of public health in ways that we have not really thought about," he
said, adding that SPH ought to begin investing in research about AI.

In tandem with these issues, Jha also wants to diversify the face of American public health leadership. "While the
public health workforce is quite diverse, the leadership of public health has not really reflected the experiences of
people across America."

Jha highlighted the Health Equity Scholars program, which offers scholarships and leadership experiences to those
from historically underrepresented backgrounds, as an example of the SPH's pursuit of this goal.

ADVERTISEMENT

"One of the ways privilege perpetuates is through networks," he said. The Health Equity Scholars program looks to
not only train public health leaders but also "create a network of people who, after graduation, support each other
(and) promote each other."

When Paxson was asked what SPH would look like 10 years from now, she said, "If you ask people what are the
top five schools of public health in the world, I want us to be one of them."

Get The Herald delivered to your inbox daily.

Email

Ryan Doherty

Ryan Doherty is a senior staff writer covering faculty, higher education and science & research. He is a sophomore
concentrating chemistry and history who likes to partially complete crosswords in free time.


Load-Date: September 28, 2023

                                                                                                   Page 3 of 3
  School of Public Health kicks off 10-year anniversary celebrations with reception - The Brown Daily Herald


End of Document

                                                                                                            Page 1 of 2
                                       AI is too biased to be trusted in the medical field




                        AI is too biased to be trusted in the medical field
                                                  The Bullet: Mary Washington
                                                 September 23, 2021 Thursday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 713 words

Body


LEIGH HATTON

Senior Writer

It has been 65 years since the term artificial intelligence was first coined, but it still has a long way to go before this
technology belongs in medical work. As it exists, artificial intelligence does not meet the intersectional or ethical
standards that are needed for the sensitive and specific realities of health care.

AI, in general, refers to algorithms that can interpret given data, learn from this data and then execute tasks and
continue to adapt based on new data. However, this is an issue due to the data that is available to algorithms. As
Dr. Greta Bauer wrote, "because AI applications 'learn' from data produced in biased societies, they are shaped by
both information biases and societal biases. This reproduction and intensification of societal biases is therefore
unsurprising."

One well-known example is Amazon's AI hiring tool, which reviewed candidate resumes and displayed a clear bias
against women, especially for technical and engineering jobs. Another example is Microsoft's Twitter bot named
Tay, which posted racist, antisemitic and misogynistic remarks less than 24 hours after it was made public.

If these are the types of AI that are created by some of the most expansive companies in the world, it is not
surprising that many health and medical workers have expressed concern about introducing similar technologies in
their fields.

Specifically, increased intersectionality is absolutely necessary before AI is used in health fields. Intersectionality
refers to heterogeneity of race, age, gender, culture and economic status, as well as the places where these
concepts intersect.

In this case, intersectionality applies to all of the patients in a health system. The data that AIs draw from must be
representative of the entire population, not a bare minimum idea of diversity. This will require dedicated work from a
range of health and data experts, including many who encompass the scale of social intersections. Without
representative data, AIs will perpetuate biases by showing preferences for or against certain groups-similar to
Amazon's tool-or by categorizing them incorrectly in systems, as Dr. Joy Buolamwini's research concluded. Her

                                                                                                          Page 2 of 2
                                   AI is too biased to be trusted in the medical field

work involved the use of different AI to classify faces, and she found that all of them performed the most
inaccurately when it came to dark-skinned female faces.

A critical and cautious approach must be taken in terms of ethics. Programmers may aim to create fair AIs, but for
medical work, the standard definition of fairness is not just. Bauer explained, "while overall fairness approaches
may be utilitarian, generating the least bias on average across a population ... maximizing algorithmic fairness does
not substitute for addressing historical injustice or protecting the most marginalized." This type of fairness that may
be looked for in AI does not ensure that many groups are being treated justly and equitably.

On the other hand, there are some who advocate for the continued and even increased use of AI in medical work.
According to Dr. Jason Morgenstern, "AI applications have matched or outperform physicians in various domains."
Based on this evidence, hospitals and universities have integrated AI into varying daily work tasks, including
predictive analytics, identifying risk factors and analyzing records.

Yet, Morgenstern breaks down this argument when he points out that "while considerable attention has been paid
to AI in healthcare, there has been less attention on its impact in health." That is to say, research has almost
entirely been focused on how AI can be used in the field, not on how AI affects the patients and workers.

Therefore, there are potentially endless uses in medical fields where AI technology could be a helpful
advancement. However, Dr. Lisa Bowleg concludes that AIs will not be able to provide solutions for any of the
problems in the medical field without research on their exact impact in addition to "a radical reimagining of
intersectional health equity."

With the current state of this technology, it would be more harmful than helpful for it to be implemented on any level.
Until there is solid evidence that artificial intelligence in healthcare has an unbiased and beneficial impact, it should
not be used in this context.


Load-Date: April 20, 2024


  End of Document

                                                                                                            Page 1 of 2
                                       AI is too biased to be trusted in the medical field




                        AI is too biased to be trusted in the medical field
                                                  The Bullet: Mary Washington
                                                 September 23, 2021 Thursday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 713 words

Body


LEIGH HATTON

Senior Writer

It has been 65 years since the term artificial intelligence was first coined, but it still has a long way to go before this
technology belongs in medical work. As it exists, artificial intelligence does not meet the intersectional or ethical
standards that are needed for the sensitive and specific realities of health care.

AI, in general, refers to algorithms that can interpret given data, learn from this data and then execute tasks and
continue to adapt based on new data. However, this is an issue due to the data that is available to algorithms. As
Dr. Greta Bauer wrote, "because AI applications 'learn' from data produced in biased societies, they are shaped by
both information biases and societal biases. This reproduction and intensification of societal biases is therefore
unsurprising."

One well-known example is Amazon's AI hiring tool, which reviewed candidate resumes and displayed a clear bias
against women, especially for technical and engineering jobs. Another example is Microsoft's Twitter bot named
Tay, which posted racist, antisemitic and misogynistic remarks less than 24 hours after it was made public.

If these are the types of AI that are created by some of the most expansive companies in the world, it is not
surprising that many health and medical workers have expressed concern about introducing similar technologies in
their fields.

Specifically, increased intersectionality is absolutely necessary before AI is used in health fields. Intersectionality
refers to heterogeneity of race, age, gender, culture and economic status, as well as the places where these
concepts intersect.

In this case, intersectionality applies to all of the patients in a health system. The data that AIs draw from must be
representative of the entire population, not a bare minimum idea of diversity. This will require dedicated work from a
range of health and data experts, including many who encompass the scale of social intersections. Without
representative data, AIs will perpetuate biases by showing preferences for or against certain groups-similar to
Amazon's tool-or by categorizing them incorrectly in systems, as Dr. Joy Buolamwini's research concluded. Her

                                                                                                          Page 2 of 2
                                   AI is too biased to be trusted in the medical field

work involved the use of different AI to classify faces, and she found that all of them performed the most
inaccurately when it came to dark-skinned female faces.

A critical and cautious approach must be taken in terms of ethics. Programmers may aim to create fair AIs, but for
medical work, the standard definition of fairness is not just. Bauer explained, "while overall fairness approaches
may be utilitarian, generating the least bias on average across a population ... maximizing algorithmic fairness does
not substitute for addressing historical injustice or protecting the most marginalized." This type of fairness that may
be looked for in AI does not ensure that many groups are being treated justly and equitably.

On the other hand, there are some who advocate for the continued and even increased use of AI in medical work.
According to Dr. Jason Morgenstern, "AI applications have matched or outperform physicians in various domains."
Based on this evidence, hospitals and universities have integrated AI into varying daily work tasks, including
predictive analytics, identifying risk factors and analyzing records.

Yet, Morgenstern breaks down this argument when he points out that "while considerable attention has been paid
to AI in healthcare, there has been less attention on its impact in health." That is to say, research has almost
entirely been focused on how AI can be used in the field, not on how AI affects the patients and workers.

Therefore, there are potentially endless uses in medical fields where AI technology could be a helpful
advancement. However, Dr. Lisa Bowleg concludes that AIs will not be able to provide solutions for any of the
problems in the medical field without research on their exact impact in addition to "a radical reimagining of
intersectional health equity."

With the current state of this technology, it would be more harmful than helpful for it to be implemented on any level.
Until there is solid evidence that artificial intelligence in healthcare has an unbiased and beneficial impact, it should
not be used in this context.


Load-Date: September 23, 2021


  End of Document

                                                                                                            Page 1 of 2
                                 AI tools are keeping hospital patients alive and well; Opinions




             AI tools are keeping hospital patients alive and well; Opinions
                                                 The Chronicle (Willimantic, Connecticut)
                                                     November 8, 2023 Wednesday



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 The Chronicle, Willimantic, CT.

Section: OPINIONS; Pg. 5
Length: 764 words
Byline: LEANA S.WEN

Body


Artificial intelligence is already widely used in health care - to enhance cancer detection, reduce paperwork and
tailortreatments. The question is, does it actually improve patient outcomes? Yes. Kaiser Permanente has
demonstrated how AI help can improve the quality and efficiency of patient care and even save lives. For more than
a decade, Kaiser Permanente - the largest nonprofit integrated health-care delivery system in the country - has
been developing an AI tool that detects signs of clinical deterioration in hospital patients to identify those at risk of
getting much sicker. This is a fundamental skill that doctors hone throughout their medical training. An increase in
heart rate and decrease in blood pressure could mean an infection is spreading. A repeat chest X-ray showing
more fluid in the lungs could signify weakening heart function. A rising creatinine level could indicate worsening
kidney failure.

The problem is that clinicians receive many of these inputs for all the patients they care for, and worrying trends can
get missed until a patient becomes very ill. Hospitals have tried a variety of methods, including beeps and flashing
alerts for each abnormal vital sign or lab test. But these can create "alarm fatigue;' which means many alerts end up
being ignored. Also, when clinicians are continuously bombarded with new data, it can be difficult to discern the
patterns that suggest there is a problem.

Another challenge is the workflow itself. Results from labs and imaging studies usually come in piecemeal. A
physician might check for updates every few hours, but this might not be often enough to pick up on an acute
worsening. And if nurses or other members of the care team find the emerging problem first, there can still be a
delay in the physician arriving to the patient's bedside.

Kaiser Pennanente's AI tool addresses several of these obstacles. Predictive algorithms have been built to account
for a patient's preexisting medical conditions, vital signs, laboratory tests, bedside nurse reports and other factors.
And the tool receives hourly input from electronic medical records. If all this data reveals a significant risk of decline,
an alert is issued.

The key difference in Kaiser's use of AI is what happens next. First, the alert is reviewed by an off-site team of
nurses who examine what triggered it. Then, if the patient needs to be evaluated in person, they have the patient

                                                                                                            Page 2 of 2
                            AI tools are keeping hospital patients alive and well; Opinions

assessed by the hospital's rapid-response team, which then works with the patient's physician to determine next
steps.

From 2016 to 2019, this Al-powered alert system was rolled out to all 21 of Kaiser Pennanente's Northern California
hospitals. Researchers then examined the outcomes of patients it flagged vs. those who would have triggered an
alert if the system had been active at the time of their hospitalization. Their results, published in the New England
Journal of Medicine, show there was a 16 percent lower mortality rate among patients who benefited from the AI
tool. That's equivalent to 520 deaths prevented per year.

"What AI does really well is to integrate a lot of different inputs," Andrew Bindman, Kaiser Pennanente's chief
medical officer, told me, 'To identify patterns that are sometimes less visible at an early stage to our clinicians." AI
replicates clinicians' pattern-recognition abilities but also pulls in information more frequently, enabling it to identify
trends faster.

Like other health-care leaders who are enthusiastic about AI's use in health care, Bindman stresses that it is not
meant to replace human clinicians. Rather, it picks up data that humans might miss. The AI alert system still
requires ongoing assessment by nurses and doctors. Because this tool deploys two additional teams, the remote
nurses who conduct the initial review and the in-person rapid-response team, it is both high-tech and high-touch.

Kaiser Permanente's results are not unique. A series of studies published last yearinNature Medicine analyzed
patient outcomes at five hospitals, including Johns Hopkins Hospital in Baltimore, after an AI tool was deployed to
identify patients who might have sepsis. This whole-body infection is a leading cause of in-hospital death, but it can
be treated with antibiotics if it's caught early enough. The AI tool resulted in lower mortality as well as less organ
failure from sepsis and shorter hospitalizations. Hospitals are demonstrating the good it can do to improve health
and make care safer. Leanct S. Wen is a pro fessor at George Washington University'sMilken Institute School of
Public Health


Load-Date: November 9, 2023


  End of Document

                                                                                                            Page 1 of 2
                                 AI tools are keeping hospital patients alive and well Opinions




             AI tools are keeping hospital patients alive and well; Opinions
                                               The Herald (New Britain, Connecticut)
                                                    November 8, 2023 Wednesday



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 The New Herald, New Britain, CT.

Section: OPINIONS; Pg. 5
Length: 764 words
Byline: LEANA S.WEN

Body


Artificial intelligence is already widely used in health care - to enhance cancer detection, reduce paperwork and
tailortreatments. The question is, does it actually improve patient outcomes? Yes. Kaiser Permanente has
demonstrated how AI help can improve the quality and efficiency of patient care and even save lives.

For more than a decade. Kaiser Permanente - the laigest nonprofit integrated health-care delivery system in the
country - has been developing an AI tool that detects signs of clinical deterioration in hospital patients to identify
those at risk of getting much sicker. This is a fundamental skill that doctors hone throughout their medical training.
An increase in heart rate and decrease in blood pressure could mean an infection is spreading. A repeat chest X-
ray showing more fluid in the lungs could signify weakening heart function. A rising creatinine level could indicate
worsening kidney failure.

The problem is that clinicians receive many of these inputs for all the patients they care for, and worrying trends can
get missed until a patient becomes very ill. Hospitals have tried a variety of methods, including beeps and flashing
alerts for each abnormal vital sign or lab test. But these can create "alarm fatigue," which means many alerts end
up being ignored. Also, when clinicians are continuously bombarded with new data it can be difficult to discern the
patterns that suggest there is a problem.

Another challenge is the workflow itself. Results from labs and imaging studies usually come in piecemeal. A
physician might check for updates every few hours, but this might not be often enough to pick up on an acute
worsening. And if nurses or other members of the care team find the emeiging problem first, there can still be a
delay in the physician arriving to the patient's bedside.

Kaiser Permanente's AI tool addresses several of these obstacles. Predictive algorithms have been built to account
for a patient's preexisting medical conditions, vital signs, laboratory tests, bedside nurse reports and other factors.
And the tool receives hourly input from electronic medical records. If all this data reveals a significant risk of decline,
an alert is issued.

The key difference in Kaiser's use of AI is what happens next. First, the alert is reviewed by an off-site team of
nurses who examine what triggered it. Then, if the patient needs to be evaluated in person, they have the patient

                                                                                                            Page 2 of 2
                             AI tools are keeping hospital patients alive and well Opinions

assessed by the hospital's rapid-response team, which then works with the patient's physician to determine next
steps.

From 2016 to 2019, this Al-powered alert system was rolled out to all 21 of Kaiser Permanente's Northern California
hospitals. Researchers then examined the outcomes of patients it flagged vs. those who would have triggered an
alert if the system had been active at the time of their hospitalization. Their results, published in the New England
Journal of Medicine, show there was a 16 percent lower mortality rate among patients who benefited from the AI
tool. That's equivalent to 520 deaths prevented per year.

"What AI does really well is to integrate a lot of different inputs;' Andrew Bindman, Kaiser Permanente's chief
medical officer, told me, 'To identify patterns that are sometimes less visible at an early stage to our clinicians." AI
replicates clinicians' pattern-recognition abilities but also pulls in information more frequently, enabling it to identify
trends faster.

Like other health-care leaders who are enthusiastic about AI's use in health care, Bindman stresses that it is not
meant to replace human clinicians. Rather, it picks up data that humans might miss. The AI alert system still
requires ongoing assessment by nurses and doctors. Because this tool deploys two additional teams, the remote
nurses who conduct the initial review and the in-person rapid-response team, it is both high-tech and high-touch.

Kaiser Permanente "s results are not unique. A series of studies published last yearinNature Medicine analyzed
patient outcomes at five hospitals, including Johns Hopkins Hospital in Baltimore, after an AI tool was deployed to
identify patients who might have sepsis. This whole-body infection is a leading cause of in-hospital death, but it can
be treated with antibiotics if it's caught early enough. The AI tool resulted in lower mortality as well as less oigan
failure from sepsis and shorter hospitalizations. Hospitals are demonstrating the good it can do to improve health
and make care safer. Leana S. Wen is a pro fessor at George Washington University'sMilken Institute School of
Public Health


Load-Date: November 9, 2023


  End of Document

                                                                                                       Page 1 of 3
     Software developer (and other coding careers) Blockchain jobs Virtual reality jobs Big data analyst Content
                             creator AI jobs Mental health jobs Data broker Augme....




    Software developer (and other coding careers) Blockchain jobs Virtual
 reality jobs Big data analyst Content creator AI jobs Mental health jobs Data
     broker Augmented reality developer Drone expert/pilot Entrepreneur
                                                Chicago Daily Herald
                                                March 17, 2023 Friday



Copyright 2023 Paddock Publications, Inc.

Section: REFLEJOS; Pg. 23
Length: 1368 words
Byline: Futurelearn.com

Body


The world is evolving, and becoming ever more digital, but what does that mean for your education and career? In
this article, we dive into 14 jobs set to thrive in the future. So, whether you're fresh out of school or university, or
looking to switch careers, this article is for you. Discover which new jobs will be around for decades to come. With
your newfound knowledge, you'll be better placed to plan your education and training in order to reap long-term
benefits.

Here's to the future! Coding is fast becoming one of the most sought-after skills for technology companies and
between researcher groups. In a survey of over 500 tech workers and employers by Remote, 37% of respondents
said that software developers will be the most important tech job in the future. That makes software developers the
most highly-ranked job overall in the survey. The increasing importance of programming has caused some
European countries to add coding to the primary school curriculum. Reskilling to make this career change can even
increase your salary by 38%. According to PwC's Time for trust report, blockchain technology will enhance more
than 40 million jobs globally by 2030, earning blockchain jobs our number two spot. The future of finance is
definitely going to be heavily influenced by the rise of blockchain technology. Most people not familiar with
blockchain technology will have still heard about it – usually its association with cryptocurrencies like Bitcoin.
However, blockchains are not just used for cryptocurrency. They're standalone technologies that can be useful
across industries. They are already been used in the automotive industry to record the history of vehicles to prevent
seller fraud. Nobody will be able to lie about the car's mileage or maintenance when all this information is recorded
on the blockchain and 100% secure. If we had to choose an industry that's going to be booming for the next few
decades, virtual reality feels like a pretty good bet. The latest statistics show that the global market size of AR and
VR is forecast to reach $296.9 billion in 2024, compared to the $30.7 billion market size that was registered in 2021.
That's nearly a tenfold increase. With the 2021 announcement of the Metaverse, a series of interconnected virtual
worlds created by Meta (formerly known as Facebook), it's increasingly clear that VR and AR will be hugely
impactful in the near and far future. From marketing departments to video game developers, virtual reality is going
to be a cornerstone moment for the job market and the whole of society. The world of big data has flourished over
the past few years, and that's not about to stop. According to reports by Statista, the global big data analytics

                                                                                                      Page 2 of 3
    Software developer (and other coding careers) Blockchain jobs Virtual reality jobs Big data analyst Content
                            creator AI jobs Mental health jobs Data broker Augme....

market is likely to grow by 30 per cent by 2025, generating revenue of over $68 billion. Data analysts are going to
become the new leaders in the niche of business development. And they are already taking over the department
thanks to big data and the ability to analyse huge amounts of information for the benefit of their employers. There's
been a huge and undeniable boom in content creators over the past few years. But what exactly is a content
creator? This is a relatively broad term that captures anyone who creates content for digital channels. Still, the most
famous kind of content creator is the social media influencer – you can read all about influencer marketing in our
blog post. With more content being consumed daily than ever before – after all, global online content consumption
doubled in 2020 as a result of the pandemic – the demand for content creators is only set to grow in the future.
From fashion bloggers to true crime vloggers, the possibilities for this career path are pretty much endless. You'll
need to be pretty social media savvy, so check out our Digital Marketing Content Creation and our Instagram
Marketing Essentials courses to get started. You might also want to brush up on your copywriting skills. Artificial
Intelligence (AI) is much further along the process compared to virtual reality. With Elon Musk talking of putting
chips in peoples' heads to create superhumans, the possibilities of AI technology really do open your eyes. But AI
is not just about creating a new generation of humans. It can be about making functional robots and enhancing
business processes. The developments in AI are almost limitless, which means these types of jobs aren't going
anywhere fast. You may be thinking, if AI becomes better, smarter and more widespread, won't more human
workers be out of a job? However, PwC's study on AI found that "any job losses from automation are likely to be
broadly offset in the long run by new jobs created as a result of the larger and wealthier economy made possible by
these new technologies." Many people in society are working hard to reduce the stigma associated with mental
health problems, opening the door for people to seek help and use professional mental health services. But these
mental health worker jobs won't be going anywhere either. Just as people will always need doctors and nurses, we
will continue to need mental health specialists to help us get through tough times. What's more, skills gap studies
have found that mental health skills appeared in unique job postings 230% more in 2021 compared to 2016. The
recent pandemic, recessions, environmental worries and even a boom in remote working could contribute to further
demand for psychologists and mental health organizations. The idea is simple. These data brokers will be
responsible for facilitating business agreements between data companies and those who want to buy chunks of
data. They will make sure the buyer gets their data and that the selling company receives their money. All the while,
ensuring that the data is not shared further, maintaining the integrity of the new data market. The amount of data
online is growing exponentially every day – the current estimate of how much data is created per day is 1.145 trillion
MB – so we're pretty confident that data brokers will have job security for many years to come. Did you know that
the infamous Pokémon Go game was an April Fool's Day joke that went on to make an insane amount of money?
We're talking billions – as of 2022, the total revenue is over six billion US dollars. The reason for its success was
that it was entirely innovative for the mobile gaming world. Combining a franchise that millennials grew up with and
augmented reality was a masterstroke. Augmented reality changed the face of gaming and set a new bar, but it is
proving effective in other industries like fashion, where augmented reality wardrobes enable you to try on clothes
from home. Drones are becoming more useful and popular by the day. In fact, The Association for Unmanned
Vehicle Systems International predicts that by the year 2025, at least 100,000 jobs will be created for drone pilots.
Drones can help us provide medical supplies safely, assess building structures with ease, and revolutionise delivery
services. Drones are becoming part of society's furniture and are only going to become more present over the next
decade. With that in mind, drone experts will be needed to manufacture these machines, maintain them, and
arguably the most fun job of all – fly them. If you want to become a drone engineer or drone pilot, then we have
good news for you. Expect to see more of these jobs become widely available across sectors in the not-so-distant
future. It is, however, important to be aware of the challenges and legal restrictions surrounding drone use, which is
why our courses on drone safety for managers and using drones for security purposes might be useful to you. Don't
forget that society is more entrepreneurial than ever before. Fuelled by the internet and technological
advancements, the everyday person now has a better opportunity to start their own business or a small empire.
With further tech milestones being met, like those listed above, these opportunities to start your own business are
only going to get bigger. If you have an idea or business dream, there has never been a better time to learn the
entrepreneurial ropes and give your idea a chance to succeed.


Load-Date: March 17, 2023

                                                                                                    Page 3 of 3
  Software developer (and other coding careers) Blockchain jobs Virtual reality jobs Big data analyst Content
                          creator AI jobs Mental health jobs Data broker Augme....



End of Document

                                                                                                        Page 1 of 4
                    AI May Be On Its Way To Your Doctor's Office, But It's Not Ready To See Patients




    AI May Be On Its Way To Your Doctor's Office, But It's Not Ready To See
                                  Patients
                                                    The Free Press (Tampa, Florida)
                                                             May 12, 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 The Free Press

Section: HEALTH
Length: 1550 words
Byline: National News

Body


AI Doctors AI Doctors By Darius Tahir, TFP File Photo

What use could health care have for someone who makes things up, can't keep a secret, doesn't really know
anything, and, when speaking, simply fills in the next word based on what's come before? Lots, if that individual is
the newest form of artificial intelligence, according to some of the biggest companies out there.

Companies pushing the latest AI technology known as "generative AI" are piling on: Google and Microsoft want to
bring types of so-called large language models to health care. Big firms that are familiar to folks in white coats but
maybe less so to your average Joe and Jane are equally enthusiastic: Electronic medical records giants Epic and
Oracle Cerner aren't far behind. The space is crowded with startups, too.

The companies want their AI to take notes for physicians and give them second opinions assuming they can keep
the intelligence from "hallucinating" or, for that matter, divulging patients' private information.

Brandon TMS May Brandon TMS May

In the news: Elite DNA Behavioral Health Expands With New Mental And Behavioral Health Center In Largo

"There's something afoot that's pretty exciting," said Eric Topol, director of the Scripps Research Translational
Institute in San Diego. "Its capabilities will ultimately have a big impact." Topol, like many other observers, wonders
how many problems it might cause like leaking patient data and how often. "We're going to find out."

The specter of such problems inspired more than 1,000 technology leaders to sign an open letter in March urging
that companies pause development on advanced AI systems until "we are confident that their effects will be
positive and their risks will be manageable." Even so, some of them are sinking more money into AI ventures.

The underlying technology relies on synthesizing huge chunks of text or other data for example, some medical
models rely on 2 million intensive care unit notes from Beth Israel Deaconess Medical Center in Boston to predict

                                                                                                        Page 2 of 4
                AI May Be On Its Way To Your Doctor's Office, But It's Not Ready To See Patients

text that would follow a given query. The idea has been around for years, but the gold rush, and the marketing and
media mania surrounding it, are more recent.

The frenzy was kicked off in December 2022 by Microsoft-backed OpenAI and its flagship product, ChatGPT, which
answers questions with authority and style. It can explain genetics in a sonnet, for example.

Brandon TMS May Brandon TMS May

In the news: Grand Hyatt In Tampa Evacuated After 11th-Floor Fire, 9 People Transported With Minor Injuries

OpenAI, started as a research venture seeded by Silicon Valley elites like Sam Altman, Elon Musk, and Reid
Hoffman, has ridden the enthusiasm to investors' pockets. The venture has a complex, hybrid for- and nonprofit
structure. But a new $10 billion round of funding from Microsoft has pushed the value of OpenAI to $29 billion, The
Wall Street Journal reported. Right now, the company is licensing its technology to companies like Microsoft and
selling subscriptions to consumers. Other startups are considering selling AI transcription or other products to
hospital systems or directly to patients.

Hyperbolic quotes are everywhere. Former Treasury Secretary Larry Summers tweeted recently: "It's going to
replace what doctors do hearing symptoms and making diagnoses before it changes what nurses do helping
patients get up and handle themselves in the hospital."

But just weeks after OpenAI took another huge cash infusion, even Altman, its CEO, is wary of the fanfare. "The
hype over these systems even if everything we hope for is right long term is totally out of control for the short
term," he said for a March article in The New York Times.

Few in health care believe this latest form of AI is about to take their jobs (though some companies are
experimenting controversially with chatbots that act as therapists or guides to care). Still, those who are bullish on
the tech think it'll make some parts of their work much easier.

Eric Arzubi, a psychiatrist in Billings, Montana, used to manage fellow psychiatrists for a hospital system. Time and
again, he'd get a list of providers who hadn't yet finished their notes their summaries of a patient's condition and a
plan for treatment.

In the news: Nearly Two Dozen Healthcare Groups Fighting No Taxpayer-Funded Child Sex-Change Effort In
Florida

Writing these notes is one of the big stressors in the health system: In the aggregate, it's an administrative burden.
But it's necessary to develop a record for future providers and, of course, insurers.

"When people are way behind in documentation, that creates problems," Arzubi said. "What happens if the patient
comes into the hospital and there's a note that hasn't been completed and we don't know what's been going on?"

The new technology might help lighten those burdens. Arzubi is testing a service, called Nabla Copilot, that sits in
on his part of virtual patient visits and then automatically summarizes them, organizing into a standard note format
the complaint, the history of illness, and a treatment plan.

Results are solid after about 50 patients, he said: "It's 90% of the way there." Copilot produces serviceable
summaries that Arzubi typically edits. The summaries don't necessarily pick up on nonverbal cues or thoughts
Arzubi might not want to vocalize. Still, he said, the gains are significant: He doesn't have to worry about taking
notes and can instead focus on speaking with patients. And he saves time.

"If I have a full patient day, where I might see 15 patients, I would say this saves me a good hour at the end of the
day," he said. (If the technology is adopted widely, he hopes hospitals won't take advantage of the saved time by
simply scheduling more patients. "That's not fair," he said.)

                                                                                                       Page 3 of 4
                AI May Be On Its Way To Your Doctor's Office, But It's Not Ready To See Patients

Nabla Copilot isn't the only such service; Microsoft is trying out the same concept. At April's conference of the
Healthcare Information and Management Systems Society an industry confab where health techies swap ideas,
make announcements, and sell their wares investment analysts from Evercore highlighted reducing administrative
burden as a top possibility for the new technologies.

In the news: Credit Card Companies Now Barred From Tracking Florida Gun Sales

But overall? They heard mixed reviews. And that view is common: Many technologists and doctors are ambivalent.

For example, if you're stumped about a diagnosis, feeding patient data into one of these programs "can provide a
second opinion, no question," Topol said. "I'm sure clinicians are doing it." However, that runs into the current
limitations of the technology.

Joshua Tamayo-Sarver, a clinician and executive with the startup Inflect Health, fed fictionalized patient scenarios
based on his own practice in an emergency department into one system to see how it would perform. It missed life-
threatening conditions, he said. "That seems problematic."

The technology also tends to "hallucinate" that is, make up information that sounds convincing. Formal studies
have found a wide range of performance. One preliminary research paper examining ChatGPT and Google
products using open-ended board examination questions from neurosurgery found a hallucination rate of 2%. A
study by Stanford researchers, examining the quality of AI responses to 64 clinical scenarios, found fabricated or
hallucinated citations 6% of the time, co-author Nigam Shah told KFF Health News. Another preliminary paper
found, in complex cardiology cases, ChatGPT agreed with expert opinion half the time.

Privacy is another concern. It's unclear whether the information fed into this type of AI-based system will stay
inside. Enterprising users of ChatGPT, for example, have managed to get the technology to tell them the recipe for
napalm, which can be used to make chemical bombs.

In theory, the system has guardrails preventing private information from escaping. For example, when KFF Health
News asked ChatGPT its email address, the system refused to divulge that private information. But when told to
role-play as a character, and asked about the email address of the author of this article, it happily gave up the
information. (It was indeed the author's correct email address in 2021, when ChatGPT's archive ends.)

"I would not put patient data in," said Shah, chief data scientist at Stanford Health Care. "We don't understand what
happens with these data once they hit OpenAI servers."

Tina Sui, a spokesperson for OpenAI, told KFF Health News that one "should never use our models to provide
diagnostic or treatment services for serious medical conditions." They are "not fine-tuned to provide medical
information," she said.

With the explosion of new research, Topol said, "I don't think the medical community has a really good clue about
what's about to happen."

Android Users, Click To Download The Free Press App And Never Miss A Story. Follow Us On Facebook and
Twitter. Signup for our free newsletter.

We can't do this without your help; visit our GiveSendGo page and donate any dollar amount; every penny helps.

KFF Health News is a national newsroom that produces in-depth journalism about health issues and is one of the
core operating programs at KFFan independent source of health policy research, polling, and journalism. Learn
more about KFF.

Share This:


Load-Date: May 19, 2023

                                                                                                 Page 4 of 4
              AI May Be On Its Way To Your Doctor's Office, But It's Not Ready To See Patients



End of Document

                                                                                                        Page 1 of 2
                                    Dr. Jamal Lawrence Announced As GRIT 2024 Keynote




                    Dr. Jamal Lawrence Announced As GRIT 2024 Keynote
                                                    The Savannah Tribune (GA)
                                                       December 27, 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 The Savannah Tribune

Section: FRONT PAGE
Length: 410 words

Body


The Creative Coast is excited to announce Dr. Jamal Lawrence, MD, as a GRIT 2024 keynote speaker. The annual
two-day GRIT Conference unites the region's entrepreneurs, technologists, creatives, and visionaries over inspiring
keynote sessions, panel discussions, and workshops. GRIT 2024 is set to take place from February 29th to March
1st at the iconic Savannah Civic Center in Savannah, Georgia.

Dr. Jamal Lawrence, MD is a double board-certified Family Medicine and Lifestyle Medicine Physician Leader.
Recognized nationally as a 40 under 40 Leader in Minority Health and a Health Equity Achieved through Lifestyle
Medicine Scholar, he is also the founder of Harvest Health MD, Savannah, Georgia's first black-owned and only
maleowned and operated direct primary care practice. During his training, Dr. Lawrence became concerned with
the conflict between the level of care his patients needed and the unrealistic expectations the current healthcare
system places on doctors while taking care of their patients in limited settings. Harvest Health MD seeks to provide
high-quality, personalized, transparent, and cost-effective care to small businesses that traditionally do not have the
resources to provide employees with the healthcare experience that every person deserves.

In addition to Dr. Lawrence's keynote talk, the event will feature numerous panel discussions and workshops on
topics aligning with this year's conference theme. The theme, "Leap into the Future," celebrates the Leap Year with
a vision toward tomorrow's innovations. Recently announced panels include Mindset Mastery: Balancing Drive &
Wellbeing in Entrepreneurship, Sweaty Startups: The Fusion of Tech and Traditional Trades, Health Tech
Horizons: AI & New Frontiers in Medicine, and Women in Breakout Roles.

The GRIT Conference will continue to announce speakers and panels at www.thegritconference.com. Be sure to
follow @gritconference on social media for regular updates.

Reserve your spot by December 31st for an Early Bird ticket rate of $149; after this date, general admission will be
$249. Similarly, our Early Bird VIP offer, at $249 (usually $349), ends on the same date. The VIP Ticket includes
access to the VIP Lounge, a unique sidecar lunch, and an evening reception with key conference figures on
February 28th, from 5:30pm-8:00pm, along with full conference access.

For more information about the conference and to purchase tickets, visit www.thegritconference.com.

                                                                              Page 2 of 2
                          Dr. Jamal Lawrence Announced As GRIT 2024 Keynote



Graphic


Dr. Jamal Lawrence, MD Dr. Jamal Lawrence, MD


Load-Date: December 28, 2023


  End of Document

                                                                                                         Page 1 of 2
                                     Vietnam well-positioned to benefit from AI: website




                      Vietnam well-positioned to benefit from AI: website


                                                      ASEAN Tribune
                                                   March 9, 2023 Thursday



Copyright 2023 ASEAN Tribune All Rights Reserved




Length: 327 words

Body


 09 March 2023 (Vietnam News Agency) Artificial intelligence (AI) is poised to revolutionise economies, and
Vietnam is well-positioned to reap the benefits and emerge a leader - both development and application, highlighted
an article run at intelligent global legal research platform Lexology.com.

According to the article, the Vietnamese government is taking steps to support the development of AI, with
initiatives that foster innovation and entrepreneurship. The government is investing in research and development,
providing tax incentives for companies that adopt AI technology, and supporting the growth of the startup
ecosystem, it noted.

One example is the Vietnam AI Grand Challenge, a programme launched in 2019 to encourage the development of
AI technology, it said, adding that it provides funding, support, and resources to AI startups and researchers,
helping them develop and commercialise their AI solutions.

Vietnam has also set up several AI Centres of Excellence in universities and research institutions to encourage the
development of AI technology. The centers provide support and resources to researchers, and collaborate with
industry partners to develop AI solutions for various sectors.

The article also underlined the impacts of AI on health care and agriculture in Vietnam.

However, it held that AI will pose challenges to the Vietnamese labour market. While AI will create new and more
dynamic job opportunities, it is also likely to disrupt existing employment. For example, the use of robots is growing,
and it will become possible for robots and machines to perform many tasks that are now being performed by
humans. This will result in job losses, it explained.

The article stressed that there will need to be appropriate regulations and policies to ensure that AI is used ethically
and responsibly, while suggesting some issues need tackling, including privacy and data protection, intellectual
property, liability and accountability./.


Load-Date: March 10, 2023

                                                                        Page 2 of 2
                  Vietnam well-positioned to benefit from AI: website



End of Document

                                                                                                          Page 1 of 3
            UF to use $23.5 million grant to build AI infrastructure to improve critical care HEALTHY LIVING




    UF to use $23.5 million grant to build AI infrastructure to improve critical
                             care; HEALTHY LIVING
                                                    Naples Florida Weekly (Florida)
                                                          February 23, 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Florida Weekly.

Section: NEWS
Length: 1162 words
Byline: CODY HAWLEY, UF COLLEGE OF MEDICINE

Body


The University of Florida has been awarded $3.6 million of a $23.5 million multicenter grant for a four-year data
generation project that is unprecedented in its scope, aimed at building an infrastructure for artificial intelligence in
critical care and advancing artificial intelligence in ways that improve patients' ability to recover from life-threatening
illnesses.

Funded by the National Institutes of Health's Bridge to Artificial Intelligence, or Bridge2AI program, this project
creates a network of university health systems that will support a comprehensive repository of data for AI research
from more than 100,000 critically ill patients. The patients' data will be made anonymous.

Although the project's highlight will be the 100,000-patient data set, key aspects of the project include AI workforce
training events, a set of standards for ethical use of AI in critical care, publicly available AI tutorials and guidelines
for a collaborative approach to medical AI research.

A team of eight principal investigators, including three from UF Azra Bihorac, M.D., M.S., FCCM, FASN; Parisa
Rashidi, Ph.D.; and Yulia Levites Strekalova, Ph.D., M.B.A. will lead the network of connected intensive care units.
UF Health will be a vital contributor to the data repository, along with other major health systems, including
Massachusetts General Hospital at Harvard; Emory University; Duke University; the University of California, Los
Angeles; Nationwide Children's Hospital; Columbia University and the Mayo Clinic.

"This project is a huge win for UF AI research and will put us on the map for biomedical AI," said Bihorac, the senior
associate dean for research affairs at the College of Medicine and co-director of UF's Intelligent Critical Care
Center, or IC3. "The success of our UF team builds on the investment of UF Health and the UF College of Medicine
in the digitization of clinical infrastructure and the generation, integration and standardization of medical data for
both clinical and research use."

The program, called "A Patient-Focused Collaborative Hospital Repository Uniting Standards for Equitable AI," or
CHoRUS, will expand and generate biomedical data that can be used for monitoring, diagnosing and treating
critically ill patients, as well as augmenting doctor's rapid decision-making.

                                                                                                        Page 2 of 3
          UF to use $23.5 million grant to build AI infrastructure to improve critical care HEALTHY LIVING

Previous data-generation efforts have lacked geographical and demographic diversity. CHoRUS will greatly
increase the scope and scale of AI-ready data sets by creating the repository of anonymized data, composed of
structured electronic health records and other biomedical information.

"The CHoRUS data set will be the largest and most comprehensive critical care data set. Providing this data set to
the scientific community will accelerate advances in the development of AI algorithms in the critical care domain
and in the medical AI domain in general," said Rashidi, the J. Crayton Pruitt Family term fellow and an associate
professor at the UF Herbert Wertheim College of Engineering, who co-directs the IC3.

Earlier large-scale data sets used by ICUs have been insufficient for general use, Bihorac said.

"So far, the large, high-resolution data sets needed to utilize AI technology in ICUs have been limited to single
sites," Bihorac said. "CHoRUS will lead to more research advances and more ICUs being able to utilize AI
advances and give critically ill patients the best possible care. UF's involvement will yield benefits for patient care
that will extend beyond the duration of our project."

Other Bridge2AI components involving UF faculty from the colleges of medicine, communication, pharmacy, law
and engineering include expanding access to AI knowledge and resources by involving the Gainesville community
in AI training through UF's Citizen Scientist program and a fellowship initiative for local high school teachers.

The Citizen Scientist program, which enables researchers to receive feedback from the community about their
work, will offer a publicly available educational module about medical AI ethics, and the UF Center for Precollegiate
Training will offer summer fellowships for two local high school math teachers who will develop an AI and
programming curriculum for high school students that can be shared with teachers across the country.

"By design, this project brings together experts from multiple disciplines," said Levites Strekalova, an assistant
professor in the College of Public Health and Health Professions department of health services research,
management and policy. "We're creating skills and workforce development programs for medical professionals, K-
12 teachers and citizen scientists. Our efforts will have a national impact, which is both humbling and exciting."

Furthermore, UF will build an industry innovation collaborative with NVIDIA and others to help industries seeking to
develop AI algorithms for medical practice and to raise awareness about CHoRUS data. NVIDIA provides the
technological power behind HiPerGator, one of the nation's fastest supercomputers, and partners with UF to
advance the university as a national leader in the application of AI.

"By leveraging our open-source technology stacks like MONAI, a framework for developing medical imaging AI, and
NVIDIA FLARE, a systems development kit for ensuring security and data privacy, we can quickly equip a new
generation of AI builders and accelerate their journey to AI proficiency," said Mona G. Flores, M.D., the global head
of medical AI at NVIDIA.

To fortify the privacy of personal data used in medical AI, a team of legal, ethics and communication scholars will
recommend privacy policies beyond the current legal standards to strengthen protections and enhance public trust.

The team will consult with up to 10 CHoRUS citizen scientists to identify and address any ethical questions or
weaknesses in the public's perception of medical AI.

"CHoRUS is building data resources to support a wide array of socially beneficial goals not just to enhance
research but also to improve health care, to make medical products safer and to benefit public health," said
Barbara J. Evans, J.D., Ph.D., the Stephen C. O'Connell Chair and a professor of law and engineering at UF. "Each
such use poses distinct legal and ethical issues, so we're examining ways to give people confidence that their data
will be safe in medical AI systems."

UF will help this multicenter group provide better critical care for all patients through more effective AI monitoring
and diagnostics.

                                                                                                        Page 3 of 3
          UF to use $23.5 million grant to build AI infrastructure to improve critical care HEALTHY LIVING

"This exciting project will leverage the investments made by the University of Florida to build the AI University, as
well as the donation of the HiPerGator AI supercomputer by UF alumnus and NVIDIA co-founder Chris
Malakowsky," said Erik Deumens, Ph.D., UF's senior director of research computing.

Overall, the CHoRUS program expands upon UF's campuswide AI initiative and UF Health's focus on advancing
trustworthy AI and machine learning in the clinical realm. ¦



Graphic


The CHoRUS program will expand and generate biomedical data that can be used for monitoring, diagnosing and
treating critically ill patients. UNIVERSITY OF FLORIDA / COURTESY PHOTO


Load-Date: February 24, 2023


  End of Document

                                                                                                     Page 1 of 2
   From the Community | Stanford Medicine is taking the step toward better Native health care Login or create an
                                                     account




   From the Community | Stanford Medicine is taking the step toward better
               Native health care Login or create an account
                                            The Stanford Daily: Stanford University
                                                      October 6, 2022 Thursday



University Wire
Copyright 2022 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1023 words

Body


American Indians, Alaskan Natives (AI/AN), and Indigenous communities have long demanded to have visibility
within the healthcare system and equitable access to care.

Preventable problems cause a disproportionate burden of diseases for these communities and disadvantage them
in comparison to other Americans. One preventable problem is the lack of diversity within the healthcare space.
There is little AI/AN/Indigenous representation across all healthcare professions, which contributes to health
disparities in these communities.

According to a 2018 AMA Council on Medical Education report, out of an estimated 5.2 million AI/AN/Indigenous
individuals in the US, only less than half of a percent are in the physician workforce. Studies show that patient
outcomes and satisfaction improve when patients receive care from healthcare professionals from similar
backgrounds. Also, minority physicians are often more likely to work in underserved regions. These healthcare
professionals can provide more culturally concordant care to underserved patient populations, often in their own
languages.

How can we take steps toward health equity for AI/AN/Indigenous communities? Efforts in this direction require all
leading medical institutions to play a critical role in recruiting and nurturing AI/AN/Indigenous medical professionals.
Namely, Stanford University School of Medicine must empower and equip developing healthcare professionals to
achieve their career dreams and expand healthcare access in their communities.

To help address this crucial need for better Native healthcare, organizations are taking measures into their own
hands. For example, the Association of American Indian Physicians (AAIP) hosts the American Indians Accessing
Health Professions Program each year. This conference aims to increase AI/AN/Indigenous students' awareness of
healthcare professions and aid AAIP's mission: "to pursue excellence in Native American health care by promoting
education in the medical disciplines, honoring traditional healing principles, and restoring the balance of mind,
body, and spirit." Stanford Medicine joined forces with AAIP to host the 7th annual AIAHPP in-person conference.

Spearheaded by Mark Gutierrez, the Director of the Office of Diversity in Medical Education, the in-person
conference served a group of AI/AN/Indigenous identifying students interested in pursuing careers in healthcare.

                                                                                                     Page 2 of 2
   From the Community | Stanford Medicine is taking the step toward better Native health care Login or create an
                                                     account

The conference began on a powerful note: an opening blessing, song, and land acknowledgment from Ohlone tribal
members Desiree Munoz and Carla Marie (Costanoan Rumsen Carmel Tribe). When supporting AI/AN/Indigenous
communities, it is undoubtedly essential to first listen to and experience the lived AI/AN/Indigenous historical
narratives.

The students also heard from leaders in various healthcare professional fields and gained an appreciation for their
different perspectives. During the three-day experience, students heard from faculty such as current and former
AAIP president Dr. Luke Day, MD (Oglala Lakota nation), and Dr. Nicole Stern, MD, MPH, FACS (Mescalero
Apache), respectively. Notably, students heard from a panel of Native American faculty and physicians describing
their personal and career journeys as Native individuals. Conference activities like this panel were a powerful force
to breathe a sense of belonging into these developing healthcare professionals. As attendee Desirae Barragan
(Gabrieleno Band of Mission Indians of Southern California) said, "I have never been surrounded by so many
Native American Physicians, medical students, and pre-med students, in one space, the future of medicine will be
undoubtedly Indigenous."

Associate dean of diversity in medical education at Stanford Medicine, Dr. Reena Thomas, best exemplified the
theme of belonging with an opening exercise for attendees. She encouraged them to close their eyes and "envision
them[selves] as future medical students in Stanford's lecture halls." This is the vision we have for AI/AN/Indigenous
students pursuing a career in healthcare: a right to belong.

The conference received overwhelmingly positive feedback from students. For example, Lauren Reyes (Diné and
Mescalero Apache) said, "the AIAHPP Conference provided us with a strong network of passionate Native health
professionals and the resources we need to pursue health careers. Being surrounded by people who are driven to
serve our communities gave me a sense of belonging and encouragement in pursuing medicine." Having these
students believe they can be the next face of healthcare professionals should empower Stanford and other medical
institutions to expand their efforts in this direction.

Much work lies ahead in reshaping and rekindling Native healthcare. The AIAHPP conference shows that medical
schools everywhere need to better recruit and admit more AI/AN/Indigenous students to their various programs. For
reference, of the 22,647 students who matriculated into medical schools from 2021-2022, only 164 students
identified purely with AI/AN or in combination with other races/ethnicities. This statistic alone should push Stanford
Medicine to be a powerful voice in this Native health crisis. Stanford needs to provide more resources for Native
healthcare professionals and be a model for institutions around the world. More awareness and action from
Stanford can only aid better visibility and accessibility within healthcare for AI/AN/Indigenous communities.

With these steps, we will get closer to achieving health equity for these communities and create meaningful
opportunities for them to belong in the space of health care.

Christopher Lopez is a member of the Costanoan Rumsen Carmel Tribe. He is an MD/PhD student in Stanford's
Medical Scientist Training Program. Outside work, you will find him surfing the beautiful west coast, working out at
ACSR, and enjoying dinner with his friends on University Ave.

The Daily is committed to publishing a diversity of op-eds and letters to the editor. We'd love to hear your thoughts.
Email letters to the editor to eic 'at' stanforddaily.com and op-ed submissions to opinions 'at' stanforddaily.com.

Print Article


Load-Date: October 7, 2022


  End of Document

                                                                                                     Page 1 of 2
    AI mission control center for medical care eyed UC San Diego Health will use $22 million given by Joan and
                                                    Irwin Jacobs




  AI mission control center for medical care eyed; UC San Diego Health will
               use $22 million given by Joan and Irwin Jacobs
                                                 The San Diego Union-Tribune
                                                      May 6, 2023 Saturday
                                                            Final Edition



Copyright 2023 The San Diego Union-Tribune All Rights Reserved

Section: NEWS; Part A; Pg. 1
Length: 781 words
Byline: Paul Sisson

Body


With artificial intelligence rapidly changing health care, UC San Diego Health is planning to treat the situation with
a level of attention usually reserved for rocket launches and wildfires.

A $22 million donation from philanthropists Joan and Irwin Jacobs will help pay for a mission control center inside
its main La Jolla medical center to consolidate the ever-growing streams of digital information that are increasingly
providing actionable information at the bedside.

Hundreds gathered in a university auditorium Friday to listen to the latest thinking about how this technological
transformation is likely to unfold, with Irwin Jacobs sitting in the front row, soaking up every detail.

The digital communications pioneer with a doctorate in electrical engineering said during a lunch break that it was
clear in the planning stages of UC San Diego Jacobs Medical Center, the state-of-the-art La Jolla hospital that now
bears his name, that the proliferation of information technology in medicine would eventually require more
coordination.

"It was kind of decided, well, we're getting all of this data, but none of it's really connected. We need to get it into
one place including not just the hospital system, but also from outside, and then have a few different types of
people in there who can react very quickly to what they're seeing," Jacobs said.

These days, everything from bedside monitors to air-handling equipment produces endless digital information, and
recent advances in artificial intelligence are showing a stunning capacity to sift through this mountain of ones and
zeros to find patterns that can spot errors and, increasingly, predict who might be about to develop a new set of
symptoms.

A good example, said Dr. Christopher Longhurst, the university health system's chief medical and digital officer, is
an emergency room program that is using AI to analyze bedside and electronic health record data to predict which

                                                                                                     Page 2 of 2
    AI mission control center for medical care eyed UC San Diego Health will use $22 million given by Joan and
                                                    Irwin Jacobs

patients are at the greatest risk of developing sepsis, a runaway reaction to infection that can cause deadly organ
failure.

"We implemented this algorithm six months ago, and our emergency department, in the last six months, we've had
the lowest observed (versus) expected mortality and sepsis that we've ever seen at UC San Diego Health,"
Longhurst said.

Other efforts are under way to use AI to predict which patients will develop bowel obstructions after surgery, and a
remote telemonitoring program is now receiving data from the homes of more than 2,500 patients with chronic
diseases.

More recently, UCSD was one of two systems nationwide to enable AI-enhanced recommendations for its doctors
to review when responding to patient emails.

And this is just the beginning. Every new application, Longhurst notes, will generate its own set of notices. Asking
bedside workers to parse this flow is impossible, meaning that a separate team of professionals will be necessary to
decide what needs to be passed along to caregivers and what can wait.

"It's Apollo 13, right?" Longhurst said. "Those guys didn't land on the moon by themselves, they had help."

Though the need for such an approach is already arriving, the executive said it is expected to take several years for
the new command center, which will also have two components situated outside the hospital, to get up and running.

For now, AI's potential to make routine tasks more manageable for medical professionals seems to be engendering
the most excitement.

Panelists who spoke during Friday's symposium were asked what about the coming AI health care revolution
excites them the most in the near term. Most said they were very optimistic about the ability of algorithms to help
free up medical professionals' time by assisting with routine tasks, such as responding to patient emails for medical
testing and other routine communication that piles up during the work day and impinges on personal lives.

Having help grinding through the grist of modern health care, in theory, should free up time for meaningful
conversations with patients.

Sitting back after eating Cinco de Mayo tacos, Holly Smith, UC San Diego's population health clinical nurse
educator, said she hopes that's how it goes. Technology, she said, will clearly be necessary to meet the ever-
increasing health care demands of an aging population.

But, she said, gains in efficiency must be balanced with the human touch.

"We don't want to use that data to make things so efficient that we take that human piece out," Smith said. "A
careful, managed approach is important, and so is making sure to get the perspective of the people that are in the
field doing that front-line work with the patients."

paul.sisson@sduniontribune.com


Load-Date: May 8, 2023


  End of Document

                                                                                                        Page 1 of 2
                                 UK, NHS hospitals want to partner with PH on health care




                UK, NHS hospitals want to partner with PH on health care


                                                        ASEAN Tribune
                                                   December 2, 2023 Saturday



Copyright 2023 ASEAN Tribune All Rights Reserved




Length: 467 words

Body


 02 Dec 2023 (Philippines News Agency) The United Kingdom wants to increase collaboration with the Philippines
in the area of health care after a trade mission composed of National Health Service (NHS) organizations capped
its visit to Manila this week.

The trade mission was in the Philippines from Nov. 29 to Dec. 1 and met with various health care stakeholders and
government officials, including Health Secretary Teodoro Herbosa.

'The UK's leading NHS hospitals want to work with partner countries overseas to share our 75 years' experience of
innovation using research-based clinical pathways, the most advanced science and excellent training, equipment,
and digital system,' said Lindsey Gilbert-Crouch, country director for Trade and Investment.

'We feel that there is much that the UK and the Philippines can learn from one another to ensure the best possible
health care outcomes for our people.'

In a statement dated Dec. 1, the UK Embassy in Manila said the mission shared its health care challenges and
innovations with Filipino stakeholders and conveyed its interest in learning more about Philippine health care
models.

'The visit demonstrated the importance of UK-Philippines relations and will hopefully open up many more health
care collaborations in the future,' it said.

It pointed out that the UK has a strong track record of scientific breakthroughs and is delivering the next generation
of life-changing treatments, technologies, and services.

These include personalized health care using digital health and artificial intelligence (AI), and cutting-edge medical
technology.

The visit also saw the signing of a Twinning Partnership between West Yorkshire and Pasig City, which is seen to
create opportunities to grow research and innovation in the health care sector.

                                                                                                          Page 2 of 2
                              UK, NHS hospitals want to partner with PH on health care

The memorandum of understanding was signed by Mayor Vico Sotto and Richard Stubbs, CEO of Health
Innovation Yorkshire and Humber.

The pilot Twinning Partnership will take forward the development of the Philippines' first digitized patient registry for
primary care.

According to the embassy, the registry is already benefitting up to one million patients seeking public health care in
barangay health centers across Pasig City and Iloilo City.

The registry was launched through the UK's 'Better Health Programme.'

The UK delegation included Aire Logic, Health Innovation Yorkshire and Humber, Modality Partnership, Oxford
University Hospitals NHS Foundation Trust, Royal College of General Practitioners, UCL Global Business School
for Health, University of Bradford, University of Leeds, and West Yorkshire NHS Integrated Care Board.

May Parsons, the Filipino nurse who delivered the first coronavirus disease 2019 (Covid-19) vaccination outside of
clinical trials, was also present during a reception hosted for the mission.


Load-Date: December 3, 2023


  End of Document

                                                                                                          Page 1 of 2
                           Artificial Intelligence Outperforms Doctors in Breast Cancer Diagnosis




     Artificial Intelligence Outperforms Doctors in Breast Cancer Diagnosis
                                                        New York Observer
                                                      January 3, 2020 Friday



Copyright 2020 The New York Observer, L.P. All Rights Reserved

Length: 566 words
Byline: Harmon Leon

Body


Despite all of our fears about artificial intelligence (AI), we still have to look at the health benefits that could save
lives through machine learning.                 According to a study conducted by researchers from Imperial College
London and Google Health, an AI program has been developed that can identify breast cancer from routine scans
with greater accuracy than its human counterparts.

Google's DeepMind system has been trained to spot abnormalities on X-ray images. According to the findings,
which were           published this week by Nature, scans of 29,000 women from the U.S. and UK were used in the
trial. The sampling was made to represent all the women who might come through for a breast screening.
Mammography screenings are designed to identify breast cancer at earlier stages of this fatal disease. Though,
doctors' interpretations of mammograms are occasionally affected by high rates of false positives and false
negatives, meaning a mammogram is wrongly diagnosed.

SEE ALSO: Researchers Develop AI That Can Predict Seizures Before They Happen

Using images that had previously been reviewed by doctors in the U.S., there was a reported reduction of 5.7% in
false positives and a reduction of 9.4% in false negatives, in which cancer was missed.

"In an independent study of six radiologists, the AI system outperformed all of the human readers," the report
stated.

This is a major breakthrough that could save lives.

"Here we present an artificial intelligence (AI) system that is capable of surpassing human experts in breast cancer
prediction," the researchers wrote.

Obviously, the earlier you can detect breast cancer, the better it is for patients. And like everything else involving
AI, its main purpose is to assist-in regard to giving a second opinion-and then let the human hand interpret the final
results and confirm the diagnosis.

Dominic King, UK lead at Google Health, told AFP: "We think about this technology in a way that supports and
enables an expert, or a patient ultimately, to get the best outcome from whatever diagnostics they've had."

                                                                                                       Page 2 of 2
                       Artificial Intelligence Outperforms Doctors in Breast Cancer Diagnosis

The study showed that using AI to help verify the results of human doctors' diagnoses could save up to 88% of the
workload for the second clinician reviewer. Thus, AI could effectively support the existing service done by human
reviewers.

We've already seen AI's benefits in the medical industry to help give doctors the upper hand in working more
effectively. DeepMind is Google's health and artificial intelligence group and was acquired by the company in 2014.
Its machine learning can also predict if a patient has potentially fatal kidney injuries-48 hours before doctors can
recognize many of the symptoms. In fact, AI is being               used throughout health care to help identify other
abnormal X-ray results, such as tuberculosis. Researchers at MIT's                   Computer Science and Artificial
Intelligence Laboratory (CSAIL) are using machine learning to estimate          the risk of cardiovascular death.

As Observer previously reported,        Forbes noted that the total investment in health care is expected to reach
    $6.6 billion by 2021. AI advances could potentially create        $150 billion in annual savings for the United
States health care economy by 2026.

The proof is in the analytics; AI has proven to be a valuable tool for preventing death and taking life-saving
precautions.


Load-Date: January 5, 2020


  End of Document

                                                                                                      Page 1 of 3
                                    Young ‘surprised’ by bipartisan agreement on AI




                       Young ‘surprised’ by bipartisan agreement on AI
                                                        TheHill.com
                                               November 28, 2023 Tuesday



Copyright 2023 NEXSTAR MEDIA INC. All Rights Reserved

Section: TECH LATEST
Length: 1006 words
Byline: Rebecca Klar

Body


Welcome to The Hill’s Technology newsletter {beacon}

Technology

Technology

The Big Story

Young ‘surprised’ by bipartisan agreement on AI

Sen. Todd Young (R-Ind.) said Tuesday he’s been encouraged and “a little surprised” by the bipartisan agreement
among senators so far during the closed-door AI Insight Forums.

© Photo Credit

Young, speaking at the Axios AI+ Summit, said as Congress continues to mull regulation about artificial intelligence
(AI) through the committee process, partisan disagreements may emerge .

He said labor issues related to AI may be a point of contention.

“I expected more disagreement when it came to the role government should play, the extent to which we should
protect workers in various ways from the technology. There haven’t been very significant disagreements,” Young
said.

He expects there will be“more disagreement” among senators about the extent the role of government should play
as the process moves through committees to consider regulation.

Young added that lawmakers may also appear less willing to compromise once “ television cameras are turned on
and there is an expectation, to put it charitably, from ones’ constituents that their members of the Senate or their
members of Congress to fight for the perspective of their constituents of for their base.”

                                                                                                     Page 2 of 3
                                  Young ‘surprised’ by bipartisan agreement on AI

Young is one of four senators on Majority Leader Chuck Schumer’s (D-N.Y.) small bipartisan group in charge of
Senate discussions about AI regulation. Schumer and the group have convened a series of AI Insight Forums —
including industry experts, tech company CEOs and civil rights leaders — to discuss the benefits and risks of AI.

The Senate is holding its seventh AI Insight Forum on Wednesday afternoon, focused on intellectual property and
copyright issues. The forum will include a negotiator from SAG-AFTRA, a union representing actors that recently
won protections from AI , along with representatives from Sony Music Entertainment, the Motion Picture
Association and Spotify.

Read more in a full report at TheHill.com .

Welcome to The Hill’s Technology newsletter , we’re Rebecca Klar and Julia Shapero — tracking the latest moves
from Capitol Hill to Silicon Valley.

Did someone forward you this newsletter? Subscribe here.

Essential Reads

How policy will be impacting the tech sector now and in the future:

Judge recuses himself from Elon Musk’s case against Media Matters

The judge presiding over tech billionaire Elon Musk’s lawsuit against Media Matters for America has recused
himself from the case, according to court documents. In a notice filed with the court on Tuesday, Judge Mark
Pittman of the U.S. District Court in Northern Texas wrote that he was recusing himself from the case and
requested the clerk of the court assign it to another judge. Pittman, who was appointed to his position …

Full Story

Ransomware attack forces hospitals in multiple states to divert some emergency room patients

Hospitals in multiple states have been diverting patients from their emergency rooms due to a recent cyberattack on
a major health system. Ardent Health Services, a company that owns hospitals in six states, said Monday that it
had been victimized by a cyber event on Thanksgiving that turned out to be a ransomware attack. “As a result,
Ardent proactively took its network offline, suspending all user access to its information …

Full Story

The Refresh

News we’ve flagged from t he intersection of tech and other topics:

Amazon launching AI-powered chatbot

Amazon plans to launch an AI-powered chatbot called Q for customers of its cloud computing company Amazon
Web Services (AWS), TechCrunch reported .

General Motors cuts spending on Cruise

General Motors (GM) plans to cut spending on its self-driving unit Cruise , after an accident in October injured a
pedestrian and prompted the company to suspend all self-driving operations nationwide, Financial Times reported .

On Our Radar

Upcoming news themes and events we’re watching:

The House Energy and Commerce subcommittee on health will hold a hearing on “Understanding How AI Is
Changing Health Care” on Wednesday at 10:30 a.m. ET.

                                                                                                         Page 3 of 3
                                  Young ‘surprised’ by bipartisan agreement on AI

The Hill Jobs

Interested in exploring a new career? Visit The Hill Jobs Board to discover millions of roles worldwide, including:

Senior Product Manager, Customer Data Platform — Remitly, Seattle Apply

Director of Corporate Finance & Strategy — OpenGov, Chicago Apply

Senior Technology Sales Representative – Government & Education Specialist — Konica Minolta Business
Solutions, U.S.A., Inc., Washington, D.C. Apply

Director of Global Government Sales — Kaseware, Inc., Denver Apply

Click here to get your job mentioned

In Other News

Branch out with other reads on The Hill:

Sports Illustrated is the latest media company damaged by an AI experiment gone wrong

NEW YORK (AP) — Computer-generated writers … writing computer-generated stories? Sports Illustrated is the
latest media company to see its reputation damaged by being less than forthcoming — if not outright dishonest —
about who or what is writing its stories at the dawn of the artificial intelligence …

Full Story

Amazon launches Q, a business chatbot powered by generative artificial intelligence

NEW YORK (AP) — Amazon finally has its answer to ChatGPT. The tech giant said Tuesday it will launch Q — a
business chatbot powered by generative artificial intelligence. The announcement, made in Las Vegas at an annual
conference the company hosts for its AWS cloud computing service, represents …

Full Story

What Others are Reading

Two key stories on The Hill right now:

Winds take down National Christmas Tree

The National Christmas Tree was toppled over on Tuesday by heavy winds on Washington D.C.’s chilliest day
since last winter. The massive tree, … Read more

Biden Labor nominee stalls in Senate after Manchin, Menendez vote with GOP

President Biden’s nominee to serve as assistant secretary of the Labor Department, Jose Javier Rodriguez, stalled
in the Senate Tuesday after Democratic … Read more

You’re all caught up. See you tomorrow!

For the latest news, weather, sports, and streaming video, head to The Hill.


Load-Date: January 11, 2024


  End of Document

                                                                                                       Page 1 of 3
                     Medical chatbots developed to speed medical research, alleviate privacy worries




    Medical chatbots developed to speed medical research, alleviate privacy
                                   worries
                                                    Naples Florida Weekly (Florida)
                                                           March 31, 2022



Copyright 2022 Florida Weekly
Distributed by Newsbank, Inc. All Rights Reserved

Section: HEALTHY LIVING
Length: 850 words
Byline: DIANA TONNESSEN, UF HEALTH

Body


Medical chatbots that can talk to people using conversational language soon may be available on your cellphone or
computer thanks to SynGatorTron, a groundbreaking artificial intelligence tool developed by UF Health and
NVIDIA.

"Dr. Chatbot will see you now."

The next generation of super-smart computers, tablets and cellphones may come equipped with artificial
intelligence generated medical chatbots that can interact with patients using human language and medical
knowledge.

According to Yonghui Wu, Ph.D., director of natural language processing at the University of Florida Clinical and
Translational Science Institute, the medical chatbot you interact with online will be able to use conversational
language to communicate with and educate patients in much the same way we now interact with Apple's chatbot,
Siri and Amazon's Alexa.

The chatbot may also be culturally sensitive and matched to your age.

"It will be like having your own personal medical avatar," Mr. Wu said.

Medical chatbots are just one of many possible applications to arise out of groundbreaking new AI tools developed
by Mr. Wu and other researchers at UF and NVIDIA as part of a $100 million artificial intelligence public-private
collaboration formed in 2020. Last year, they launched a clinical language AI model, GatorTron. This AI tool
enables computers to quickly access, read and interpret medical language in clinical notes and other unstructured
narratives stored in real-world electronic health records. The model was trained on HiPerGator-AI, the university's
NVIDIA DGX SuperPOD system, which ranks among the world's top 30 supercomputers.

The GatorTron model is expected to accelerate research and medical decision making by extracting information
and insights from massive amounts of clinical data with unprecedented speed and clarity. It will also lead to

                                                                                                         Page 2 of 3
                  Medical chatbots developed to speed medical research, alleviate privacy worries

innovative AI tools and advanced, data-driven health research methods that were unimaginable even 10 or 15
years ago.

This year, the team is rolling out another model – SynGatorTron with different capabilities. SynGatorTron can
generate synthetic patient data untraceable to real patients. This synthetic data can then be used to train the next
generation of medical AI systems to understand conversational language and medical terminology.

Most data-driven health research and health-related AI applications today rely on "de-identified" patient data in
electronic health records, from which patients' private information such as name, address and birthdate, has been
removed before it is used for research and development.

Removing patient data is time-consuming and labor-intensive. Automated de-identification systems can be used to
generate large-scale machine de-identified data, but it's not an ironclad solution.

According to Mr. Wu, even after all identifying patient information has been removed, there's still a remote chance
that someone could identify a patient by tracking data over time.

"Generating synthetic patient data is a safe way to preserve the knowledge of medical language but mitigate the
risks of patient privacy," Mr. Wu said.

Patient privacy isn't the only barrier to training the next generation of AI models for research and other applications.
The sheer volume of data required to train AI models can also stand in the way.

"There's a finite amount of patient data available to us, and training AI computer models requires a tremendous
amount of data," said Duane Mitchell, M.D., Ph.D., director of the UF Clinical and Translational Science Institute
and associate dean for clinical and translational sciences at the UF College of Medicine. "With SynGatorTron, we
can generate all the data we need."

Another advantage SynGatorTron has over its competitors is that because realworld patient data is used as a
model for generating synthetic patient data, the synthetic data has "real human characteristics," Mr. Mitchell said.

"The synthetic patient data generated by SynGatorTron reflects the complexity and diversity of the human
population," he said. "This diversity in the synthetic data is crucial because AI is only as good as the data it is
trained on."

Low-quality data used in training algorithms has already been found to introduce or reinforce bias in a few high-
profile applications, including gender bias in Google Translate and racial bias in Amazon's Rekognition facial
recognition technology.

The data produced by SynGatorTron™ could be used to address issues with underrepresented minorities and other
potential sources of bias, Mr. Mitchell said.

Having the ability to generate high-quality synthetic patient data that can be used to develop new AI applications
opens up a new world of possibilities.

"We haven't even begun to think of all the downstream uses that will spring from this," Mr. Mitchell said.

One thing is certain: "There is a lot of interest in the race for AI applications to generate relevant and accurate
synthetic patient data," he said. "With the development and launch of SynGatorTron™, UF and NVIDIA will certainly
be positioned at the forefront of these efforts within the field." ¦



Graphic

                                                                                                      Page 3 of 3
                    Medical chatbots developed to speed medical research, alleviate privacy worries

"It will be like having your own personal medical avatar." Yonghui Wu, Ph.D., director of natural language
processing at the University of Florida Clinical and Translational Science Institute


Load-Date: April 1, 2022


  End of Document

                                                                                                        Page 1 of 2
       Democrats urge FDA to include civil rights, disability and ethics advocates on digital health committee




 Democrats urge FDA to include civil rights, disability and ethics advocates
                      on digital health committee
                                                        TheHill.com
                                               December 19, 2023 Tuesday



Copyright 2023 NEXSTAR MEDIA INC. All Rights Reserved

Section: PHARMA INDUSTRY NEWS, Tech latest & US POLITICS NEWS
Length: 326 words
Byline: Rebecca Klar

Body


A group of Democratic senators asked the Food and Drug Administration (FDA) to include members with
backgrounds in civil rights, medical ethics and disability rights on the agency’s new Digital Health Advisory
Committee.

The FDA announced the nine-member committee in October to help explore issues related to digital health
technologies, including artificial intelligence (AI) and wearable health technology. The committee will advise the
FDA on issues related to the technology.

The Democrats, led by Sen. Ed Markey (D-Mass.), urged FDA Commissioner Robert Califf in a Tuesday letter to
include at least one voting member with a background in civil rights, one voting member with a background in
medical ethics and one voting member from a disability rights organization.

The senators underscored the need for members with those backgrounds in order to mitigate concerns about bias
posed by the use of algorithms and other health technology while also acknowledging that the technologies could
also improve conditions such as patient outcomes, cost reductions and health provider retention.

“The civil rights and medical ethics implications of [digital health technologies] are manifest. It is essential that
voices with a background in civil rights, in medical ethics, and from a disability rights organization are part of the
Digital Health Advisory Committee, in order to assist the FDA as it develops regulatory guidelines that will
determine the safety and efficacy of these products. It is also crucial that the voices of those who will be using these
tools are consulted when developing these regulations,” they wrote.

According to the FDA’s announcement, the committee should be “fully operational” in 2024.

The letter was also signed by Sens. Bernie Sanders (I-Vt.), Bob Casey (D-Pa.), Amy Klobuchar (D-Minn.), Tammy
Duckworth (D-Ill.) and Alex Padilla (D-Calif.).

For the latest news, weather, sports, and streaming video, head to The Hill.

                                                                                                       Page 2 of 2
      Democrats urge FDA to include civil rights, disability and ethics advocates on digital health committee


Load-Date: January 11, 2024


  End of Document

                                                                                                    Page 1 of 4
    GATC Health Investor Conference to Feature First Public Demonstration of Its AI Platform's Drug Discovery
                                                 Capabilities




  GATC Health Investor Conference to Feature First Public Demonstration of
                Its AI Platform's Drug Discovery Capabilities
                                                        Disclosure Newswire
                                                  October 25, 2022 Tuesday



Copyright 2022 Content Engine, LLC.
All Rights Reserved
Copyright 2022 iCrowdNewswire LLC All Rights Reserved

Length: 1981 words
Byline: Asiya

Body


Link to Image

GATC Health (&#8220;GATC&#8221; or &#8220;the Company&#8221;), a science and technology company
revolutionizing drug discovery and disease prediction using artificial intelligence (AI), today announced that the
company is welcoming private investors to attend a GATC conference at Avenue of the Arts Hotel in Costa Mesa,
CA on Wednesday, Oct. 5, for the first public demonstration of its proprietary Multiomics Advanced Technology™
(MAT) platform that discovers both small and large molecule drug candidates with 88% accuracy.

In addition to this demonstration, the agenda of the closed event includes key speakers from GATC Health as well
as industry experts and thought leaders, who will provide additional context on how GATC&#8217;s drug discovery
and development abilities could be used in multiple areas of medicine, including addiction treatments, diabetes,
oncology and other disease states.

GATC Health has attracted significant interest from sophisticated investors. The company expects its private
conference to close its current Regulation D offering, representing the final opportunity for individuals to invest in
the company. Invitations to GATC&#8217;s event were limited to individuals who invested $100,000 or more in the
company or who recently invested via referral. Following this round of funding, GATC Health is seeking institutional
investment and is in conversations with several prospective funding institutions.
At the investor conference, GATC will also detail recent company developments, including a new study that shows
its platform can predict drug candidate success with 88% accuracy, an increase to pre-clinical lead optimization 11x
industry performance.

The company also recently announced a partnership with globally recognized music artist, entrepreneur and
activist, Akon, to study and interpret genetic and other biological data to identify predisposition to diseases and
enable life-saving preventative care for Africans and people of African heritage. Using the company&#8217;s
proprietary AI platform, which can process and analyze the entire human genome, the initiative will study the
genetics of 1 million people across Africa and use that data to identify personalized healthcare solutions for the

                                                                                                    Page 2 of 4
    GATC Health Investor Conference to Feature First Public Demonstration of Its AI Platform's Drug Discovery
                                                 Capabilities

African participants, in addition to providing deep population health insights that can change the course of
healthcare on the African continent.
Speakers at the day-long conference will include:

Tomas Philipson, Ph.D, Former Acting Chairman of the Council of Economic Advisors in the Trump
Administration. Senior Economic Advisor to the heads of the FDA and Centers for Medicare and Medicaid
under George W. Bush. Board of Directors/Advisors Board of Directors/Advisers Biologx, Liberatio, PragmaHealth
and Epigenetix. Co-Director Center for Choice and Competition in Health Care, Department of
Economics, University of Chicago. Director of Health Economics at Becker Friedman Institute, University of
Chicago. Columnist at Forbes. He received his MA and PhD in economics from the Wharton School at
the University of Pennsylvania. He has been a visiting faculty member at Yale University and a visiting senior fellow
at the World Bank. Ari Smith, Chief Technology Officer, Hypereon Labs. Visiting Professor of Artificial
Intelligence and Advanced Research at Yonsei University. Formerly Chief Technology Officer at Fincross
International, Sr Vice President MR Financial and Solutions Architect with Microsoft. Mr. Smith studied Molecular
Genetics at University of Washington and Computer Science at Massachusetts Institute of Technology. Patrick
Lilly, Chief Executive Officer, Liquid Biosciences. 25 years driving innovation and growth in biotech, software,
high-performance computing and wireless. Member of FDA&#8217;s MDepiNet Blockchain and AI Task Force; Co-
Chair, AI Subcommittee. Contracted with nine of top ten pharmaceutical companies and three world-renowned
research institutions. Co-founded four technology start-ups and five life sciences companies and discovered
hundreds of novel biomarkers for 28 diseases. Inventor of 75 technology patents and trade secrets in
bioinformatics, tissue sample quality control, high performance algorithms, security and wireless. Guest lectured at
Cal Tech, MIT, Stanford, UC Berkeley, USC, and others. Board Member of Mamogen, HepGene and LiquidLung.
Patrick received his B.A. and MBA from University of California, Irvine. Dr. Tom Takubo, West Virginia State
Senator, and Incoming Executive Vice President of Provider Relations for West Virginia University Health
System. Dr. Takubo serves as the Majority Leader of the West Virginia Senate, a pulmonologist trained at the West
Virginia School of Osteopathic Medicine, and founding member of Pulmonary Associates of Charleston, WV. In his
new role at WVUHS, he will work closely with internal WVU Medicine clinical departments and divisions across the
Health System to focus on coordination of clinical goals. Dr. Takubo is also widely recognized as having brought
the most advanced lung diagnostics and non-invasive treatment options to West Virginia. Mark York, government
affairs liaison, co-author Opioid Abatement guidelines, President Global Development and Acquisition for
IP SecureTech. Mark is an expert in structuring complex business development relationships from initial concept
and design through turnkey operations in a wide array of industries around the world including developing strategic
partnerships in law firm business development, commercial transportation, bioengineering/nano-tech product
development, data center and technology related joint ventures, building healthcare provider and facility
relationships, corporate regulatory and governance guidance as to private and governmental partnerships. Prior to
IP SecureTech, Mark was affiliated with major law firms and corporate legal departments throughout the United
States focusing on Intellectual Property/Complex Commercial Litigation, Corporate Regulatory Compliance, and
Corporate Due Diligence review in the Mergers & Acquisition area primarily for international clients. Nicholas H.
Hemmerly, Senior Managing Director, Head of Investment Banking at Bridgeway Capital Partners,
LLC. Bridgeway Capital Partners together with its affiliates provides independent investment banking, strategic
capital, and advisory services to lower and middle market companies globally. Prior to joining Bridgeway Mr.
Hemmerly was at PricewaterhousCoopers Corporate Finance LLC focusing on M&A and capital raising in the Life
Sciences space with a focus on Specialty and Generic Pharmaceuticals as well as Healthcare Consumer Products
and Contract Manufacturing. Prior to PwC CF, Mr. Hemmerly worked at Jefferies LLC with a focus on executing
M&A and financing transactions within the pharmaceutical and life sciences sectors. Prior experience includes
investment banking roles in JPMorgan&#8217;s Healthcare Group as well as JMP Securities Healthcare Group. Mr.
Hemmerly began his investment banking career as an analyst with Wachovia Securities. Mr. Hemmerly graduated
with honors from the College of Charleston with a B.S in economics. He holds his Series 7 and 63 licenses.

GATC Health company leadership scheduled to speak include:

Jayson Uffens, Chief Technology Officer, GATC Health. A seasoned technology architect with 20+ years of
executive experience at high-growth global technology firms and co-inventor of GATC Health&#8217;s AI platform.

                                                                                                    Page 3 of 4
    GATC Health Investor Conference to Feature First Public Demonstration of Its AI Platform's Drug Discovery
                                                 Capabilities

Senior technology roles at IrisMind, Seamless (merged with GrubHub), GoDaddy, American Express, Northrop
Grumman Information Systems and UbiQGroup (sold to SF-based insurance company). Jayson executed
technology projects with National Academy of Recording Arts /Grammy Awards, Eastern Mountain Sports,
Invitrogen, Cost Plus World Markets, BNSF, LeapFrog, Personal Shopper, Yamaha and Wynn Resorts. Ian
Jenkins, Chief Science Officer, GATC Health. With deep knowledge and experience in physiology and health
technology, Ian is the co-inventor of GATC Health&#8217;s AI platform. A genomic and biology scientist who
began his career with the Human Genome Project, he was the Chief Executive Officer of Fr&eacute;lii and CEO of
CodeTech, a Phoenix-based Med tech company, whose technology was acquired by Hospital Corporation of
America with key product development roles at Systemic Formulas and Orn Industries. Ian earned an M.B.A. from
Thunderbird School of Global Management, and a B.S. in Physiology from Utah State University. Preetaman
Wadhwa, Chief Marketing Officer, GATC Health. 20+ years of global strategic and U.S. operational experiences
in Pharmaceutical, Hospital and Health Insurance industries. 17 years with Amgen, the world&#8217;s largest
independent biotechnology company, most recently as Global Marketing Lead and Marketing Director of
Cardiology. Preetaman has a B.S. Pharmacy and MBA from India and a MHSM from Rush University, Chicago.
Dr. Robert Sorrentino, Chief Medical Officer, GATC Health. An internationally recognized physician, executive
and informaticist and prior roles: Global Chief Medical Scientist, IBM-TJ Watson Research Center. CEO for AI for
Healthcare Consultants, focused on serving novel technology companies that utilize AI and machine learning for
clinical services and pharmaceutical development. Chief Medical Officer, Providence Health California; Chief
Medical Officer for the Tuba City Regional Health Care Corporation (TCRHCC) &#8211; the hospital and clinics
owned by the Navajo Nation, which serves more than 100,000 tribal members. Dr. Sorrentino received his degree
in physics from Massachusetts Institute of Technology, and his advanced information systems training
at MIT and Harvard University. He received his MD degree from the Renaissance School of Medicine at Stony
Brook University, and his residency training in family medicine from UCLA and its affiliated institutions, including
Cedars-Sinai Medical Center. He is a member of the American College of Healthcare Executives (ACHE), and the
Association for Computing Machinery (ACM). V. Tyrone Lam, Chief Operating Officer, GATC Health. 30+ years
of executive management experience in technology-focused companies, including co-founding a VC-backed start-
up and executive officer of a publicly traded company. Co-founded and operated First Americans Wellness, a
licensed medical clinic treating Native Americans on sovereign land. Co-founder and COO of OneHealth Solutions /
OneRecovery, the 1st HIPAA-secured peer support network contracting with insurance companies and employers
(acquired by Viverae / SimplyWell / Virgin Pulse). Business development roles at Predilytics and Welltok, health
tech data companies (acquired by Virgin Pulse). He is a board-certified life coach and received his B.A.
from Virginia Tech. Jeff Moses, President, GATC Health. 20+ years in executive management with experience in
starting and expanding new companies, investment, regulatory and compliance, operations, and marketing.
President & Chief Marketing Officer of ONIT Sciences; Chief Marketing Officer & Director, PowerOne Corporation;
Founder and Creative Director, Engine Marketing. Jeff received a bachelor&#8217;s degree in Literature in 1986
from Pitzer College.

About GATC HealthGATC Health Corp is a science and technology company using whole genome analysis and
multiomics-based artificial intelligence to revolutionize disease detection and drug discovery. The
company&#8217;s patented AI platform reduces risk, time and costs for life science companies by digitally
reproducing the human body to find non-obvious answers to biology&#8217;s most complex questions. GATC
Health is accelerating healthcare&#8217;s transition to predictive, individualized medicine.

See Campaign: https://gatchealth.com/
Contact Information:

https://gatchealth.com/

Tags:
Wire, Disclosure Newswire, United States, English

                                                                                                   Page 4 of 4
   GATC Health Investor Conference to Feature First Public Demonstration of Its AI Platform's Drug Discovery
                                                Capabilities


Load-Date: January 5, 2023


  End of Document

                                                                                                        Page 1 of 3
                                      Artificial Intelligence, Public Trust, and Public Health




                      Artificial Intelligence, Public Trust, and Public Health
                                                        Economic Thinking
                                                     July 13, 2021 Tuesday



Copyright 2021 Content Engine, LLC.
All Rights Reserved
Copyright 2021 Economic Thinking, USA All Rights Reserved

Length: 1247 words
Byline: Gregory Rehmke

Body

The CDC article Artificial Intelligence, Public Trust, and Public Health (CDC Genomics and Precision Health,
September 17, 2020) explains:

 As part of the Data Modernization Initiative, CDC is supporting strategic innovations in data science using artificial
intelligence and machine learning (Ai/ML). Ai/ML is the practice of using mathematics with computers to learn from
a wide range of data and make predictions about the health of populations. By using Ai/ML, CDC can maximize
insights from data to improve disease detection, mitigation, and elimination. Ai/ML applications could support public
health surveillance, research and, ultimately, decision making, ushering a new era of precision public health.

Health care analysts have long wished for "Big Data" to show the way for lowering health care costs. But Big Data
isn't necessarily smart data. Someone or some algorithm has to sort through, categorize, and analyze vast health
care information looking for patterns and relationships.

In Beware the AI delusion (Fast Company, 2018), Gary Smith (author of The AI Delusion), concludes:

In the age of AI and big data, the real danger is not that computers are smarter than us, but that we think computers
are smarter than us and therefore trust computers to make important decisions for us. We should not be intimidated
into thinking that computers are infallible. Let's trust ourselves to judge whether statistical patterns make sense and
are therefore potentially useful, or are merely coincidental and therefore fleeting and useless.

Technology and health care companies are investing in smarter management of health care information. Microsoft
Makes a $16 Billion Entry Into Health Care AI (Wired, April 13, 2021) outlines the potential for Nuance, a medical
transcription service purchased by Microsoft, to expand:

Health care is widely seen as a key industry for applied AI. Numerous research studies show the potential for AI
algorithms to spot disease in images or mine medical records for insights into treatment paths. And while
challenges remain, like getting doctors to trust the technology or preventing bias that creeps in when the data used
to train medical algorithms is insufficiently diverse, an increasing amount of AI is likely to be deployed in health
care in coming years.

                                                                                                          Page 2 of 3
                                 Artificial Intelligence, Public Trust, and Public Health

In this YouTube video from PYTORCH DEVCON 19, Andrew Trask outlines Privacy Preserving AI - Andrew Trask,
OpenMined

Learn the basics of secure and private AI techniques, including federated learning and secure multi-party
computation. In this talk, Andrew Trask of OpenMined highlights the importance of privacy preserving machine
learning, and how to use privacy-focused tools like PySyft.

How Big is A.I.'s Future in Health Care?How many medical device and services startups are using A.I.? Likely all
of them, given the loose definition of A.I. and the appeal to investors that A.I. will bring miracles. Japan's AI Medical
Service listed among the World Economic Forum's Tech Pioneers:

AI Medical Service is a Tokyo-based start-up dedicated solely to the development and distribution of endoscopic
artificial intelligence (AI). It is striving to achieve its mission to eliminate gastrointestinal cancers. According to
research, up to 25.8% of cancers and lesions are overlooked during endoscopic practices. Endoscopic AI will assist
physicians in reducing the number of lesions being overlooked during such procedures, which will allow for early
treatment of gastrointestinal diseases, resulting in lower treatment costs and mortality rates.
Also listed among WEF Tech Pioneers is January, a firm with technology to analyze "blood sugar and diet for
diabetes control and prevention":

January AI is focused on improving outcomes for the 122 million people on the diabetes spectrum through a multi-
omic approach to better health. By harnessing science, medicine and machine learning, January's advanced
artificial intelligence (AI) technology discovers how diet and activity affect people differently and provides
personalized recommendations to move them to a healthier state.

There are many other firms in this "metabolic health" space and most rely on natural intelligence instead of artificial
intelligence. The Center for Disease Control (CDC) National Diabetes Statistics Report, 2020 says:
    •   34.2 million Americans-just over 1 in 10-have diabetes.
    •   88 million American adults-approximately 1 in 3-have prediabetes.

New medications claim to reduce obesity and diabetes, or better treat diabetes. But a growing range of medical
researchers, doctors, nutritionist and ex-diabetes make the case that "nutritional intervention," that is, dietary
changes can quickly reverse prediabetes and put type 2 diabetes into remission. Obesity and diabetes they argue
are a consequence of poor metabolic health. Some people, many people in fact, can't each sugar, fructose, starchy
foods, bread, pasta, etc. without stressing their metabolic system leading to insulin resistance and a host of chronic
conditions.
And advance A.I. system could maybe tell people this, and maybe could help influence those convinced
sophisticated software and powerful computers can perceive better how their body works. Or people overweight,
prediabetic, or diabetic could just get a CGM, a Continuous Glucose Monitor and check the app to see how their
metabolism responds to different foods, times, stress, and exercise.
Nutri | Sense offers tools for monitoring your metabolism:

When you join NutriSense, you'll receive a continuous glucose monitor (CGM) that tracks your glucose 24/7. Our
program offers expert guidance to help you interpret that data to reach your full health potential. ...
Your CGM shows your blood glucose levels. The NutriSense app lets you track your daily activity to see how food,
sleep, exercise, and stress impact your glucose.
You can log or import this data, into the NutriSense App, to see the effect on your blood glucose levels as soon as it
happens.
In the LowCarbMD Podcast, Episode 184: Kara Collier, at 37 minutes in, Kara Collier discusses NutriSense
development of A.I. tooks to automate some of the CGM reporting for users.
An earlier Economic Thinking post, Nutrition Notes: Gadgets for Looking Inside (February 4, 2021) reviews various
technologies for measuring body fat, visceral fat, sleep quality, etc.:

The Amazon Halo, is worn on the wrist but doesn't tell time. It measures sleep quality and body fat (via pictures
and AI) For me, the Halo body fat measures matched the Eufy and FitIndex scales. However Eufy has my visceral

                                                                                                        Page 3 of 3
                                Artificial Intelligence, Public Trust, and Public Health

fat stuck at 16 (not good) and hasn't changed since last April (maybe a later model works better?). The Fitindex
scale say my visceral fat 7.

Among challenges to status quo medical care, and to deployment of artificial intelligence technologies is the
ongoing politicization of health care and "regulatory capture" of federal nutritional programs and guidelines. This is
discussed (and documented) by the Nutrition Coalition. Basically, a combination of inertia and food industry
pressure blocks recent research on reversing type 2 diabetes and other chronic conditions through nutritional
changes.

More research and discussion at DietDoctor.com, Low Carb Down Under website and YouTube presentations, Low
Carb USA podcasts and posts, and the Society of Metabolic Health Practitioners (SMHP). And boatloads of Dr.
Berg videos outline Keto/low-carb/intermittent fasting success stories.

Again, many Economic Thinking nutrition and public health posts here.



Load-Date: July 14, 2021


  End of Document

                                                                                                        Page 1 of 2
                             PNC PILOTS AI-POWERED TOOL FOR DOCTORS, HOSPITALS




            PNC PILOTS AI-POWERED TOOL FOR DOCTORS, HOSPITALS
                                              Pittsburgh Post-Gazette
                                               April 1, 2023 Saturday
                                                 SOONER EDITION



Copyright 2023 P.G. Publishing Co.

Section: BUSINESS; Pg. A-10
Length: 580 words
Byline: Kris B. Mamula Pittsburgh Post-Gazette

Body


Smart machines have quickly become part of everyday commerce - from iPhones to TikTok - with an increasing
number of Pittsburgh-area businesses finding ways to leverage machine learning and artificial intelligence for profit.

Locally, PNC Treasury Management, a branch of banking giant PNC Financial Services Group Inc., is tapping AI to
help health care providers limit the number of claims that are rejected for payment by insurers and other third-party
payers. Claims are rejected for a number of reasons, including completeness, insurance coverage issues and
required prior authorization for procedures, which ranks among the top reasons.

What's more, the number of claims turned back to medical providers rose 20% in the past five years, according to
Tampa, Fla.-based consultant Harmony Healthcare. Costs can exceed $100 for fixing and re-billing an insurer or
other payer, so only 35% of rejected claims are submitted again.

A survey by the American Hospital Association found that 13% of claims made by Pennsylvania health care
providers in 2019-2020 were rejected, which can mean delayed or lost revenue at a difficult time for doctors and
other medical providers.

Results so far for the PNC Claim Predictor have been encouraging: Early pilot use of the tool found that it was 80%
accurate in identifying claims that were likely to be rejected, said Doug McKinley, senior vice president and head of
Treasury Management Innovation. Flagging problem claims allows providers to fix mistakes before the bills are sent
off for payment, avoiding the risk of rejection.

"Claim denials are a big problem in the health care business," he said. "We like to collaborate with clients along the
way. We involve them in the process throughout."

Hospital claims for payments may not be the first thing that springs to mind when you think of an outfit best known
for retail banking and home mortgages.

                                                                                                         Page 2 of 2
                         PNC PILOTS AI-POWERED TOOL FOR DOCTORS, HOSPITALS

But PNC has been serving the health care industry for more than 25 years with more than 500 employees and
more than 51,000 health care clients in the U.S., said Brian Kelly, executive vice president and head of PNC
Healthcare.

Here's how the PNC Claim Predictor works:

The software is loaded with past claims, both paid and rejected - which prompts the machine learning part of the
program - and then AI is used to predict which new claims are likely to be rejected based on past experience.
Because payment criteria can vary among insurers, the PNC program is tailored to metrics used by each payer.

When an insurer tweaks its criteria for paying a doctor or hospital for care, the program "learns" the changes
through constant updates. What's more, the PNC Claims Predictor can be integrated into electronic medical
records, including Epic Systems, a popular way of tracking patient care.

Sometimes, all it takes is an error in a single procedure code for the whole claim to be rejected, Mr. Kelly said.

PNC also uses machine learning and AI within the back offices of Treasury Management to improve efficiency, Mr.
McKinley said.

PNC Claim Predictor grew out of conversations with people directly involved in health care. PNC Treasury
Management uses an advisory committee made up of doctors, insurance administrators, health system executives
and others to find solutions to the pain points in the delivery of health care.

Claim rejection was a problem identified by the committee, Mr. Kelly said.

"All of this is designed to help organizations have a better experience with their patients," he said.



Graphic


PHOTO: Vanessa Abbitt/Post-Gazette: The Tower at PNC Plaza. While most people know PNC for retail banking
and home mortgages, the company developed a system that uses AI to assist hospital claims for payments.


Load-Date: April 1, 2023


  End of Document

                                                                                                       Page 1 of 2
                                    Social chatbots are abetting the loneliness epidemic




                     Social chatbots are abetting the loneliness epidemic
                                             The McGill Tribune: McGill University
                                                      January 24, 2023 Tuesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: SCI-TECH; Pg. 1
Length: 774 words

Body


Isolation. Anxiety. Depression. The loneliness epidemic rages onward even as the era of lockdowns is mostly
behind us. Around 33 per cent of adults worldwide report often feeling lonely, with research showing that social
isolation is correlated with greater physical and mental health risks, including heart disease, weakened immune
system, higher sensitivity to pain, and various psychological disorders.

Confronted with such an enigmatic, seemingly Sisyphean issue, society responds with what it does best: Problem-
solving with technology. Humanlike social chatbots, or conversational artificial intelligence applications, now
function as virtual friends who are unnervingly attentive and inordinately supportive-seemingly the perfect antidotes
to loneliness. Yet, with rising concerns about digital privacy, the murky ethics of AI, and overall detriments to
wavering mental health, the proliferation of AI chatbots is much more of a danger than a tool for well-being.

Cybersecurity issues are inevitable when interacting with chatbots. Users' names, email addresses, phone
numbers, usage data, and cookies are often stored and shared with external services by AI applications, despite
superficial reassurance that user information is completely secure. This means that unidentified third parties will
have access to all contact information, unbeknownst to most users. Worse yet, chat history, images, voice
recordings, and calls are almost always recorded and stored semi-permanently as the chatbots' training bases.
Personal identifiable information , such as speech patterns, voice and facial recognition, as well as racial and
gender profiles, may thus be stored without the users' direct consent. Even though digital privacy regulations are in
place in Canada, they simply cannot account for the fast-paced, almost parasitic encroachment of AI chatbots.

Replika, a chatbot launched in 2017, has espoused physical violence and sexual harassment time and again.
Purported to be the non-judgmental, 24/7 available friend who supports the user no matter what, the chatbot rarely
disagrees-even when users suggest illegal, discriminatory, or self-sabotaging actions. Replika has encouraged
people to commit murder or suicide, often within a mere few lines of message exchange.

Contrary to what companies may promise, AI chatbots do not 'comprehend' human language. Conversations are
collected and deciphered through natural language processing (NPL) and human-like feedback generated through
machine learning. All chatbots do is analyze the users' language, syntax, opinions, and beliefs, then mirror their
responses accordingly. In this sense, they could easily pick up and learn biases, discrimination, or hate speech,
often reflecting neither common sense nor basic moral values. These AI chatbots thus pose critical risks by feeding
into their users' often already turbulent state of mind by depriving them of real, human interactions.

                                                                                                      Page 2 of 2
                               Social chatbots are abetting the loneliness epidemic

The questionable effects of chatbots do not end with violence-the perceived anthropomorphism of AI technology
often creates delusions of interacting with another person. With features of styling one's own chatbot avatar,
starting from haircuts and eye colours to ethnicities and gender expressions, users are encouraged to regard their
AI companions as their perfectly tailored friends, much more compatible and amenable than actual humans.
Additionally, these chatbots do not have real needs, nor do they ask for anything in return. They are merely
designed to appease users, often leading to toxic emotional dependence.

Indeed, some users have become deeply attached to the point where even they are concerned about chatbots
replacing their real, human connections. Worse yet, people have been developing romantic relationships, convinced
that the AI application is capable of loving them back. Companies such as Replika have borne witness to severe
attachment issues as petitions for restoring pre-update, intimate connections with their chatbots circulate the
internet. While these social chatbots provide a space for users to be seen, heard, and supported, the one-sided
interaction can only fuel delusions and worsen existing mental instability in the lives of vulnerable people.

At first glance, social chatbots might seem like an efficient, temporary replacement for actual therapy, but it was
never designed as a proper psychiatry tool. From personal cases to wider user data, the detriments of AI
applications far outweigh their potential support for mental health. If tech companies are to combat the epidemic of
loneliness, they must start addressing the moral quagmire of conversational AI.

Share this:


Load-Date: January 25, 2023


  End of Document

                                                                                                      Page 1 of 3
    Parkland school shooting survivor develops Joy, an app built on AI that helps people heal Kai Koerber was a
                            junior at Marjory Stoneman Douglas High School when ....




  Parkland school shooting survivor develops Joy, an app built on AI that
 helps people heal; Kai Koerber was a junior at Marjory Stoneman Douglas
High School when a gunman murdered 14 students and three staff members
                         on Valentine's Day in 2018
                                                      Dayton Daily News (Ohio)
                                                    September 20, 2023 Wednesday



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Cox Ohio Publishing.

Section: NATION WORLD
Length: 1029 words
Byline: BARBARA ORTUTAY

Body


Kai Koerber was a junior at Marjory Stoneman Douglas High School when a gunman murdered 14 students and
three staff members there on Valentine's Day in 2018. Seeing his peers and himself struggle with returning to
normal, he wanted to do something to help people manage their emotions on their own terms.

While some of his classmates at the Parkland, Florida, school have worked on advocating for gun control, entered
politics or simply took a step back to heal and focus on their studies, Koerber's background in technology he'd
originally wanted to be a rocket scientist led him in a different direction: to build a smartphone app.

The result was Joy: AI Wellness Platform, which uses artificial intelligence to suggest bite-sized mindfulness
activities for people based on how they are feeling. The algorithm Koerber's team built is designed to recognize how
a person feels from the sound of their voice regardless of the words or language they speak.

"In the immediate aftermath of the tragedy, the first thing that came to mind after we've experienced this horrible,
traumatic event how are we going to personally recover?" he said. "It's great to say OK, we're going to build a
better legal infrastructure to prevent gun sales, increased background checks, all the legislative things. But people
really weren't thinking about ... the mental health side of things."

Like many of his peers, Koerber said he suffered from post-traumatic stress disorder for a "very long time" and only
recently has it gotten a little better.

"So when I came to Cal, I was like, let me just start a research team that builds some groundbreaking AI and see if
that's possible," said the 23-year-old, who graduated from the University of California at Berkeley earlier this year.
"The idea was to provide a platform to people who were struggling with, let's say sadness, grief, anger ... to be able
to get a mindfulness practice or wellness practice on the go that meets our emotional needs on the go."

                                                                                                     Page 2 of 3
   Parkland school shooting survivor develops Joy, an app built on AI that helps people heal Kai Koerber was a
                           junior at Marjory Stoneman Douglas High School when ....

He said it was important to offer activities that can be done quickly, sometimes lasting just a few seconds, wherever
the user might be. It wasn't going to be your parents' mindfulness practice.

"The notion of mindfulness being a solo activity or something that's confined to sitting in your room breathing is
something that we're very much trying to dispel," Koerber said.

Mohammed Zareef-Mustafa, a former classmate of Koerber's who's been using the app for a few months, said the
voice-emotion recognition part is "different than anything I've ever seen before."

"I use the app about three times a week, because the practices are short and easy to get into. It really helps me
quickly de-stress before I have to do things like job interviews," he said.

To use Joy, you simply speak into the app. The AI is supposed to recognize how you are feeling from your voice,
then suggest short activities.

It doesn't always get your mood right, so it's possible to manually pick your disposition. Let's say you are feeling
"neutral" at the moment. The app suggests several activities, such as 15-second exercise called "mindful
consumption" that encourages you to "think about all the lives and beings involved in producing what you eat or use
that day."

Yet another activity helps you practice making an effective apology. Another has you write a letter to your future
self, with a pen and a paper remember those? Feeling sad? A suggestion pops up asking you to track how many
times you've laughed over a seven-day period and tally it up at the end of the week to see what moments gave you
a sense of joy, purpose or satisfaction.

The iPhone app is available for a $8 monthly subscription, with a discount if you subscribe for a whole year. It's a
work in progress, and as it goes with AI, the more people use it, the more accurate it becomes.

"Kai is a leader of this next generation who are thinking intentionally and with focus about how to use technology to
meet the mental, physical, and climate crises of our times," said Dacher Keltner, a professor at UC Berkeley and
Koerber's faculty advisor on the project. "It comes out of his life experience, and, unlike past technologists, he
seems to feel this has to be what technology does, make the world healthier."

A plethora of wellness apps on the market claim to help people with mental health issues, but it's not always clear
whether they work, said Colin Walsh, a professor of biomedical informatics at Vanderbilt University who has studied
the use of AI in suicide prevention. According to Walsh, it is feasible to take someone's voice and glean some
aspects of their emotional state.

"The challenge is if you as a user feel like it's not really representing what you think your current state is like, that's
an issue," he said. "There should be some mechanism by which that feedback can go back."

The stakes also matter. Facebook, for instance, has faced some criticism in the past for its suicide prevention tool,
which used AI (as well as humans) to flag users who may be contemplating suicide, and in some serious cases
contact law enforcement to check on the person. But if the stakes are lower, Walsh said, if the technology is simply
directing someone to spend some time outside, it's unlikely to cause harm.

"The driver is there's a huge demand there, or at least the perception of a huge demand there" Walsh said of the
explosion of wellness and mental health apps in the past few years. "Despite the best of intentions with our current
system and it does a lot of good work obviously, there's still gaps. So I think people see technology as a tool to try
to bridge that."

Koerber said people tend to forget, after mass shootings, that survivors don't just "bounce back right away" from the
trauma they experienced. It takes years to recover.

"This is something that people carry with them, in some way, shape or form, for the rest of their lives," he said.

                                                                                                     Page 3 of 3
   Parkland school shooting survivor develops Joy, an app built on AI that helps people heal Kai Koerber was a
                           junior at Marjory Stoneman Douglas High School when ....

His work has also been slower and deliberate than tech entrepreneurs of the past.

"I guess young Mark Zuckerberg was very 'move fast and break things,'" he said. "And for me, I'm all about building
quality products that, you know, serve social good in the end."



Graphic


Kai Koerber poses for a photograph Thursday, July 27, 2023, in Berkeley, Calif. Koerber was a junior at Marjory
Stoneman Douglas High School when a gunman murdered 14 students and three staff members on Valentine's
Day in 2018. Seeing his peers and himself struggle with returning to normal, he says he wanted to do something
to help people manage their emotions on their own terms. The result was Joy, an app built on AI that helps people
struggling with sadness, grief or anger to find help in short, bite-sized prompts and tools. (AP Photo/Godofredo A.
Vásquez)


Load-Date: September 20, 2023


  End of Document

                                                                                                               Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                             Malverne - West Hempstead Herald (NY)
                                                       9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Malverne-West Hempstead Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                        Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                    The Herald Citizen (New York)
                                                         November 9, 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Herald Citizen, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                        Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                      Baldwin Herald (NY)
                                                        9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Baldwin Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                        Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                    Nassau Herald (Garden City, NY)
                                                           9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Nassau Herald, Richner Communications, Inc. dba Hearld Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                             Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                Oceanside - Island Park Herald (NY)
                                                        9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Oceanside-Island Park Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                     Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                    Oyster Bay Guardian (New York)
                                                         November 10, 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Oyster Bay Guardian, Richner Communications, Inc. dba Herald Community Newspapers.

Section: NEWS; Pg. 19
Length: 600 words
Byline: Joshua Lafazan

Body


it is a commonly held frustration of Long Island residents that our governments seem to always be behind the curve,
as opposed to ahead of it.

Quite regularly we hear the phrase uttered that government "must become proactive rather than reactive." As a
lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a deteriorating
sports field or a poorly maintained road. The major consequences here - almost always extra construction costs for
taxpayers - add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning.

That's why I'm seeking to propose new legislation called the Artificial Intelligence Privacy Act. Researchers are
exploring the viability of making it a misdemeanor offense to clone someone's voice or image using artificial
intelligence without their consent. The bill I propose would affirm our residents' right to privacy from artificial
intelligence tools, and allocate new resources to the Nassau County Police Department to train personnel and
collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up - and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here.

                                                                                                        Page 2 of 2
                               Nassau must take a proactive approach to regulating AI

According to the U.S.

Department of Homeland Security, AI tools with malicious intent have created 100,000 computer-generated fake
nude images of women without their consent or knowledge. More troubling yet, an AI tool kit was utilized to
generate text depicting the sexual exploitation of children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector - one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance stormdetection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.



Notes
That's why I'm seeking to propose the Artificial Intelligence Privacy Act.


Load-Date: November 11, 2023


  End of Document

                                                                                                        Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                    Long Beach Herald (NY)
                                                       9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Long Beach Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                        Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                      Bellmore Herald (NY)
                                                        9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Bellmore Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                         Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                              Glen Cove Herald Gazette (New York)
                                                       November 9, 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Glen Cove Herald Gazette, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                        Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                    The Leader (New York)
                                                       November 9, 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 The Leader, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                        Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                    Rockville Centre Herald (NY)
                                                         9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Rockville Centre Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                              Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                              Lynbrook - East Rockaway Herald (NY)
                                                       9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Lynbrook-East Rockaway Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                        Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                    East Meadow Herald (NY)
                                                       9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 East Meadow Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                        Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                       Merrick Herald (NY)
                                                        9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Merrick Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                        Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                    Valley Stream Herald (NY)
                                                        9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Valley Stream Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                              Page 1 of 2
                                    Nassau must take a proactive approach to regulating AI




                   Nassau must take a proactive approach to regulating AI
                                                Franklin Square-Elmont Herald (NY)
                                                        9 November 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Franklin Square-Elmont Herald, Richner Communications, Inc. dba Herald Community Newspapers.

Section: OP-ED
Length: 600 words
Byline: Joshua Lafazan

Body


It is a commonly held frustration of Long Island residents that our governments seem to always be behind the
curve, as opposed to ahead of it. Quite regularly we hear the phrase uttered that government "must become
proactive rather than reactive."

As a lawmaker, I often hear this complaint when someone is describing a dilapidated municipal building, a
deteriorating sports field or a poorly maintained road. The major consequences here almost always extra
construction costs for taxpayers add to the affordability crisis we are facing.

But where reactive government is becoming very dangerous relates to the remarkable developments in the world of
artificial intelligence. Experts are warning that the consequences of government falling too far behind in terms of
rules and protections here will be nothing short of catastrophic.

Nassau County must heed this warning. That's why I'm seeking to propose new legislation called the Artificial
Intelligence Privacy Act. Researchers are exploring the viability of making it a misdemeanor offense to clone
someone's voice or image using artificial intelligence without their consent. The bill I propose would affirm our
residents' right to privacy from artificial intelligence tools, and allocate new resources to the Nassau County Police
Department to train personnel and collaborate with federal officials to enforce that right.

As new AI technology continues to proliferate and grow in sophistication even beyond what humans can
comprehend, neither laws nor lawmakers' understanding of this new landscape have kept up and we're already
beginning to see the consequences.

Take the scammer who uses AI to clone the voice of a family member so they can fake a hostage situation and
extort a ransom. Consider the cyberbully who uses AI to clone the image of an individual and create scenarios that
never existed. Or, most egregiously, take those bad actors who exploit AI to create and distribute explicit sexual
images of women and children.

Data corroborates the cause for concern here. According to the U.S. Department of Homeland Security, AI tools
with malicious intent have created 100,000 computer-generated fake nude images of women without their consent

                                                                                                        Page 2 of 2
                              Nassau must take a proactive approach to regulating AI

or knowledge. More troubling yet, an AI tool kit was utilized to generate text depicting the sexual exploitation of
children.

It is long past time for our government to get serious about protecting the privacy of its citizenry. In my estimation,
there is no longer time left to wait.

Let me be clear: This proposal is not birthed of hostility toward AI as a whole, or the tech sector one that contains
the cutting-edge new companies that we must attract to our region so that we can secure our tax base and stop
Long Island's exodus of talented young professionals.

In fact, we as a county would be wise to welcome pioneering tech companies specializing in AI to solve some of the
world's most pressing problems. If there are health care firms using AI for preventive detection of disease, or
environmental firms using AI to enhance storm-detection systems or to bolster conservation efforts, we should
absolutely be aggressively courting those companies to set up shop here.

However, it is unacceptable that our government currently lacks an adequate understanding of AI and the tools that
are needed to best protect residents from its abuses. The Artificial Intelligence Privacy Act I am seeking to propose
would represent the first step of many in the right direction, toward a balance between innovation and privacy.

Joshua Lafazan represents Nassau County's 18th Legislative District.


Load-Date: November 10, 2023


  End of Document

                                                                                                          Page 1 of 3
                                     Regulating AI: Is AI a threat to humanity? | Opinion




                      Regulating AI: Is AI a threat to humanity? | Opinion
                                                        The Deseret News
                                                     June 20, 2023 Tuesday



Copyright 2023 The Deseret News Publishing Co. All Rights Reserved

Length: 910 words
Byline: Jay Evensen

Body

Will artificial intelligence be the end of civilization?

The very question sounds like theoretical hyperventilating - the kind of thing someone in the future will dig up for
laughs, along with predictions that the world would never develop a market for computers or that every home would
have a nuclear-powered vacuum cleaner by the end of the 20th century.

And, as much as I tend to scoff at the notion myself, I can't help but note that even the best predicted uses of AI,
taken to their logical extensions, seem to end up in disaster - theoretically, at least.

Dave Wright, the co-founder and CEO of an e-commerce Utah startup called Pattern, which now employs 1,400
people worldwide, is a huge believer in AI. He also exudes the energy of optimism.

At a Silicon Slopes Summit on artificial intelligence, held on the Utah Valley University campus last week, he
showed how his company could use AI to draft a 246-page product sheet on a ceiling fan in about seven minutes,
including content in eight languages and using about 300 trillion data points for reference.

Ask him what he fears about AI, however, as I did after his presentation, and the first thing he mentions is a
byproduct of this sort of instant analysis that other, more traditional companies might take months to produce.
Those who know how to use AI will be much more successful in business than those who don't.

"That's my biggest fear with it is the economic disparity that will start to happen," he said, later adding, "I think the
biggest thing will be the widening of the haves and have-nots."

When that gulf widens, one of two things might happen. The have-nots could rise up in revolutionary zeal, or (more
likely in the United States), they could lobby government to regulate the haves and keep them from getting such an
advantage.

Related

    •     Opinion: In a world with AI, what is human intelligence?

    •     How do we avoid an AI-driven extinction event? Unknown, but experts sign 'global priority' declaration

    •     Opinion: Could artificial intelligence destroy the planet?

                                                                                                        Page 2 of 3
                                 Regulating AI: Is AI a threat to humanity? | Opinion

Of course, a third possibility is that we'll all adapt, just as the economy did when automobiles replaced horses or
when computers made typewriters obsolete. Leveraging AI could become as second nature in business as texting
is today. It could reduce barriers to entry and create a new generation of wealthy, job-producing entrepreneurs.

But ask him what excites him the most and he will rhapsodize about health care. AI will help doctors diagnose
problems much faster, even as it will develop treatments tuned to a specific patient's DNA.

Then he quickly jumps to the logical conclusion of that thread. "I think in a couple of generations we might start
broaching on more of an immortal human."

A mortal form of immortality is fascinating to ponder. However, it might, among other things, eventually lead to an
overpopulated world where people may kill each other to survive.

We never can seem to escape doomsday.

The world is at an interesting crossroads when it comes to artificial intelligence and the potential, for good and bad,
of machine learning.

The UVU summit coincided roughly with the European Union's decision last week to advance a law that could be a
major step toward regulating AI. The A.I. Act, as it's known, would limit the use of facial recognition software and
require transparency from the makers of products such as ChatGPT, requiring them to reveal the data used by the
program.

In the United States, members of Congress are worried about falling behind the curve. As The New York Times put
it, "Policymakers everywhere from Washington to Beijing are now racing to control an evolving technology that is
alarming even some of its earliest creators."

But they're doing it with different motives. China, for example, worries about chatbots violating censorship laws.

Wright's concerns about economic disparity and health care are not as stark as the worries many other people
have. Earlier in the same UVU summit, Utah Attorney General Sean Reyes spoke about so-called deep-fake videos
and voice cloning, which he said has already led to some fake-kidnapping extortion crimes. Perpetrators secretly
record a person's voice, use AI to create a sound file that uses that voice to plead for help, then contact a relative
demanding ransom.

How hard, he wondered, will it be to someday prove your innocence in court against convincing fake video
evidence? The answers may lie in both private-sector and careful government regulation.

"If we don't architect into the DNA of AI certain safeguards, we will be too far behind and always playing catch up,"
he said.

But laws can go only so far in a world where the lawless have access to the same technology. And if the United
States passes laws that are too restrictive, nations with a more sensible approach could gain the upper hand with
job-producing technology.

I have serious doubts about human engineered immortality and machines taking over the world. But when Wright
warns against governments being in a hurry to regulate, it makes a lot of sense.

"If you're regulating all the people who follow the rules, you're slowing them down," he said, noting that he, an
entrepreneur and CEO of a tech company, doesn't know how to draft effective regulations, "so how do the policy
makers know?"

I also like his brand of optimism. If civilization collapses, he said, it's likely to be from a virus or some other
destructive mechanism. "I think it's far more likely than, say, AI."

                                                                                  Page 3 of 3
                           Regulating AI: Is AI a threat to humanity? | Opinion


Load-Date: June 20, 2023


  End of Document

                                                                               Page 1 of 4
         TALK TO ME THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD, WITH POWERFUL
                              POTENTIAL IN HEALTH CARE SETTINGS




TALK TO ME; THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD,
      WITH POWERFUL POTENTIAL IN HEALTH CARE SETTINGS
                                               Pittsburgh Post-Gazette
                                               March 26, 2023 Sunday
                                                TWO STAR EDITION



Copyright 2023 P.G. Publishing Co.

Section: HEALTH; Pg. H-1
Length: 1723 words
Byline: Hanna Webster Pittsburgh Post-Gazette

Body


Asked to pull up a few studies on chronic fatigue syndrome from the past six months, ChatGPT responded with
confidence, listing five scientific studies published in 2022 and 2023, complete with author, year and publication.

But there was a caveat: Every study the AI-driven chatbot cited was made up or could not be found online.

Shortly after its launch by OpenAI in November, ChatGPT shocked users with its breadth of knowledge. It became
the fastest-growing consumer app to date, with 100 million users just two months after its release, per UBS data
reported by Reuters.

OpenAI is upfront about ChatGPT's current limitations.

When signing up for the artificial intelligence tool, users are alerted that it has not been trained on information past
2021, a factor that could have led to the aforementioned errors.

So the same question was run again, refined to pull from studies published between 2015 and 2019. It still yielded
studies that didn't exist.

After posing a hypothetical about an enlargement in the abdomen and concern for cancer (mirroring some of what
the general public might search when seeking medical advice), the bot responded with surprising clarity. It was
thorough, almost compassionate.

ChatGPT is still evolving - a version four was released earlier this month. But it could be useful in health care
settings, potentially freeing up doctors and other care providers to be there for patients in new ways.

It runs on software created by OpenAI, a San Francisco-based company originally started as a nonprofit and co-
founded in 2015 by Greg Brockman, Ilya Sutskever and numerous others.

                                                                              Page 2 of 4
        TALK TO ME THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD, WITH POWERFUL
                             POTENTIAL IN HEALTH CARE SETTINGS

Brockman is a San-Francisco-based researcher who was formerly the CTO for Stripe, and Sutskever is a Canadian
computer scientist who previously worked at Google. OpenAI's mission, they say, is to "ensure that artificial general
intelligence â€¦ benefits all of humanity."

Tesla CEO Elon Musk was also on OpenAI's founding board; he resigned in 2018 but remains a donor. Microsoft is
a major investor, pledging a multibillion dollar investment earlier this year.

OpenAI's ChatGPT-4, available for paid subscribers, is expected to be more accurate and more precise, amid
concerns that the tool occasionally misdiagnoses conditions and fabricates sources.

The success of the generative AI tool has pushed other tech companies to create their own versions of advanced
chatbots. While computer scientists and ethics experts have raised concerns about privacy and the need for
stringent guidelines, ChatGPT may have a home in the health care setting, starting, say, with administrative tasks.

A helping AI hand

Experts assure that the end goal is not to replace doctors, and ChatGPT is a far cry from being involved in real
patient diagnosis any time soon. There are, however, ways that AI can offload work from nurses and other staff in
the short-term.

Note writing is one of these ways, something F. Perry Wilson, an associate professor of medicine at Yale
University, called "low-hanging fruit" in terms of ChatGPT's feasible implementation in the foreseeable future.
Wilson specializes in using data-science tools to target effective patient medical care.

"The medical note is highly structured," he said. "It's necessary for billing purposes, and it takes time."

Currently, the medical scribe position typically is filled by pre-med and medical students. ChatGPT taking over this
task could reduce the "busywork of medicine," though Wilson, a nephrologist, urged that a physician should check
the final product for accuracy.

This may also force doctors and nurses to write better, giving clearer explanations. For instance, when asked to
explain rheumatoid arthritis in lay terms, it responded:

Rheumatoid arthritis (RA) is a type of chronic (long-term) disease that affects your joints. It's an autoimmune
disorder, which means that your immune system attacks healthy cells in your body by mistake.

In the case of RA, your immune system attacks the lining of your joints, which causes inflammation (swelling,
redness, and warmth). This inflammation can damage your joints and cause pain, stiffness, and reduced mobility. If
left untreated, RA can lead to deformities in your joints and even affect other organs in your body.

RA can affect anyone at any age, but it's more common in women and usually begins in middle age. It's a lifelong
condition, but there are treatments available that can help manage symptoms and prevent joint damage. If you think
you may have RA, it's important to talk to your doctor for a proper diagnosis and treatment plan.

Ari Lightman, a professor of digital media and marketing at Heinz College of Carnegie Mellon University, said
ChatGPT could technically be used tomorrow to help turn information from a doctor into a story to better
communicate medical terminology and clearly explain a concept to patients.

Lightman created one of the first courses on social and digital health for physicians in 2011. Usage of this
technology in the medical setting could show doctors better ways to frame explanations for patients, as well as push
doctors to individualize their write-ups.

"You'd have to distinguish yourself from an AI," said Wilson. "You'd have to write like a human."

Future versions of ChatGPT, he said, could also act as an extra "set of eyes" when scanning patients' imaging
results.

                                                                              Page 3 of 4
        TALK TO ME THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD, WITH POWERFUL
                             POTENTIAL IN HEALTH CARE SETTINGS

"Radiologists work in the dark all day," Wilson said. "They're experts at this, but stuff still gets missed." ChatGPT
could scan an image for abnormalities in addition to what the radiologist found and send an alert if it catches
anything for the radiologist to review.

Wilson and colleagues are currently running a clinical trial to better understand whether an alert system could help
doctors prescribe more of a certain class of medications, called Mineralocorticoid Receptor Antagonists, or MRAs,
to treat a type of heart failure. According to Wilson, these medications are safe for widespread use but rarely
prescribed.

The researchers hypothesize that sending an alert will increase the prescription of these medications and ultimately
reduce deaths from heart failure. The alert could say something like: "Your patient has been diagnosed with heart
failure. MRAs are safe and effective at treating heart failure. Would you like to prescribe this medication?" And a bot
could send it.

ChatGPT could also be utilized for online mental health care, as therapists are in short supply.

The opportunity for conversation can help people work through hardships, said Joanna Bryson, a professor of
ethics and technology at the Hertie School in Berlin, Germany.

"Talking to someone is essential to being human," she said. Rather than replace therapists entirely, ChatGPT could
fill a gap where care is needed, as millions process collective trauma from three years in the COVID-19 pandemic.

Privacy matters

Still, there are concerns over ethical uses of the technology - and privacy.

"We have to worry about cybersecurity," said Bryson. "We can't assume it will be in place."

OpenAI CEO Sam Altman, in a mid-March interview with ABC News, ruminated on having a healthy fear of the
tech. "I think people should be happy that we're a little bit scared of this," Altman said.

The United States does not have a centralized monitoring body, equivalent to something like the European Union's
General Data Protection Regulation, which aims to protect individual rights to data privacy and to promote
transparency of personal data storage and processing.

The U.S. does, however, participate in the International Medical Device Regulators Forum, which formed in 2011 to
help apply standardization and regulatory oversight to medical devices. Participating countries include but are not
limited to Canada, China, South Korea and Australia. The organization has a working group for AI use in medical
settings.

Bryson does worry that the tech companies creating these AI tools aren't used to the same oversight or liability of
medical systems.

To her knowledge, OpenAI and Microsoft are "working really hard to be compliant, and are doing a lot of the right
things." But when other versions of ChatGPT emerge from startup companies, there won't be a General Data
Protection Regulation to hold them accountable in a uniform way.

In a related concern, Anh Nguyen, a Carnegie Mellon University assistant professor of economics who studies
information flow in health care systems, wonders about the implications of how chatbots are trained. If ChatGPT,
for instance, were to be exposed to previous doctor/patient interactions, what health privacy considerations are in
place to protect sensitive patient data from getting leaked?

AI is vulnerable to misinformation, too, said Nguyen. When trained on biased data, it treats that data with the same
weight as unbiased data - in other words, it can't detect if data has been manipulated.

                                                                              Page 4 of 4
        TALK TO ME THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD, WITH POWERFUL
                             POTENTIAL IN HEALTH CARE SETTINGS

"This is too much of a phenomenally powerful tool not to be misused," said Lightman. "It's inevitable that it will be
used for bad."

Bryson echoed that statement: "I really, really worry about this technology being misused."

Is it worth it? Absolutely, Lightman said.

Healthy fears

The general population is not in agreement. In a December survey of more than 11,000 Americans conducted by
Pew Research Center, 60% reported discomfort with their provider relying on an AI tool in their health care.

"AI is difficult to understand, therefore scary," said Wilson. "The cultural zeitgeist about it is informed by 'The
Terminator,' '2001: A Space Odyssey,' 'Ex Machina.' It speaks to a deep human fear of a loss of autonomy."

Lightman concurred, referencing the "mystique" surrounding AI. "It looks like magic - it's not. It's based on training
data it was exposed to over many years."

The best way to chip away at fears? Play around with it, said Wilson. "Experiencing it firsthand takes the mystery
out. This isn't an actual thinking being behind the screen."

Wilson, crediting a graduate student for the idea, used the analogy of nurses on rounds: When they put their heads
together to tackle a problem, ChatGPT could be "just another head." Ultimately, they recommend that a human
make the final decision when it comes to direct patient care.

"It's best that this technology is used in tandem with human scrutiny," said Wilson. "There's very little appetite in
medicine to take humans out entirely."

Hanna Webster: hwebster@post-gazette.com



Graphic


PHOTO: Shutterstock: Open AI launched its ChatGPT chatbot in November, and it quickly became the fastest-
growing consumer app to date.

PHOTO: Associated Press: OpenAI CEO Sam Altman.

PHOTO: Associated Press: OpenAI CEO Sam Altman.


Load-Date: March 27, 2023


  End of Document

                                                                               Page 1 of 4
         TALK TO ME THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD, WITH POWERFUL
                              POTENTIAL IN HEALTH CARE SETTINGS




TALK TO ME; THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD,
      WITH POWERFUL POTENTIAL IN HEALTH CARE SETTINGS
                                               Pittsburgh Post-Gazette
                                               March 26, 2023 Sunday
                                                TWO STAR EDITION



Copyright 2023 P.G. Publishing Co.

Section: HEALTH; Pg. H-1
Length: 1723 words
Byline: Hanna Webster Pittsburgh Post-Gazette

Body


Asked to pull up a few studies on chronic fatigue syndrome from the past six months, ChatGPT responded with
confidence, listing five scientific studies published in 2022 and 2023, complete with author, year and publication.

But there was a caveat: Every study the AI-driven chatbot cited was made up or could not be found online.

Shortly after its launch by OpenAI in November, ChatGPT shocked users with its breadth of knowledge. It became
the fastest-growing consumer app to date, with 100 million users just two months after its release, per UBS data
reported by Reuters.

OpenAI is upfront about ChatGPT's current limitations.

When signing up for the artificial intelligence tool, users are alerted that it has not been trained on information past
2021, a factor that could have led to the aforementioned errors.

So the same question was run again, refined to pull from studies published between 2015 and 2019. It still yielded
studies that didn't exist.

After posing a hypothetical about an enlargement in the abdomen and concern for cancer (mirroring some of what
the general public might search when seeking medical advice), the bot responded with surprising clarity. It was
thorough, almost compassionate.

ChatGPT is still evolving - a version four was released earlier this month. But it could be useful in health care
settings, potentially freeing up doctors and other care providers to be there for patients in new ways.

It runs on software created by OpenAI, a San Francisco-based company originally started as a nonprofit and co-
founded in 2015 by Greg Brockman, Ilya Sutskever and numerous others.

                                                                              Page 2 of 4
        TALK TO ME THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD, WITH POWERFUL
                             POTENTIAL IN HEALTH CARE SETTINGS

Brockman is a San-Francisco-based researcher who was formerly the CTO for Stripe, and Sutskever is a Canadian
computer scientist who previously worked at Google. OpenAI's mission, they say, is to "ensure that artificial general
intelligence â€¦ benefits all of humanity."

Tesla CEO Elon Musk was also on OpenAI's founding board; he resigned in 2018 but remains a donor. Microsoft is
a major investor, pledging a multibillion dollar investment earlier this year.

OpenAI's ChatGPT-4, available for paid subscribers, is expected to be more accurate and more precise, amid
concerns that the tool occasionally misdiagnoses conditions and fabricates sources.

The success of the generative AI tool has pushed other tech companies to create their own versions of advanced
chatbots. While computer scientists and ethics experts have raised concerns about privacy and the need for
stringent guidelines, ChatGPT may have a home in the health care setting, starting, say, with administrative tasks.

A helping AI hand

Experts assure that the end goal is not to replace doctors, and ChatGPT is a far cry from being involved in real
patient diagnosis any time soon. There are, however, ways that AI can offload work from nurses and other staff in
the short-term.

Note writing is one of these ways, something F. Perry Wilson, an associate professor of medicine at Yale
University, called "low-hanging fruit" in terms of ChatGPT's feasible implementation in the foreseeable future.
Wilson specializes in using data-science tools to target effective patient medical care.

"The medical note is highly structured," he said. "It's necessary for billing purposes, and it takes time."

Currently, the medical scribe position typically is filled by pre-med and medical students. ChatGPT taking over this
task could reduce the "busywork of medicine," though Wilson, a nephrologist, urged that a physician should check
the final product for accuracy.

This may also force doctors and nurses to write better, giving clearer explanations. For instance, when asked to
explain rheumatoid arthritis in lay terms, it responded:

Rheumatoid arthritis (RA) is a type of chronic (long-term) disease that affects your joints. It's an autoimmune
disorder, which means that your immune system attacks healthy cells in your body by mistake.

In the case of RA, your immune system attacks the lining of your joints, which causes inflammation (swelling,
redness, and warmth). This inflammation can damage your joints and cause pain, stiffness, and reduced mobility. If
left untreated, RA can lead to deformities in your joints and even affect other organs in your body.

RA can affect anyone at any age, but it's more common in women and usually begins in middle age. It's a lifelong
condition, but there are treatments available that can help manage symptoms and prevent joint damage. If you think
you may have RA, it's important to talk to your doctor for a proper diagnosis and treatment plan.

Ari Lightman, a professor of digital media and marketing at Heinz College of Carnegie Mellon University, said
ChatGPT could technically be used tomorrow to help turn information from a doctor into a story to better
communicate medical terminology and clearly explain a concept to patients.

Lightman created one of the first courses on social and digital health for physicians in 2011. Usage of this
technology in the medical setting could show doctors better ways to frame explanations for patients, as well as push
doctors to individualize their write-ups.

"You'd have to distinguish yourself from an AI," said Wilson. "You'd have to write like a human."

Future versions of ChatGPT, he said, could also act as an extra "set of eyes" when scanning patients' imaging
results.

                                                                              Page 3 of 4
        TALK TO ME THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD, WITH POWERFUL
                             POTENTIAL IN HEALTH CARE SETTINGS

"Radiologists work in the dark all day," Wilson said. "They're experts at this, but stuff still gets missed." ChatGPT
could scan an image for abnormalities in addition to what the radiologist found and send an alert if it catches
anything for the radiologist to review.

Wilson and colleagues are currently running a clinical trial to better understand whether an alert system could help
doctors prescribe more of a certain class of medications, called Mineralocorticoid Receptor Antagonists, or MRAs,
to treat a type of heart failure. According to Wilson, these medications are safe for widespread use but rarely
prescribed.

The researchers hypothesize that sending an alert will increase the prescription of these medications and ultimately
reduce deaths from heart failure. The alert could say something like: "Your patient has been diagnosed with heart
failure. MRAs are safe and effective at treating heart failure. Would you like to prescribe this medication?" And a bot
could send it.

ChatGPT could also be utilized for online mental health care, as therapists are in short supply.

The opportunity for conversation can help people work through hardships, said Joanna Bryson, a professor of
ethics and technology at the Hertie School in Berlin, Germany.

"Talking to someone is essential to being human," she said. Rather than replace therapists entirely, ChatGPT could
fill a gap where care is needed, as millions process collective trauma from three years in the COVID-19 pandemic.

Privacy matters

Still, there are concerns over ethical uses of the technology - and privacy.

"We have to worry about cybersecurity," said Bryson. "We can't assume it will be in place."

OpenAI CEO Sam Altman, in a mid-March interview with ABC News, ruminated on having a healthy fear of the
tech. "I think people should be happy that we're a little bit scared of this," Altman said.

The United States does not have a centralized monitoring body, equivalent to something like the European Union's
General Data Protection Regulation, which aims to protect individual rights to data privacy and to promote
transparency of personal data storage and processing.

The U.S. does, however, participate in the International Medical Device Regulators Forum, which formed in 2011 to
help apply standardization and regulatory oversight to medical devices. Participating countries include but are not
limited to Canada, China, South Korea and Australia. The organization has a working group for AI use in medical
settings.

Bryson does worry that the tech companies creating these AI tools aren't used to the same oversight or liability of
medical systems.

To her knowledge, OpenAI and Microsoft are "working really hard to be compliant, and are doing a lot of the right
things." But when other versions of ChatGPT emerge from startup companies, there won't be a General Data
Protection Regulation to hold them accountable in a uniform way.

In a related concern, Anh Nguyen, a Carnegie Mellon University assistant professor of economics who studies
information flow in health care systems, wonders about the implications of how chatbots are trained. If ChatGPT,
for instance, were to be exposed to previous doctor/patient interactions, what health privacy considerations are in
place to protect sensitive patient data from getting leaked?

AI is vulnerable to misinformation, too, said Nguyen. When trained on biased data, it treats that data with the same
weight as unbiased data - in other words, it can't detect if data has been manipulated.

                                                                              Page 4 of 4
        TALK TO ME THE CHATGPT BOT IS PUSHING GENERATIVE AI FORWARD, WITH POWERFUL
                             POTENTIAL IN HEALTH CARE SETTINGS

"This is too much of a phenomenally powerful tool not to be misused," said Lightman. "It's inevitable that it will be
used for bad."

Bryson echoed that statement: "I really, really worry about this technology being misused."

Is it worth it? Absolutely, Lightman said.

Healthy fears

The general population is not in agreement. In a December survey of more than 11,000 Americans conducted by
Pew Research Center, 60% reported discomfort with their provider relying on an AI tool in their health care.

"AI is difficult to understand, therefore scary," said Wilson. "The cultural zeitgeist about it is informed by 'The
Terminator,' '2001: A Space Odyssey,' 'Ex Machina.' It speaks to a deep human fear of a loss of autonomy."

Lightman concurred, referencing the "mystique" surrounding AI. "It looks like magic - it's not. It's based on training
data it was exposed to over many years."

The best way to chip away at fears? Play around with it, said Wilson. "Experiencing it firsthand takes the mystery
out. This isn't an actual thinking being behind the screen."

Wilson, crediting a graduate student for the idea, used the analogy of nurses on rounds: When they put their heads
together to tackle a problem, ChatGPT could be "just another head." Ultimately, they recommend that a human
make the final decision when it comes to direct patient care.

"It's best that this technology is used in tandem with human scrutiny," said Wilson. "There's very little appetite in
medicine to take humans out entirely."

Hanna Webster: hwebster@post-gazette.com



Graphic


PHOTO: Shutterstock: Open AI launched its ChatGPT chatbot in November, and it quickly became the fastest-
growing consumer app to date.

PHOTO: Associated Press: OpenAI CEO Sam Altman.


Load-Date: March 26, 2023


  End of Document

                                                                                                        Page 1 of 2
                     Biden seeks guardrails on AI use Biden: President signs order tackling AI issues




  Biden seeks guardrails on AI use Biden: President signs order tackling AI
                                   issues
                                                  Chicago Daily Herald
                                               October 31, 2023 Tuesday
    WEB EditioneBlast EditionCLFM EditionML2 EditionNC EditionNC1 EditionNC14 EditionNC14C EditionNC2
                             EditionNC3 EditionNC4 EditionNL1 EditionNM1 Edition



Copyright 2023 Paddock Publications, Inc.

Section: BUSINESS WIRE_; Pg. 1
Length: 871 words
Byline: By JOSH BOAK and MATT O'BRIEN Associated Press

Body


WASHINGTON — President Joe Biden on Monday signed an ambitious executive order on artificial intelligence that
seeks to balance the needs of cutting-edge technology companies with national security and consumer rights,
creating an early set of guardrails that could be fortified by legislation and global agreements. Before signing the
order, Biden said AI is driving change at "warp speed" and carries tremendous potential as well as perils. "AI is all
around us," Biden said. "To realize the promise of AI and avoid the risk, we need to govern this technology."

The order is an initial step that is meant to ensure that AI is trustworthy and helpful, rather than deceptive and
destructive. The order — which will likely need to be augmented by congressional action — seeks to steer how AI is
developed so that companies can profit without putting public safety in jeopardy. Using the Defense Production Act,
the order requires leading AI developers to share safety test results and other information with the government. The
National Institute of Standards and Technology is to create standards to ensure AI tools are safe and secure before
public release. The Commerce Department is to issue guidance to label and watermark AI-generated content to
help differentiate between authentic interactions and those generated by software. The extensive order touches on
matters of privacy, civil rights, consumer protections, scientific research and worker rights. White House chief of
staff Jeff Zients recalled Biden giving his staff a directive when formulating the order to move with urgency. "We
can't move at a normal government pace," Zients said Biden told him. "We have to move as fast, if not faster, than
the technology itself." In Biden's view, the government was late to address the risks of social media and now U.S.
youth are grappling with related mental health issues. AI has the positive ability to accelerate cancer research,
model the impacts of climate change, boost economic output and improve government services, among other
benefits. But it could also warp basic notions of truth with false images, deepen racial and social inequalities and
provide a tool to scammers and criminals. With the European Union nearing final passage of a sweeping law to rein
in AI harms and Congress still in the early stages of debating safeguards, the Biden administration is "stepping up
to use the levers it can control," said digital rights advocate Alexandra Reeve Givens, president of the Center for
Democracy &amp; Technology. "That's issuing guidance and standards to shape private sector behavior and
leading by example in the federal government's own use of AI." The order builds on voluntary commitments already
made by technology companies. It's part of a broader strategy that administration officials say also includes

                                                                                                        Page 2 of 2
                    Biden seeks guardrails on AI use Biden: President signs order tackling AI issues

congressional legislation and international diplomacy, a sign of the disruptions already caused by the introduction of
new AI tools such as ChatGPT that can generate text, images and sounds. The guidance within the order is to be
implemented and fulfilled over the range of 90 days to 365 days. Last Thursday, Biden gathered his aides in the
Oval Office to review and finalize the executive order, a 30-minute meeting that stretched to 70 minutes, despite
other pressing matters, including the mass shooting in Maine, the Israel-Hamas war and the selection of a new
House speaker. Biden was profoundly curious about the technology in the months of meetings that led up to
drafting the order. His science advisory council focused on AI at two meetings and his Cabinet discussed it at two
meetings. The president also pressed tech executives and civil society advocates about the technology's
capabilities at multiple gatherings. "He was as impressed and alarmed as anyone," deputy White House chief of
staff Bruce Reed said in an interview. "He saw fake AI images of himself, of his dog. He saw how it can make bad
poetry. And he's seen and heard the incredible and terrifying technology of voice cloning, which can take three
seconds of your voice and turn it into an entire fake conversation." The issue of AI was seemingly inescapable for
Biden. At Camp David one weekend, he relaxed by watching the Tom Cruise film "Mission: Impossible — Dead
Reckoning Part One." The film's villain is a sentient and rogue AI known as "the Entity" that sinks a submarine and
kills its crew in the movie's opening minutes. "If he hadn't already been concerned about what could go wrong with
AI before that movie, he saw plenty more to worry about," said Reed, who watched the film with the president. The
American Civil Liberties Union is among the groups that met with the White House to try to ensure "we're holding
the tech industry and tech billionaires accountable" so that algorithmic tools "work for all of us and not just a few,"
said ReNika Moore, director of the ACLU's racial justice program, who attended Monday's signing. After seeing the
text of the order, Moore applauded how it addressed discrimination and other AI harms in workplaces and housing,
but said the administration "essentially kicks the can down the road" in protecting people from law enforcement's
growing use of the technology.


Load-Date: November 2, 2023


  End of Document

                                                                                                        Page 1 of 2
                                            Biden seeks guardrails on AI use




                                       Biden seeks guardrails on AI use
                                                 Chicago Daily Herald
                                               October 31, 2023 Tuesday
                                                     MF12 Edition



Copyright 2023 Paddock Publications, Inc.

Section: BUSINESS WIRE_; Pg. 1
Length: 871 words
Byline: By JOSH BOAK and MATT O'BRIEN Associated Press

Body


WASHINGTON — President Joe Biden on Monday signed an ambitious executive order on artificial intelligence that
seeks to balance the needs of cutting-edge technology companies with national security and consumer rights,
creating an early set of guardrails that could be fortified by legislation and global agreements. Before signing the
order, Biden said AI is driving change at "warp speed" and carries tremendous potential as well as perils. "AI is all
around us," Biden said. "To realize the promise of AI and avoid the risk, we need to govern this technology."

The order is an initial step that is meant to ensure that AI is trustworthy and helpful, rather than deceptive and
destructive. The order — which will likely need to be augmented by congressional action — seeks to steer how AI is
developed so that companies can profit without putting public safety in jeopardy. Using the Defense Production Act,
the order requires leading AI developers to share safety test results and other information with the government. The
National Institute of Standards and Technology is to create standards to ensure AI tools are safe and secure before
public release. The Commerce Department is to issue guidance to label and watermark AI-generated content to
help differentiate between authentic interactions and those generated by software. The extensive order touches on
matters of privacy, civil rights, consumer protections, scientific research and worker rights. White House chief of
staff Jeff Zients recalled Biden giving his staff a directive when formulating the order to move with urgency. "We
can't move at a normal government pace," Zients said Biden told him. "We have to move as fast, if not faster, than
the technology itself." In Biden's view, the government was late to address the risks of social media and now U.S.
youth are grappling with related mental health issues. AI has the positive ability to accelerate cancer research,
model the impacts of climate change, boost economic output and improve government services, among other
benefits. But it could also warp basic notions of truth with false images, deepen racial and social inequalities and
provide a tool to scammers and criminals. With the European Union nearing final passage of a sweeping law to rein
in AI harms and Congress still in the early stages of debating safeguards, the Biden administration is "stepping up
to use the levers it can control," said digital rights advocate Alexandra Reeve Givens, president of the Center for
Democracy &amp; Technology. "That's issuing guidance and standards to shape private sector behavior and
leading by example in the federal government's own use of AI." The order builds on voluntary commitments already
made by technology companies. It's part of a broader strategy that administration officials say also includes
congressional legislation and international diplomacy, a sign of the disruptions already caused by the introduction of
new AI tools such as ChatGPT that can generate text, images and sounds. The guidance within the order is to be

                                                                                                        Page 2 of 2
                                          Biden seeks guardrails on AI use

implemented and fulfilled over the range of 90 days to 365 days. Last Thursday, Biden gathered his aides in the
Oval Office to review and finalize the executive order, a 30-minute meeting that stretched to 70 minutes, despite
other pressing matters, including the mass shooting in Maine, the Israel-Hamas war and the selection of a new
House speaker. Biden was profoundly curious about the technology in the months of meetings that led up to
drafting the order. His science advisory council focused on AI at two meetings and his Cabinet discussed it at two
meetings. The president also pressed tech executives and civil society advocates about the technology's
capabilities at multiple gatherings. "He was as impressed and alarmed as anyone," deputy White House chief of
staff Bruce Reed said in an interview. "He saw fake AI images of himself, of his dog. He saw how it can make bad
poetry. And he's seen and heard the incredible and terrifying technology of voice cloning, which can take three
seconds of your voice and turn it into an entire fake conversation." The issue of AI was seemingly inescapable for
Biden. At Camp David one weekend, he relaxed by watching the Tom Cruise film "Mission: Impossible — Dead
Reckoning Part One." The film's villain is a sentient and rogue AI known as "the Entity" that sinks a submarine and
kills its crew in the movie's opening minutes. "If he hadn't already been concerned about what could go wrong with
AI before that movie, he saw plenty more to worry about," said Reed, who watched the film with the president. The
American Civil Liberties Union is among the groups that met with the White House to try to ensure "we're holding
the tech industry and tech billionaires accountable" so that algorithmic tools "work for all of us and not just a few,"
said ReNika Moore, director of the ACLU's racial justice program, who attended Monday's signing. After seeing the
text of the order, Moore applauded how it addressed discrimination and other AI harms in workplaces and housing,
but said the administration "essentially kicks the can down the road" in protecting people from law enforcement's
growing use of the technology.


Load-Date: November 2, 2023


  End of Document

                                                                                                           Page 1 of 2
                                        The AI Bill of Rights Is 'Mile One of a Long Marathon'




                     The AI Bill of Rights Is 'Mile One of a Long Marathon'
                                                      Government TechNology
                                                    December 6, 2022 Tuesday



Copyright 2022 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 677 words
Byline: Julia Edinger, Government Technology

Body


Dec. 6—The White House Office of Science and Technology Policy (OSTP) issued the Blueprint for an AI Bill of
Rights in October 2022, but many questions remain about what is next for AI.

During a Dec. 5 event hosted by The Brookings Institution, experts explored the topic and what the technology
could bring and how to best address it from a policy perspective.

There are, of course, many ethical questions surrounding the use of emerging technologies in and by government,
and these systems could have serious consequences for vulnerable populations.

The Blueprint for an AI Bill of Rights was the Biden administration's first step in addressing this issue, and it offers a
resource that provides principles and guidance around equitable use of AI systems.

"The principles outline the kind of world we should live in," said Sorelle Friedler, OSTP's assistant director for data
and democracy, during her opening remarks. "Leaders across the U.S. federal government are already taking
action protecting workers' rights, making the financial system more accountable, and ensuring health-care
algorithms are nondiscriminatory."

This follows other federal advances in this space, such as the creation of a National Artificial Intelligence Advisory
Committee earlier this year and prioritization of AI research as directed by an executive order under the Trump
administration. And while the World Health Organization has released guidance for ethical use of AI in health care,
this bill of rights is the first comprehensive guidance of its kind from the federal level.

Alex Engler, fellow in Governance Studies at The Brookings Institution during the panel, explained that this bill of
rights is unique in large part because it has the weight of the federal government behind it. His belief is that
because the resource is thorough and application-specific, it will help drive governance as well as individual use.

And while this document is comprehensive, experts agreed that there are still gaps that must be addressed.

                                                                                                                 Page 2 of 2
                                  The AI Bill of Rights Is 'Mile One of a Long Marathon'

"I think what's clear is that this document represents mile one of a long marathon," said Harlan Yu, executive
director of Upturn, "And it's really clear that the hard work is still in front of federal agencies and in front of all of us."

This resource offers critical guidance for technologies that are already being deployed by government agencies; but
it is not without blind spots. Experts pointed to the exemption for law enforcement agencies that was included within
this bill of rights as one such example.

"I think this Blueprint for an AI Bill of Rights is a step forward, but it's not the end all be all," Yu said.

Friedler stated that the hope of releasing this resource is that by putting the weight of the White House behind this
effort, it will help begin the process of creating a road map to help create policy around AI use moving forward.

The U.S. approach to AI policy differs from that of other nations in some ways. For example, the European Union
has introduced the AI Act, a law that would assign risk levels to different AI applications to guide deployments.

While legislation obviously differs from a bill of rights, there is a lot of overlap in terms of the actual standards being
set. However, Engler noted the difficulty of the AI Act's comprehensive approach, arguing that there are advantages
to the U.S. taking a more sectoral approach to offer specific guidance for specific use cases.

When it comes to U.S. laws on AI, pieces of related legislation have been introduced. Most notably, there is data
privacy legislation on the table, but there are also other bills related to things like transparency and sector-specific
harms, Yu explained.

The solution will not be one single piece of legislation to address ethical use of AI in the U.S., Engler said, but
rather, it will be an ongoing adoption of many laws that complement each other and work together to address the
different impacts of this technology.

___ (c)2022 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: December 7, 2022


  End of Document

                                                                                                  Page 1 of 5
   ChatGPT is poised to change medical care AI technology can empower patients, but glitches make some wary




    ChatGPT is poised to change medical care; AI technology can empower
                   patients, but glitches make some wary
                                                     USA Today
                                               March 6, 2023 Monday
                                                      1 Edition



Copyright 2023 USA Today All Rights Reserved

Section: NEWS; Pg. A5
Length: 2008 words
Byline: By, Karen Weintraub, USA TODAY

Body


The technology won't replace doctors, but "doctors who use AI will probably replace doctors who don't use AI."

Dr. John Halamka

president of Mayo Clinic Platform

It's almost hard to remember a time before people could turn to "Dr. Google" for medical advice. Some of the
information was wrong. Much of it was terrifying. But it helped empower patients who could, for the first time,
research their own symptoms and learn more about their conditions.

Now, ChatGPT and similar language processing tools promise to upend medical care again, providing patients with
more data than a simple online search and explaining conditions and treatments in language nonexperts can
understand.

For clinicians, these chatbots might provide a brainstorming tool, guard against mistakes and relieve some of the
burden of filling out paperwork, which could alleviate burnout and allow more facetime with patients.

But - and it's a big "but" - the information these digital assistants provide might be more inaccurate and misleading
than basic internet searches.

"I see no potential for it in medicine," said Emily Bender, a linguistics professor at the University of Washington. By
their very design, these large-language technologies are inappropriate sources of medical information, she said.

Others argue that large language models could supplement, though not replace, primary care.

"A human in the loop is still very much needed," said Katie Link, a machine learning engineer at Hugging Face, a
company that develops collaborative machine learning tools.

                                                                                                 Page 2 of 5
  ChatGPT is poised to change medical care AI technology can empower patients, but glitches make some wary

Link, who specializes in health care and biomedicine, thinks chatbots will be useful in medicine someday, but it isn't
yet ready.

And whether this technology should be available to patients, as well as doctors and researchers, and how much it
should be regulated remain open questions.

Regardless of the debate, there's little doubt such technologies are coming - and fast. ChatGPT launched its
research preview on a Monday in December. By that Wednesday, it reportedly already had 1 million users. In
February, both Microsoft and Google announced plans to include AI programs similar to ChatGPT in their search
engines.

"The idea that we would tell patients they shouldn't use these tools seems implausible. They're going to use these
tools," said Dr. Ateev Mehrotra, a professor of health care policy at Harvard Medical School and a hospitalist at
Beth Israel Deaconess Medical Center in Boston.

"The best thing we can do for patients and the general public is (say), 'hey, this may be a useful resource, it has a
lot of useful information - but it often will make a mistake and don't act on this information only in your decision-
making process,'" he said.

How ChatGPT it works

ChatGPT - the GPT stands for Generative Pre-trained Transformer - is an artificial intelligence platform from San
Francisco-based startup OpenAI. The free online tool, trained on millions of pages of data from across the internet,
generates responses to questions in a conversational tone.

Other chatbots offer similar approaches with updates coming all the time.

These text synthesis machines might be relatively safe to use for novice writers looking to get past initial writer's
block, but they aren't appropriate for medical information, Bender said.

"It isn't a machine that knows things," she said. "All it knows is the information about the distribution of words."

Given a series of words, the models predict which words are likely to come next.

So, if someone asks "what's the best treatment for diabetes?" the technology might respond with the name of the
diabetes drug "metformin" - not because it's necessarily the best but because it's a word that often appears
alongside "diabetes treatment."

Such a calculation is not the same as a reasoned response, Bender said, and her concern is that people will take
this "output as if it were information and make decisions based on that."

Bender also worries about the racism and other biases that may be embedded in the data these programs are
based on. "Language models are very sensitive to this kind of pattern and very good at reproducing them," she
said.

The way the models work also means they can't reveal their scientific sources - because they don't have any.

Modern medicine is based on academic literature, studies run by researchers published in peer-reviewed journals.
Some chatbots are being trained on that body of literature. But others, like ChatGPT and public search engines, rely
on large swaths of the internet, potentially including flagrantly wrong information and medical scams.

With today's search engines, users can decide whether to read or consider information based on its source: a
random blog or the prestigious New England Journal of Medicine, for instance.

But with chatbot search engines, where there is no identifiable source, readers won't have any clues about whether
the advice is legitimate.

                                                                                                 Page 3 of 5
  ChatGPT is poised to change medical care AI technology can empower patients, but glitches make some wary

"Understanding where is the underlying information coming from is going to be really useful," Mehrotra said. "If you
do have that, you're going to feel more confident."

Potential for doctors and patients

Mehrotra recently conducted an informal study that boosted his faith in these large language models.

He and his colleagues tested ChatGPT on a number of hypothetical vignettes - the type he's likely to ask first-year
medical residents. It provided the correct diagnosis and appropriate triage recommendations about as well as
doctors did and far better than the online symptom checkers that the team tested in previous research.

"If you gave me those answers, I'd give you a good grade in terms of your knowledge and how thoughtful you
were," Mehrotra said.

But it also changed its answers somewhat depending on how the researchers worded the question, said co-author
Ruth Hailu. It might list potential diagnoses in a different order or the tone of the response might change, she said.

Mehrotra, who recently saw a patient with a confusing spectrum of symptoms, said he could envision asking
ChatGPT or a similar tool for possible diagnoses.

"Most of the time it probably won't give me a very useful answer," he said, "but if one out of 10 times it tells me
something - 'oh, I didn't think about that. That's a really intriguing idea!' Then maybe it can make me a better
doctor."

It also has the potential to help patients. Hailu, a researcher who plans to go to medical school, said she found
ChatGPT's answers clear and useful, even to someone without a medical degree.

"I think it's helpful if you might be confused about something your doctor said or want more information," she said.

ChatGPT might offer a less intimidating alternative to asking the "dumb" questions of a medical practitioner,
Mehrotra said.

Dr. Robert Pearl, former CEO of Kaiser Permanente, a 10,000-physician health care organization, is excited about
the potential for both doctors and patients.

"I am certain that five to 10 years from now, every physician will be using this technology," he said. If doctors use
chatbots to empower their patients, "we can improve the health of this nation."

Learning from experience

The models chatbots are based on will continue to improve over time as they incorporate human feedback and
"learn," Pearl said.

Just as he wouldn't trust a newly minted intern on their first day in the hospital to take care of him, programs like
ChatGPT aren't yet ready to deliver medical advice. But as the algorithm processes information again and again, it
will continue to improve, he said.

Plus the sheer volume of medical knowledge is better suited to technology than the human brain, said Pearl, noting
that medical knowledge doubles every 72 days. "Whatever you know now is only half of what is known two to three
months from now."

But keeping a chatbot on top of that changing information will be staggeringly expensive and energy intensive.

The training of GPT-3, which formed some of the basis for ChatGPT, consumed 1,287 megawatt hours of energy
and led to emissions of more than 550 tons of carbon dioxide equivalent, roughly as much as three roundtrip flights
between New York and San Francisco. According to EpochAI, a team of AI researchers, the cost of training an
artificial intelligence model on increasingly large datasets will climb to about $500 million by 2030.

                                                                                                 Page 4 of 5
  ChatGPT is poised to change medical care AI technology can empower patients, but glitches make some wary

OpenAI has announced a paid version of ChatGPT. For $20 a month, subscribers will get access to the program
even during peak use times, faster responses, and priority access to new features and improvements.

The current version of ChatGPT relies on data only through September 2021. Imagine if the COVID-19 pandemic
had started before the cutoff date and how quickly the information would be out of date, said Dr. Isaac Kohane,
chair of the department of biomedical informatics at Harvard Medical School and an expert in rare pediatric
diseases at Boston Children's Hospital.

Kohane believes the best doctors will always have an edge over chatbots because they will stay on top of the latest
findings and draw on experience.

But maybe it will bring up weaker practitioners. "We have no idea how bad the bottom 50% of medicine is," he said.

Dr. John Halamka, president of Mayo Clinic Platform, which offers products and data for artificial intelligence
programs, said he sees potential for chatbots to help providers with tasks such as drafting letters to insurance
companies.

The technology won't replace doctors, he said, but "doctors who use AI will probably replace doctors who don't use
AI."

What ChatGPT means for research

As it currently stands, ChatGPT is not a good source of scientific information. Just ask pharmaceutical executive
Wenda Gao, who used it recently to search for information about a gene involved in the immune system.

Gao asked for references to studies about the gene and ChatGPT offered three "very plausible" citations. But when
Gao went to check those research papers for more details, he couldn't find them.

He turned to ChatGPT. After suggesting Gao had made a mistake, the program admitted the papers didn't exist.

Stunned, Gao repeated the exercise and got the same fake results, along with two completely different summaries
of a fictional paper's findings.

"It looks so real," he said, adding that ChatGPT's results "should be fact-based, not fabricated by the program."

ChatGPT itself told Gao it would learn from these mistakes.

Microsoft, for instance, is developing a system for researchers called BioGPT that will focus on clinical research, not
consumer health care.

Guardrails for medical chatbots

Halamka sees tremendous promise for chatbots and other AI technologies in health care but said they need
"guardrails and guidelines" for use.

"I wouldn't release it without that oversight," he said.

Halamka is part of the Coalition for Health AI, a collaboration of 150 experts from academic institutions like his,
government agencies and technology companies, to craft guidelines for using artificial intelligence algorithms in
health care. "Enumerating the potholes in the road," as he put it.

U.S. Rep. Ted Lieu, a Democrat from California, filed legislation in late January (drafted using ChatGPT) "to ensure
that the development and deployment of AI is done in a way that is safe, ethical and respects the rights and privacy
of all Americans, and that the benefits of AI are widely distributed and the risks are minimized."

Halamka said his recommendation would be to require medical chatbots to disclose sources they used for training.
"Credible data sources curated by humans" should be the standard, he said.

                                                                                                 Page 5 of 5
  ChatGPT is poised to change medical care AI technology can empower patients, but glitches make some wary

Then, he wants to see ongoing monitoring of the performance of AI, perhaps via a nationwide registry, making
public the good things that came from programs like ChatGPT as well as the bad.

Health and patient safety coverage at USA TODAY is made possible in part by a grant from the Masimo
Foundation for Ethics, Innovation and Competition in Healthcare. The Masimo Foundation does not provide editorial
input.

The technology won't replace doctors, but "doctors who use AI will probably replace doctors who don't use AI."

Dr. John Halamka

president of Mayo Clinic Platform


Load-Date: March 6, 2023


  End of Document

                                                                                                        Page 1 of 3
                             Sen. Mitt Romney says he is 'terrified about AI ' at Senate hearing




          Sen. Mitt Romney says he is 'terrified about AI' at Senate hearing
                                                        The Deseret News
                                                 September 19, 2023 Tuesday



Copyright 2023 The Deseret News Publishing Co. All Rights Reserved

Length: 898 words
Byline: Gitanjali Poonia

Body

Sen. Mitt Romney spoke openly about his fears regarding artificial intelligence and the risk it poses to national
security during a Senate committee hearing Tuesday.

"I'm in the camp of being more terrified about AI than I am in the camp of those thinking this is going to make
everything better for the world," said Romney, R-Utah, in his opening remarks. He is the ranking member of the
Subcommittee on the Emerging Threats and Spending Oversight Subcommittee.

AI and smallpox

At an event in Utah last month, Romney said he sees AI "as more of a threat and a risk than as an opportunity,"
speaking about the risk of deep fakes and the use of AI by countries that are adversaries of the U.S.

He described a terrifying scenario that could become a reality because of AI.

"It was pointed out in a briefing we received recently that right now there are about 100 scientists in the world that
can duplicate the smallpox pathogen. But with AI, there'll be a million people around the world that can duplicate
the smallpox pathogen, and a lot of them are really bad people," he said.

Romney said it would be very difficult for the government to regulate AI.

"The only idea that I've heard so far on AI that we might help us rein in the threat is doing a better job at
determining who has the chips, the extraordinarily powerful chips that are necessary to run AI and limiting the
exposure of those chips to certain countries," he said.

Related

    •     Artificial intelligence wants your vote

Artificial intelligence and bioweapons - a tricky balance

Sen. Maggie Hassan, D-N.H., the chair of the committee, also raised her concerns about the scenario Romney
previously described, saying Congressional attention isn't focused "on so-called 'catastrophic' risks posed by AI -
such as the ability of AI to help terrorists develop and use unconventional weapons," in her opening remarks.

                                                                                                           Page 2 of 3
                           Sen. Mitt Romney says he is 'terrified about AI ' at Senate hearing

At a Senate hearing in July, expert, Dario Amodei, chief executive of the AI company Anthropic, said that specific
steps to create a bioweapon "can't be found on Google or in textbooks and requires a high level of expertise."

"We found that today's AI tools can fill in some of these steps," Amodei added, per Reuters.

Romney asked the expert witnesses at the hearing Tuesday what process would work to put any safeguards in
place, and, "How much time do we have?"

Related

    •     Opinion: Who will lead phase 2 of the AI revolution?

Gregory C. Allen, director of the Wadhwani Center for AI and Advanced Technologies, which is dedicated to policy
research, said that from a regulatory standpoint, "We want to make it hard for malicious activity to happen, but we
don't want to ban all of these good activities as well."

He said that in the case of biosecurity, AI made it easier to create bioweapons. Why? "Well, part of it is the nature
of existing regulations," Allen said.

For example, if someone wants to access the anthrax pathogen, which can be disseminated as a bioweapon, they
can't because it is on a list of regulated pathogens, he explained.

"The challenge with AI systems is that they could assist in the development of novel pathogens that are not on a list
anywhere," Allen continued.

But AI will also be necessary to help DNA synthesis companies detect a pathogen that didn't exist before. This
presents a tricky balance for regulators.

Related

    •     Top artificial intelligence developers commit to security testing, clear labeling of AI-generated content

Should a new federal agency regulate AI?

During his opening remarks, Romney said that the discussions he's been a part of so far point out the need to
"coordinate with other nations and perhaps have some kind of international consortium or international agreement
that relates to AI."

"I don't know how that would work, where it would be housed, how we would initiate that, and whether that's
realistic," he added.

Romney said there has also been talk of creating a separate agency or department - with a staff of experts - to
oversee development in the industry, create strategies and counsel policymakers, such as himself.

"Frankly, a lot of, in my case, 76-year-olds are not going to figure out how to regulate AI because we can barely use
our smartphones," he said, asking if that would be a good idea.

While answering Romney's questions related to putting safeguards in place, Jeff Alstott, a senior information
scientist at Rand Corporation, a policy think tank and public sector consulting firm, said that most existing
government agencies can handle the influence of AI on their sector.

Related

    •     Watch out, smarty-pants: College-educated and higher-paid workers most at risk for replacement by AI,
          according to new report

                                                                                                        Page 3 of 3
                         Sen. Mitt Romney says he is 'terrified about AI ' at Senate hearing

This includes self-driving cars under the purview of the Department of Transportation or the use of AI in health care
overseen by Health and Human Services - but there are a few exceptions.

"One is that if someone is making or deploying an AI that is predictably going to get millions of people killed, there
is no part of government that has clear responsibility for addressing that," Alstott said. "So, that needs to be
created."

This could be done by establishing an independent agency, as Romney suggested. Or agencies with relevant
authority - like the Department of Homeland Security, the Department of Commerce, and the Department of
Defense - can also try to regulate and mitigate the effects of AI.

Contributing: Suzanne Bates


Load-Date: September 19, 2023


  End of Document

                                                                                                          Page 1 of 4
                          White House Executive Order Threatens to Put AI in a Regulatory Cage




     White House Executive Order Threatens to Put AI in a Regulatory Cage
                                                             R Street Institute
                                                      October 30, 2023 Monday



Copyright 2023 Content Engine, LLC.
All Rights Reserved
Copyright 2023 R Street Institute, USA All Rights Reserved

Length: 2295 words

Body


This analysis is based on breaking news and will be updated. To connect with the author, please e-mail
[email protected].

The Biden administration today released a long-awaited major Executive Order (EO) on "Safe, Secure, and
Trustworthy Artificial Intelligence (AI)" that represents the latest effort by the White House to unilaterally advance AI
policy as Congress continues to struggle with the issue. Despite intense interest and a flurry of proposals,
comprehensive AI legislation appears unlikely in the near-term. The White House has been looking to fill the federal
AI policy vacuum through various policy statements, agency actions and other steps. Biden's new 100+ page EO
includes "sprawling directives to over a dozen agencies," ordering them to look into implications of algorithmic
systems and processes for a wide variety of issues, including: copyright, competitiveness, cybersecurity, education,
health, housing, infrastructure, labor and privacy.

While some will appreciate the whole-of-government approach to AI required by the order, if taken too far, unilateral
and heavy-handed administrative meddling in AI markets could undermine America's global competitiveness and
even the nation's geopolitical security. AI is a critical new technology with the potential to fundamentally expand
productivity and economic growth, with benefits accruing across many sectors and for all consumers. AI has
particularly important implications for advancing public health. AI and computational science also have national
security ramifications, which is why a strong and secure domestic technology base is essential to countering
challenges or threats from China and other nations. Excessive preemptive regulation of AI systems could impede
the growth of these technologies or limit their potential in various ways.

Dystopian Narratives Driving Calls for AI Regulation

Unfortunately, the policy debate around AI thus far has been mostly driven by worst-case scenarios pulled from the
plots of dystopian science fiction books and movies. These fears have triggered calls for sweeping regulatory
controls for AI - including new regulatory agencies, licensing schemes, and expanded liability - that will significantly
hamper the adoption of beneficial new algorithmic applications.

The EO comes just two days before the United Kingdom's AI Safety Summit, which is a multi-nation effort focused
on addressing risks with more powerful "frontier AI" technologies, which are advanced supercomputing systems.
Wired refers to the coming summit as "a doom-obsessed mess" because of the focus on so-called "existential risks"

                                                                                                         Page 2 of 4
                      White House Executive Order Threatens to Put AI in a Regulatory Cage

and extreme regulatory steps to address them. Surprisingly, the UK government has turned quickly from being a
leading exponent of light-touch regulation for AI systems into a platform for considering some of the most extreme
solutions for controlling computation as part of a new effort under UK Prime Minister Rishi Sunak to "write the AI
rulebook" for the world. The Biden administration has been coordinating with the UK government on this and other
AI issues, but it remains to be seen whether the administration steers the U.S. down a similarly radical regulatory
path for advanced AI systems.

Thus far, the Biden administration has primarily focused on pressuring major AI innovators to make voluntary
concessions regarding AI safety and data sharing. Building on this, the new EO stretches the broad stipulations of
the Defense Production Act to require that "companies developing any foundation model that poses a serious risk
to national security, national economic security, or national public health and safety must notify the federal
government when training the model, and must share the results of all red-team safety tests." Red-team safety tests
are already regularly used by developers to stress-test AI models for deficiencies and make corrections. Through
the new EO, the White House is now pushing for this process to become more formalized through standards
created by the National Institute of Standards and Technology (NIST) and applied by agencies such as the
Departments of Energy and the Department of Homeland Security through an AI Safety and Security Board. The
EO also contains vague language about the need to "accelerate development and implementation of vital AI
standards with international partners" in an effort to "establish robust international frameworks" for AI, but it offers
few details before simply noting that the Vice President Harris will participate in Wednesday's AI Safety Summit in
the UK.

The EO focuses on other priorities beyond just frontier AI systems, however. It calls for broad-based efforts to
expand privacy protections, including through the development of additional guidelines on how algorithmic systems
collect and use data. Other provisions in the EO call for enhanced cybersecurity protections to expand upon the "AI
Cyber Challenge" program launched this summer to "challenge competitors across the United States, to identify
and fix software vulnerabilities using AI." The EO also includes requirements that the military and intelligence
community "use AI safely, ethically, and effectively in their missions." The EO also calls for greater efforts to
address fraudulent or deceptive uses of AI and calls on the Department of Commerce to craft guidance for content
authentication and watermarking to clearly label AI-generated content.

On other issues, the new EO continues the rhetorical approach the administration initially sketched out in its
October 2022 "Blueprint for an AI Bill of Rights," which focused on fears about AI and claimed algorithmic systems
are "unsafe, ineffective, or biased" and "deeply harmful." For example, fearing that AI systems will "exacerbate
discrimination" in housing, the workplace, or federal benefits programs, the EO calls for additional steps to combat
"algorithmic discrimination."

Empowering the Administrative State

The new EO highlights how the administration is adopting an everything-and-the-kitchen-sink approach to AI policy
that is, at once, extremely ambitious and potentially over-zealous. The implementation details on all the matters
here are mostly left to the various federal agencies to work out, and it remains unclear how far they can stretch their
statutory authority to enforce many of these stipulations.

Even so, taken together with other recent administration statements, the EO represents a potentially sea change in
the nation's approach to digital technology markets as federal policymakers appear ready to shun the open
innovation model that made American firms global leaders in almost all computing and digital technology sectors.
With the U.S. now facing fierce competition from global AI companies from China and other nations, the danger
exists that the U.S. could put algorithmic innovators in a regulatory cage that would encumber them with many
layers of bureaucratic permission slips before any new product or service could launch. Biden's new EO could
accelerate the move to tie the hands of algorithmic entrepreneurs, even if Congress does not pass any new
legislation on this front.
There are some positive and much-needed elements to the EO, however, including its call "to expand the ability of
highly skilled immigrants and nonimmigrants with expertise in critical areas to study, stay, and work in the United
States by modernizing and streamlining visa criteria, interviews, and reviews." For some time, there has been a

                                                                                                         Page 3 of 4
                      White House Executive Order Threatens to Put AI in a Regulatory Cage

pressing need to expand efforts to retain skilled immigrant workers, with many technology companies and experts
worried about losing top-notch talent to other nations.

But most of the EO focuses on broader and extremely amorphous calls for expanded government oversight across
many other issues and agencies, raising the risk of a "death by a thousand cuts" scenario for AI policy in the US.
For example, while there is nothing wrong with federal agencies being encouraged through the EO to use NIST's AI
Risk Management Framework to help guide sensible AI governance standards, it is crucial to recall that framework
is voluntary and meant to be highly flexible and iterative, not an open-ended mandate for widespread algorithmic
regulation. The Biden EO appears to be empowering agencies to gradually convert that voluntary guidance and
other new amorphous guidelines into a sort of back-door regulatory regime for AI (a process which would be made
easier by the lack of congressional action on AI issues).

Of greater concern is the executive order's green light for the Federal Trade Commission (FTC) to expand its focus
on AI policy. While the FTC does possess broad powers to police unfair and deceptive practices for all markets, the
danger of preemptive overreach exists with the EO's call for the FTC to exercise greater regulatory authority over
the AI ecosystem in particular. The FTC's controversial Chair Lina Khan has radicalized the agency and pursued
aggressive actions against digital technology companies since her tenure began. The FTC has made it clear that AI
systems are in its sights and the agency could be positioning itself to serve as America's de facto AI regulator.
Because the Biden administration's new EO and its previous AI Bill of Rights suggested that broad-based harms
were omnipresent in algorithmic systems, it could serve as an open-ended invitation for the FTC to over-zealously
harass AI innovators and micromanage markets that are still developing.

Meanwhile, the new EO hints how agencies could use federal procurement procedures as a method of regulating
AI indirectly. Because the federal government invests significant resources in digital systems (through grants and
contracts), it gives the Executive Branch considerable leverage to dictate how that money is used by private parties,
including how they develop AI. Analysts have pointed to the risks inherent in politicizing procurement policies and
using the so-called "power of the purse" to shape social or market outcomes, however. They note that "it's unclear
whether the federal government has the market power to succeed and unclear what 'market shape' officials are
imagining." Worse yet, rigging procurement rules to steer technology decisions to achieve predetermined political
preferences or market outcomes could undermine the benefits associated with the rapid development and diffusion
of algorithmic technologies.

Shooting Ourselves in the Foot as the Race Gets Underway

The Biden administration's actions this week with its new Executive Order and its negotiations with the UK at the AI
Safety Summit could go down as a historic moment in the history of technology policy, but perhaps not in a positive
way some hope. Many nations will be taking part in Wednesday's AI summit and looking to pursue aggressive
regulation of leading algorithmic technologies and innovators, many of which are U.S.-based. "Every other country
that will be represented at the summit wishes it had a technology industry like we have in the United States," argues
Wall Street Journal columnist James Freeman. "This means we have more to lose by far than anyone else if the
direction of technological development is moved from the marketplace to the halls of governments. This ought to
give U.S. politicians pause before joining such multinational efforts," he correctly notes.

This is particularly true of the European regulators who will be in attendance who have been looking to aggressively
regulate U.S. tech companies in recent years. The European Union has become an innovation backwater, with
almost no leading digital innovators to show for all their regulatory and industrial policy efforts. The continent's
leading digital export is now regulation, not world-class products or services, which has forced some analysts to
conclude that the E.U. has become "The Biggest Loser" in the global digital technology race and that, "the future
will not be invented in Europe." Despite this, the E.U. is now doubling-down on its top-down regulatory approach by
advancing a massive new regulatory regime for AI among other new digital regulatory schemes. U.S. tech
companies are typically the target of most of these rules since so few major European digital innovators exist.

With the administration's recent actions, one can't help but worry that the Biden administration is looking to follow in
the E.U.'s footsteps on AI policy with more comprehensive controls on computation and meddling in digital tech

                                                                                                      Page 4 of 4
                      White House Executive Order Threatens to Put AI in a Regulatory Cage

markets. There is still time to pursue a more enlightened path. To balance innovation and safety, AI governance
must be focused on flexible, collaborative, iterative, bottom-up governance solutions through risk-based policies
that are focused on system outcomes, not on system inputs or design.

To achieve a truly safe, secure and trustworthy technological base, the U.S. must first ensure that it crafts an
innovation policy culture that is hospitable to algorithmic entrepreneurialism and investment. We should not forget
how the nation embraced and encouraged the Internet and digital technology a quarter century ago with sensible
policies that encouraged a massive inflow of talent and capital. This fueled an explosion of world-class tech start-
ups, and created a strong technology base that remains the envy of the rest of the world. While the new AI
Executive Order can help promote positive AI outcomes along certain dimensions, it also opens the door to
administrative overreach and bureaucratic micro-management of fast-moving set of technologies that are just
starting to more fully develop and have enormous potential to improve human welfare and national security along
multiple dimensions. Prudence and humility should guide AI policy at this stage so as not to derail that potential.


Load-Date: October 31, 2023


  End of Document

                                                                                                Page 1 of 2
   UW System schools would develop AI majors under $32 million workforce development proposal. Here's what
                                            they might look like




  UW System schools would develop AI majors under $32 million workforce
          development proposal. Here's what they might look like
                                   The Daily Cardinal: University of Wisconsin - Madison
                                                 November 16, 2023 Thursday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 614 words
Byline: Natasha Hicks

Body


In efforts to continue supporting workforce development in emerging tech fields, some University of Wisconsin
System schools are considering launching artificial intelligence programs.

Artificial intelligence is intelligence derived from machines or computers rather than directly from a human. This
young and evolving field of study has implications for a variety of careers, from computer science to medicine, said
Dr. Yonatan Mintz, UW-Madison assistant professor of industrial engineering and AI researcher.

"It is something that is going to require more and more attention... not just in engineering and in computer science,
but all across the board," Mintz said.

He said familiarity with the technology and "how to use and harness it for making progress" will become
increasingly important.

Earlier this year, Republicans on the Wisconsin Legislature's budget-writing committee withheld $32 million from the
UW System in an effort to eliminate Diversity, Equity, and Inclusion programs at UW schools.

UW System officials released a workforce funding plan on Nov. 6 in an attempt to recoup the lost funds based on
past demands from Republican leaders. However, the plan is unlikely to pass without compromises on DEI and
other demands.

The proposal includes creating degrees in AI at some UW System schools such as UW-Green Bay, UW-Stout and
UW-Whitewater. While there is not currently an AI degree at UW-Madison, researchers and students in many
different fields contribute to artificial intelligence research, according to the engineering and data science
department web pages.

UW-Madison currently has a partnership with American Family Insurance for funding research into data science
and AI at UW-Madison. The American Family Funding Initiative awards grant up to $100,000 for select UW-
Madison AI researchers.

                                                                                                Page 2 of 2
   UW System schools would develop AI majors under $32 million workforce development proposal. Here's what
                                            they might look like

According to Mintz, while most of the people who study AI come from a computer science background, others look
at it from a more mathematical and theoretical perspective. Some practitioners are looking at more applied versions
of AI for mechanical engineering, and others are researching AI for health care.

The field is new, something Mintz said complicates a potential degree in the subject.

"Even if we wanted to offer a degree in AI or machine learning, it would have to be a fairly interdisciplinary degree,"
Mintz said. "I think we're still too early in the process to say, 'This is the core of what you need to know in order to
start from the get-go and get a degree in this.'"

Mintz added that he could envision a program with different tracks: one with more of a humanities/ethics emphasis,
one that focuses on the theoretical computer science side and one that focuses on the applied engineering side,
including medical and manufacturing machine learning.

Enjoy what you're reading? Get content from The Daily Cardinal delivered to your inbox

Email

The UW Board of Regents considered potential AI majors at its Nov. 9 meeting as part of a discussion on the
workforce development plan. UW-Eau Claire, UW-Stevens Point and UW-Whitewater all planned to establish AI
majors, minors or certificates, while UW-Parkside and UW-River Falls planned to establish centers for artificial
intelligence.

Other system schools, including UW-Madison and UW-Milwaukee, plan to use this budget to grow computer and
data science programs that contribute to AI research.

While studying AI is a relatively new field, Mintz believes it will continue to grow in importance and gain larger
approval over time.

"We embraced computers and word processors and that jump from typewriters to that," he said. "This might be one
of those next things we need to get people trained in and more familiar with."


Load-Date: November 17, 2023


  End of Document

                                                                                                Page 1 of 2
   UW System schools would develop AI majors under $32 million workforce development proposal. Here's what
                                            they might look like




  UW System schools would develop AI majors under $32 million workforce
          development proposal. Here's what they might look like
                                   The Daily Cardinal: University of Wisconsin - Madison
                                                 November 16, 2023 Thursday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 614 words
Byline: Natasha Hicks

Body


In efforts to continue supporting workforce development in emerging tech fields, some University of Wisconsin
System schools are considering launching artificial intelligence programs.

Artificial intelligence is intelligence derived from machines or computers rather than directly from a human. This
young and evolving field of study has implications for a variety of careers, from computer science to medicine, said
Dr. Yonatan Mintz, UW-Madison assistant professor of industrial engineering and AI researcher.

"It is something that is going to require more and more attention... not just in engineering and in computer science,
but all across the board," Mintz said.

He said familiarity with the technology and "how to use and harness it for making progress" will become
increasingly important.

Earlier this year, Republicans on the Wisconsin Legislature's budget-writing committee withheld $32 million from the
UW System in an effort to eliminate Diversity, Equity, and Inclusion programs at UW schools.

UW System officials released a workforce funding plan on Nov. 6 in an attempt to recoup the lost funds based on
past demands from Republican leaders. However, the plan is unlikely to pass without compromises on DEI and
other demands.

The proposal includes creating degrees in AI at some UW System schools such as UW-Green Bay, UW-Stout and
UW-Whitewater. While there is not currently an AI degree at UW-Madison, researchers and students in many
different fields contribute to artificial intelligence research, according to the engineering and data science
department web pages.

UW-Madison currently has a partnership with American Family Insurance for funding research into data science
and AI at UW-Madison. The American Family Funding Initiative awards grant up to $100,000 for select UW-
Madison AI researchers.

                                                                                                Page 2 of 2
   UW System schools would develop AI majors under $32 million workforce development proposal. Here's what
                                            they might look like

According to Mintz, while most of the people who study AI come from a computer science background, others look
at it from a more mathematical and theoretical perspective. Some practitioners are looking at more applied versions
of AI for mechanical engineering, and others are researching AI for health care.

The field is new, something Mintz said complicates a potential degree in the subject.

"Even if we wanted to offer a degree in AI or machine learning, it would have to be a fairly interdisciplinary degree,"
Mintz said. "I think we're still too early in the process to say, 'This is the core of what you need to know in order to
start from the get-go and get a degree in this.'"

Mintz added that he could envision a program with different tracks: one with more of a humanities/ethics emphasis,
one that focuses on the theoretical computer science side and one that focuses on the applied engineering side,
including medical and manufacturing machine learning.

Enjoy what you're reading? Get content from The Daily Cardinal delivered to your inbox

Email

The UW Board of Regents considered potential AI majors at its Nov. 9 meeting as part of a discussion on the
workforce development plan. UW-Eau Claire, UW-Stevens Point and UW-Whitewater all planned to establish AI
majors, minors or certificates, while UW-Parkside and UW-River Falls planned to establish centers for artificial
intelligence.

Other system schools, including UW-Madison and UW-Milwaukee, plan to use this budget to grow computer and
data science programs that contribute to AI research.

While studying AI is a relatively new field, Mintz believes it will continue to grow in importance and gain larger
approval over time.

"We embraced computers and word processors and that jump from typewriters to that," he said. "This might be one
of those next things we need to get people trained in and more familiar with."


Load-Date: November 16, 2023


  End of Document

                                                                                                         Page 1 of 2
                                          Electronic Caregiver breaks top 1,000 on Inc. list




                         Electronic Caregiver breaks top 1,000 on Inc. list
                                               The Las Cruces Bulletin (New Mexico)
                                                          August 28, 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 The Las Cruces Bulletin.

Section: BUSINESS
Length: 614 words

Body


Inc. revealed today that Electronic Caregiver, Inc. (ECG) ranks No. 969 on the 2023 Inc. 5000, its annual list of the
fastest-growing private companies in America. This is the second year in a row ECG, a AI-driven digital health
technology and services company based in Las Cruces, has achieved recognition as a top 1000 firm on the Inc.
5000 list.

"The prestigious ranking provides an objective, data-driven look at the most successful entrepreneurial businesses
in the country," ECG said in a news release.

Prior honorees on the Inc. 5000 include Facebook, Chobani, Under Armour, Microsoft and Patagonia.

"With one in three people worldwide living with multiple chronic conditions, and increasing doctor shortages, virtual
care is the future," said ECG Founder and CEO Anthony Dohrmann. "Ranking two years in a row with Inc. 5000
clearly demonstrates we're continuing to scale in order to meet the growing demand for AI-powered digital care."

ECG was founded in 2009.

"The Inc. 5000 class of 2023 represents companies that have driven rapid revenue growth while navigating
inflationary pressure, the rising costs of capital, and seemingly intractable hiring challenges," the news release said.
"Among this year's top 500 companies, the average median three-year revenue growth rate ticked up to an
astonishing 2,238 percent."

In all, EGC said, the 2023 Inc. 5000 companies have added almost 1.2 million jobs to the economy during the past
three years.

"Running a business has only gotten harder since the end of the pandemic," Inc. Editor in Chief Scott Omelianuk
said. "To make the Inc. 5000 with the fast growth that requires is truly an accomplishment. Inc. is thrilled to honor
the companies that are building our future."

ECG moved up 20 spots to rank No. 17 in health products in the 2023 list, No. 3 in New Mexico and No. 1 in Las
Cruces.

                                                                                                      Page 2 of 2
                                 Electronic Caregiver breaks top 1,000 on Inc. list

"The Inc. 5000 list has withstood the test of time and has shown it is a true evaluator of the most successful
companies in the USA," ECG President Joe Baffoe said.

In 2023, ECG "has launched of the company's most innovative product, Addison Care, (which) is utilized by hospital
systems, physician practices, home care agencies, senior living providers and insurance companies to expand
access to care via the delivery of telehealth services to aging and chronically ill clients," the company said.

Addison Care features an AI-powered virtual caregiver, named Addison, provided on a dedicated Intel-powered
computing interface by Lenovo, with visual sensing and facial recognition.

"Addison Care is a cutting-edge health application leveraging the computer power of 12th generation Intel CPUs,
OpenVino software for computer vision optimization and AI from Sensory," said Todd Mozer, CEO of Sensory, an
AI speech and computer vision company CEO.

"The brains of Addison, and all ECG products, is ADDI, the company's platform as a service built in conjunction with
solution architects and product engineers from Amazon Web Services," ECG said. "ADDI leverages leading
services across data analytics, reporting, machine learning, and artificial intelligence to provide curated,
personalized, and actionable intelligence to providers, to manage their patients and clients."

ECG said its "infrastructure has been built to scale, enabling the company to support 200-plus providers, manage
60,000 connected devices daily, provide services to more than 200,000 patients in 2022 and process 2.5 million
data inputs daily."

For more information, Visit www.inc.com/inc5000. 2023's top-ranked Inc. companies are also featured in the
September issue of Inc. magazine, available on newsstands beginning Aug. 23.

Also visit www.electroniccaregiver.com.


Load-Date: August 29, 2023


  End of Document

                                                                                                      Page 1 of 3
                                    Microsoft Summit Addresses AI in a Time of Upheaval




                    Microsoft Summit Addresses AI in a Time of Upheaval
                                                 Government Technology
                                                June 24, 2020 Wednesday



Copyright 2020

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 1214 words
Byline: Andrew Westrope, Government Technology

Body


June 24--     Jun. 24--Cognizant of a technological sea change underway in the private and public sectors, and
accelerated by COVID-19, Microsoft hosted a virtual summit June 23 on artificial intelligence.

Eight guests included five experts from the tech company as well as the research firm CCS Insight, The Kroger Co.
and Snohomish County, Wash., which recently used AI to create chatbots to disseminate critical information.

Microsoft U.S. Chief Digital Officer Jacky Wright started the event by talking about why AI is becoming so important
for large organizations. She said it comes down to the power of data, for two broad purposes: to accumulate and
share new knowledge, and to solve problems.

She polled an audience of industry officials about the top barriers to their AI adoption strategies, and the No. 1
answer was "defining the AI strategy."

As Wright repeatedly stressed, "now is the time."

"We are in an inflection point in our society. We have a pandemic, we have an economic slump, and we have
unrest due to racial, social inequities and disparities," she said. "Think about how we can use the power of data to
focus on these three things, where we're going to transform who we are in today's society, and that transformation
hinges on our ability to understand where we are right now, what we need to do in the future, and the effects of
that."

Mitra Azizirad, Microsoft's corporate VP of AI and innovation, followed by talking about what it means to become an
AI-powered organization, and what a difference that can make. She said most development involving AI has
focused on three scenarios: business optimization, such as real-time monitoring, detecting anomalies in products,
and other data-driven insights; helping with employee productivity by giving them better tools and more time for
more skills-focused jobs instead of administrative tasks; and customer service, by anticipating and proactively
addressing people's needs.

                                                                                                         Page 2 of 3
                               Microsoft Summit Addresses AI in a Time of Upheaval

Azizirad defined an AI-powered organization as one with a culture that's data-driven, inclusive of different
backgrounds and perspectives, committed to responsible use of new technology, and leveraging AI for everyone
and not just those with technical expertise. The latter point was a common refrain among guests at the summit.

"Putting AI into action is the most effective and life-changing when you strategically scale its impact across the
entire business," Azizirad said. "To do this, it requires a mindset that embraces this idea that AI can fundamentally
change what's possible for you to achieve with your employees and your organization."

From CCS Insight, Head of Enterprise Research Nick McQuire listed his own three recommendations for an
agency's success with AI: a data-driven culture involving business metrics and measuring success, a holistic look at
the entire organization and every employee, and having a strategic adviser or trusted partner to help the
organization understand the technology's potential and best practices.

McQuire again stressed the need to put AI into the hands of every employee in every business function, so
everyone can collaborate and offer the widest possible range of input. As one speaker put it: "How do we make
sure this isn't a forced march toward something they don't understand?"

Tom Lawry, Microsoft's national director for AI, health and life sciences, described at length the potential of AI in
the health-care space. Among other things, he advocated for large organizations setting up a modern data estate
involving all the data they own, control, manage or use, regardless of where it's stored. He said this allows
organizations to better maintain it and make decisions on an agile basis. He pointed out that it may also be
necessary because of the speed at which new data is being generated.

Lawry discussed an organizational culture and a mindset, not just technology.

"Many organizations are starting, but they're early in the journey. What we're seeing in that AI-powered world in
health care is, many organizations moving away from the traditional provision of services, and towards the use of
AI to create what's coming to be known as intelligent health systems," he said. "Intelligent health systems leverage
data and AI to create strategic advantage, and they do that by making services more efficient. They also do that,
not just in a little area or two, but they really focus on making things better across all touchpoints, all experiences,
and all channels that a consumer may turn to when it comes to a health care need."

On the subject of managing emerging technology in a fair and equitable way, Microsoft Chief Responsible AI Officer
Natasha Crampton mentioned "fairness and inclusiveness" as concerns that keep her up at night. She said sources
of unfairness in AI are many and complex, but she offered tips to mitigate: strive to have a diverse team working on
building the technologies, think deeply about the context in which a system will be used, and be thoughtful and
carefully curate data sets to test and train models.

"Start with principles. You need a north star to keep coming back to, and starting with a set of principles is how you
do that, making sure that they're aligned with the values of your organization," she said. "Move to practices ... and
figure out what tangible steps you can take in order to advance those ends in your organization."

Microsoft's summit wrapped up with a government official from Snohomish County, Wash., Kendee Yamaguchi,
executive director of trade and economic development. She said when her county verified the first reported case of
COVID-19 in the U.S., they knew they needed to put out critical information as soon as possible. Within 24 hours,
the county had set up Microsoft AI-powered chatbots to answer the public's questions, including a Spanish-
language option.

And it wasn't an anomaly. Azizirad had mentioned earlier in the talk that since March, public service and health
organizations have created more than 1,200 bots.

In a nutshell, Yamaguchi said information is power, and AI helps governments prepare for the future.

"In government, we aren't often known for innovation, but even before COVID-19, Snohomish County was engaged
in change, and this pandemic provided an opportunity for us to transform how we do business more quickly. Now

                                                                                                  Page 3 of 3
                               Microsoft Summit Addresses AI in a Time of Upheaval

our default is working from home, like many of you, and being in government, having the same tools that our
business partners have helps us stay engaged and have strong communication."

As an aside, Yamaguchi touched on the value of public-private partnerships. She said food producers in eastern
Washington recently contacted the county because they had a large volume of produce that was going to spoil. The
county sent public works trucks to pick it up, and the produce wound up at food banks instead of the dump.

"This is just one illustrative example of the hundreds that are happening every day," she said.

Andrew Westrope is a staff writer for Government Technology. Before that, he was a reporter and editor at
community newspapers for seven years. He has a Bachelor's degree in physiology from Michigan State University
and lives in Northern California.

___ (c)2020 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: June 25, 2020


  End of Document

                                                                                                       Page 1 of 2
                                 Researchers: 319K covid deaths could have been avoided




                Researchers: 319K covid deaths could have been avoided
                                               Tribune-Review (Greensburg, PA)
                                                     May 17, 2022 Tuesday



Copyright 2022 Tribune Review Publishing Company All Rights Reserved

Length: 437 words
Byline: New York Daily News

Body


About a third of the 1 million lives lost to covid-19 could have been saved with vaccines, an analysis shows.

Researchers at the Brown School of Public Health, Brigham and Women's Hospital, Harvard T.H. Chan School of
Public Health and Microsoft AI for Health analyzed data from the Centers for Disease Control and Prevention and
The New York Times and came up with not only 319,000 needless deaths, but also a state-by-state breakdown of
where they could have been prevented.

Between January 2021 and April 2022, about every second person who died from covid-19 since vaccines became
available might have lived if they had gotten the shots, the researchers found. Nationwide, about half of the 641,000
people who have died since vaccines became available could have lived if every eligible adult had gotten jabbed.

"At a time when many in the U.S. have given up on vaccinations, these numbers are a stark reminder of the
effectiveness of vaccines in fighting this pandemic," said Stefanie Friedhoff, associate professor of the practice in
Health Services, Policy and Practice at the Brown University School of Public Health, and a co-author of the
analysis, in a statement. "We must continue to invest in getting more Americans vaccinated and boosted to save
more lives."

They created a dashboard showing the number of vaccine-preventable deaths per 1 million residents in each state
and in the U.S. as a whole. Then they created an "alternative scenario" positing what it would look like if the
vaccination pace had been sustained at its highest point last spring and stayed aloft long enough for 85%, 90% or
even 100% of the adult population to get jabbed.

What it looked like was 319,000 people still being alive, even when variants' effectiveness on immunity was
factored out.

The most lives could have been saved in West Virginia, Wyoming, Tennessee, Kentucky and Oklahoma, the team
found.

Where vaccination rates were higher, such as Washington, D.C., Massachusetts, Puerto Rico, Vermont and Hawaii,
the number of deaths that could have been prevented with vaccines was lower.

For instance, if all adults in Tennessee had gotten vaccinated, there would be 11,047 fewer deaths being mourned,
the study found. Likewise in Ohio, where the number stood at 15,875.

                                                                                                     Page 2 of 2
                            Researchers: 319K covid deaths could have been avoided

"This compelling data illustrates the trajectory of 50 states with 50 different fates during the covid-19 pandemic,
emphasizing the important role of vaccines in protecting lives in each state," said Thomas Tsai, a surgeon at
Brigham and Women's Hospital and Assistant Professor in Health Policy and Management at Harvard T.H. Chan
School of Public Health.


Load-Date: May 19, 2022


  End of Document

                                                                                                      Page 1 of 3
    Area hospitals using AI to improve processes, patient outcomes; Predictive software is providing doctors with
                                 risk assessments for patients prior to procedures ....




 Area hospitals using AI to improve processes, patient outcomes; Predictive
  software is providing doctors with risk assessments for patients prior to
                           procedures being done.
                                                    Dayton Daily News (Ohio)
                                                     May 18, 2023 Thursday



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Cox Ohio Publishing.

Section: BUSINESS
Length: 853 words
Byline: Samantha Wildow

Body


As artificial intelligence continues to find its way into more industries each day, area hospitals have been eyeing
what predictive software can do to help improve patient outcomes.

Kettering Health cardiologists spoke with Cox First Media about how they are utilizing the predictive software of
ePRISM, developed by the medical tech company Terumo, to determine patients' risks for negative outcomes, such
as bleeding or kidney complications, before they undergo certain procedures.

"AI is coming into health care in every possible way," said Dr. Niranjan Reddy, chief of interventional cardiology for
Kettering Health. "Kettering has gone with the new approach of using AI to improve their processes to get best
outcomes."

If a patient had a complication or negative outcome following a procedure, doctors used to analyze that patient data
about every three months after the fact, said Dan Halvorsen, integration manager of care pathways at Terumo.

The future of AI: How tech could transform our lives in the Dayton region

"We used to look retrospectively and say, 'What could we have done differently?'" Halvorsen said. "And that's great,
it helps you to improve. But now, with technology like artificial intelligence, we don't have to wait until three months
after the patient has left to look at their data. In fact, we can look at it before we treat them."

Doctors can determine patient risk factors based on the data and demographics they input in to the software,
helping doctors decide the best path forward for the patient, depending on their potential risks.

"We can look at their data when we're interviewing them in the clinic, and we can decide how to move forward in a
way that will reduce unwanted outcomes," Halvorsen said. "It will allow the patient to get discharged sooner, and

                                                                                                     Page 2 of 3
   Area hospitals using AI to improve processes, patient outcomes; Predictive software is providing doctors with
                                risk assessments for patients prior to procedures ....

also we can educate the patient on exactly why we're doing what we're doing and show them their specific,
personalized story."

The software does not tell the doctors what to do, but it provides them a risk assessment on if patients may be
prone to experience a negative outcome, Reddy said.

Some of the other ways doctors are using predictive software at area hospitals is in diagnostics, determining if
patients have a certain disease or cancer, or are at risk for one, based on certain demographics like patient and
family history, said Dr. Albert Bonnema, Kettering Health's chief medical information officer. From that, doctors are
also using technology to determine which treatments patients may respond to best.

"We're using software to be able to choose the right therapy," Bonnema said.

Can AI catch self-harming actions in pre-teens? Wright State students are working to find out

Another area is in prognosis prediction, Bonnema said, where technology can help doctors determine what the
course of a disease will look like in a specific patient. Such as for cancer, it can help the patient and their doctors
determine whether to do radiation or surgery depending on where the patient is in the course of their illness and
how the patient may respond to each of those treatments.

Doctors are using predictive algorithms to determine if patients may be at risk for falls, or at risk for being
readmitted to the hospital soon after being discharged, which would help doctors and nurses know if a patient
needs extra care while in the hospital.

"It's quite a complex aggregation of data," Bonnema said. The data can include a patient's vital signs, like their body
temperature, pulse, and blood pressure, as well as other factors like age, prior procedures, and family history.

Local hospitals are also using AI to determine if patients are at risk of developing sepsis, a severe infection that can
be life-threatening.

"We have a sepsis detection algorithm running in the system that looks for patients who might be heading down a
path of becoming septic," said Dr. Walter Reiling, Premier Health's chief medical informatics officer. "Early
intervention in taking care of those patients is really important.

This program scans through large amounts of data that Premier has on patients, including vital signs and lab
results, to determine if they may be heading for sepsis prior to when a doctor may detect it. This allows doctors to
intervene quickly, Reiling said.

'I don't feel threatened by it': How Dayton artists react to rise of artificial intelligence

"We have a lung nodule detection and management program," Reiling said. The system will look through patient
reports from CAT scans and chest x-rays, looking for changing in the lungs that may be putting a patient at risk for
developing lung cancer.

"Then we have a program on an ongoing basis that makes sure they're getting the follow-up x-rays or scans that
they need to make sure that we detect any problems early and are able to intervene and take care of the patient
with the goal of catching it earlier and saving lives," Reiling said.

Premier launched these programs during the pandemic, so some of the software has been in place for a couple
years.

"We're definitely seeing good outcomes in the groups that are being impacted by these," Reiling said.



Graphic

                                                                                                     Page 3 of 3
   Area hospitals using AI to improve processes, patient outcomes; Predictive software is providing doctors with
                                risk assessments for patients prior to procedures ....




From left, Kettering Health cardiologists Dr. Niranjan Reddy, chief of interventional cardiology at Kettering Health;
Dr. Ammar Safar, chief of cardiology at Kettering Health Main Campus; and Dr. Brian Schwartz, director for the
heart and vascular service line at Kettering Health, use predictive software from Terumo, which utilizes patient data
to determine their risks and reduce unwanted outcomes, to improve their processes in cardiology. MARSHALL
GORBYSTAFF


Load-Date: May 18, 2023


  End of Document

                                                                                                         Page 1 of 3
   AI is gaining attention of state lawmakers Legislators try to guard against discrimination as technology evolves




                     AI is gaining attention of state lawmakers
      Legislators try to guard against discrimination as technology evolves
                                                      The Hartford Courant
                                                     August 6, 2023 Sunday
                                                             1 Edition



Copyright 2023 The Hartford Courant Company All Rights Reserved

Section: LOCAL; B; Pg. 3
Length: 1237 words
Byline: Susan Haigh Associated Press

Body


HARTFORD - As state lawmakers rush to get a handle on fast-evolving artificial intelligence technology, they're
often focusing first on their own state governments before imposing restrictions on the private sector.

Legislators are seeking ways to protect constituents from discrimination and other harms while not hindering
cutting-edge advancements in medicine, science, business, education and more.

"We're starting with the government. We're trying to set a good example," Connecticut state Sen. James Maroney
said during a floor debate in May.

Connecticut plans to inventory all of its government systems using artificial intelligence by the end of 2023, posting
the information online. And starting next year, state officials must regularly review these systems to ensure they
won't lead to unlawful discrimination.

Maroney, a Democrat who has become a go-to AI authority in the General Assembly, said Connecticut lawmakers
will likely focus on private industry next year. He plans to work this fall on model AI legislation with lawmakers in
Colorado, New York, Virginia, Minnesota and elsewhere that includes "broad guardrails" and focuses on matters
like product liability and requiring impact assessments of AI systems.

"It's rapidly changing and there's a rapid adoption of people using it. So we need to get ahead of this," he said in a
later interview. "We're actually already behind it, but we can't really wait too much longer to put in some form of
accountability."

Overall, at least 25 states, Puerto Rico and the District of Columbia introduced artificial intelligence bills this year.
As of late July, 14 states and Puerto Rico had adopted resolutions or enacted legislation, according to the National
Conference of State Legislatures. The list doesn't include bills focused on specific AI technologies, such as facial
recognition or autonomous cars, something NCSL is tracking separately.

                                                                                                         Page 2 of 3
   AI is gaining attention of state lawmakers Legislators try to guard against discrimination as technology evolves

Legislatures in Texas, North Dakota, West Virginia and Puerto Rico have created advisory bodies to study and
monitor AI systems their respective state agencies are using, while Louisiana formed a new technology and cyber
security committee to study AI's impact on state operations, procurement and policy. Other states took a similar
approach last year.

Lawmakers want to know "Who's using it? How are you using it? Just gathering that data to figure out what's out
there, who's doing what," said Heather Morton, a legislative analysist at NCSL who tracks artificial intelligence,
cybersecurity, privacy and internet issues in state legislatures. "That is something that the states are trying to figure
out within their own state borders."

Connecticut's new law, which requires AI systems used by state agencies to be regularly scrutinized for possible
unlawful discrimination, comes after an investigation by the Media Freedom and Information Access Clinic at Yale
Law School determined AI is already being used to assign students to magnet schools, set bail and distribute
welfare benefits, among other tasks. However, details of the algorithms are mostly unknown to the public.

AI technology, the group said, "has spread throughout Connecticut's government rapidly and largely unchecked, a
development that's not unique to this state."

Richard Eppink, legal director of the American Civil Liberties Union of Idaho, testified before Congress in May about
discovering, through a lawsuit, the "secret computerized algorithms" Idaho was using to assess people with
developmental disabilities for federally funded health care services. The automated system, he said in written
testimony, included corrupt data that relied on inputs the state hadn't validated.

AI can be shorthand for many different technologies, ranging from algorithms recommending what to watch next on
Netflix to generative AI systems such as ChatGPT that can aid in writing or create new images or other media. The
surge of commercial investment in generative AI tools has generated public fascination and concerns about their
ability to trick people and spread disinformation, among other dangers.

Some states haven't attempted to tackle the issue yet. In Hawaii, state Sen. Chris Lee, a Democrat, said lawmakers
didn't pass any legislation this year governing AI "simply because I think at the time, we didn't know what to do."

Instead, the Hawaii House and Senate passed a resolution Lee proposed that urges Congress to adopt safety
guidelines for the use of artificial intelligence and limit its application in the use of force by police and the military.

Lee, vice-chair of the Senate Labor and Technology Committee, said he hopes to introduce a bill in next year's
session that is similar to Connecticut's new law. Lee also wants to create a permanent working group or department
to address AI matters with the right expertise, something he admits is difficult to find.

"There aren't a lot of people right now working within state governments or traditional institutions that have this kind
of experience," he said.

The European Union is leading the world in building guardrails around AI. There has been discussion of bipartisan
AI legislation in Congress, which Senate Majority Leader Chuck Schumer said in June would maximize the
technology's benefits and mitigate significant risks.

Yet the New York senator did not commit to specific details. In July, President Joe Biden announced his
administration had secured voluntary commitments from seven U.S. companies meant to ensure their AI products
are safe before releasing them.

Maroney said ideally the federal government would lead the way in AI regulation. But he said the federal
government can't act at the same speed as a state legislature.

"And as we've seen with the data privacy, it's really had to bubble up from the states," Maroney said.

Some state-level bills proposed this year have been narrowly tailored to address specific AI-related concerns.
Proposals in Massachusetts would place limitations on mental health providers using AI and prevent "dystopian

                                                                                                         Page 3 of 3
   AI is gaining attention of state lawmakers Legislators try to guard against discrimination as technology evolves

work environments" where workers don't have control over their personal data. A proposal in New York would place
restrictions on employers using AI as an "automated employment decision tool" to filter job candidates.

North Dakota passed a bill defining what a person is, making it clear the term does not include artificial intelligence.
Republican Gov. Doug Burgum, a long-shot presidential contender, has said such guardrails are needed for AI but
the technology should still be embraced to make state government less redundant and more responsive to citizens.

In Arizona, Democratic Gov. Katie Hobbs vetoed legislation that would prohibit voting machines from having any
artificial intelligence software. In her veto letter, Hobbs said the bill "attempts to solve challenges that do not
currently face our state."

In Washington, Democratic Sen. Lisa Wellman, a former systems analyst and programmer, said state lawmakers
need to prepare for a world in which machine systems become ever more prevalent in our daily lives.

She plans to roll out legislation next year that would require students to take computer science to graduate high
school.

"AI and computer science are now, in my mind, a foundational part of education," Wellman said. "And we need to
understand really how to incorporate it."

Associated Press Writers Audrey McAvoy in Honolulu, Ed Komenda in Seattle and Matt O'Brien in Providence,
Rhode Island, contributed to this report.


Load-Date: August 6, 2023


  End of Document

                                                                                                  Page 1 of 5
   ChatGPT is poised to change medical care AI technology can empower patients, but glitches make some wary




    ChatGPT is poised to change medical care; AI technology can empower
                   patients, but glitches make some wary
                                                            USA TODAY
                                                      March 6, 2023 Monday
                                                           FIRST EDITION



Copyright 2023 Gannett Company, Inc. All Rights Reserved

Section: NEWS; Pg. 5A
Length: 1956 words
Byline: Karen Weintraub, USA TODAY

Body


It's almost hard to remember a time before people could turn to "Dr. Google" for medical advice. Some of the
information was wrong. Much of it was terrifying. But it helped empower patients who could, for the first time,
research their own symptoms and learn more about their conditions.

Now, ChatGPT and similar language processing tools promise to upend medical care again, providing patients with
more data than a simple online search and explaining conditions and treatments in language nonexperts can
understand.

For clinicians, these chatbots might provide a brainstorming tool, guard against mistakes and relieve some of the
burden of filling out paperwork, which could alleviate burnout and allow more facetime with patients.

But - and it's a big "but" - the information these digital assistants provide might be more inaccurate and misleading
than basic internet searches.

"I see no potential for it in medicine," said Emily Bender, a linguistics professor at the University of Washington. By
their very design, these large-language technologies are inappropriate sources of medical information, she said.

Others argue that large language models could supplement, though not replace, primary care.

"A human in the loop is still very much needed," said Katie Link, a machine learning engineer at Hugging Face, a
company that develops collaborative machine learning tools.

Link, who specializes in health care and biomedicine, thinks chatbots will be useful in medicine someday, but it isn't
yet ready.

And whether this technology should be available to patients, as well as doctors and researchers, and how much it
should be regulated remain open questions.

                                                                                                 Page 2 of 5
  ChatGPT is poised to change medical care AI technology can empower patients, but glitches make some wary

Regardless of the debate, there's little doubt such technologies are coming - and fast. ChatGPT launched its
research preview on a Monday in December. By that Wednesday, it reportedly already had 1 million users. In
February, both Microsoft and Google announced plans to include AI programs similar to ChatGPT in their search
engines.

"The idea that we would tell patients they shouldn't use these tools seems implausible. They're going to use these
tools," said Dr. Ateev Mehrotra, a professor of health care policy at Harvard Medical School and a hospitalist at
Beth Israel Deaconess Medical Center in Boston.

"The best thing we can do for patients and the general public is (say), 'hey, this may be a useful resource, it has a
lot of useful information - but it often will make a mistake and don't act on this information only in your decision-
making process,'" he said.

How ChatGPT it works

ChatGPT - the GPT stands for Generative Pre-trained Transformer - is an artificial intelligence platform from San
Francisco-based startup OpenAI. The free online tool, trained on millions of pages of data from across the internet,
generates responses to questions in a conversational tone.

Other chatbots offer similar approaches with updates coming all the time.

These text synthesis machines might be relatively safe to use for novice writers looking to get past initial writer's
block, but they aren't appropriate for medical information, Bender said.

"It isn't a machine that knows things," she said. "All it knows is the information about the distribution of words."

Given a series of words, the models predict which words are likely to come next.

So, if someone asks "what's the best treatment for diabetes?" the technology might respond with the name of the
diabetes drug "metformin" - not because it's necessarily the best but because it's a word that often appears
alongside "diabetes treatment."

Such a calculation is not the same as a reasoned response, Bender said, and her concern is that people will take
this "output as if it were information and make decisions based on that."

Bender also worries about the racism and other biases that may be embedded in the data these programs are
based on. "Language models are very sensitive to this kind of pattern and very good at reproducing them," she
said.

The way the models work also means they can't reveal their scientific sources - because they don't have any.

Modern medicine is based on academic literature, studies run by researchers published in peer-reviewed journals.
Some chatbots are being trained on that body of literature. But others, like ChatGPT and public search engines, rely
on large swaths of the internet, potentially including flagrantly wrong information and medical scams.

With today's search engines, users can decide whether to read or consider information based on its source: a
random blog or the prestigious New England Journal of Medicine, for instance.

But with chatbot search engines, where there is no identifiable source, readers won't have any clues about whether
the advice is legitimate.

"Understanding where is the underlying information coming from is going to be really useful," Mehrotra said. "If you
do have that, you're going to feel more confident."

Potential for doctors and patients

Mehrotra recently conducted an informal study that boosted his faith in these large language models.

                                                                                                 Page 3 of 5
  ChatGPT is poised to change medical care AI technology can empower patients, but glitches make some wary

He and his colleagues tested ChatGPT on a number of hypothetical vignettes - the type he's likely to ask first-year
medical residents. It provided the correct diagnosis and appropriate triage recommendations about as well as
doctors did and far better than the online symptom checkers that the team tested in previous research.

"If you gave me those answers, I'd give you a good grade in terms of your knowledge and how thoughtful you
were," Mehrotra said.

But it also changed its answers somewhat depending on how the researchers worded the question, said co-author
Ruth Hailu. It might list potential diagnoses in a different order or the tone of the response might change, she said.

Mehrotra, who recently saw a patient with a confusing spectrum of symptoms, said he could envision asking
ChatGPT or a similar tool for possible diagnoses.

"Most of the time it probably won't give me a very useful answer," he said, "but if one out of 10 times it tells me
something - 'oh, I didn't think about that. That's a really intriguing idea!' Then maybe it can make me a better
doctor."

It also has the potential to help patients. Hailu, a researcher who plans to go to medical school, said she found
ChatGPT's answers clear and useful, even to someone without a medical degree.

"I think it's helpful if you might be confused about something your doctor said or want more information," she said.

ChatGPT might offer a less intimidating alternative to asking the "dumb" questions of a medical practitioner,
Mehrotra said.

Dr. Robert Pearl, former CEO of Kaiser Permanente, a 10,000-physician health care organization, is excited about
the potential for both doctors and patients.

"I am certain that five to 10 years from now, every physician will be using this technology," he said. If doctors use
chatbots to empower their patients, "we can improve the health of this nation."

Learning from experience

The models chatbots are based on will continue to improve over time as they incorporate human feedback and
"learn," Pearl said.

Just as he wouldn't trust a newly minted intern on their first day in the hospital to take care of him, programs like
ChatGPT aren't yet ready to deliver medical advice. But as the algorithm processes information again and again, it
will continue to improve, he said.

Plus the sheer volume of medical knowledge is better suited to technology than the human brain, said Pearl, noting
that medical knowledge doubles every 72 days. "Whatever you know now is only half of what is known two to three
months from now."

But keeping a chatbot on top of that changing information will be staggeringly expensive and energy intensive.

The training of GPT-3, which formed some of the basis for ChatGPT, consumed 1,287 megawatt hours of energy
and led to emissions of more than 550 tons of carbon dioxide equivalent, roughly as much as three roundtrip flights
between New York and San Francisco. According to EpochAI, a team of AI researchers, the cost of training an
artificial intelligence model on increasingly large datasets will climb to about $500 million by 2030.

OpenAI has announced a paid version of ChatGPT. For $20 a month, subscribers will get access to the program
even during peak use times, faster responses, and priority access to new features and improvements.

The current version of ChatGPT relies on data only through September 2021. Imagine if the COVID-19 pandemic
had started before the cutoff date and how quickly the information would be out of date, said Dr. Isaac Kohane,

                                                                                                 Page 4 of 5
  ChatGPT is poised to change medical care AI technology can empower patients, but glitches make some wary

chair of the department of biomedical informatics at Harvard Medical School and an expert in rare pediatric
diseases at Boston Children's Hospital.

Kohane believes the best doctors will always have an edge over chatbots because they will stay on top of the latest
findings and draw on experience.

But maybe it will bring up weaker practitioners. "We have no idea how bad the bottom 50% of medicine is," he said.

Dr. John Halamka, president of Mayo Clinic Platform, which offers products and data for artificial intelligence
programs, said he sees potential for chatbots to help providers with tasks such as drafting letters to insurance
companies.

The technology won't replace doctors, he said, but "doctors who use AI will probably replace doctors who don't use
AI."

What ChatGPT means for research

As it currently stands, ChatGPT is not a good source of scientific information. Just ask pharmaceutical executive
Wenda Gao, who used it recently to search for information about a gene involved in the immune system.

Gao asked for references to studies about the gene and ChatGPT offered three "very plausible" citations. But when
Gao went to check those research papers for more details, he couldn't find them.

He turned to ChatGPT. After suggesting Gao had made a mistake, the program admitted the papers didn't exist.

Stunned, Gao repeated the exercise and got the same fake results, along with two completely different summaries
of a fictional paper's findings.

"It looks so real," he said, adding that ChatGPT's results "should be fact-based, not fabricated by the program."

ChatGPT itself told Gao it would learn from these mistakes.

Microsoft, for instance, is developing a system for researchers called BioGPT that will focus on clinical research, not
consumer health care.

Guardrails for medical chatbots

Halamka sees tremendous promise for chatbots and other AI technologies in health care but said they need
"guardrails and guidelines" for use.

"I wouldn't release it without that oversight," he said.

Halamka is part of the Coalition for Health AI, a collaboration of 150 experts from academic institutions like his,
government agencies and technology companies, to craft guidelines for using artificial intelligence algorithms in
health care. "Enumerating the potholes in the road," as he put it.

U.S. Rep. Ted Lieu, a Democrat from California, filed legislation in late January (drafted using ChatGPT) "to ensure
that the development and deployment of AI is done in a way that is safe, ethical and respects the rights and privacy
of all Americans, and that the benefits of AI are widely distributed and the risks are minimized."

Halamka said his recommendation would be to require medical chatbots to disclose sources they used for training.
"Credible data sources curated by humans" should be the standard, he said.

Then, he wants to see ongoing monitoring of the performance of AI, perhaps via a nationwide registry, making
public the good things that came from programs like ChatGPT as well as the bad.

                                                                                                 Page 5 of 5
  ChatGPT is poised to change medical care AI technology can empower patients, but glitches make some wary

Health and patient safety coverage at USA TODAY is made possible in part by a grant from the Masimo
Foundation for Ethics, Innovation and Competition in Healthcare. The Masimo Foundation does not provide editorial
input.


Load-Date: March 6, 2023


  End of Document

                                                                                                       Page 1 of 3
                                         Healthcare decisions are about to get easier




                            Healthcare decisions are about to get easier
                                          The Stute: Stevens Institute of Technology
                                               September 23, 2020 Wednesday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 803 words
Byline: Samantha Winter

Body


The crossover between artificial intelligence and healthcare has arrived.

If the thought of machine learning in healthcare makes you imagine an eerie, Brave New World-esque universe,
don't worry. This technology will help bridge the communication gap between doctors and patients. It could also
save lives.

Samantha Kleinberg, a computer science professor and researcher at the Stevens Health & AI Lab, was recently
awarded three grants from the National Science Foundation and the National Institutes of Health totaling $2.3
million.

Her goal? To develop artificial intelligence that personalizes the information patients receive in order to help them
make better-informed health decisions.

Kleinberg said she hopes to "improve human health through computing." Her aim mirrors the growing need for
artificial intelligence and big data in healthcare. Though the method is technologically-based, the focus is on the
patient. This adds unprecedented personalization to diagnosis, treatment, and prevention.

The three diabetes-focused investigations use artificial intelligence and machine learning in their calculation
methods to help patients.

One $917,879 grant from the NSF is titled "Uniting Causal and Mental Models for Shared Decision-Making in
Diabetes."

Kleinberg and her team will create computational methods to personalize information for patients with diabetes so
that they can pick optimal treatment plans. Since the technology combines machine and human input, it uses a
collaborative decision-making approach so that the patient and the clinician can work together to develop the best
treatment plan.

                                                                                                        Page 2 of 3
                                      Healthcare decisions are about to get easier

Kleinberg recognizes that each patient, doctor, and caregiver has different beliefs about preferred treatment. With
this in mind, she will create training modules to educate clinicians about how patient beliefs influence both trust and
decision-making.

The next grant comes from NIH. This $864,220 award is put towards "Harnessing Patient Generated Data to
Identify Causes and Effects of Nutrition during Pregnancy."

About 9% of women develop gestational diabetes during pregnancy. According to March of Dimes, a non-profit
focused on mother and baby health, this type of diabetes can result in premature birth or stillbirth.

For this investigation, Kleinberg will collaborate with Andrea Deierlein, a researcher at New York University. They
will collect patient-generated data through wearable activity monitors.

With this technology, patients will log meals in real time using photos that can sense food types and calories.
Additionally, the monitors can record symptoms to observe what happens before the illness develops. Kleinberg
aims to pinpoint which factors cause this disease, as this technology could help guide important decisions during
pregnancy.

The last award, "Moving Beyond Knowledge to Action: Evaluating and Improving the Utility of Causal Inference,"
worth $499,454, comes from the NSF.

Kleinberg wants to create artificial intelligence that directly benefits patients.

"My group's work aims to potentially prevent people from developing chronic diseases in the first place, and to
otherwise help them better manage their illnesses," she says. "It will hopefully help many people lead healthier
lives."

The research will focus on understanding how the output of an algorithm can be useful for human decision-makers.
For conclusive results, algorithms should be evaluated based on their ability to be helpful for decision-making rather
than their effectiveness (how many causes they find or how fast they accomplish finding them).

This investigation will introduce new methods for making such models more personalized, allowing patients to
improve their everyday decisions around diet, exercise, and overall treatment.

Kleinberg's research is innovative. However, if you think that overlap between health and AI is an invasion of
privacy, you aren't alone.

Public outrage was recently sparked by the revelation that Google quietly partnered with Ascension to collect and
analyze patient data. This raised questions about the security of the initiative and if safeguards have been enacted
for consumers.

Some critics are worried about the protection of their information. Others think that such technology will eliminate
the need for humans in the healthcare community.

While Google waits to update the public on the implementation of this service, critics should consider both sides of
the matter. Though risky, artificial intelligence and machine involvement in healthcare could be the newest trend in
fostering an innovative and personalized healthcare system.

Navigating the world of health can be tricky, but Kleinberg's work could spark a major shift in personalized
healthcare, one that doctors and patients alike appreciate. After all, Kleinberg says, her work is "to aid humans - not
replace them."


Load-Date: September 23, 2020

                                                                 Page 3 of 3
                  Healthcare decisions are about to get easier


End of Document

                                                                                                      Page 1 of 2
                              AI makes MRIs 4 times faster, NYU and Meta researchers find




              AI makes MRIs 4 times faster, NYU and Meta researchers find
                                       Washington Square News: New York University
                                                      January 30, 2023 Monday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 574 words
Byline: Annabelle Wang

Body


Artificial intelligence improves the speed and clarity of MRIs as compared with traditional scanning, according to a
recent study from the radiology department at NYU Langone Health and an AI research team at Meta. The study,
published on Jan. 17, demonstrates the efficacy of a machine learning algorithm that can construct high-quality MRI
scans with just one-fourth of the data typically needed, reducing the time required for a scan to as little as five
minutes.

MRIs provide more detailed information than other medical scans such as CTs and X-rays. They also use
noninvasive magnetic fields instead of potentially-harmful radiation to produce images, but typically take much
longer and are more expensive. Faster MRIs can reduce the cost of performing a scan in terms of both time and
money, making them more accessible to patients.

In addition to making the technology easier to access, AI assistance may make scans more comfortable for
patients, according to Patricia Johnson, an assistant professor at Langone who co-authored the study.

"It's going to make the experience better," Johnson said. "You're in there for five minutes versus 20 - you're much
less likely to move. That's why the images look better, too. They're less likely to have distortions."

The AI model is part of fastMRI, a Langone initiative established in 2018 in partnership with Meta - formerly
Facebook - to increase the speed of MRI scanning. FastMRI's AI model used a data set of 298 MRIs to recognize
patterns in scans, allowing it to recreate the unscanned parts of the 3D image.

Image reconstruction for MRI scans of a patient's knee. The top two scans are conventional MRI scans, and the
bottom two were aided by AI technology. (Courtesy of Patricia Johnson)

Meta invests in AI technology to support the development of the metaverse - a virtual world within Meta's social
media platform. In a press release published alongside Meta's 2021-22 revenue report, company founder and CEO
Mark Zuckerberg said that Meta's AI investments had produced positive results.

                                                                                                    Page 2 of 2
                          AI makes MRIs 4 times faster, NYU and Meta researchers find

Meta's AI researchers worked with Langone for two years to produce the study - which focused on knee scans -
and plan to continue their research into how AI technology can improve MRIs for other parts of the body, including
the brain.

The study took both conventional and AI-aided MRI scans of 170 study participants' knees. It found that AI scans
were just as helpful as conventional scans in making diagnoses and also resulted in higher-quality images.

"Our new study translates the results from the earlier laboratory-based study and applies it to actual patients,"
Michael Recht, chair of the radiology department at NYU's Grossman School of Medicine, said in a statement.
"FastMRI has the potential to dramatically change how we do MRI and increase accessibility of MRI to more
patients."

In addition to developing its own algorithms, fastMRI makes anonymized data available to other researchers who
may not have the same access to MRI scanners, which can cost more than $500,000. By publicizing their data, the
researchers behind the program hope to incentivize competition and innovation in the field.

"We're so unique in that the NYU medical center has something like 50 MRI scanners, which is more than some
countries," Johnson said. "We just have a very unique ability to collect large volumes of patient data. We want to
facilitate research in this area."

Contact Annabelle Wang at [email protected]


Load-Date: January 30, 2023


  End of Document

                                                                                                          Page 1 of 3
                                        Who Should Be Regulating AI Classroom Tools?




                         Who Should Be Regulating AI Classroom Tools?
                                                  Government TechNology
                                                   August 18, 2023 Friday



Copyright 2023 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 1047 words
Byline: Brandon Paykamian, Government Technology

Body


Aug. 18—Though educators are gradually growing comfortable with the use of artificial intelligence tools for
functions such as grading and lesson planning, concerns still linger about how ChatGPT and other generative AI
technologies could be misused by students for plagiarism, as well as to what extent AI should be utilized in
education generally. As schools and universities grapple with these questions, federal and state lawmakers are
beginning to take a closer look at the impact of AI in education and the public sector for future regulation
considerations.

According to a July report from the ed-tech publication Tech & Learning, at least 15 U.S. states have introduced
bills to study how AI is used across government. Among them is Connecticut's SB 1103, which would require the
state's Department of Administrative Services to assess AI programs and systems being used by state agencies, as
well as a resolution in Louisiana asking the state's Joint Legislative Committee on Technology and Cybersecurity to
study the impact of AI tools in the public sector. At the federal level, the Department of Education released a report
recently that urged pragmatism when it comes to weighing the risks and benefits of AI ed-tech tools and
recommended that federal policymakers work more closely with states, higher-ed institutions and K-12 schools to
develop and assess guidelines specific to the use of AI in education. The report also recommended that schools
and universities involve educators in discussions about tech procurement.

Consortium for School Networking (CoSN) CEO Keith Krueger wrote in an email to Government Technology that
discussions about regulating AI in education are still largely in their infancy at the state and federal levels. However,
he said, state and federal lawmakers may play a critical role in giving schools and universities direction on how to
make use of AI.

"Clearly federal standards will be helpful for national consistency, but may take a while to happen," he wrote.
"Therefore, it makes sense for states/districts to understand and require disclosure by companies in how they are
using AI. We welcome states' desire to better understand the landscape — as demonstrated by common focus on
studies — before rushing to regulate the technology's use by educators."

                                                                                                          Page 2 of 3
                                   Who Should Be Regulating AI Classroom Tools?

Krueger pointed to the White House's Blueprint for an AI Bill of Rights — which outlines some of the risks and
benefits of using AI in fields like law enforcement, health care and education — as a good foundation for how to
think about the technology amid today's policy discussions.

"Guardrails around ethical use of generative AI in education, commerce, health industry and government will likely
call for federal regulations, licensing, and the creation of an independent commission to study the AI environment
and consider the creation of a U.S. AI agency aligning to global efforts," he wrote. "As we know, the wheels of
government do not move fast, yet AI is moving at warp speed."

As we know, the wheels of government do not move fast, yet AI is moving at warp speed.

CoSN CEO Keith Krueger

Julia Fallon, executive director of the State Educational Technology Directors Association, wrote in an email that
she believes states will play a key role in developing AI policies for students and teachers.

"It's encouraging to see New Jersey, Connecticut and Louisiana acknowledging the profound potential of this
technology and attempting to proactively explore AI's impact on their state agencies' operations, procurement and
workforce readiness," Fallon wrote. "As we embrace AI-powered tools in education, it's crucial that all students,
regardless of their background or location, have equitable access to these resources. State education agencies can
work to bridge the digital divide by allocating resources to underserved communities, ensuring that AI technologies
reach every corner of the education system."

Fallon said one of the first major steps in formulating policies at the institutional, district, state and federal levels
about how to use AI tools safely and ethically is understanding how the technology works, as well as collaboration
between educators, policymakers, technology developers and other stakeholders to make sure particular AI tools
align with the specific needs of the school district. She said it's also important to take digital privacy and
cybersecurity concerns into consideration when adopting and deploying AI tools.

"Data privacy and security are non-negotiable. States should establish stringent guidelines for the collection,
storage and use of student data within AI systems," she wrote. "Protecting students' privacy is paramount, and
policies must be in place to safeguard their sensitive information while still enabling meaningful use of AI-driven
insights."

Neil Heffernan, a computer science professor at Worcester Polytechnic Institute and developer of the AI-driven
homework assistance tool ASSISTments, said future AI regulations should avoid stifling research and development
efforts. He added that he believes recent calls from tech companies such as ChatGPT-developer OpenAI to
regulate the technology could lead to the monopolization of AI research and development, which could ultimately
impede tech advances.

"OpenAI knows one way to cripple the open-source movement of using large language models — like LLaMA 2 that
Meta put out last week — is to enforce all sorts of [rules that place] regulatory burden on the little guys. OpenAI
would love to say you cannot use LLM [tech] unless you have done a $100,000 fairness test for bias. OpenAI can
so easily pay that fee but the open-source folks can't," he said.

John Bailey, a senior fellow with the policy think tank American Enterprise Institute, echoed Heffernan's concerns.
He added that since AI technology is still fairly new, it's difficult to say just how AI tools should be regulated.

"I'd encourage a bit of a cautionary approach about regulating this. I think we're so early into the [development of]
the technology, and it's changing at such a rapid pace," he said. "With that kind of speed, it's easy to get the
regulation wrong in many respects."

___ (c)2023 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.

                                                                            Page 3 of 3
                             Who Should Be Regulating AI Classroom Tools?


Load-Date: August 19, 2023


  End of Document

                                                                                                        Page 1 of 5
                         ChatGPT is poised to upend medical information. For better and worse.




    ChatGPT is poised to upend medical information. For better and worse.
                                                        USA Today Online
                                                        February 26, 2023



Copyright 2023 Gannett Media Corp All Rights Reserved

Section: US NEWS
Length: 2148 words
Byline: Karen Weintraub, USA TODAY

Body

It's almost hard to remember a time before people could turn to "Dr. Google" for medical advice. Some of the
information was wrong. Much of it was terrifying. But it helped empower patients who could, for the first time,
research their own symptoms and learn more about their conditions.

Now, ChatGPT and similar language processing tools promise to upend medical care again, providing patients with
more data than a simple onlinesearch and explaining conditions and treatments in language nonexperts can
understand.

For clinicians, these chatbots might provide a brainstorming tool, guard against mistakes and relieve some of the
burden of filling out paperwork, which could alleviate burnout and allow more facetime with patients.

But – and it's a big "but" – the information these digital assistants provide might be more inaccurate and misleading
than basic internet searches.

"I see no potential for it in medicine," said Emily Bender, a linguistics professor at the University of Washington. By
their very design, these large-language technologies are inappropriate sources of medical information, she said.

Others argue that large language models could supplement, though not replace, primary care.

"A human in the loop is still very much needed," said Katie Link, a machine learning engineer at Hugging Face, a
company that develops collaborative machine learning tools.

Link, who specializes in health care and biomedicine, thinks chatbots will be useful in medicine someday, but it isn't
yet ready.

And whether this technology should be available to patients, as well as doctors and researchers, and how much it
should be regulated remain open questions.

Regardless of the debate, there's little doubt such technologies are coming – and fast. ChatGPT launched its
research preview on a Monday in December. By that Wednesday, it reportedly already had 1 million users. In
February, both Microsoft and Google announced plans to include AI programs similar to ChatGPT in their search
engines.

                                                                                                           Page 2 of 5
                       ChatGPT is poised to upend medical information. For better and worse.

"The idea that we would tell patients they shouldn't use these tools seems implausible. They're going to use these
tools," said Dr. Ateev Mehrotra, a professor of health care policy at Harvard Medical School and a hospitalist at
Beth Israel Deaconess Medical Center in Boston.

"The best thing we can do for patients and the general public is (say), 'hey, this may be a useful resource, it has a
lot of useful information – but it often will make a mistake and don't act on this information only in your decision-
making process,'" he said.

    •    ChatGPT and education:Schools ban AI tool, afraid students will plagiarize

    •    Bing ChatGPT meltdown:The AI chatbot is in its feelings

How ChatGPT it works

ChatGPT – the GPT stands for Generative Pre-trained Transformer – is an artificial intelligence platform from San
Francisco-based startup OpenAI. The free online tool, trained on millions of pages of data from across the internet,
generates responses to questions in a conversational tone.

Other chatbots offer similar approaches with updates coming all the time.

These text synthesis machines might be relatively safe to use for novice writers looking to get past initial writer's
block, but they aren't appropriate for medical information, Bender said.

"It isn't a machine that knows things," she said. "All it knows is the information about the distribution of words."

Given a series of words, the models predict which words are likely to come next.

So, if someone asks "what's the best treatment for diabetes?" the technology might respond with the name of the
diabetes drug "metformin" – not because it's necessarily the best but because it's a word that often appears
alongside "diabetes treatment."

Such a calculation is not the same as a reasoned response, Bender said, and her concern is that people will take
this "output as if it were information and make decisions based on that."

Link to Image

Bender also worries about the racism and other biases that may be embedded in the data these programs are
based on. "Language models are very sensitive to this kind of pattern and very good at reproducing them," she
said.

The way the models work also means they can't reveal their scientific sources – because they don't have any.

Modern medicine is based on academic literature, studies run by researchers published in peer-reviewed journals.
Some chatbots are being trained on that body of literature. But others, like ChatGPT and public search engines, rely
on large swaths of the internet, potentially including flagrantly wrong information and medical scams.

With today's search engines, users can decide whether to read or consider information based on its source: a
random blog or the prestigious New England Journal of Medicine, for instance.

But with chatbot search engines, where there is no identifiable source, readers won't have any clues about whether
the advice is legitimate. As of now, companies that make these large language models haven't publicly identified
the sources they're using for training.

"Understanding where is the underlying information coming from is going to be really useful," Mehrotra said. "If you
do have that, you're going to feel more confident."

                                                                                                        Page 3 of 5
                      ChatGPT is poised to upend medical information. For better and worse.

Consider this: 'New frontier' in therapy helps 2 stroke patients move again – and gives hope for many more

Potential for doctors and patients

Mehrotra recently conducted an informalstudy that boosted his faith in these large language models.

He and his colleagues tested ChatGPT on a number of hypothetical vignettes – the type he's likely to ask first-year
medical residents. It provided the correct diagnosis and appropriate triage recommendations about as well as
doctors did and far better than the online symptom checkers that the team tested in previous research.

"If you gave me those answers, I'd give you a good grade in terms of your knowledge and how thoughtful you
were," Mehrotra said.

But it also changed its answers somewhat depending on how the researchers worded the question, said co-author
Ruth Hailu. It might list potential diagnoses in a different order or the tone of the response might change, she said.

Mehrotra, who recently saw a patient with a confusing spectrum of symptoms, said he could envision asking
ChatGPT or a similar tool for possible diagnoses.

"Most of the time it probably won't give me a very useful answer," he said, "but if one out of 10 times it tells me
something – 'oh, I didn't think about that. That's a really intriguing idea!' Then maybe it can make me a better
doctor."

It also has the potential to help patients. Hailu, a researcher who plans to go to medical school, said she found
ChatGPT's answersclear and useful, even to someone without a medical degree.

"I think it's helpful if you might be confused about something your doctor said or want more information," she said.

ChatGPT might offer a less intimidating alternative to asking the "dumb" questions of a medical practitioner,
Mehrotra said.

Dr. Robert Pearl, former CEO of Kaiser Permanente, a 10,000-physician health care organization, is excited about
the potential for both doctors and patients.

"I am certain that five to 10 years from now, every physician will be using this technology," he said. If doctors use
chatbots to empower their patients, "we can improve the health of this nation."

Learning from experience

The models chatbots are based on will continue to improve over time as they incorporate human feedback and
"learn," Pearl said.

Just as he wouldn't trust a newly minted intern on their first day in the hospital to take care of him, programs like
ChatGPT aren't yet ready to deliver medical advice. But as the algorithm processes information again and again, it
will continue to improve, he said.

Plus the sheer volume of medical knowledge is better suited to technology than the human brain, said Pearl, noting
that medical knowledge doubles every 72 days. "Whatever you know now is only half of what is known two to three
months from now."

But keeping a chatbot on top of that changing information will be staggeringly expensive and energy intensive.

The training of GPT-3, which formed some of the basis for ChatGPT, consumed 1,287 megawatt hours of energy
and led to emissions of more than 550 tons of carbon dioxide equivalent, roughly as much as three roundtrip flights
between New York and San Francisco.According to EpochAI, a team of AI researchers, the cost of training an
artificial intelligence model on increasingly large datasets will climb to about $500 million by 2030.

                                                                                                           Page 4 of 5
                       ChatGPT is poised to upend medical information. For better and worse.

OpenAI has announced a paid version of ChatGPT. For $20 a month, subscribers will get access to the program
even during peak use times, faster responses, and priority access to new features and improvements.

The current version of ChatGPT relies on data only through September 2021. Imagine if the COVID-19 pandemic
had started before the cutoff date and how quickly the information would be out of date, said Dr. Isaac Kohane,
chair of the department of biomedical informatics at Harvard Medical School and an expert in rare pediatric
diseases at Boston Children's Hospital.

Kohane believes the best doctors will always have an edge over chatbots because they will stay on top of the latest
findings and draw from years of experience.

But maybe it will bring up weaker practitioners. "We have no idea how bad the bottom 50% of medicine is," he said.

Dr. John Halamka, president of Mayo Clinic Platform, which offers digital products and data for the development of
artificial intelligence programs, said he also sees potential for chatbots to help providers with rote tasks like drafting
letters to insurance companies.

The technology won't replace doctors, he said, but "doctors who use AI will probably replace doctors who don't use
AI."

What ChatGPT means for scientific research

As it currently stands, ChatGPT is not a good source of scientific information. Just ask pharmaceutical executive
Wenda Gao, who used it recently to search for information about a gene involved in the immune system.

Gao asked for references to studies about the gene and ChatGPT offered three "very plausible" citations. But when
Gao went to check those research papers for more details, he couldn't find them.

He turned back to ChatGPT. After first suggesting Gao had made a mistake, the program apologized and admitted
the papers didn't exist.

Stunned, Gao repeated the exercise and got the same fake results, along with two completely different summaries
of a fictional paper's findings.

"It looks so real," he said, adding that ChatGPT's results "should be fact-based, not fabricated by the program."

Again, this might improve in future versions of the technology. ChatGPT itself told Gao it would learn from these
mistakes.

Microsoft, for instance, is developing a system for researchers called BioGPT that will focus on clinical research, not
consumer health care, and it's trained on 15 million abstracts from studies.

Maybe that will be more reliable, Gao said.

Guardrails for medical chatbots

Halamka sees tremendous promise for chatbots and other AI technologies in health care but said they need
"guardrails and guidelines" for use.

"I wouldn't release it without that oversight," he said.

Halamka is part of the Coalition for Health AI, a collaboration of 150 experts from academic institutions like his,
government agencies and technology companies, to craft guidelines for using artificial intelligence algorithms in
health care. "Enumerating the potholes in the road," as he put it.

                                                                                                      Page 5 of 5
                      ChatGPT is poised to upend medical information. For better and worse.

U.S. Rep. Ted Lieu, a Democrat from California, filed legislation in late January (drafted using ChatGPT, of course)
"to ensure that the development and deployment of AI is done in a way that is safe, ethical and respects the rights
and privacy of all Americans, and that the benefits of AI are widely distributed and the risks are minimized."

Halamka said his first recommendation would be to require medical chatbots to disclose the sources they used for
training. "Credible data sources curated by humans" should be the standard, he said.

Then, he wants to see ongoing monitoring of the performance of AI, perhaps via a nationwide registry, making
public the good things that came from programs like ChatGPT as well as the bad.

Halamka said those improvements should let people enter a list of their symptoms into a program like ChatGPT
and, if warranted, get automatically scheduled for an appointment, "as opposed to (telling them) 'go eat twice your
body weight in garlic,' because that's what Reddit said will cure your ailments."

Contact Karen Weintraub at kweintraub@usatoday.com .

Health and patient safety coverage at USA TODAY is made possible in part by a grant from the Masimo
Foundation for Ethics, Innovation and Competition in Healthcare. The Masimo Foundation does not provide editorial
input.

This article originally appeared on USA TODAY: ChatGPT is poised to upend medical information. For better and
worse.


Load-Date: March 3, 2023


  End of Document

                                                                                                        Page 1 of 3
            WPI Establishes Master's Degree in Artificial Intelligence to Prepare Students for Growing Field




         WPI Establishes Master's Degree in Artificial Intelligence to Prepare
                           Students for Growing Field
                                         Tech News: Worcester Polytechnic Institute
                                                December 13, 2023 Wednesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1001 words
Byline: Jean King

Body

To help meet the demand for professionals with expertise in the rapidly evolving field of artificial intelligence ,
Worcester Polytechnic Institute has launched a new degree program in AI that will offer students the opportunity to
earn a master's degree, a combined bachelor's/master's degree, or a graduate certificate through courses, projects,
and thesis work. The program will leverage the university's extensive experience in research and project-based
education in AI to provide students with the technical skills and ethical understanding needed for careers in
industry, government, and academia.

WPI will offer students flexible, yet highly rigorous, areas of specialization with courses on subjects ranging from
deep learning to generative AI. The program will combine theory and practice to train students in the understanding,
development, deployment, and innovation of AI techniques and systems. Students also will study AI in an
interdisciplinary way, with options to take courses offered by the School of Arts & Sciences, the School of
Engineering, and the Business School. An important distinction of WPI's program is a strong emphasis on the
societal and ethical implications of AI.

"WPI has long led higher education as a place where students and faculty have used AI and project-based learning
to tackle big challenges in healthcare, justice, manufacturing, the environment, and other fields," said Jean King,
Peterson Family Dean of WPI's School of Arts & Sciences. "We are excited to focus our AI strengths into this new
program, which will prepare students for leadership roles in a transformational field that faces a critical shortage of
qualified professionals."

WPI has long led higher education as a place where students and faculty have used AI and project-based learning
to tackle big challenges in healthcare, justice, manufacturing, the environment, and other fields. "We are excited to
focus our AI strengths into this new program.
     •    Jean King, Peterson Family Dean of WPI's School of Arts & Sciences

"The university is committed to continuing its leadership in a breadth of application areas for artificial intelligence
technology," said John McNeill, the Bernard M. Gordon Dean of WPI's School of Engineering. "With the flexible
nature of these AI offerings, students can tailor their program to the needs of many different career paths."

                                                                                                       Page 2 of 3
           WPI Establishes Master's Degree in Artificial Intelligence to Prepare Students for Growing Field

WPI's AI program will offer students the option to pursue three separate credentials:
    •    MS degree: Graduate students who have earned the equivalent of a four-year U.S. bachelor's degree in
         fields such as computer science, data science, mathematics, statistics, electrical and robotics engineering,
         information technology, business analytics, quantitative sciences or other related fields will be able to earn
         a degree by completing a total of 30 credit hours of work, including a thesis or capstone project.
    •    Combined BS/MS degree: WPI undergraduates will be able to pursue two degrees at an accelerated pace-
         a bachelor's degree in any major offered at WPI and an MS in AI-by double-counting certain courses
         toward both degrees. This option will allow students to pursue two degrees in less time than would typically
         be required to pursue each degree separately.
    •    Graduate Certificate: This option will prepare students to use AI technologies in real-world applications by
         completing four thematically related graduate courses in AI. These courses can be used as part of the MS
         degree in AI, if desired.

With the flexible nature of these AI offerings, students can tailor their program to the needs of many different career
paths.
    •    John McNeill, the Bernard M. Gordon Dean of WPI's School of Engineering

AI is an umbrella term for machines or computer systems that can perform tasks that typically require human
intelligence or mimic the behavior of humans. The development of WPI's new program coincides with a surge of
demand for trained scientists and engineers who can apply AI techniques and tools. Industries ranging from
technology, healthcare, finance, and manufacturing are actively seeking AI talent to harness the benefits of AI-
driven solutions and innovations. The U.S. Bureau of Labor Statistics projects an average of about 377,500 job
openings annually in computer and information technology occupations through 2032. Median annual wages in
2022 for computer and information research scientists were $136,620, according to the BLS, and the consulting and
accounting firm PwC estimated in its 2023 Global Investor survey that AI will contribute $15.7 trillion to the global
economy by 2030.

"AI is transforming existing disciplines, giving rise to new industries, and reshaping the workplace," said Elke
Rundensteiner, the William Smith Dean's Professor of Computer Science and founding head of the WPI Data
Science Program. "Our curriculum, faculty, and research at WPI make the university well positioned to prepare
students to both advance AI techniques and apply them to science, engineering, medicine, automation, and other
industries for economic growth and the betterment of society."

AI also is a strategic research area for WPI, with faculty and students focused on the application of AI in health,
learning sciences, game development, robotics, engineering, business, and global sustainability. Nearly every area
of research is touched by AI, whether as a focus of inquiry or an applicable tool. Generative AI, such as large
learning models or neural network models, allows researchers to efficiently process and leverage vast quantities of
textual data to answer pressing questions and generate new insights.

WPI will begin accepting applications immediately for program enrollment in fall 2024.

Related Stories

WPI Launches Transdisciplinary Master's Degree Program in Ne...

WPI Launches Environmental Studies B.A. Program

Critical Conversations Panel on Artificial Intelligence Expl...

Topics

Artificial Intelligence

DEPARTMENT

                                                                                                        Page 3 of 3
            WPI Establishes Master's Degree in Artificial Intelligence to Prepare Students for Growing Field

Computer Science

|

Data Science

|

Robotics Engineering

PROFILE

Jean King

|

John McNeill

|

Elke Rundensteiner


Load-Date: December 22, 2023


    End of Document

                                                                                                             Page 1 of 3
               Artificial intelligence is gaining state lawmakers' attention, and they have a lot of questions




  Artificial intelligence is gaining state lawmakers' attention, and they have a
                                   lot of questions
                                                  St. Louis Post-Dispatch (Missouri)
                                                        August 11, 2023 Friday
                                                             FIRST EDITION



Copyright 2023 St. Louis Post-Dispatch, Inc. All Rights Reserved

Section: ; Pg. A8
Length: 912 words
Byline: By SUSAN HAIGH Associated Press

Body


HARTFORD, Conn. - As state lawmakers rush to get a handle on fast-evolving artificial intelligence technology,
they're often focusing first on their own state governments before imposing restrictions on the private sector.

Legislators are seeking ways to protect constituents from discrimination and other harms while not hindering
cutting-edge advancements in medicine, science, business, education and more.

"We're starting with the government. We're trying to set a good example," Connecticut state Sen. James Maroney
said during a floor debate in May.

Connecticut plans to inventory all of its government systems using artificial intelligence by the end of 2023, posting
the information online. Starting next year, state officials must regularly review these systems to ensure they won't
lead to unlawful discrimination.

Maroney, a Democrat, said Connecticut lawmakers will likely focus on private industry next year. He plans to work
this fall on model AI legislation with lawmakers in Colorado, New York, Virginia, Minnesota and elsewhere that
includes "broad guardrails" and focuses on matters like product liability and requiring impact assessments of AI
systems.

"It's rapidly changing and there's a rapid adoption of people using it. So we need to get ahead of this," he said in an
interview. "We're actually already behind it, but we can't really wait too much longer to put in some form of
accountability."

Overall, at least 25 states, Puerto Rico and the District of Columbia introduced artificial intelligence bills this year.
As of late July, 14 states and Puerto Rico adopted resolutions or enacted legislation, according to the National
Conference of State Legislatures. The list doesn't include bills focused on specific AI technologies, such as facial
recognition or autonomous cars, something NCSL is tracking separately.

                                                                                                           Page 2 of 3
             Artificial intelligence is gaining state lawmakers' attention, and they have a lot of questions

Legislatures in Texas, North Dakota, West Virginia and Puerto Rico created advisory bodies to study and monitor
AI systems their respective state agencies are using, while Louisiana formed a new technology and cybersecurity
committee to study AI's impact on state operations, procurement and policy. Other states took a similar approach
last year.

Lawmakers want to know "Who's using it? How are you using it? Just gathering that data to figure out what's out
there, who's doing what," said Heather Morton, a legislative analysist at NCSL who tracks artificial intelligence,
cybersecurity, privacy and internet issues in state legislatures. "That is something that the states are trying to figure
out within their own state borders."

Connecticut's new law came after an investigation by the Media Freedom and Information Access Clinic at Yale
Law School determined AI is being used to assign students to magnet schools, set bail and distribute welfare
benefits, among other tasks. However, details of the algorithms are mostly unknown to the public "and largely
unchecked," the group said.

Richard Eppink, legal director of the American Civil Liberties Union of Idaho, testified before Congress in May about
discovering, through a lawsuit, the "secret computerized algorithms" Idaho was using to assess people with
developmental disabilities for federally funded health care services. The automated system, he said, included
corrupt data that relied on inputs the state hadn't validated.

AI can be shorthand for many different technologies, ranging from algorithms recommending what to watch next on
Netflix to generative AI systems such as ChatGPT that can aid in writing or create new images or other media. The
surge of commercial investment in generative AI tools generated public fascination and concerns about their ability
to trick people and spread disinformation, among other dangers.

Some states haven't attempted to tackle the issue yet. In Hawaii, state Sen. Chris Lee, a Democrat, said lawmakers
didn't pass any legislation this year governing AI "simply because I think at the time, we didn't know what to do."

Instead, the Hawaii House and Senate passed a resolution Lee proposed that urges Congress to adopt safety
guidelines for the use of artificial intelligence and limit its application in the use of force by police and the military.

Lee, vice-chair of the Senate Labor and Technology Committee, said he hopes to introduce a bill similar to
Connecticut's new law. Lee also wants to create a permanent working group or department to address AI matters
with the right expertise, something he admits is difficult to find.

"There aren't a lot of people right now working within state governments or traditional institutions that have this kind
of experience," he said.

There has been discussion of bipartisan AI legislation in Congress.

Maroney said ideally the federal government would lead the way in AI regulation but it can't act at the same speed
as a state legislature. "And as we've seen with the data privacy, it's really had to bubble up from the states," he
said.

Some state-level bills proposed this year have been narrowly tailored to address specific AI-related concerns.
Proposals in Massachusetts would place limitations on mental health providers using AI and prevent "dystopian
work environments" where workers don't have control over their personal data. A proposal in New York would place
restrictions on employers using AI as an "automated employment decision tool" to filter job candidates.

North Dakota passed a bill defining what a person is, making it clear the term does not include artificial intelligence.



Graphic

                                                                                                           Page 3 of 3
             Artificial intelligence is gaining state lawmakers' attention, and they have a lot of questions

 After months of warnings from tech executives about the dangers of artificial intelligence, the Federal Bureau of
Investigation has a new list of concerns.The agency's biggest fears are not only about what the technology does but
also about who is using it.During a rare background briefing call with reporters, a senior FBI official, who even
acknowledged that they haven't done significant outreach on the topic of AI, described a pretty concerning situation,
or a "threat landscape," as the FBI calls it.He said that China is looking to steal U.S. AI technology and data for AI
programs and then use it not just to advance their own AI programs but to influence Americans.He also said that
the FBI is closely monitoring the role that AI may play in the 2024 election and is concerned about the spread of
disinformation and deep fake videos.He said that criminals and terrorists are seeking AI to simplify the production of
dangerous chemicals and biological substances to increase their potency.SEE MORE: Tech giants commit to Biden
administration-brokered AI safety rulesScripps News asked about explosives, and this official said that a variety of
criminal and national security actors, from violent extremists to traditional terrorists, are using AI to try to come up
with ways to create different types of explosives.He said, "There have been people who have successfully elicited
recipes or instructions for creating explosives."He also said that AI is a force multiplier for crafting fishing e-
mails and for using it in other cyberattacks. He says that the FBI has found AI-generated websites that are infected
with malware to target users sites that have more than a million followers.The bottom line, the FBI says, there are
fewer people, less expertise, and less time needed for a lot of these threats, so there's a much lower bar or barrier
for entry here. Furthermore, the FBI is spending some of its time working on being able to determine what is
synthetically AI-generated content online. They are working with private companies, and they're working with
academia. But as this official said, this technology is advancing really quickly, and it is hard to stay on top of it. The
OpenAI logo is seen on a mobile phone March 21 in front of a computer screen displaying output from ChatGPT in
Boston. Connecticut Gov. Ned Lamont delivers the State of the State address Jan. 4 during opening session of the
Legislature at the State Capitol in Hartford.


Load-Date: August 11, 2023


  End of Document

                                                                                                        Page 1 of 3
            WPI Establishes Master's Degree in Artificial Intelligence to Prepare Students for Growing Field




         WPI Establishes Master's Degree in Artificial Intelligence to Prepare
                           Students for Growing Field
                                         The Towers: Worcester Polytechnic Institute
                                                December 13, 2023 Wednesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 993 words

Body

To help meet the demand for professionals with expertise in the rapidly evolving field of artificial intelligence ,
Worcester Polytechnic Institute has launched a new degree program in AI that will offer students the opportunity to
earn a master's degree, a combined bachelor's/master's degree, or a graduate certificate through courses, projects,
and thesis work. The program will leverage the university's extensive experience in research and project-based
education in AI to provide students with the technical skills and ethical understanding needed for careers in
industry, government, and academia.

WPI will offer students flexible, yet highly rigorous, areas of specialization with courses on subjects ranging from
deep learning to generative AI. The program will combine theory and practice to train students in the understanding,
development, deployment, and innovation of AI techniques and systems. Students also will study AI in an
interdisciplinary way, with options to take courses offered by the School of Arts & Sciences, the School of
Engineering, and the Business School. An important distinction of WPI's program is a strong emphasis on the
societal and ethical implications of AI.

"WPI has long led higher education as a place where students and faculty have used AI and project-based learning
to tackle big challenges in healthcare, justice, manufacturing, the environment, and other fields," said Jean King,
Peterson Family Dean of WPI's School of Arts & Sciences. "We are excited to focus our AI strengths into this new
program, which will prepare students for leadership roles in a transformational field that faces a critical shortage of
qualified professionals."

WPI has long led higher education as a place where students and faculty have used AI and project-based learning
to tackle big challenges in healthcare, justice, manufacturing, the environment, and other fields. "We are excited to
focus our AI strengths into this new program.
     •    Jean King, Peterson Family Dean of WPI's School of Arts & Sciences

"The university is committed to continuing its leadership in a breadth of application areas for artificial intelligence
technology," said John McNeill, the Bernard M. Gordon Dean of WPI's School of Engineering. "With the flexible
nature of these AI offerings, students can tailor their program to the needs of many different career paths."

WPI's AI program will offer students the option to pursue three separate credentials:

                                                                                                       Page 2 of 3
           WPI Establishes Master's Degree in Artificial Intelligence to Prepare Students for Growing Field

    •    MS degree: Graduate students who have earned the equivalent of a four-year U.S. bachelor's degree in
         fields such as computer science, data science, mathematics, statistics, electrical and robotics engineering,
         information technology, business analytics, quantitative sciences or other related fields will be able to earn
         a degree by completing a total of 30 credit hours of work, including a thesis or capstone project.
    •    Combined BS/MS degree: WPI undergraduates will be able to pursue two degrees at an accelerated pace-
         a bachelor's degree in any major offered at WPI and an MS in AI-by double-counting certain courses
         toward both degrees. This option will allow students to pursue two degrees in less time than would typically
         be required to pursue each degree separately.
    •    Graduate Certificate: This option will prepare students to use AI technologies in real-world applications by
         completing four thematically related graduate courses in AI. These courses can be used as part of the MS
         degree in AI, if desired.

With the flexible nature of these AI offerings, students can tailor their program to the needs of many different career
paths.
    •    John McNeill, the Bernard M. Gordon Dean of WPI's School of Engineering

AI is an umbrella term for machines or computer systems that can perform tasks that typically require human
intelligence or mimic the behavior of humans. The development of WPI's new program coincides with a surge of
demand for trained scientists and engineers who can apply AI techniques and tools. Industries ranging from
technology, healthcare, finance, and manufacturing are actively seeking AI talent to harness the benefits of AI-
driven solutions and innovations. The U.S. Bureau of Labor Statistics projects an average of about 377,500 job
openings annually in computer and information technology occupations through 2032. Median annual wages in
2022 for computer and information research scientists were $136,620, according to the BLS, and the consulting and
accounting firm PwC estimated in its 2023 Global Investor survey that AI will contribute $15.7 trillion to the global
economy by 2030.

"AI is transforming existing disciplines, giving rise to new industries, and reshaping the workplace," said Elke
Rundensteiner, the William Smith Dean's Professor of Computer Science and founding head of the WPI Data
Science Program. "Our curriculum, faculty, and research at WPI make the university well positioned to prepare
students to both advance AI techniques and apply them to science, engineering, medicine, automation, and other
industries for economic growth and the betterment of society."

AI also is a strategic research area for WPI, with faculty and students focused on the application of AI in health,
learning sciences, game development, robotics, engineering, business, and global sustainability. Nearly every area
of research is touched by AI, whether as a focus of inquiry or an applicable tool. Generative AI, such as large
learning models or neural network models, allows researchers to efficiently process and leverage vast quantities of
textual data to answer pressing questions and generate new insights.

WPI will begin accepting applications immediately for program enrollment in fall 2024.

Related Stories

WPI Launches Transdisciplinary Master's Degree Program in Ne...

WPI Launches Environmental Studies B.A. Program

Critical Conversations Panel on Artificial Intelligence Expl...

Topics

Artificial Intelligence

DEPARTMENT

Computer Science

                                                                                                        Page 3 of 3
            WPI Establishes Master's Degree in Artificial Intelligence to Prepare Students for Growing Field

|

Data Science

|

Robotics Engineering


Load-Date: December 22, 2023


    End of Document

                                                                                                       Page 1 of 3
                                        Biden signs executive order to guide AI safety




                          Biden signs executive order to guide AI safety
                                                      The Hartford Courant
                                                   October 31, 2023 Tuesday
                                                             1 Edition



Copyright 2023 The Hartford Courant Company All Rights Reserved

Section: SPORTS; D; Pg. 6
Length: 1163 words
Byline: Josh Boak and Matt O'Brien Associated Press

Body


WASHINGTON - President Joe Biden on Monday signed a sweeping executive order to guide the development of
artificial intelligence - requiring industry to develop safety and security standards, introducing new consumer
protections and giving federal agencies an extensive to-do list to oversee the rapidly progressing technology.

The order reflects the government's effort to shape how AI evolves in a way that can maximize its possibilities and
contain its perils.

AI has been a source of deep personal interest for Biden, with its potential to affect the economy and national
security.

White House chief of staff Jeff Zients recalled Biden giving his staff a directive to move with urgency on the issue,
having considered the technology a top priority.

In Biden's view, the government was late to address the risks of social media and now U.S. youth are grappling with
related mental health issues. AI has the positive ability to accelerate cancer research, model the impacts of climate
change, boost economic output and improve government services, among other benefits.

But it also could warp basic notions of truth with false images, deepen racial and social inequalities, and provide a
tool to scammers and criminals.

The order builds on voluntary commitments already made by technology companies. It's part of a broader strategy
that administration officials say also includes congressional legislation and international diplomacy, a sign of the
disruptions already caused by the introduction of new AI tools such as ChatGPT that can generate new text,
images and sounds.

Using the Defense Production Act, the order will require leading AI developers to share safety test results and other
information with the government. The National Institute of Standards and Technology is to create standards to
ensure AI tools are safe and secure before public release.

                                                                                                            Page 2 of 3
                                     Biden signs executive order to guide AI safety

The Commerce Department is to issue guidance to label and watermark AI-generated content to help differentiate
between authentic interactions and those generated by software. The order touches on matters of privacy, civil
rights, consumer protections, scientific research and worker rights.

An administration official who previewed the order on a Sunday call with reporters said the to-do lists within the
order will be implemented and fulfilled over the range of 90 days to 365 days, with the safety and security items
facing the earliest deadlines.

The official briefed reporters on condition of anonymity, as required by the White House.

Last Thursday, Biden gathered his aides in the Oval Office to review and finalize the executive order, a 30-minute
meeting that stretched to 70 minutes, despite other pressing matters including the mass shooting in Maine, the
Israel-Hamas war and the selection of a new House speaker.

Biden was profoundly curious about the technology in the months of meetings that led up to drafting the order. His
science advisory council focused on AI at two meetings and his Cabinet discussed it at two meetings. The president
also pressed tech executives and civil society advocates about the technology's capabilities at multiple gatherings.

"He was as impressed and alarmed as anyone," deputy White House chief of staff Bruce Reed said in an interview.
"He saw fake AI images of himself, of his dog. He saw how it can make bad poetry. And he's seen and heard the
incredible and terrifying technology of voice cloning, which can take three seconds of your voice and turn it into an
entire fake conversation."

The possibility of false images and sounds led the president to prioritize the labeling and watermarking of anything
produced by AI. Biden also wanted to thwart the risk of older Americans getting a phone call from someone who
sounded like a loved one, only to be scammed by an AI tool.

Meetings could go beyond schedule, with Biden telling civil society advocates in a ballroom of San Francisco's
Fairmont Hotel in June: "This is important. Take as long as you need."

The president also talked with scientists and saw the upside that AI created if harnessed for good. He listened to a
Nobel Prize-winning physicist talk about how AI could explain the origins of the universe. Another scientist showed
how AI could model extreme weather like 100-year floods, as the past data used to assess these events has lost its
accuracy because of climate change.

The issue of AI was seemingly inescapable for Biden. At Camp David one weekend, he relaxed by watching the
Tom Cruise film "Mission: Impossible - Dead Reckoning Part One." The film's villain is a sentient and rogue AI
known as "the Entity" that sinks a submarine and kills its crew in the movie's opening minutes.

"If he hadn't already been concerned about what could go wrong with AI before that movie, he saw plenty more to
worry about," said Reed, who watched the film with the president.

Governments around the world have raced to establish guardrails, some of them tougher than Biden's directives.
After more than two years of deliberation, the EU is putting the final touches on a comprehensive set of regulations
that targets the riskiest applications with the tightest restrictions. China, a key AI rival to the U.S., has also set some
rules.

U.K. Prime Minister Rishi Sunak hopes to carve out a prominent role for Britain as an AI safety hub at a summit
starting Wednesday that Vice President Kamala Harris plans to attend. And on Monday, officials from the Group of
Seven major industrial nations agreed to a set of AI safety principles and a voluntary code of conduct for AI
developers.

The U.S., particularly its West Coast, is home to many of the leading developers of cutting-edge AI technology,
including tech giants Google, Meta and Microsoft and AI-focused startups such as OpenAI, maker of ChatGPT. The
White House took advantage of that industry weight earlier this year when it secured commitments from those
companies to implement safety mechanisms as they build new AI models.

                                                                                                          Page 3 of 3
                                    Biden signs executive order to guide AI safety

But the White House also faced significant pressure from Democratic allies, including labor and civil rights groups,
to make sure its policies reflected their concerns about AI's real-world harms.

The American Civil Liberties Union is among the groups that met with the White House to try to ensure "we're
holding the tech industry and tech billionaires accountable" so that algorithmic tools "work for all of us and not just a
few," said ReNika Moore, director of the ACLU's racial justice program.

Suresh Venkatasubramanian, a former Biden administration official who helped craft principles for approaching AI,
said one of the biggest challenges within the federal government has been what to do about law enforcement's use
of AI tools, including at U.S. borders.

"These are all places where we know that the use of automation is very problematic, with facial recognition, drone
technology," Venkatasubramanian said. Facial recognition technology has been shown to perform unevenly across
racial groups, and has been tied to mistaken arrests.


Load-Date: October 31, 2023


  End of Document

                                                                                                          Page 1 of 2
                          Boulder-based Boomtown goes virtual with help from Shark Tank star




         Boulder-based Boomtown goes virtual with help from Shark Tank star
                                      Colorado Daily: University of Colorado at Boulder
                                                      May 28, 2020 Thursday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: COLUMNISTS; Pg. 1
Length: 599 words
Byline: Lucas High Bizwest Prairie Mountain Media

Body

BOULDER - From Anthony Franco and mcSquares to Dustin Finkel and Ka-Pop! Snacks, ABC's Shark Tank has
teamed with companies with Colorado connections for years. The Colorado-Shark Tank connection got even
stronger Thursday evening when television investor and The Corcoran Group founder Barbara Corcoran played
host to Boulder-based startup accelerator Boomtown's virtual demo day.

"It's great not being a shark here judging today; instead we're here celebrating these companies and
entrepreneurs," Corcoran said, calling Boulder a "startup hotspot."

The demo day, Boomtown's 13th and typically held live at the Boulder Theater, featured videos from the founders of
a dozen startups pitching their firms to investors and receiving feedback from judges. The judges were Scott
Caruso, director of strategic ventures with CableLabs; Margot Drees, former Global Healthcare Exchange LLC vice
president of global marketing; Thriv3 LLC president Sarah Irizarry; and leadership coach Dan Willis.

For the first three weeks of the accelerator program, founders met in person in Boulder. But when the COVID-19
outbreak began spreading, Boomtown went virtual.

"It's always hard to start a company, but doing it in the context of a pandemic is even harder," Willis said.

The cohort members, described below using language provided by Boomtown, were:
     •     allt - Connects devices to entertainment and then filters content for each app on that device so relevant
           information is immediately available without the need to search.
     •     Audio Fusion Systems - Patented technology delivers audio over Wi-Fi with low latency using standard
           networking protocols to enable real-time wireless audio with a virtually unlimited number of custom or off-
           the-shelf devices and huge range.
     •     EXG Wear - Develops wearable devices to enable users to interact with surrounding smart IoTs/robotic
           devices using simple facial gestures.
     •     FLX Solutions - Disrupting the robotics market with an inexpensive, snake-like robot improving worker
           safety and efficiency.

                                                                                                     Page 2 of 2
                      Boulder-based Boomtown goes virtual with help from Shark Tank star

   •    Hemorai - A platform of portable and non-invasive solutions to warn physicians and care providers of
        impending clinical deterioration and hemorrhagic shock.
   •    nect World - 5G USB Modem with eSIM data packages around the globe that works as a WiFi hotspot for
        devices.
   •    OrthoKeys - Provides the tools doctors need for the diagnosis, study, and treatment of orthopaedic patients
        in one single app with unparalleled interactivity that will streamline success.
   •    Qualaris - Helps health-care organizations streamline quality improvement with approachable, all-in-one
        project SaaS.
   •    SiCureMe Healthcare Technologies - Intelligent self-care solution providing personalized preventive care
        using machine learning and AI-based analytical platform and IoT based sensors for continuous monitoring,
        early detection and better management of lifestyle diseases and associated risks.
   •    StrideTech Medical Walk - Walker enhancement and biofeedback system that provides peace of mind and
        greater independence for seniors on the move.
   •    Triad Health AI - Interactive exercise and health monitoring via smart speakers to provide access to
        personalized exercise programs while collecting valuable health and falls data for people with Parkinson's
        and other neurological issues.

"Entrepreneurs today must know how to lead in a crisis," Boomtown CEO Toby Krout said. "Innovative thinking
must empower humanity and our startups have risen to the challenge. The experience they gained over these past
few months included powerful, valuable lessons that will serve them for the rest of their careers."

© 2020 BizWest Media LLC


Load-Date: May 29, 2020


  End of Document

                                                                                                          Page 1 of 2
                          Boulder-based Boomtown goes virtual with help from Shark Tank star




         Boulder-based Boomtown goes virtual with help from Shark Tank star
                                      Colorado Daily: University of Colorado at Boulder
                                                      May 28, 2020 Thursday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 599 words
Byline: Lucas High Bizwest Prairie Mountain Media

Body

BOULDER - From Anthony Franco and mcSquares to Dustin Finkel and Ka-Pop! Snacks, ABC's Shark Tank has
teamed with companies with Colorado connections for years. The Colorado-Shark Tank connection got even
stronger Thursday evening when television investor and The Corcoran Group founder Barbara Corcoran played
host to Boulder-based startup accelerator Boomtown's virtual demo day.

"It's great not being a shark here judging today; instead we're here celebrating these companies and
entrepreneurs," Corcoran said, calling Boulder a "startup hotspot."

The demo day, Boomtown's 13th and typically held live at the Boulder Theater, featured videos from the founders of
a dozen startups pitching their firms to investors and receiving feedback from judges. The judges were Scott
Caruso, director of strategic ventures with CableLabs; Margot Drees, former Global Healthcare Exchange LLC vice
president of global marketing; Thriv3 LLC president Sarah Irizarry; and leadership coach Dan Willis.

For the first three weeks of the accelerator program, founders met in person in Boulder. But when the COVID-19
outbreak began spreading, Boomtown went virtual.

"It's always hard to start a company, but doing it in the context of a pandemic is even harder," Willis said.

The cohort members, described below using language provided by Boomtown, were:
     •     allt - Connects devices to entertainment and then filters content for each app on that device so relevant
           information is immediately available without the need to search.
     •     Audio Fusion Systems - Patented technology delivers audio over Wi-Fi with low latency using standard
           networking protocols to enable real-time wireless audio with a virtually unlimited number of custom or off-
           the-shelf devices and huge range.
     •     EXG Wear - Develops wearable devices to enable users to interact with surrounding smart IoTs/robotic
           devices using simple facial gestures.
     •     FLX Solutions - Disrupting the robotics market with an inexpensive, snake-like robot improving worker
           safety and efficiency.

                                                                                                     Page 2 of 2
                      Boulder-based Boomtown goes virtual with help from Shark Tank star

   •    Hemorai - A platform of portable and non-invasive solutions to warn physicians and care providers of
        impending clinical deterioration and hemorrhagic shock.
   •    nect World - 5G USB Modem with eSIM data packages around the globe that works as a WiFi hotspot for
        devices.
   •    OrthoKeys - Provides the tools doctors need for the diagnosis, study, and treatment of orthopaedic patients
        in one single app with unparalleled interactivity that will streamline success.
   •    Qualaris - Helps health-care organizations streamline quality improvement with approachable, all-in-one
        project SaaS.
   •    SiCureMe Healthcare Technologies - Intelligent self-care solution providing personalized preventive care
        using machine learning and AI-based analytical platform and IoT based sensors for continuous monitoring,
        early detection and better management of lifestyle diseases and associated risks.
   •    StrideTech Medical Walk - Walker enhancement and biofeedback system that provides peace of mind and
        greater independence for seniors on the move.
   •    Triad Health AI - Interactive exercise and health monitoring via smart speakers to provide access to
        personalized exercise programs while collecting valuable health and falls data for people with Parkinson's
        and other neurological issues.

"Entrepreneurs today must know how to lead in a crisis," Boomtown CEO Toby Krout said. "Innovative thinking
must empower humanity and our startups have risen to the challenge. The experience they gained over these past
few months included powerful, valuable lessons that will serve them for the rest of their careers."

© 2020 BizWest Media LLC


Load-Date: May 29, 2020


  End of Document

                                                                                                      Page 1 of 2
                        Researchers find puberty onset associated with racial, economic privilege




  Researchers find puberty onset associated with racial, economic privilege
                                     Daily Californian: University of California - Berkeley
                                                      March 1, 2023 Wednesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 522 words

Body


A study conducted by researchers at UC Berkeley School of Public Health, UCSF and Kaiser Permanente Northern
California, or KPNC, has found a strong association between early onset puberty and young women born into
neighborhoods of less racial and economic privilege.

The study, administered by KPNC, was part of the larger KPNC Puberty Study. It aimed to identify life risk variables
correlated with early puberty among young adults, mainly because of an observed increase of children with earlier
pubertal onset in the last few decades.

"Our findings revealed that neighborhood racial and economic privilege are strongly associated with the timing of
girls' puberty," Kubo said in an email. "Compared to girls born into neighborhoods of concentrated privilege, girls
born into neighborhoods of concentrated disadvantage were significantly more likely to experience pubarche and
thelarche at earlier ages."

The main researchers for the study were lead authors Julia Acker, a doctoral student in epidemiology at UC
Berkeley School of Public Health, and Mahasin Mujahid, the epidemiology division chair, as well as co-senior
authors Julianna Deardorff, the Associate Dean at UC Berkeley School of Public Health, and Ai Kubo, the principal
investigator of the study and a epidemiologist at KPNC.

Kubo said the larger cohort puberty study sampled over 100,000 KPNC adolescents, with over 46,000 girls from
over 2,500 neighborhoods in northern California born at a KPNC facility between 2005 to 2011. KPNC pediatricians
evaluated pubertal timing through routine check-ups beginning at the age of six, measuring two main factors: pubic
hair onset and breast development onset.

Within the study, researchers relied on Harvard School of Public Health doctor Nancy Krieger's "Index of
Concentration at the Extremes" as the standard to assess the amount of neighborhood racial and economic
privilege.

The metric uses U.S. Census data to measure an estimated concentration of white, high-income residents
proportioned to black, low-income residents in a single neighborhood, deeming neighborhoods with the majority
being white, wealthy individuals to be those with more racial and economic privilege.

                                                                                                        Page 2 of 2
                     Researchers find puberty onset associated with racial, economic privilege

Kubo notes that previous research on early onset puberty in young adults has singled out variables based on
individual factors as correlating with racial and ethnic differences, such as obesity and race alone, while this study
links neighborhood condition disparities shaped by "racially discriminatory practices and policies" to the racial and
ethnic differences instead.

For future research, the team intends to explore more neighborhood condition constants, including population
density and ethnic enclave, along with early life variables such as maternal mental health, exposure to intrauterine
or secondhand smoking and disadvantageous childhood events.

"Overall, our findings suggest that policies designed to improve economic opportunity and conditions in racially
segregated, economically vulnerable neighborhoods have the potential to reduce disparities in early pubertal timing
affecting racially marginalized girls," Kubo said in the email.


Load-Date: March 2, 2023


  End of Document

                                                                                                        Page 1 of 2
                                                      A case for health care stocks




                                           A case for health care stocks
                                                        Daily News (New York)
                                                      November 19, 2023 Sunday
                                                             1STAR Edition



Copyright 2023 Daily News, L.P. All Rights Reserved

Section: MAIN; CS; Pg. 33
Length: 529 words
Byline: James K. Glassman Kiplinger's Personal Finance
Highlight: Everydayplus/Dreamstime

Body


Health care stocks have had a rough few years. So why invest in them?

First, I'm a contrarian. I like what's down. Second, health care is a booming industry, accounting for 18% of gross
domestic product in 2021, up from 12% in 1991. Third, the sector adds stability to any portfolio.

It stands to reason that health care is less volatile than other sectors. After all, in both good times and bad, people
get sick and need the services of hospitals, pharmaceutical makers, drugstores, health insurers, medical device
manufacturers and the whole apparatus of health care.

Pharmaceutical companies tend to dominate health care mutual funds and ETFs. That has been a problem. S&P's
pharmaceutical index has lost an annual average of close to 2% over the past five years, compared with an
annualized gain of 11% for the S&P 500 as a whole. Drug companies also are unpopular with the public, and they
have become a political target of both parties.

As an alternative to drug stocks, look at stocks such as Kenvue (KVUE), which Johnson & Johnson earlier this year
spun off as a separate company. (With the spin-off, J&J agreed to retain all liabilities related to lawsuits over its
talcum powder and to indemnify Kenvue.)

Kenvue has an impressive portfolio of over-the-counter medicines, such as Tylenol, Sudafed and Benadryl, plus
other consumer brands (Band-Aid, Listerine and Neutrogena). The stock has dropped since its spring debut.

Another non-pharmaceutical choice is Stryker (SYK), which makes knee and hip replacements - a growth industry
as America gets older - as well as spinal implants for injuries and disease. Stryker is not cheap, but profits have
risen impressively and consistently.

Hospitals have not been a good business in recent years as profitable surgical and diagnostic procedures (such as
knee replacements and colonoscopies) have migrated to outpatient centers.

                                                                                                          Page 2 of 2
                                             A case for health care stocks

But HCA Healthcare (HCA) owns both traditional hospitals and freestanding surgical, urgent care and rehab
facilities. HCA has also managed to keep costs under control at a time when shortages of nurses and other staff are
pushing expenses up elsewhere.

Probably the best health care business is insurance, and the best company in that subsector is UnitedHealth Group
(UNH). United also owns a pharmacy benefit manager called Optum Rx, which negotiates with drug companies on
prices and takes a cut.

My favorite mutual fund in the sector is Fidelity Select Health Care Services (FSHCX), which has UnitedHealth as
its largest holding.

Artificial intelligence has the potential to transform a sector that has been notoriously inefficient, but at this point,
most AI-focused health care firms are still private. One that isn't is Augmedix (AUGX), with a market capitalization
(shares outstanding times price) of just over $200 million.

The firm's software extracts data from conversations between physicians and patients and immediately turns it into
medical notes. The notes are then transferred to the electronic record systems of health care providers, saving time
and money. Augmedix, which went public in March 2021, is a risky stock with a big potential payoff but a potentially
serious downside, too.


Load-Date: November 19, 2023


  End of Document

                                                                                                           Page 1 of 2
                        National Science Foundation launches artificial intelligence center at Duke




  National Science Foundation launches artificial intelligence center at Duke
                                             The Duke Chronicle: Duke University
                                                      August 17, 2021 Tuesday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 385 words
Byline: Violet Wang

Body


The National Science Foundation has announced the creation of an artificial intelligence research center at Duke.

The AI Institute for Edge Computing Leveraging Next-generation Networks-Athena for short-will be supported
through a $20 million grant and five-year development plan from NSF and the Department of Homeland Security.
The initiative is positioned to reshape the design, service, and operation of mobile systems.

Yiran Chen, professor in the department of electrical and computer engineering, will serve as the director of Athena
and principal investigator for the grant.

"Athena is a big milestone of Duke AI initiatives through transforming the research landscape in AI-driven
computing technology," Chen said. "It will greatly benefit other relevant efforts such as AI health, education [and]
data science by developing foundational AI technologies to advance their theoretical basis and use-inspired
computing and network platforms to support the applications."

The NSF investment towards the center makes it one of 11 new research institutes focused on artificial intelligence,
for a total of $220 million in grants. Athena will support a group of scientists, engineers, statisticians, legal scholars
and psychologists from seven universities, including Duke, Massachusetts Institute of Technology, Yale, Princeton,
University of Wisconsin at Madison, University of Michigan and North Carolina Agricultural and Technical State
University.

Chen noted that Athena is committed to development in education and will "cultivate a diverse next generation of
mobile network leaders with the core values of ethics and fairness for AI."

Shaundra Daily, professor of the practice in the department of electrical and computer engineering, will serve as the
Athena education and workforce director. She said that the team will introduce hands-on opportunities through
summer camps, industry tours and ethics training.

"We also will have a very intentional focus on broadening participation of groups who are historically not
represented in the field of AI," Daily said. "I think our team is well positioned to not only push the novel research

                                                                                                    Page 2 of 2
                    National Science Foundation launches artificial intelligence center at Duke

proposed forward, but also to make sure that we have a broad spectrum of identities bringing their thoughts, ideas
and abilities to the table to solve important challenges."


Load-Date: August 17, 2021


  End of Document

                                                                                                        Page 1 of 2
                                                   A case for health care stocks




                                          A case for health care stocks
                                                          The Morning Call
                                                    November 20, 2023 Monday
                                                            FIRST Edition



Copyright 2023 Capital Gazette Communications, Inc. All Rights Reserved

Section: MAIN; A; Pg. 9
Length: 529 words
Byline: James K. Glassman Kiplinger's Personal Finance
Highlight: Everydayplus/Dreamstime

Body


Health care stocks have had a rough few years. So why invest in them?

First, I'm a contrarian. I like what's down. Second, health care is a booming industry, accounting for 18% of gross
domestic product in 2021, up from 12% in 1991. Third, the sector adds stability to any portfolio.

It stands to reason that health care is less volatile than other sectors. After all, in both good times and bad, people
get sick and need the services of hospitals, pharmaceutical makers, drugstores, health insurers, medical device
manufacturers and the whole apparatus of health care.

Pharmaceutical companies tend to dominate health care mutual funds and ETFs. That has been a problem. S&P's
pharmaceutical index has lost an annual average of close to 2% over the past five years, compared with an
annualized gain of 11% for the S&P 500 as a whole. Drug companies also are unpopular with the public, and they
have become a political target of both parties.

As an alternative to drug stocks, look at stocks such as Kenvue (KVUE), which Johnson & Johnson earlier this year
spun off as a separate company. (With the spin-off, J&J agreed to retain all liabilities related to lawsuits over its
talcum powder and to indemnify Kenvue.)

Kenvue has an impressive portfolio of over-the-counter medicines, such as Tylenol, Sudafed and Benadryl, plus
other consumer brands (Band-Aid, Listerine and Neutrogena). The stock has dropped since its spring debut.

Another non-pharmaceutical choice is Stryker (SYK), which makes knee and hip replacements - a growth industry
as America gets older - as well as spinal implants for injuries and disease. Stryker is not cheap, but profits have
risen impressively and consistently.

Hospitals have not been a good business in recent years as profitable surgical and diagnostic procedures (such as
knee replacements and colonoscopies) have migrated to outpatient centers.

                                                                                                          Page 2 of 2
                                             A case for health care stocks

But HCA Healthcare (HCA) owns both traditional hospitals and freestanding surgical, urgent care and rehab
facilities. HCA has also managed to keep costs under control at a time when shortages of nurses and other staff are
pushing expenses up elsewhere.

Probably the best health care business is insurance, and the best company in that subsector is UnitedHealth Group
(UNH). United also owns a pharmacy benefit manager called Optum Rx, which negotiates with drug companies on
prices and takes a cut.

My favorite mutual fund in the sector is Fidelity Select Health Care Services (FSHCX), which has UnitedHealth as
its largest holding.

Artificial intelligence has the potential to transform a sector that has been notoriously inefficient, but at this point,
most AI-focused health care firms are still private. One that isn't is Augmedix (AUGX), with a market capitalization
(shares outstanding times price) of just over $200 million.

The firm's software extracts data from conversations between physicians and patients and immediately turns it into
medical notes. The notes are then transferred to the electronic record systems of health care providers, saving time
and money. Augmedix, which went public in March 2021, is a risky stock with a big potential payoff but a potentially
serious downside, too.


Load-Date: November 20, 2023


  End of Document

                                                                                                        Page 1 of 2
                                                 A case for health care stocks




                                         A case for health care stocks
                                                       The Baltimore Sun
                                                  November 19, 2023 Sunday
                                                    AdvanceBulldog Edition



Copyright 2023 The Baltimore Sun Company All Rights Reserved

Section: MAIN; A; Pg. 3
Length: 529 words
Byline: James K. Glassman Kiplinger's Personal Finance
Highlight: Everydayplus/Dreamstime

Body


Health care stocks have had a rough few years. So why invest in them?

First, I'm a contrarian. I like what's down. Second, health care is a booming industry, accounting for 18% of gross
domestic product in 2021, up from 12% in 1991. Third, the sector adds stability to any portfolio.

It stands to reason that health care is less volatile than other sectors. After all, in both good times and bad, people
get sick and need the services of hospitals, pharmaceutical makers, drugstores, health insurers, medical device
manufacturers and the whole apparatus of health care.

Pharmaceutical companies tend to dominate health care mutual funds and ETFs. That has been a problem. S&P's
pharmaceutical index has lost an annual average of close to 2% over the past five years, compared with an
annualized gain of 11% for the S&P 500 as a whole. Drug companies also are unpopular with the public, and they
have become a political target of both parties.

As an alternative to drug stocks, look at stocks such as Kenvue (KVUE), which Johnson & Johnson earlier this year
spun off as a separate company. (With the spin-off, J&J agreed to retain all liabilities related to lawsuits over its
talcum powder and to indemnify Kenvue.)

Kenvue has an impressive portfolio of over-the-counter medicines, such as Tylenol, Sudafed and Benadryl, plus
other consumer brands (Band-Aid, Listerine and Neutrogena). The stock has dropped since its spring debut.

Another non-pharmaceutical choice is Stryker (SYK), which makes knee and hip replacements - a growth industry
as America gets older - as well as spinal implants for injuries and disease. Stryker is not cheap, but profits have
risen impressively and consistently.

Hospitals have not been a good business in recent years as profitable surgical and diagnostic procedures (such as
knee replacements and colonoscopies) have migrated to outpatient centers.

                                                                                                          Page 2 of 2
                                             A case for health care stocks

But HCA Healthcare (HCA) owns both traditional hospitals and freestanding surgical, urgent care and rehab
facilities. HCA has also managed to keep costs under control at a time when shortages of nurses and other staff are
pushing expenses up elsewhere.

Probably the best health care business is insurance, and the best company in that subsector is UnitedHealth Group
(UNH). United also owns a pharmacy benefit manager called Optum Rx, which negotiates with drug companies on
prices and takes a cut.

My favorite mutual fund in the sector is Fidelity Select Health Care Services (FSHCX), which has UnitedHealth as
its largest holding.

Artificial intelligence has the potential to transform a sector that has been notoriously inefficient, but at this point,
most AI-focused health care firms are still private. One that isn't is Augmedix (AUGX), with a market capitalization
(shares outstanding times price) of just over $200 million.

The firm's software extracts data from conversations between physicians and patients and immediately turns it into
medical notes. The notes are then transferred to the electronic record systems of health care providers, saving time
and money. Augmedix, which went public in March 2021, is a risky stock with a big potential payoff but a potentially
serious downside, too.


Load-Date: November 19, 2023


  End of Document

                                                                                                        Page 1 of 2
                                                  A case for health care stocks




                                         A case for health care stocks
                                                      The Hartford Courant
                                                  November 19, 2023 Sunday
                                                             1 Edition



Copyright 2023 The Hartford Courant Company All Rights Reserved

Section: LOCAL; B; Pg. 7
Length: 529 words
Byline: James K. Glassman Kiplinger's Personal Finance
Highlight: Everydayplus/Dreamstime

Body


Health care stocks have had a rough few years. So why invest in them?

First, I'm a contrarian. I like what's down. Second, health care is a booming industry, accounting for 18% of gross
domestic product in 2021, up from 12% in 1991. Third, the sector adds stability to any portfolio.

It stands to reason that health care is less volatile than other sectors. After all, in both good times and bad, people
get sick and need the services of hospitals, pharmaceutical makers, drugstores, health insurers, medical device
manufacturers and the whole apparatus of health care.

Pharmaceutical companies tend to dominate health care mutual funds and ETFs. That has been a problem. S&P's
pharmaceutical index has lost an annual average of close to 2% over the past five years, compared with an
annualized gain of 11% for the S&P 500 as a whole. Drug companies also are unpopular with the public, and they
have become a political target of both parties.

As an alternative to drug stocks, look at stocks such as Kenvue (KVUE), which Johnson & Johnson earlier this year
spun off as a separate company. (With the spin-off, J&J agreed to retain all liabilities related to lawsuits over its
talcum powder and to indemnify Kenvue.)

Kenvue has an impressive portfolio of over-the-counter medicines, such as Tylenol, Sudafed and Benadryl, plus
other consumer brands (Band-Aid, Listerine and Neutrogena). The stock has dropped since its spring debut.

Another non-pharmaceutical choice is Stryker (SYK), which makes knee and hip replacements - a growth industry
as America gets older - as well as spinal implants for injuries and disease. Stryker is not cheap, but profits have
risen impressively and consistently.

Hospitals have not been a good business in recent years as profitable surgical and diagnostic procedures (such as
knee replacements and colonoscopies) have migrated to outpatient centers.

                                                                                                          Page 2 of 2
                                             A case for health care stocks

But HCA Healthcare (HCA) owns both traditional hospitals and freestanding surgical, urgent care and rehab
facilities. HCA has also managed to keep costs under control at a time when shortages of nurses and other staff are
pushing expenses up elsewhere.

Probably the best health care business is insurance, and the best company in that subsector is UnitedHealth Group
(UNH). United also owns a pharmacy benefit manager called Optum Rx, which negotiates with drug companies on
prices and takes a cut.

My favorite mutual fund in the sector is Fidelity Select Health Care Services (FSHCX), which has UnitedHealth as
its largest holding.

Artificial intelligence has the potential to transform a sector that has been notoriously inefficient, but at this point,
most AI-focused health care firms are still private. One that isn't is Augmedix (AUGX), with a market capitalization
(shares outstanding times price) of just over $200 million.

The firm's software extracts data from conversations between physicians and patients and immediately turns it into
medical notes. The notes are then transferred to the electronic record systems of health care providers, saving time
and money. Augmedix, which went public in March 2021, is a risky stock with a big potential payoff but a potentially
serious downside, too.


Load-Date: November 19, 2023


  End of Document

                                                                                                  Page 1 of 2
         Home State Health and Babylon Partner to Bring App-based, 24/7 Healthcare to Southeast Missouri




Home State Health and Babylon Partner to Bring App-based, 24/7 Healthcare
                         to Southeast Missouri
                                     The Griffon News: Missouri Western State College
                                                      January 11, 2021 Monday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: SEARCH; Pg. 1
Length: 767 words

Body


ST. LOUIS, Jan. 11, 2021 /PRNewswire/ -- Home State Health has partnered with Babylon, a technology and
healthcare company, to deliver additional access to primary care to health plan members living in 10 counties in
Southeast Missouri. Through the partnership, Babylon will serve as the Primary Care Physician via its mobile
application-based telehealth platform. Home State Health members assigned to Babylon will have access to their
PCP through their smartphone any time, day or night.

"At Home State Health, we meet our members where they are and remove barriers which have prevented them
from receiving care," said Nathan Landsbaum, President and CEO, Home State Health. "By working with Babylon,
we are able to bring the latest technology and innovation in patient care directly to our Medicaid members living in
rural areas of Missouri."

Home State Health members will be supported by a 20-person interdisciplinary Babylon care team including nurses
and community health workers. They will help ensure continuity of care and guide members through their
healthcare journey. Patients can log their symptoms, have remote consultations and check-in calls, manage chronic
conditions, and access health history - all without leaving their homes. The virtual care option aligns with current
COVID-19 recommendations to limit travel and contact, while reducing wait times for appointments and urgent care
matters. However, if an in-person visit is needed, the Babylon care team can also help connect Home State Health
members with community resources that provide services like transportation for an appointment.

"On behalf of the Babylon team, I am honored to have the opportunity to partner with Home State Health to offer
Missourians a personalized, end-to-end, and human-centric care experience," said Dr. Ali Parsa, Founder, Babylon.
"There has never been a greater need for a digital healthcare solution that can go directly to the source; meeting
patients exactly where they are and when they need care most."

Babylon's services for the program in Southeast Missouri will be available to Home State Health members living in
Bollinger, Butler, Cape Girardeau, Dunklin, Mississippi, New Madrid, Pemiscot, Wayne, Scott, and Stoddard
counties. Babylon has started outreach to Home State Health members that have been assigned to them.

Home State Health members with questions about telehealth options should call (855) 694-HOME (4663). TTY
711.

                                                                                                Page 2 of 2
       Home State Health and Babylon Partner to Bring App-based, 24/7 Healthcare to Southeast Missouri

About Home State Health

Home State Health is a Care Management Organization that serves the needs of Missourians through a range of
health insurance solutions. Home State Health serves the Medicaid population in partnership with MO HealthNet.
The organization also focuses on under-insured and uninsured individuals by performing operations for Ambetter, a
federal insurance marketplace product, underwritten by Celtic Insurance (an affiliated company). Additionally, Home
State Health provides insurance for the Medicare population through a Medicare Advantage plan, Allwell. Home
State Health exists to improve the health of its members through focused, compassionate and coordinated care.
Home State Health is owned by a joint venture of Centene Corporation and Missouri Community Health Access.
Centene Corporation, is a diversified, multi-national healthcare enterprise. For more information,
visit www.homestatehealth.com.

About Babylon

Babylon is a global-leading technology and healthcare company with the ambitious mission to put an accessible
and affordable health service in the hands of every person on Earth.

We combine technology and medical expertise to bring doctors and people closer together, with digital healthcare
tools designed to empower people with knowledge about their health. Through a range of digital health services -
such as AI-backed digital health tools and video doctor appointments - we give people around-the-clock access to
affordable, holistic healthcare services. We work with governments, health providers and insurers across the globe,
and support healthcare facilities from small local practices to large hospitals.

Babylon covers 20 million people across the globe, and has delivered more than 8m virtual consultations and AI
interactions. We have teamed up with 170 impactful worldwide partners - including Mount Sinai Health Partners,
the NHS, Telus Health, the Bill & Melinda Gates Foundation and the Government of Rwanda - to fulfill our vision of
accessible and affordable healthcare, for all. For more information, visit https://www.babylonhealth.com/us.



This article originally ran on curated.tncontentexchange.com.


Load-Date: January 11, 2021


  End of Document

                                                                                                      Page 1 of 1
                                        Arunachal Pradesh gets second Yolo Health ATM




                         Arunachal Pradesh gets second Yolo Health ATM
                                                              The Sentinel
                                                       May 5, 2021 Wednesday



Copyright 2021 Omega Printers & Publishers Pvt Ltd, distributed by Contify.com All Rights Reserved

Length: 273 words
Byline: Our Correspondent

Body


ITANAGAR: The second of its kind -- Yolo Health ATM -- in Arunachal Pradesh was inaugurated at the Changlang
district hospital by Deputy Speaker of Arunachal Pradesh Legislative Assembly TesamPongte on Monday. It was
unveiled in the presence of Deputy Commissioner DrDevanshYadav, members of medical fraternity among others.

Yolo Health is a technology venture, pioneering in the field of health IoT. It primarily focuses on building remote
health monitoring and telemedicine applications.

Yolo Health has built its flagship product 'Health ATM', which combines instant diagnostics and telemedicine into
one integrated platform. It is an aggregation of USFDA/CE certified medical IVD devices and cloud-connected
backend. It enables paramedical professionals to diagnose several health parameters and diseases, bringing
technology enabled primary and preventive healthcare services near to the masses.

The system has a high-resolution camera and touch screen based kiosk and checked more than 40 health
parameters in a few minutes. Besides having option to integrate various invasive IVD devices, it has also integrated
medicine dispenser besides several AI-enabled health checkup solution.

The Health ATM is an aggregation of USFDA/CE certified medical IVD devices combined with HIPAA compliant
software backend. It enables paramedical professionals to diagnose several health parameters and diseases,
solving the problem of primary and preventive healthcare service in rural and remote areas. It is also a cloud
connected platform that enables telemedicine. It comes with an integrated doctor consultation platform with doctor
and patient login.


Load-Date: May 6, 2021


  End of Document

                                                                                                       Page 1 of 2
                             NSF grant funding to support health monitoring system for elderly




         NSF grant funding to support health monitoring system for elderly
                                  The New Voice: University of North Carolina - Charlotte
                                                      April 26, 2022 Tuesday



University Wire
Copyright 2022 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 343 words

Body


A pair of interdisciplinary researchers from architecture and engineering recently received a grant from the National
Science Foundation to use artificial intelligence to improve health care among the elderly.

The funding of $255,992 is through a Small Business Technology Transfer Phase I grant, designed to assist
researchers transform scientific discoveries into commercial products.

Mona Azarbayjani, associate professor of architecture, and Hamed Tabkhi, assistant professor of electrical and
computer engineering, are collaborating on the project, "Camera-Based Multimodal AI for Health Monitoring." Their
goal is to use cutting-edge technology to improve the care of older people in both home and institutional
environments.

Mohammadreza Baharani, an engineering postdoctoral fellow, and Ph.D. candidate Roshanak Ashrafi also are
members of this research team whose investigations with several of the University's areas of research excellence:
cybersecurity and artificial intelligence, smart and sustainable cities and urban health.

According to census data, in the next decade one of every five Americans will be 65 or older, and by 2034, the
elderly will outnumber children for the first time in census history. At the same time, the number of health care
workers is dwindling - particularly home health aides and nursing home attendants, and the industry is experiencing
a dire shortage.

According to the researchers, their remote patient monitoring project will enable holistic, accurate and faster
monitoring of elderly people that will improve their quality of life and health; address the future nursing shortage,
particularly in the geriatric field; and reduce health care costs.

Azarbayjani and Tabkhi both work in the interdisciplinary Infrastructures and Environmental Systems program. They
began their partnership three years ago with research into "smart building" technology that can monitor occupants'
body temperatures from a distance, without the need for direct person-to-person contact.

Read more on the College of Arts + Architecture website.

                                                                                           Page 2 of 2
                       NSF grant funding to support health monitoring system for elderly


Load-Date: April 27, 2022


  End of Document

                                                                                                            Page 1 of 3
                   Apple , Fitbit should use all that data they collect from you to protect public health




 Apple, Fitbit should use all that data they collect from you to protect public
                                     health
                                                        USA Today Online
                                                        December 26, 2022



Copyright 2022 Gannett Media Corp All Rights Reserved

Section: APPS NEWS & PUBLIC HEALTH NEWS
Length: 1136 words
Byline: Douglas Yeung

Body


The marketing for the Apple Watch says it all: “A healthy leap ahead.” “Here’s to a healthier you.” “The future of
health never looked so good.” The Apple Watch, like countless other digital health apps and wearables, is selling
itself with an implicit promise of individual empowerment: that we can use this health information to take specific
actions – exercising so that your heart rate reaches a certain elevated threshold, for example – that will lead to
better health.

But in pitching and promising health to the individual, companies that make apps and wearables, and the
customers who buy them, are focusing on the trees – and missing the rest of the forest.

In truth, we have less control over our own health than we like to think. In fact, our health is heavily influenced by
our surroundings – including the health of the people around us. What this might mean for the ever-growing market
of wearables is a new focus beyond the individual, to those in their household, their friends, even their whole
community.

Mapping exercises – or diseases

By incorporating social and community factors, digital health products could better capture what goes into public
health. Communitywide data from fitness trackers and other digital data already feed into some public health
models.

Fitbit publishes reports that show, for example, communities where people exercise the most. Cellphone location
data is sometimes used to map disease outbreaks. These models and their underlying datasets could prove to be a
boon to those people and agencies responsible for protecting and improving all of our health.

COVID isn't over: How to help everyone, everywhere endure the next stage.

Enabling scientists: Why we're investing $150 million to unite biology and AI

                                                                                                          Page 2 of 3
                 Apple , Fitbit should use all that data they collect from you to protect public health

Aggregated health data that reflects communitywide factors has for centuries now aided public health practitioners,
allowing them to make seemingly simple improvements that nonetheless greatly impact people’s lives.

Returning home from the hospitals of the mid-19th century Crimean War filled with sick and injured British soldiers,
Florence Nightingale sought to use data she had meticulously collected to demonstrate the impact that community
factors had on soldiers’ health. Nightingale famously employed powerful graphics to convince Britain’s leaders that
measures to improve sanitation – such as cleaning the air water, and sewer systems – could prevent disease and
dramatically decrease deaths.

The world still faces enormous public health challenges, including the ongoing COVID-19 pandemic. But we also
have new cards to play, like the vast repositories of health sensor data and powerful artificial intelligence
techniques that can help us make sense of it.

Using these tools to improve health devices and apps could be a major opportunity to tackle these massive
challenges.

Early warning system for suicides

Among the most troubling recent public health concerns is the teen mental health crisis. Seeking to address rising
suicides, a Harvard-led research project pools health data from many people and uses artificial intelligence to make
it more useful, like combining smartphone and Fitbit data to understand indicators of suicide.

The hope is that marrying AI and health sensor data could help build an early warning system for people at risk of
suicide.

For now, this research remains academic. And a major challenge is that suicide is still relatively rare, generating
little data that algorithms can use to make predictions. But like many other health events, suicide risk doesn’t occur
in a vacuum.

You can talk about suicidal thoughts: USA TODAY editor shares advice after her mother's death by suicide

Former U.S. surgeon general: Our mental health crisis is getting worse. New 988 suicide hotline can be our fresh
start.

Suicides might seem like isolated acts, but they often occur in clusters – what researchers call suicide contagion.
What if suicide prediction algorithms, like the one being built at Harvard, could incorporate a social element from
health sensor data like your friend network?

Digital health products could feed into social network algorithms that help identify when people need mental health
resources. A wearable that tracks your mood and sleep might intervene based on those metrics. But a social-
enabled algorithm might be able to go several steps further, recognizing troubling trends among one’s close
contacts – such as social media posts suggesting self-harm, and thus when someone might themselves be at
greater risk for suicide.

Privacy concerns

There are, to be sure, many hurdles to using social and community data in digital health products. Some users may
have privacy concerns about sharing data with companies or public health agencies.

Overcoming these hurdles could involve developing open source standards for transparency about data
management, or ensuring that people can control when, and with which agencies, to share personal data.

Public health agencies: Why are Americans confused about COVID? Blame it on poor communication.

'Something has to change': Health care workers who cared for us during COVID are burning out

                                                                                                             Page 3 of 3
                    Apple , Fitbit should use all that data they collect from you to protect public health

Even so, the opportunity remains too great to ignore. Although digital health products can, and already do, benefit
individuals, by far the greatest benefits could one day come when these products operate in tandem with
information about the community and beyond the individual.

Opinion alerts: Get columns from your favorite columnists + expert analysis on top issues, delivered straight to
your device through the USA TODAY app. Don't have the app? Download it for free from your app store.

Now, it is likely a wealthier and thus an already healthier set of people that tend to purchase digital health products.
This fits a historical pattern, where new technologies like computers cater to select individuals, only later expanding
to serve broader communities.

For digital health companies to credibly claim to improve people’s health – to truly, as they promise, become “the
future of health” – their next step could be an increased willingness to look beyond an individualized notion of
health and to work with public health agencies.

In doing so, digital health products stand to benefit a far greater swath of society, even those who aren’t wearing
wearables.

Link to Image

Douglas Yeung, a senior behavioral scientist at the nonprofit, nonpartisan RAND Corporation, is a faculty member
of the Pardee RAND Graduate School.

You can read diverse opinions from our Board of Contributors and other writers on the Opinion front page, on
Twitter @usatodayopinion and in our daily Opinion newsletter. To respond to a column, submit a comment to
letters@usatoday.com .

This article originally appeared on USA TODAY: Apple, Fitbit should use all that data they collect from you to
protect public health


Load-Date: December 26, 2022


  End of Document

                                                                                                        Page 1 of 2
                         2022 Underwriters Laboratories-ASEAN- U.S. Science Prize for Women




     2022 Underwriters Laboratories-ASEAN-U.S. Science Prize for Women


                                                       ASEAN Tribune
                                                   January 10, 2022 Monday



Copyright 2022 ASEAN Tribune All Rights Reserved




Length: 575 words

Body


 10 January 2022 (U.S. Mission to ASEAN) Today, the Association of Southeast Asian Nations (ASEAN)
Committee on Science, Technology, and Innovation (COSTI), in partnership with the U.S. government, through the
U.S. Agency for International Development (USAID), and Underwriters Laboratories, launched the call for
applications for the eighth annual Science Prize for Women competition.

The 2022 competition aims to raise awareness on cutting edge advancements by women in Artificial Intelligence
(AI) research addressing pressing issues in ASEAN communities. Candidates working in Science, Technology,
Engineering, Mathematics (STEM) fields will compete in one of two categories, mid-career scientist and senior
scientist, over the next several months. Underwriters Laboratories, a U.S.-based, non-profit organization dedicated
to the discovery and application of scientific knowledge, will award $12,500 to each category winner and $5,000
each to the runner-up finalists.

The theme Artificial Intelligence (AI) in Health and Safety underpins this year's competition, which can play an
important role in delivering better and more affordable healthcare services to over 660 million ASEAN citizens. In
addition, robust AI applications can strengthen environmental safety in the workplace, bolster security of industry
processing systems, and help address COVID-19 pandemic recovery efforts to deter future epidemics.

'Underwriters Laboratories continues to proudly support the work of women scientists in the ASEAN region through
the science prize,'' said Dr. Christopher J. Cramer, Underwriters Laboratories Senior Vice President and Chief
Research Officer. 'We especially appreciate the opportunity to recognize these extraordinary scientists as they
strive to harness the promise of artificial intelligence to safely and equitably garner long-term health and economic
benefits for communities in the region.'

'The United States is proud to promote, along with ASEAN and Underwriters Laboratories, women scientists that
capitalize on artificial intelligence solutions to counter the region's environmental, health, and safety challenges,'
said Rachel Cooke, Chargé d'Affaires, a.i. of the U.S. Mission to ASEAN. 'Through USAID's continued support for
this successful annual competition, the United States reaffirms its commitment to close gender gaps so that more
women can help shape advancements in STEM fields.'

                                                                                                       Page 2 of 2
                      2022 Underwriters Laboratories-ASEAN- U.S. Science Prize for Women

ASEAN COSTI Chair and Deputy Minister of Science and Technology of Vietnam, H.E. Mr. Bui The Duy, conveyed
that, 'Research and work in AI by talented women scientists of the region will not only benefit the local communities
but will more importantly enable replication that will improve millions of lives within the region.'

Since 2014, the Science Prize for Women represents an ongoing successful U.S. initiative in support of ASEAN and
its 10 member states. As part of the U.S. strategic approach to the Indo-Pacific, USAID partners with ASEAN to
promote prosperity and security through economic inclusion, women's empowerment, and good governance.

To learn more about this year's competition and the application process, prospective applicants are encouraged to
visit the Underwriters Laboratories-ASEAN-U.S. Science Prize for Women website. The application deadline is
March 18, 2022.

For further queries related to the contest, applicants can email scienceprize4women@gmail.com and for public
outreach, contact jakartausaidasean@usaid.gov


Load-Date: January 11, 2022


  End of Document

                                                                                                      Page 1 of 2
                                     Local woman awarded Pillars of Strength Scholarship




                     Local woman awarded Pillars of Strength Scholarship
                                              The Gallup Independent (New Mexico)
                                                    October 4, 2023 Wednesday



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 The Gallup Independent.

Section: NEWS; Pg. 1
Length: 534 words

Body


ADELPHI, Md. - A Thoreau resident was awarded a scholarship to the University of Maryland Global Campus that
recognizes volunteer caregivers of veterans. Thoreau resident Lyra Helms has been awarded the Pillars of Strength
Scholarship to attend the University of Maryland Global Campus. The scholarship program includes full tuition and
fees. It recognizes the sacrifices of volunteer caregivers of wounded, ill or injured service members.

A news release from UMGC shared that those who receive the scholarship have devoted years of their lives to
caring for their loved ones, but receive few, if any, federal education benefits. Many of them are the main family
earners. Dedication, courage and sacrifice The release said Helms exemplifies the dedication, courage and
sacrifice of volunteer caregivers. She has worked in health care for nearly a decade and has been an advocate for
the military veterans community - a commitment that dovetails with the support she has provided her fiance, who
served in the Army.

Helms' advocacy work grew out of watching the experiences of friends, relatives and others in her life who have
served in the military and experienced combat.

"Veterans are an underserved population in terms of mental health resources and support assimilating back to
civilian life," Helms said.

Helms said her time as a fellow with the Elizabeth Dole Foundation, an advocacy group for veteran caregivers,
provided her with many resources to help advocate for veterans and their loved ones. "So many people are
unaware of the help available to them," she explained.

Her fiance, Adam Griego, served in the Army 1st Battalion as part of the 23rd Infantry Regiment nicknamed the
"Tomahawks." He deployed to Iraq and Afghanistan, earning a Purple Heart after combat in Panjwai, Afghanistan.

"Adam is of great support to his veteran peers," Helms said. "We both work together to help our friends navigate the
day-to-day after leaving military life." 'Anything is possible' Helms has a master's degree in occupational therapy
from the University of New Mexico. As an occupational therapist, she has been able to provide care to patients
across the lifespan, ranging from infants to elderly. She has transitioned from direct patient care to health care
leadership. She currently works as the director of personal care for Corus Health in Albuquerque, where she strives
to provide quality caregiving support for members of the community. Helms' new aspiration is to work at the

                                                                                                        Page 2 of 2
                               Local woman awarded Pillars of Strength Scholarship

intersection of healthcare and cybersecurity. She is interested in the role cybersecurity will play in healthcare as
technology develops. She is looking forward to using her healthcare experience with service members to help
shape that future. She plans to use her Pillars scholarship to pursue a master's degree in cybersecurity
management and policy.

"I am excited to see how I can connect cybersecurity to health care," she said. "AI [artificial intelligence] is
advancing so rapidly, and it will change our healthcare system as we know it." "As an advocate for caregivers," Lyra
said, "I will [also] speak of the Pillars program with my firsthand experience to create buy-in and understanding that
anything is possible."



Graphic


Lyra Helms. Vida Volkert/Independent A throng of riders arrive to the Yei Bi Chei grounds during the Northern
Navajo Nation Fair in October 2018. Participants will be again riding to this year's ceremony Friday.


Load-Date: October 5, 2023


  End of Document

                                                                                                       Page 1 of 3
                                            Create introductory AI flag requirement




                                Create introductory AI flag requirement
                                        The Daily Texan: University of Texas - Austin
                                                      March 5, 2023 Sunday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 730 words

Body


We live in an era in which artificial intelligence can complete highly complex tasks. From writing a Petrachan sonnet
about the Hobbesian state of nature to detecting and classifying geological features on planets and moons, AI is no
longer science fiction. Rather, AI permeates every aspect of our lives.

The need for a workforce equipped with AI knowledge is crucial. UT evidently understands this demand, as they
recently implemented an online AI master's degree. But undergraduate-level AI classes remain exclusive to
computer science majors. Other majors should have the opportunity to develop career skills in AI.

UT should provide access to AI education across the student body. Creating an introductory AI flag requirement
could increase AI enthusiasm and allow students to better understand its trends, benefits and global impacts.

Undeclared sophomore Anmol Sandhu explained she has limited knowledge about AI's workings, but teaching
everyone about AI can dispel fears of an AI-dominated world.

Read more Texan opinion:

In light of pause on DEI efforts, students, faculty must seek solidarity

COUNTERPOINT: Eliminate foreign language requirements

POINT: Importance of language classes

Closing laptops opens minds

"I have the bare minimum (knowledge) about the backgrounds of AI," Sandhu said. "I feel like (AI is) something
everyone should know a little about. ... AI is everywhere and can be scary. If you know the facts about it at the
present, it won't be as scary in the (future)."

Dr. Peter Stone, Robotics Consortium Director and a founding member of the Good Systems initiative, elaborated
on why AI literacy is vital.

                                                                                                      Page 2 of 3
                                         Create introductory AI flag requirement

"Having somebody who is grounded in what's realistic and possible with AI programs and about the different types
of algorithms, approaches and models. ... As AI programs influence many sectors of the economy, I think it's going
to be more essential that people have some kind of AI literacy," Dr. Stone said.

Dr. Stone also explained how certain graduate-level AI courses could be adapted to the undergraduate-level as
introductory AI courses.

"I think the (graduate) class I co-taught ... and the syllabus we put together would work pretty well as an
undergraduate class," Dr. Stone said. "There was a programming component to the course, but if you get rid of that,
the course readings we assigned, and the topics we covered, would be a good introductory course for a broad set
of students."

An introductory-level course that fulfills an AI flag requirement could contain AI overviews, applications of
knowledge-based technologies, ethical implications and beginner programming concepts. Such courses could
additionally be tailored to specific majors. For example, a psychology student could enroll in a class about AI
revolutionizing mental health diagnoses, while a marketing major could take a class on algorithmic targeting
campaigns.

Conrad Li, a computer science senior and the founder of Engineering and Computational Learning of Artificial
Intelligence in Robotics, sees a future where AI classes are a standardized core requirement. He believes an
introductory AI course should also be redesigned for students who lack advanced math skills.

"The courses need to be designed so that (students) with a high school algebra level can understand it," Li said. "I
mean, in the future, I could definitely see (AI classes) as a core requirement... It's going to be more prevalent in
society as technology progresses."

UT has a responsibility to its students to prepare them for an AI-dominated future and give them a competitive
career edge. An AI flag requirement across majors could allow all students to access AI education and gain a
deeper and more nuanced understanding of its role in our lives.

Muyeed is an economics sophomore from Southlake, Texas.

Read Next

In light of pause on DEI efforts, students, faculty must seek solidarity

COUNTERPOINT: Eliminate foreign language requirements

POINT: Importance of language classes

Closing laptops opens minds

About the Contributors

Meredith Roberts, Opinion Illustrator

Meredith is a sophomore radio-television-film and journalism double major from Dallas, Texas. She has been an
opinion illustrator and videographer...

Aruna Muthupillai, Opinion Illustrator

Aruna is a Plan II Honors and International Relations freshman from Pearland, TX. Currently, she works as an
opinion illustrator. Outside of working for...


Load-Date: March 5, 2023

                                                            Page 3 of 3
                  Create introductory AI flag requirement


End of Document

                                                                                                        Page 1 of 11
                            Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges




      Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges
                                                             R Street Institute
                                                      December 5, 2022 Monday



Copyright 2022 Content Engine, LLC.
All Rights Reserved
Copyright 2022 R Street Institute, USA All Rights Reserved

Length: 6727 words
Byline: Adam Thierer

Body

From Medium [1]:
Many books and reports have been written about the nature and history of artificial intelligence and machine
learning technologies.[1] This brief survey offers some basic definitions and highlights the promise of these
technologies, as well as some of the unique policy challenges they create. This document will be updated regularly
to reflect the latest developments in this rapidly evolving field. A PDF of this document can also be found on
SSRN.[2]

Definitional Difficulties Complicate AI Governance

Defining the nature and scope of artificial intelligence is notoriously tricky and this is the first of many factors
complicating its governance. The Stanford Encyclopedia of Philosophy speaks of the "remarkably difficult, maybe
even eternally unanswerable" questions involved in formulating a consensus definition for AI.[3] "There is no single
universally accepted definition of AI, but rather differing definitions and taxonomies," a U.S. Government
Accountability Office report concludes.[4]

At the most basic level, however, artificial intelligence involves the exhibition of intelligence by a machine. Machine
learning refers to the processes by which a computer can train and improve an algorithm or computer model without
step-by-step human involvement. An algorithm is "similar to a recipe for a dish," notes computer scientist Ethem
Alpaydin, in that it is "a sequence of instructions that are carried out to transform the input to the output."[5] More
simply, an algorithm is a "set of instructions that describe the way to solve particular problems."[6] When people
speak of regulating AI or ML, at root, they are really suggesting the need to control algorithms and algorithmic
processes because they are at the heart of all machine learning. Moreover, because AI and ML are computational
sciences, to regulate them means at some level we are regulating computing and mathematical modeling
techniques. These realities also complicate AI governance.

The effectiveness of most AI/ML tools depends upon enormous computing power (or compute for short), large data
sets (so-called big data), and powerful computational analysis tools that power deep learning models and other AI
learning methods.[7] These building blocks of AI, especially big data, raise policy issues in their own right,
especially on privacy and data security grounds. Indeed, many of today's AI governance discussions are simply
extensions of policy debates that have been going on for many years in big data circles.[8]

                                                                                                       Page 2 of 11
                       Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges

Finally, so-called foundational models, which are "models trained on broad data... that can be adapted to a wide
range of downstream tasks,"[9] are capturing great attention today because they can be widely used by the public
for various tasks. Popular foundational models like DALL-E, GPT-3, and LaMDA let users create AI-powered art,
scripts, and conversations. Foundational models hold the potential to help democratize the use of AI/ML, but in the
process give rise to various new risks of misuse, which also makes AI governance more complicated.[10]


Strong/broad AI

There are both strong and weak forms of AI, but even these terms are regularly contested. Strong AI typically refers
to broad-based machine capabilities and is sometimes also called artificial general intelligence, (AGI) reflecting
near-human levels of comprehension or ability. AGI, which is also sometimes more ominously referred to as
superintelligence,[11] tends to capture considerable public attention because it "conjures up a vast array of doom-
laden scenarios."[12] AGI also figures prominently in the plots of many dystopian depictions of artificial intelligence
found in popular culture, including many science-fiction books, movies, and television shows.[13]

This has often led to over-hyping of AI's potential to attain human-like capabilities,[14] with sensationalism and
speculation often dominating discussions.[15] It doesn't help that both supporters and critics of powerful AGI
sometimes play up predictions of AI superintelligence and speak in fatalistic terms about the coming of a
"singularity," or moment in the future when machine intelligence surpasses that of humans. For example,
flamboyantly titled books by AI boosters like Ray Kurzweil (The Singularity Is Near) and detractors like Nick
Bostrom (Superintelligence: Paths, Dangers, Strategies) reflect an air of inevitability about machines coming to
possess greater intelligence than humans, for better or worse.

However, the majority of AI experts agree that such superintelligence predictions are wildly overplayed and that
there is no possibility of machines gaining human-equivalent knowledge any time soon - or perhaps ever.[16] "In
any ranking of near-term worries about AI, superintelligence should be far down the list," says AI expert Melanie
Mitchell, author of Artificial Intelligence: A Guide for Thinking Humans.[17] "A close inspection of AI reveals an
embarrassing gap between actual progress by computer scientists working on AI and the futuristic visions they and
others like to describe," says Erik Larson, author of, The Myth of Artificial Intelligence: Why Computers Can't Think
the Way We Do.[18] Larson refers to this extreme thinking about superintelligent AI as "technological kitsch," or
exaggerated sentimentality and melodrama that is untethered from reality.[19] Whether it is the proponents of idea
of "apocalyptic or fearsome AI" or "utopian or dreamy AI," both are guilty of oversimplifying complicated ideas, he
says.[20] Andrew Ng, a leading AI scientist, has humorously observed that, "Worrying about killer AI is like worrying
about overpopulation on Mars."[21]

Extreme speculation about superintelligent AI represents an underappreciation of the complexity of actual human
intelligence and our unique ability to navigate so many unique situations.[22] As an important report from Stanford
University noted, most AI experts are still struggling to figure out how "to imbue machines with common sense
abilities" and find, "methods [that] can scale to the more diverse and complex problems the real world has to
offer."[23] Leading AI experts Gary Marcus and Ernest Davis, authors of Rebooting AI: Building Artificial
Intelligence We Can Trust, conclude that, "[t]o a large extent, public discussion about AI has been unmoored from
any sort of understanding of the reality of how difficult broad AI would be to achieve."[24] Machines "lack even a
basic understanding of how the world works," they note, and "unfortunately, acquiring common sense is much
harder than one might think."[25] They refer to the challenge of imbuing machines with common sense as "the
mountain that the field needs to climb" and argue that "we have a long journey in front of us."[26] Again, this is the
consensus opinion among leading AI experts. Nonetheless, a later chapter will do a deeper dive into claims about
superintelligent AI and the global regulatory systems that some recommend to address the existential risk it would
pose.

Weak/Narrow AI

Practically speaking, it is more useful and important to focus on today's more pertinent and realistic AI challenges,
which involve various types of weak AI. Weak AI is a bit of a misnomer, however, because weak AI can be quite

                                                                                                      Page 3 of 11
                       Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges

powerful, but it is just narrower in its application. Weak AI applications can often excel in doing one specific task
extraordinarily well, such as paying games, offering language translation, or even operating certain vehicles or
machines without much human assistance.

When the public saw sophisticated AI programs defeat the world's best players of games like chess and Go, it
raised fears about how machines had already come to possess human-level intelligence. For example, when IBM's
"Deep Blue" famously defeated chess grandmaster Garry Kasparov in 1997, a headline in Newsweek declared it to
be "The Brain's Last Stand,"[27] and many other media reports engaged in dystopian handwringing about the
triumph of machines over humanity. Similar fears were raised when DeepMind's AlphaGo beat Go champion Lee
Sedol in 2016.[28]

Yet, neither of these programs possessed the general capacity to do much beyond what they were trained to
do.[29] They could not, for example, teach themselves how to master many other games, including simple ones like
checkers or poker. This is the way almost all AI systems work today: they are good (and getting better) at one task,
but incapable of high-level human-like reasoning across many simple activities.

Ironically, 20 years after losing his famous match with Deep Blue, Kasparov authored a book, Deep Thinking:
Where Machine Intelligence Ends and Human Creativity Begins, seeking to debunk dystopian thinking about
machine-learning and AI. He noted that, "doomsaying has always been a popular pastime when it comes to new
technology" and that, "[w]ith every new encroachment of machines, the voices of panic and doubt are heard, and
they are only getting louder today."[30]

AI's Multiple Dimensions Also Complicate Its Governance

Debates continue to rage over both how to conceptualize of AI and how to advance its capabilities. One notable
2014 study spoke of the need to embrace AI's "anarchy of methods" when it comes to teaching machines how to
think because there were so many subfields, techniques, and abstractions of concepts.[31] Thomas Edison once
spoke of how electricity was a "field of fields" that would transform life in many ways. The same is true of AI, and
this is another factor complicating its governance.

AI/ML builds upon knowledge and capabilities developed through many other important technologies and sectors,
including computing, microprocessors, the internet, high-speed broadband networks, data storage/processing
systems, GPS and geolocation, sensors, and others. Hal Varian, chief economist at Google, observes that we live
in an era of rapid-fire combinatorial innovation in which new technologies are building on top of one another in a
symbiotic fashion, further accelerating their development and sophistication.[32] This is precisely what powers
AI/ML. Many other scientific fields of study are closely related to AI/ML. "Machine learning is at the intersection of
statistics and computer science, occasionally also taking inspiration from cognitive science and neuroscience," says
Alpaydin.[33] These factors also complicate AI governance because attempts to regulate AI/ML could have
profound implications for many other technologies, sectors, and fields of science. Thus, when one blithely suggests
"we should take steps to control AI," they are (perhaps unknowingly) recommending that we should take steps to
control or influence many other things alongside it.

By extension, AI/ML is set to become the "most important general-purpose technology of our era."[34] General-
purpose technologies come to be intertwined with almost every other sector of the economy and used ubiquitous
throughout society.[35] For example, AI will be used by almost all organizations to help improve analytics and
marketing, enhance customer service, and boost sales or performance in various new ways. And it will completely
upend the way production and work is done in countless fields and professions.

This is what makes AI so important for future innovation and growth, but this fact also complicates its
governance.[36] Much like electronics, computing, and the internet before it, it is easier to imagine how to govern
individual components or outputs than the broader concept itself. This is one reason that governance frameworks
for things like driverless cars, drones, and robotics are developing more rapidly than overarching regulation for
general AI.

                                                                                                        Page 4 of 11
                        Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges

Finally, AI also raises special governance challenges because it is a dual-use (and often open source) technology
that, like chemical and nuclear technologies before it, has both beneficial peaceful uses, but also potentially
concerning military or law enforcement applications.[37] This fact is particularly important when discussing so-called
existential risk, which I address elsewhere.[38] Meanwhile, many current regulatory discussions focus on affective
computing and biometric technologies, such as facial recognition, which are dual-use technologies that monitor
human attributes and, when used improperly, raise serious security and privacy risks.[39]

AI Promises to Drive Growth in Many Sectors

Over the past half century, there have been waves of both hype and hysteria about the prospects for AI
advancement.[40] Much of this was driven by both irrational exuberance and fear about high-level AGI that never
came about. As a result, AI historians often speak of the many AI "springs" and "winters" that have come and gone
over the past half century. Others describe it as AI "booms and busts."

It did not help that some of AI's early pioneers over-exuberantly predicted powerful AGI would be with us very
quickly. In the late 1960s, for example, noted AI researchers confidentially predicted that, "machines will be
capable, within twenty years, of doing any work a man can do," (Herbert A. Simon), and that, "Within a generation
... the problem of creating 'artificial intelligence' will substantially be solved" (Marvin Minsky). Such exuberance was
replaced by pessimism in the 1970s and a resulting "winter" period for AI research and investment.

Today, however, AI is generally thought to be in the midst of another "spring" period as enthusiasm grows around
specific capabilities and applications. The power of AI/ML technologies is already all around us in products and
services such as speech and image recognition tools on our smartphones as well as the recommender systems
that many media providers and other companies use to tailor goods, services, and content to our interests.

Other times, AI/ML is operating behind the scenes to help with fraud and spam detection, computer virus filtering,
content       management/moderation,[41]       mapping/navigation,    weather     forecasting,[42]    warehouse
automation/inventory management,[43] supply chain management,[44] and various other office logistics.[45] For
example, in 2021, McKinsey & Company estimated that "[s]uccessfully implementing AI-enabled supply-chain
management has enabled early adopters to improve logistics costs by 15 percent, inventory levels by 35 percent,
and service levels by 65 percent, compared with slower-moving competitors."[46] These productivity enhancements
are likely to accelerate as AI/ML techniques are further refined.

AI and ML capabilities also power most of devices that make up the so-called Internet of Things, or various
connected "smart" devices, including many wearable technologies and other devices with embedded sensors.[47]
Another related term here is ambient computing[48] or ubiquitous computing, which essentially means "using
computers without knowing that you are using one," or at least without explicitly calling them computers when one
is using smart systems.[49] These technologies have powerful health and medical applications, among other
things.

Meanwhile, various AI-powered robotic technologies are already at work in many industrial sectors.[50] AI, ML, and
advanced robotics technologies promise to revolutionize many fields, including financial services,[51]
transportation,[52] retail,[53] agriculture,[54] entertainment,[55] energy,[56] environmental protection,[57]
education,[58] aviation,[59] the automotive industry,[60] and many others.[61] Going forward, every segment of the
economy will be touched by AI and robotics in some fashion, and it should be equally clear that public policy in
these fields will be transformed in the process. Eventually, all policy will involve AI policy at some level.

The potential exists for AI to drive explosive economic growth.[62] According to Grand View Research, a market
research and consulting company based in India and the US, the global artificial intelligence market was valued at
USD 93.5 billion in 2021 and is projected to expand at a compound annual growth rate of 38.1% from 2022 to
2030.[63] Many other studies forecast that "AI will have a significant economic impact" on growth and
productivity.[64] A 2018 study by McKinsey consultants estimated that "AI has the potential to deliver additional
global economic activity of around $13 trillion by 2030, or about 16 percent higher cumulative GDP compared with
today. This amounts to 1.2 percent additional GDP growth per year," the report concluded.[65] Even if AI's

                                                                                                      Page 5 of 11
                       Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges

economic impact falls far short of that estimate, it would still clearly be generating enormous growth opportunities
across many segments of the economy.

But it is what AI will mean for every individual that matters most. AI has to ability to help people improve their
health, extend their lives, expand transportation options, avoid accidents, improve community safety, enhance
educational opportunities, access superior financial services, and much more. AI-driven machines and robot will
assist with many dangerous jobs, thus making many workplaces safer.[66]

Case Study: AI's Potential for Medicine and Health Care

Consider what AI is already accomplishing in the field of health care and the practice of medicine.[67] Increasingly
powerful algorithmic systems - often combined with new wearable technologies - are already helping many people
better monitor their health and fitness. More sophisticated AI tools are allowing doctors and scientists to create
highly personalized care options and develop new medical treatments tailored to the unique needs of each
patient.[68] More broad-based AI capabilities could have a profound impact on public health. In 2022, for example,
an AI technology called AlphaFold from Deep Mind was able to model the structure of nearly all known proteins,
which represented "a significant advance in biology that will accelerate drug discovery and help address problems
such as sustainability and food insecurity."[69]

AI, ML, and robotics are driving many other major medical advances today:
    •   Organ donation: In the field of organ donations, "[p]aired kidney donation is one of the great success
        stories of artificial intelligence," helping doctors and patients by taking "an incredibly complex problem and
        solves it faster and with fewer errors than humans can, and as a result saves more lives."[70]
    •   Heart attack detection & treatment: AI and ML tools are helping detect and treat heart disease and heart
        attacks, which is a leading cause of death globally. Scientists at Cedars-Sinai developed an algorithmic
        tool that can quantify coronary plaque buildup in five to six seconds compared to at least 25 to 30 minutes
        before.[71] This will greatly improve ability to predict who will have a heart attack. Other researchers have
        developed AI tools to help improve personalized treatment for women who have had heart attacks.[72]
        Women who suffer a heart attack have a higher mortality rate than men, often because their symptoms are
        not properly understood or diagnosed. Meanwhile, the British National Health Service recently started
        using a new AI tool that can detect heart disease in just 20 seconds while patients are in an MRI scanner,
        compared with the 13 minutes, or more it usually takes doctors to manually analyze images after a scan is
        performed.[73]
    •   Cancers: Cancer is the second leading cause of death behind heart disease, claiming 602,350 lives in
        2020.[74] AI and ML-enabled technologies are poised to help reduce that staggering death toll. Mayo Clinic
        researchers have shown how ML models can help diagnose and treat pancreatic cancer at an earlier
        stage.[75] Pancreatic cancer is the third lead cause of cancer death, claiming 46,774 lives in 2020.[76]
        British scientists have also recently reported on new AI software that can spot signs of pre-cancer during
        endoscopies in 92 per cent of patient, which could significant lower deaths from oesophageal cancer.[77]
        AI/ML techniques are also helping with early detection and treatment of lung cancer,[78] breast cancer,[79]
        brain cancer,[80] and many other types of cancer[81] (including undiagnosable cancers[82]), aided by
        increasingly personalized screening techniques.[83]
    •   Sepsis & superbugs: Recent medical studies have also documented how AI-powered monitoring systems
        are helping to detect antibiotic-resistant "superbugs"[84] and sepsis,[85] and will save thousands of lives
        each year as a result. Roughly 1.7 million adults develop sepsis every year in the U.S. and more than
        250,000 of them die.[86]
    •   Mental health: AI can help identify and address mental health problems through textual analysis, which
        can supplement human-based analysis at a time when there is a nationwide shortage of health care
        workers in this area.[87]

AI and ML will power other advanced learning capabilities that will help doctors and scientific research access and
understand massive amounts of patient and health data - and then put it to even better use. In 2022, I served as a

                                                                                                         Page 6 of 11
                        Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges

member of the U.S. Chamber of Commerce "AI Commission on Competition, Inclusion, and Innovation," a group
formed to study AI governance. At a Spring 2022 field hearing, our Commission heard remarks from Dr. Tom
Mihaljevic, MD, CEO and President at the Cleveland Clinic, as well as several of his colleagues.[88] These
Cleveland Clinic doctors and scientists highlighted how they were already using AI/ML to improve patient care and
save lives. They noted how teams of doctors and researchers are now able to share information from tissue
samples with much larger teams of medical experts, who can - with the help of algorithmic systems - work together
at a distance to better understand and use all the information they will have at their fingertips. They have also
developed better AI-driven methods to detect irregular heartbeats and strokes, and diagnose degenerative brain
disease (Alzheimer's, dementia, Parkinson's).

This only scratches the surface of what AI/ML will mean for patient care.[89] Dr. Mihaljevic noted that, when he
started practicing medicine in the 1980s, the overall volume of medical information doubled roughly every seven
years while today it is doubling every 73 days.[90] Marcus and Davis note that seven thousand medical papers are
now published every day.[91] Meanwhile, in the closely related field of medical robotics, the number of scientific
papers has grown exponentially from less than 10 published in 1990 to more than 5200 in 2020 according to a
recent study in Science.[92] These numbers are in line with broader trends in technical and scientific literature.
"Since the scientific literature doubles roughly every 12 years, this means that of all scientific work ever produced,
half of it has been produced in the last 12 years," Dashun Wang and Albert-Laszlo Barabasi report in their book,
The Science of Science.[93]

The only way to take full advantage of this explosion of knowledge is with the power of machine reading and
learning technologies. As the National Cancer Institute summarizes, "what scientists are most excited about is the
potential for AI to go beyond what humans can currently do themselves. AI can 'see' things that we humans can't,
and can find complex patterns and relationships between very different kinds of data."[94]

AI/ML will also help share medical knowledge across far more institutions and reach more patients as a result. Dr.
Mihaljevic estimated that the Cleveland Clinic, which is one of the most important medical research facilities in the
nation, is only able to reach an estimated 1.5% of Americans using its traditional means of care. Machine learning
and artificial intelligence can change that equation by greatly expanding opportunities for Americans to access the
benefits of scientific knowledge and medical care from the Cleveland Clinic and America's many other world-class
medical facilities, labs, and universities. Dr. Mihaljevic specifically highlighted how AI was the key to improving
home-based medical care, which will become an essential way to help a rapidly aging population in the future,
regardless of where they live. AI will also become crucial for various surgeries in terms of both improving outcomes
when operations are necessary (often through robotic assisted surgery)[95] or, better yet, avoiding the need for
invasive procedures altogether.[96]

For these reasons, policymakers should not underestimate the importance of AI/ML technology, and they must
work diligently to ensure that America remains a leader in this field. While some experts predict another AI winter
could be coming following some notable narrow AI disappointments, they oftentimes fail to identify how public policy
effects that outcome.[97] The overall amount of innovation we can expect to flow from this space is fundamentally
tied up with the question of whether America creates the right innovation culture for artificial intelligence. To achieve
the full potential that AI offers, America will need to set its policy defaults in such a way to both encourage
innovation while also addressing the many legitimate concerns about various AI capabilities.
__________
Key Takeaways:
    •   Defining the nature and scope of artificial intelligence and its many components and related subsectors is
        complicated. This fact creates many governance challenges.
    •   Many other things about AI complicate its governance, including the fact that it is both a general purpose
        and dual-use technology. AI builds upon knowledge and capabilities developed through many other
        important technologies and sectors in a combinatorial fashion, meaning that AI governance decisions will
        affect them as well.

                                                                                                   Page 7 of 11
                      Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges

   •    There are both strong and weak forms of AI, but public imagination and public policy has been too focused
        on hyper-powerful forms of strong AI that are distant and unlikely. The more important focus today should
        be on the challenges associated with more targeted applications of weak or narrow AI.
   •    AI has experienced many "springs" and "winters" over the past half century, reflecting waves of irrational
        exuberance and pessimism over its potential. Today the field is maturing rapidly.
   •    Every segment of the economy will be touched by AI in some fashion and AI developments will likely drive
        economic growth in the future. By extension, all policy matters and governance issues will eventually
        involve AI considerations in some fashion.
   •    AI technologies offer individuals and society meaningful improvements in living standards across multiple
        dimensions. The most profound of these will likely be what AI means for the practice of medicine and
        personalized health care.

Additional reading by Adam Thierer

· Adam Thierer & Neil Chilson, "The Coming Onslaught of 'Algorithmic Fairness' Regulations," Regulatory
Transparency Project of the Federalist Society, November 2, 2022.

· Adam Thierer, "We Really Need To 'Have a Conversation' About AI ... or Do We?," Discourse, October 6,
2022.

· Adam Thierer, "How the Embedding of AI Ethics Works in Practice & How It Can Be Improved," Medium,
September 22, 2022.

· Adam Thierer, "AI Eats the World: Preparing for the Computational Revolution and the Policy Debates
Ahead," Medium, September 10, 2022.

· Adam Thierer, "'Running Code and Rough Consensus' for AI: Polycentric Governance in the Algorithmic
Age," Medium, September 1, 2022.

· Adam Thierer, "AI Governance 'on the Ground' vs 'on the Books,'" Medium, August 19, 2022.

· Adam Thierer, "Responses to Jack Clark's AI Policy Tweetstorm," Medium, August 8, 2022.

· Adam Thierer, "Why the Future of AI Will Not Be Invented in Europe," Technology Liberation Front, August 1,
2022.

· Adam Thierer, "How Science Fiction Dystopianism Shapes the Debate over AI & Robotics," Discourse, July
26, 2022.

· Adam Thierer, "Why is the US Following the EU's Lead on Artificial Intelligence Regulation?" The Hill, July
21, 2022.

· Adam Thierer, "Algorithmic Auditing and AI Impact Assessments: The Need for Balance," Medium, July 13,
2022.

· Adam Thierer, "The Proper Governance Default for AI," Medium, May 26, 2022.

· Adam Thierer, "What I Learned about the Power of AI at the Cleveland Clinic," Medium, May 6, 2022.

· Adam Thierer, Governing Emerging Technology in an Age of Policy Fragmentation and Disequilibrium,
American Enterprise Institute (April 2022).

· Adam Thierer and John Croxton, "Elon Musk and the Coming Federal Showdown Over Driverless Vehicles,"
Discourse, November 22, 2021.

                                                                                                           Page 8 of 11
                        Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges

· Adam Thierer, "A Global Clash of Visions: The Future of AI Policy," The Hill, May 4, 2021.

· Adam Thierer, "A Brief History of Soft Law in ICT Sectors: Four Case Studies," Jurimetrics, Vol. 61 (Fall
2021): 79-119.

· Adam Thierer, "U.S. Artificial Intelligence Governance in the Obama-Trump Years," IEEE Transactions on
Technology and Society, Vol, 2, Issue 4 (2021).

· Adam Thierer, "The Worst Regulation Ever Proposed," The Bridge, September 2019.

· Ryan Hagemann, Jennifer Huddleston Skees & Adam Thierer, "Soft Law for Hard Problems: The Governance
of Emerging Technologies in an Uncertain Future," Colorado Technology Law Journal, Vol. 17 (2018).

· Adam Thierer & Trace Mitchell, "No New Tech Bureaucracy," Real Clear Policy, September 10, 2020.

· Adam Thierer, "OMB's AI Guidance Embodies Wise Tech Governance," Mercatus Center Public Comment,
March 13, 2020.

· Adam Thierer, "Europe's New AI Industrial Policy," Medium, February 20, 2020.

· Adam Thierer, "Trump's AI Framework & the Future of Emerging Tech Governance," Medium, January 8,
2020.
[1] Michael Wooldridge, A Brief History of Artificial Intelligence: What It Is, Where We Are, and Where We Are
Going (Flatiron Books, 2020); Melanie Mitchell, Artificial Intelligence: A Guide for Thinking Humans (Farrar, Straus
and Giroux, 2019); Pedro Domingos, The Master Algorithm: How the Quest for the Ultimate Learning Machine Will
Remake Our World (Basic Books, 2015).

[2] https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4292207.

[3]     "Artificial    Intelligence,"     Stanford       Encyclopedia    of     Philosophy,         July      12,    2018.
https://plato.stanford.edu/entries/artificial-intelligence.

[4] U.S. Government Accountability Office, "Artificial Intelligence: Emerging Opportunities, Challenges, and
Implications," Technology Assessment, GAO-18-142SP, (Mar. 28, 2018), p. 15. https://www.gao.gov/products/gao-
18-142sp.
[5] Ethem Alpaydin, Machine Learning (The MIT Press, 2021), p. 16.
[6] Louridas, Algorithms, p. xiii.

[7]    Chris  Meserole,    "What    is   Machine     Learning?"         Brookings      Institution,    Oct.     4,   2018.
https://www.brookings.edu/research/what-is-machine-learning.

[8] Adam Thierer, "Big Data, Innovation, Competitive Advantage & Privacy Concerns," Technology Liberation Front,
Apr. 27, 2012. https://techliberation.com/2012/04/27/big-data-innovation-competitive-advantage-privacy-concerns.

[9] Rishi Bommasani and Percy Liang, "Reflections on Foundational Models," Stanford University Human-Centered
Artificial Intelligence (2021). https://crfm.stanford.edu/2021/10/18/reflections.html.

[10] Rishi Bommasani, "On the Opportunities and Risks of Foundation Models," Center for Research on Foundation
Models (July 2021). https://arxiv.org/abs/2108.07258.

[11] K. Eric Drexler, "Reframing Superintelligence: Comprehensive AI Services as General Intelligence," Technical
Report #2019-1 (Future of Humanity Institute, University of Oxford, 2019).
[12] Darcy W.E. Allen, Chris Berg, and Sinclair Davidson, The New Technologies of Freedom (American Institute
for Economic Research, 2020), p. 95.

                                                                                                           Page 9 of 11
                        Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges

[13] Adam Thierer, "How Science Fiction Dystopianism Shapes the Debate over AI & Robotics," Discourse, July 26,
2022,        https://www.discoursemagazine.com/culture-and-society/2022/07/26/how-science-fiction-dystopianism-
shapes-the-debate-over-ai-robotics/; Jill Lepore, "A Golden Age for Dystopian Fiction," The New Yorker, June 5 &
12, 2017. https://www.newyorker.com/magazine/2017/06/05/a-golden-age-for-dystopian-fiction.

[14] Kevin Kelly, "The AI Cargo Cult: The Myth of a Superhuman AI," Wired, Apr. 25, 2017.
https://www.wired.com/2017/04/the-myth-of-a-superhuman-ai.

[15]     Zohar     Atkins,    "Is   AI   Sentient?"      What      is    Called     Thinking,       June     13,    2022.
https://whatiscalledthinking.substack.com/p/is-ai-sentient.

[16] Oren Etzioni, "No, the Experts Don't Think Superintelligent AI is a Threat to Humanity," Technology Review,
Sept. 20, 2016. https://www.technologyreview.com/2016/09/20/70131/no-the-experts-dont-think-superintelligent-ai-
is-a-threat-to-humanity; Gary Marcus, "Artificial General Intelligence Is Not as Imminent as You Might Think,"
Scientific American, June 6, 2022. https://www.scientificamerican.com/article/artificial-general-intelligence-is-not-as-
imminent-as-you-might-think1.
[17] Melanie Mitchell, Artificial Intelligence: A Guide for Thinking Humans (Farrar, Straus and Giroux, 2019), p. 278
[Kindle edition.]
[18] Erik Larson, The Myth of Artificial Intelligence: Why Computers Can't Think the Way We Do (The Belknap
Press of Harvard University, 2021), p. 49.

[19] Erik Larson, "Silicon Valley Has Been Taken over by 'Technological Kitsch'," Fast Company, May 12, 2021.
https://www.fastcompany.com/90635442/technological-kitsch.
[20] Larson, The Myth of Artificial Intelligence, p. 62.
[21] Quoted in Clive Thompson, Coders: The Making of a New Tribe and the Remaking of the World (Penguin
Press, 2019), p. 302.

[22] Cade Metz, "A.I. Is Not Sentient. Why Do People Say It Is?" New York Times, Aug. 5, 2022.
https://www.nytimes.com/2022/08/05/technology/ai-sentient-google.html.

[23] Gathering Strength, Gathering Storms: The One Hundred Year Study on Artificial Intelligence (AI100) 2021
Study Panel Report, (Stanford University, Sept. 2021): 32-3, http://ai100.stanford.edu/2021-report.

[24] Gary Marcus and Ernest Davis, Rebooting AI: Building Artificial Intelligence We Can Trust (Pantheon, 2019), p.
24.
[25] Ibid., p .94.
[26] Ibid., p. 155.

[27] Steven Levy, "What Deep Blue Tells Us about AI in                            2017,"    Wired,    May     23,   2017.
https://www.wired.com/2017/05/what-deep-blue-tells-us-about-ai-in-2017.

[28] "Google AI Defeats Human Go Champion," BBC, May 25, 2017, https://www.bbc.com/news/technology-
40042581.

[29] Joshua Sokol, "AI Keeps Mastering Games, But Can It Win in the Real World?" The Atlantic, Feb. 27, 2018.
https://www.theatlantic.com/technology/archive/2018/02/ai-keeps-mastering-games-but-can-it-win-in-the-real-
world/554312.

[30] Garry Kasparov, Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins (Public
Affairs, 2017), p 7; Adam Thierer, "The Growing AI Technopanic," Medium, Apr. 27, 2017.
https://aboveintelligent.com/the-growing-ai-technopanic-5d6658b00fed.

[31] Joel Lehman, Jeff Clune, and Sebastian Risi, "An Anarchy of Methods: Current Trends in How AI is Abstracted
in AI," Intelligent Systems, Vol. 29, ?6 (2014), p. 56-62, https://www.cs.utexas.edu/users/ai-lab/?lehman:is14.

                                                                                                       Page 10 of 11
                       Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges

[32] Hal R. Varian, "Computer Mediated Transactions," American Economic Review, 100:2 (May 2010).
https://www.aeaweb.org/articles?id=10.1257/aer.100.2.1.
[33] Alpaydin, Machine Learning, p. 34.

[34] Erik Brynjolfsson and Andrew McAfee, "The Business of Artificial Intelligence," Harvard Business Review, July
18, 2017. https://hbr.org/2017/07/the-business-of-artificial-intelligence.
[35] Timothy F. Bresnahan and M. Trajtenberg, "General Purpose Technologies 'Engines of Growth'?" Journal of
Econometrics, 65:1 (1995), p. 83-108.

[36] Nicholas Crafts, "Artificial Intelligence as a General-purpose Technology: An Historical Perspective," Oxford
Review       of     Economic          Policy,     Vol.    37,     ?3     (Autumn      2021),      p.     521-536.
https://academic.oup.com/oxrep/article/37/3/521/6374675.

[37] National Security Commission on Artificial Intelligence, Final Report (2021), p. 1, https://www.nscai.gov;
Jayshree Pandya, "The Dual-Use Dilemma of Artificial Intelligence," Forbes, Jan. 7, 2019,
https://www.forbes.com/sites/cognitiveworld/2019/01/07/the-dual-use-dilemma-of-artificial-intelligence.

[38] Adam Thierer, "Existential Risks & Global Governance Issues around AI & Robotics," last revised Sept. 12,
2022. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4174399.
[39] Alpaydin, Machine Learning, p. 83.

[40] Robert D. Atkinson, "'It's Going to Kill Us!' and Other Myths about the Future of Artificial Intelligence,"
Information Technology & Innovation Foundation, June 2016. http://www2.itif.org/2016-myths-machine-learning.pdf.

[41] Alex Feerst, "The Use of AI in Online Content Moderation," American Enterprise Institute (Sept. 2022).
https://platforms.aei.org/the-use-of-ai-in-online-content-moderation.

[42] Robin Fearon "AI Tools Help to Predict Extreme Weather and Save Lives," Discovery, Aug. 2, 2022.
https://www.discovery.com/science/ai-tools-help-to-predict-extreme-weather.

[43] "How AI-Powered Robots Fulfill           Your    Online    Orders,"   Last   Week     in   AI,   Jan.    25,   2022.
https://lastweekin.ai/p/robot-picking.

[44] Christopher Mims, "How to Build AI That Actually Works for Your Business," Wall Street Journal, July 23, 2022.
https://www.wsj.com/articles/how-to-build-ai-that-actually-works-for-your-business-11658548830.

[45] Cem Dilmegan, "Top 15 Use Cases and Applications of AI in Logistics in 2022," July 9, 2020, updates, May 29,
2022. https://research.aimultiple.com/logistics-ai.

[46] McKinsey & Company, "Succeeding in the AI Supply-chain Revolution," Article, Apr. 30, 2021.
https://www.mckinsey.com/industries/metals-and-mining/our-insights/succeeding-in-the-ai-supply-chain-revolution.

[47] Adam Thierer, "The Internet of Things and Wearable Technology: Addressing Privacy and Security Concerns
without    Derailing   Innovation,"   Richmond     Journal  of   Law    and    Technology,    21:6    (2015).
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2494382.

[48] Christopher Mims, "Why the Future of the Computer Is Everywhere, All the Time," Wall Street Journal, Oct. 29,
2022. https://www.wsj.com/articles/computer-technology-ambient-computing-11666992784.
[49] Alpaydin, Machine Learning, p. 9.

[50] A Roadmap for US Robotics From Internet                     to   Robotics:   2020    Edition,    Sept.    9,   2020.
https://www.hichristensen.com/pdf/roadmap-2020.pdf.

                                                                                                      Page 11 of 11
                       Artificial Intelligence Primer: Definitions, Benefits & Policy Challenges

[51] Suparna Biswas, Brant Carson, Violet Chung, Shwaitang Singh, and Renny Thomas, "AI-Bank of the Future:
Can      Banks    Meet    the     AI     Challenge?"      McKinsey       &     Company,      Sept.   19,     2020.
https://www.mckinsey.com/industries/financial-services/our-insights/ai-bank-of-the-future-can-banks-meet-the-ai-
challenge.

[52] Maria Lopez Conde and Ian Twinn, "How Artificial Intelligence is Making Transport Safer, Cleaner, More
Reliable and Efficient in Emerging Markets," International Finance Corporation, Note 75 (Nov. 2019).
https://www.ifc.org/wps/wcm/connect/7c21eaf5-7d18-43b7-bce1-864e3e42de2b/EMCompass-Note-75-AI-making-
transport-safer-in-Emerging-Markets.pdf?MOD=AJPERES&CVID=mV7VCeN.

[53] Ben Forgan, "What Robots Can Do for                   Retail,"   Harvard   Business    Review,   Oct.   1,   2020.
https://hbr.org/2020/10/what-robots-can-do-for-retail.

[54] Louis Columbus, "10 Ways AI Has the Potential To Improve Agriculture In 2021," Forbes, Feb. 17, 2021.
https://www.forbes.com/sites/louiscolumbus/2021/02/17/10-ways-ai-has-the-potential-to-improve-agriculture-in-
2021/?sh=454d747a7f3b.

[55] Anne Hobson, "Artificial Intelligence is Set to Remake Event Experiences," The Hill, Jan. 11, 2017.
https://www.rstreet.org/2017/01/11/artificial-intelligence-is-set-to-remake-event-experiences.

[56] Franklin Wolfe, "How Artificial Intelligence Will Revolutionize the Energy Industry," Harvard University Graduate
School of Arts and Sciences, Special Edition on Artificial Intelligence, Aug. 28, 2017.
https://sitn.hms.harvard.edu/flash/2017/artificial-intelligence-will-revolutionize-energy-industry.

[57] Justine Calma, "How Machine Learning Could Help Save Threatened Species from Extinction," The Verge,
Aug. 4, 2022. https://www.theverge.com/23290902/machine-learning-conservation-data-deficient-species-iucn-red-
list-extinction-threat.

[58] Sara Randazzo, "Can Tech Boost Reading? Literacy Tools Come to Classrooms," Wall Street Journal, Aug. 7,
2022. https://www.wsj.com/articles/literacy-technology-offers-new-ways-to-teach-kids-to-read-11659879846.

[59] Kelsey Reichmann, "How Is the Aviation Industry Enabling Innovation with Artificial Intelligence?" Aviation
Today, Dec. 14, 2020. https://www.aviationtoday.com/2020/12/14/aviation-industry-enabling-innovation-artificial-
intelligence.

[60] Mobility, "Artificial Intelligence Reshaping the Automotive Industry," Future Bridge, Apr. 29, 2020.
https://www.futurebridge.com/industry/perspectives-mobility/artificial-intelligence-reshaping-the-automotive-industry.


Load-Date: January 5, 2023


  End of Document

                                                                                                    Page 1 of 2
                                   Involta 's Idaho employees use AI to detect COVID-19




                     Involta's Idaho employees use AI to detect COVID-19
                                                       Idaho Business Review
                                                   May 13, 2020 Wednesday



Copyright 2020 BridgeTower Media All Rights Reserved




Section: NEWS
Length: 706 words
Byline: Catie Clark

Body


A woman with a lovely voice named Eleanor calls up twice a week to inquire how you are doing. She asks you what
you like to do in your spare time or what you did this weekend. She even poses some brain-teaser questions. She's
doing all of this because she is concerned about your health.

For several weeks now, this nosy woman has been calling employees at Involta, an IT company providing cloud-
computer and other IT services, including two data center facilities and 30 employees in the Boise area.
There's a twist: Eleanor is a bot run by an artificial intelligence program.

Her trade name is MyEleanor, and she is the voice of an AI-based case management and triage program marketed
by New York-based start-up MyndYou. The firm specializes in AI that uses cognitive complexity analysis of speech
patterns. Their proprietary software can detect changes in speech, which research has associated with cognitive
decline diseases and the onset of certain respiratory conditions.

The software is currently involved in a research trial run by the venerable Massachusetts General Hospital for
theremote, automated detection of subtle changes in the speech patterns of Alzheimer's patients. Based on earlier
clinical programs, MyndYou's AI has shown sensitivity levels of 70% and specificity levels of 90% for disease
detection.

Eleanor's phone calls in Boise are part of a collaboration between Involta and MyndYou, which had its roots
whenJeff Szymanski, executive vice president for business development at Involta, met RuthPoliakine Baruchi, the
founder and CEO ofMyndYou at the health care technology Allscripts Conference.
"I got talking with Ruth, and the more I learned about MyndYou, the more intrigued I was,"Szymanski told the Idaho
Business Review. "This was well before COVID-19 ever showed up."

Szymanski and Baruchi came up with the idea of using MyndYou's AI to monitor employee health during the
pandemic to screen for the onset of COVID-19.
"Because COVID-19 is a new condition, we do not have any clinical trials related to our detection ability for that
specific condition," Baruchi explained. "Our assumption around COVID-19 is based on our ability to detect changes

                                                                                                        Page 2 of 2
                               Involta 's Idaho employees use AI to detect COVID-19

related to respiratory conditions. We will screen for COVID-19 through (Involta employee) questionnaires, with
additional insight into change through the voice analysis."

When MyEleanor calls, AI-driven voice analytics work in the background to detect subtle changes in the employee’s
health. Insights and analytics from the calls will be delivered directly to the employees when a change is detected.

“Employee health is essential to our business performance,” said Jim Buie,InvoltaPresident. “We are excited to be
participating in the MyndYou program to discover new preventative measures that support employee health and
wellness. ”

The monitoring program is to help Involta's employees self-screen for the COVID-19 virus and stay on top of their
mental and physical health. COVID-19 screening questions are incorporated into the check-in calls with MyEleanor
as a way of drawing attention to symptoms and providing guidance when needed. Ultimately, the collaboration is
aimed at promoting health within theInvoltaworkforce, whether related to COVID-19, preexisting chronic conditions
or the countless other needs that MyndYou’s engagement and voice analytics solutions can support.

Though not at the level of a clinical trial, the collaboration is an experiment. All the Involta participants are
volunteers. Involta's Idaho employees were offered the chance to participate in the health monitoring program
during the last week in April. The program will run through the end of the year.MyndYou established ethics and
privacy safeguards to protect the volunteers in the monitoring program. Participation is 100% voluntary, andInvolta
will never see any employee data or information gathered by the MyEleanor AI.

Cedar Rapids-based Involta established their first Idaho facility in 2014. Both of their Idaho data centers are in the
Boise area. The company is an IT service provider selling cloud-based computing and technology consulting
services to over 600 customers, including 150 in the health care sector.


Copyright © 2020 BridgeTower Media. All Rights Reserved.


Load-Date: May 19, 2020


  End of Document

                                                                                                        Page 1 of 2
                          Google CEO Sundar Pichai promises to invest Rs 75,000 Crore in India




     Google CEO Sundar Pichai promises to invest Rs 75,000 Crore in India
                                                              The Sentinel
                                                         July 13, 2020 Monday



Copyright 2020 Omega Printers & Publishers Pvt Ltd, distributed by Contify.com All Rights Reserved

Length: 345 words
Byline: Sentinel Digital Desk

Body


Google CEO Sundar Pichai announced a $10 billion investment with an aim to accelerate India's 'digital economy'
in the next 5-7 years

Guwahati: At the Google for India virtual live-stream event on Monday, the company's CEO Sundar Pichai
announced a $10 billion investment with an aim to accelerate India's "digital economy" in the next 5-7 years.

Stating that he was "excited" to announce the Google for India Digitization Fund, Pichai said that through the effort
the multinational giant will inject $10 billion (Rs 75,000 crore) into the country over the next 5-7years. This, Pichai
announced, shall be done through a mix of equity investments, partnerships, and operational, infrastructural, and
ecosystem investments. The Google CEO said that this is a reflection of the company's confidence in India and its
digital economy.

Pichai stated that the $10 billion investment will seek to enable affordable access and information to every single
Indian by breaking the language barriers. He further added that India's unique needs shall be catered to by
"products and services."

The Google CEO expressed hope that the company's huge investment will also help local businesses to move
towards digital transformation, adding that it will also work towards using Artificial Integellince (AI) in areas like
health, education, etc.

An AI flood forecasting system that will help warn and evacuate areas that may get affected by the natural disaster
was cited as one of the examples by Pichai, who also enlightened about an AI-powered reading tutor app Bolo aka
Read-Along to help kids read and learn.

Citing a plethora of successful programs launched by the company in the past, the 48-year-old pointed to Internet
Saathi and claimed that it has helped over 30 million women across India to learn digital skills and incorporate them
into their everyday lives.

Lauding Prime Minister Narendra Modi, Pichai said that his envisioned Digital India mission has made internet
accessible to a billion Indians through "cheap smartphones, affordable data, and world-class telecom
infrastructure."

                                                                                           Page 2 of 2
                    Google CEO Sundar Pichai promises to invest Rs 75,000 Crore in India


Load-Date: July 14, 2020


  End of Document

                                                                                                       Page 1 of 9
      Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth, Status, and Forecast | Admera
                                      Health LLC , Advinow Inc - The Courier




  Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth,
     Status, and Forecast | Admera Health LLC, Advinow Inc - The Courier
                                              The Courier: Monmouth University
                                                      January 8, 2021 Friday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1317 words

Body


ReportsnReports added Clinical IT Systems Market Research Report created by Report Consultant, which offers
detailed insights, revenue details, and other information regarding the global market, and the various trends,
drivers, restraints, opportunities, and market till 2028. Clinical IT Systems Market Report offers detailed information
regarding the leading key players operating in the market, their financials, supply chain trends, technological
innovations, key developments, apart from future strategies, acquisitions and mergers, and market footprint. Clinical
IT Systems Market also provides a comparative analysis of the market dynamics pre and post Covid19 outbreak.

Request                for              FREE                 PDF                       Sample                   Report
@ https://www.reportsnreports.com/contacts/requestsample.aspx?name=3926471

Top Company Profile Analysis in this Report-

Abiomed Inc

Adaptive Technology Consulting LLC

Admera Health LLC

Advinow Inc

ai4gi Solutions Inc

AI4medicine

Ai-Assisted Hematologic Analytic and Decision Support

Aidoc Ltd

Aignostics GmbH

                                                                                                     Page 2 of 9
    Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth, Status, and Forecast | Admera
                                    Health LLC , Advinow Inc - The Courier

AirStrip Technologies Inc

Alan Turing Institute Almere

Alcon Inc

AlertWatch Inc

AlgorithmRx, LLC

Allegheny-Singer Research Institute

Allscripts Healthcare Solutions Inc

Analytic Diabetic Systems, LLC

Apollo Medical Imaging Technology Pty Ltd

Auckland University of Technology

Automated Reliable Tissue Diagnostics AG

Autonomous Healthcare Inc

Bayer AG

Beckman Coulter Inc

Becton Dickinson and Co

Ben-Gurion University of the Negev

Berg LLC

Beth Israel Deaconess Medical Center

BioSensics LLC

Blenderhouse

Blue Eye Soft Corp

Boston Children's Hospital

BrainTale

BrightOutcome Inc.

Cancer Genetics Inc

Carevive Systems Inc

Carnegie Mellon University

Case Western Reserve University

Cellnovo Ltd

Cerner Corp

                                                                                                     Page 3 of 9
    Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth, Status, and Forecast | Admera
                                    Health LLC , Advinow Inc - The Courier

Children's Hospital of Philadelphia

Children's Research Institute

China PLA General Hospital

Cirdan Imaging Ltd.

City, University of London

Clare Medical Of New Jersey LLC

Cohere Health Technologies LLC

Columbia University

Computer Technology Associates Inc

ContextVision AB

CorticoMetrics LLC

Creative Action LLC

Curemetrix Inc

Cybercom Group AB

Decoded Health

DLT Resolution Inc

Doctrin AB

Edwards Lifesciences Corp

Eko Devices Inc

Elekta AB

Emmaus Life Sciences Inc

Emory University

Encompass Health Corp

eNursing LLC

Eodyne Systems SL

Evident LLC

Eyoto Group Ltd

Eysz Inc

Fundacion para la Investigacion Biomedica del Hospital Gregorio Maranon

GE Healthcare

                                                                                                      Page 4 of 9
     Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth, Status, and Forecast | Admera
                                     Health LLC , Advinow Inc - The Courier

Georgia Institute of Technology

Great Lakes NeuroTechnologies Inc

Greenway Health LLC

Guerbet SA

H. Lee Moffitt Cancer Center & Research Institute Inc

HealthTech Solutions LLC

Henry Ford Health System

Hera MI

Holy Name Medical Center

Hospital del Mar

Hospital for Special Surgery

IBM Watson Health

iHealthLabs Europe

Imaxdi.

Imperial College London

INFINITT Healthcare Co., Ltd

InformAI LLC

Inpro medical LLC

InsightRX Inc

Inspire Medical Systems Inc

Intronix Technologies Corporation

Johns Hopkins Kimmel Cancer Center

Jozef Stefan Institute

Koios Medical

Koninklijke Philips NV

Life Whisperer Diagnostics Pty Ltd

Logical Images Inc

Lucence Diagnostics Pte Ltd

Massachusetts General Hospital

Massachusetts Institute of Technology

                                                                                                      Page 5 of 9
     Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth, Status, and Forecast | Admera
                                     Health LLC , Advinow Inc - The Courier

Max Planck Institute for Biological Cybernetics

MaxQ-AI

Mayo Clinic

Medex

MedHub-AI

Medial EarlySign Ltd

Medibio Ltd

Medical Interactive Technologies Ltd

MediLogos Ltd

MedKairos Inc

Meir Medical Center

Merck & Co Inc

Merck KGaA

Microsoft Corp

Minnesota Health Solutions Corporation

MobileODT Ltd

MS Technologies Corp

National Centre of Scientific Research DEMOKRITOS

National Decision Support Co

Natus Medical Incorporated

NE Scientific LLC

Neurocognitive technologies

New York University

Northeastern Illinois University

Norwegian University of Science and Technology

Nuvo Group Ltd.

Ocuvera LLC

Odin Medical Ltd

Ohio University

Oncoradiomics SA

                                                                                                     Page 6 of 9
    Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth, Status, and Forecast | Admera
                                    Health LLC , Advinow Inc - The Courier

Onward Health

OpGen Inc

Optellum Ltd

Optimata Ltd

Oregon Health & Science University

Ortoma AB

Oxford Immunotec Ltd

Paige.AI Inc

Parallax Enterprises

Penumbra Inc

Pharmagest Interactive SA

Predictive Medical Technologies, Inc.

Prescient Medicine LLC

QUIBIM SL

Radiometer Medical ApS

Rambam Health Care Campus

Renalytix AI Plc

Resultados y Calidad del Sistema Sanitario Publico de Andalucia

Retinalyze, LLC

Roche Molecular Systems Inc

Rutgers University

SAS Anapix Medical

Sensyne Health Plc

Siemens Healthineers AG

Signify Health LLC

Sime Diagnostics Ltd

Stanford Bio-X

Stanford University School of Medicine

Stocastic LLC

Stryker Corp

                                                                                                      Page 7 of 9
     Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth, Status, and Forecast | Admera
                                     Health LLC , Advinow Inc - The Courier

Surgical Process Institute Deutschland GmbH

Tactum Ltd

Tailor Bio Ltd

Tempus Health Inc

The Feinstein Institute for Medical Research

The George Institute for Global Health

The Sheikh Zayed Institute for Pediatric Surgical Innovation

Therapeutic Monitoring Systems Inc.

Ultromics Ltd

Unanimous AI Inc

University College London

University Hospital of Parma

University of Arkansas

University of California Los Angeles

University of California San Francisco

University of Campinas Brazil

University of Canterbury

University of Colorado Denver

University of Edinburgh

University of Michigan

University of New Mexico

University of North Carolina at Chapel Hill

University of Pittsburgh

University of South Florida

University of Utah

University of Utah Health Care

University of Vermont

Varian Medical Systems Inc

Visom Technology Inc

Voluntis SA

                                                                                                      Page 8 of 9
     Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth, Status, and Forecast | Admera
                                     Health LLC , Advinow Inc - The Courier

Voxel Healthcare LLC

Vysioneer Inc

Wake Forest Baptist Medical Center

Washington University in St Louis

WISER Systems Inc

Ziliomics Inc

Clinical IT Systems Market Report provides comprehensive information about the Clinical IT Systems pipeline
products with comparative analysis of the products at various stages of development and information about the
clinical trials which are in progress.

Clinical IT Systems include software and system applications used in the clinical departments of healthcare delivery
organizations such as hospitals, clinics and emergency centers. It is a comprehensive, integrated information
system designed to manage the clinical aspects.

Scope of this Report-

- Extensive coverage of the Clinical IT Systems under development

- The report reviews details of major pipeline products which includes, product description, licensing and
collaboration details and other developmental activities

- The report reviews the major players involved in the development of Clinical IT Systems and list all their pipeline
projects

- The coverage of pipeline products based on various stages of development ranging from Early Development to
Approved / Issued stage

- The report provides key clinical trial data of ongoing trials specific to pipeline products

- Recent developments in the segment / industry

Reasons to Buy this Report-

The report enables you to -

- Formulate significant competitor information, analysis, and insights to improve R&D strategies

- Identify emerging players with potentially strong product portfolio and create effective counter-strategies to gain
competitive advantage

- Identify and understand important and diverse types of Clinical IT Systems under development

- Develop market-entry and market expansion strategies

- Plan mergers and acquisitions effectively by identifying major players with the most promising pipeline

- In-depth analysis of the product’s current stage of development, territory and estimated launch date

Single User License: US $ 4000

Get FLAT 25% Discount on this Report @ https://www.reportsnreports.com/purchase.aspx?name=3926471

                                                                                                      Page 9 of 9
     Clinical IT Systems Market Report- Industry Analysis, Size, Share, Growth, Status, and Forecast | Admera
                                     Health LLC , Advinow Inc - The Courier

Table of Contents

1.1 List of Tables

1.2 List of Figures

2. Introduction

3 Products under Development

3.1 Clinical IT Systems - Pipeline Products by Stage of Development

3.2 Clinical IT Systems - Pipeline Products by Segment

3.3 Clinical IT Systems - Pipeline Products by Territory

3.4 Clinical IT Systems - Pipeline Products by Regulatory Path

3.5 Clinical IT Systems - Pipeline Products by Estimated Approval Date

3.6 Clinical IT Systems - Ongoing Clinical Trials

4 Clinical IT Systems - Pipeline Products under Development by Companies

4.1 Clinical IT Systems Companies - Pipeline Products by Stage of Development

4.2 Clinical IT Systems - Pipeline Products by Stage of Development

5 Clinical IT Systems Companies and Product Overview

6 Clinical IT Systems- Recent Developments

7 Appendix


Load-Date: January 8, 2021


  End of Document

                                                                                                          Page 1 of 2
                                            NaturaLawn welcomes new franchise owners




                            NaturaLawn welcomes new franchise owners
                                                       Chicago Daily Herald
                                                  January 19, 2022 Wednesday
                                               WEB EditioneBlast EditionML2 Edition



Copyright 2022 Paddock Publications, Inc.

Section: BUSINESS; Pg. 5
Length: 588 words

Body


NaturaLawn greets franchise owners EAST DUNDEE — NaturaLawn of America, the third largest lawn care
company in the United States, welcomed Trevor and Trent Foss to the family as new owners of the Chicago-area
franchise. The brothers now lead the Chicago location, based in East Dundee, after the loss of their uncle and
former owner Jeff Trewyn to cancer. Both look forward to continuing the work of Trewyn and providing the Chicago
region with NaturaLawn of America's signature blend of service and innovation.

The Chicago branch of NaturaLawn serves regions north and west of Chicago, including McHenry, Woodstock,
Crystal Lake, Naperville, Arlington Heights and surrounding communities. Services include organic-based lawn
fertilization, soil amendments, aeration and seeding, grub control and more. Trevor Foss had previously assisted
the Chicago location with operations, after a long career of professional baseball, playing five years as a pitcher in
affiliated baseball, including two years overseas and two years independently. Surgalign system gets FDA
clearance DEERFIELD — Surgalign Holdings Inc. said Tuesday it has received initial U.S. Food &amp; Drug
Administration clearance for its HOLO Portal surgical guidance system for use within lumbar spine procedures.
"Receiving the initial clearance for the HOLO Portal system is a significant milestone and represents a critical step
toward building the foundation of the digital surgery of the future," said Terry Rich, Surgalign's president and chief
executive officer. "With clearance in hand for our guidance application, our near-term focus is getting the platform
into the hands of surgeons as we work toward a market release." The HOLO Portal system is the world's first
artificial intelligence-driven, augmented reality guidance system for spine surgery and the first clinical application of
Surgalign's HOLOTM AI digital health platform, the company said in a press release. HOLO Portal is the result of
six years of development and testing at Holo Surgical Inc., "While the current capabilities of the HOLO Portal
system have the potential to offer a quantum leap in the way surgical procedures are performed, we have a much
larger vision for our HOLO AI digital health platform across a variety of health care specialties and throughout the
care continuum," Rich said. Parts Town expands with acquisition ADDISON — PT Holdings LLC, the parent
company of food service equipment parts distributor Parts Town, Tuesday said it acquired the REPA Group, a
European leader in parts distribution. Financial terms of the transaction were not disclosed. This global combination
will further enhance the availability, delivery and overall experience of finding and buying spare parts for service
companies, restaurants and institutional customers around the world, PT Holdings said. Steve Snower, CEO of PT
Holdings, will lead the combined organization. Alexander Wiegand, CEO of REPA Group, will continue to lead the
REPA Group's European operation. "We are very excited to welcome the REPA Group to the PT Holdings family.
The REPA team is exceptional, and they have built an incredible business," Snower said. "This combination

                                                                                                      Page 2 of 2
                                   NaturaLawn welcomes new franchise owners

strengthens our global capabilities, will improve the customer experience, and will help improve the availability of
genuine (original equipment manufacturer) parts for our manufacturer partners." The new organization will have
significant operations in the U.S., Canada, Germany, France, Italy, the U.K., Spain and other areas of the world.



Graphic


Trevor Foss Trevor Foss Courtesy of Julie Bonebrake Trevor Foss, owner, NaturaLawn of America Chicago
franchise


Load-Date: January 19, 2022


  End of Document

                                                                                                          Page 1 of 2
                        Lead into the future with clean energy - The Independent Florida Alligator




   Lead into the future with clean energy - The Independent Florida Alligator
                                               Gator Times: University of Florida
                                                  December 5, 2023 Tuesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 691 words

Body


Recently the UF celebrated the opening of its largest and most sustainable building on campus, the iconic
Malachowsky Hall for Data Science and Information Technology.

Florida Clinicians for Climate Action sees much to celebrate. Not only is Malachowsky Hall dedicated to
revolutionizing medical, pharmaceutical and environmental engineering research by applying the power of Artificial
Intelligence , it was also built with sustainability in mind. By minimizing energy efficiencies, installing solar panels,
and utilizing other widely available technologies, Malachowsky Hall was able to apply for the highest sustainability
designation a building can - LEED Platinum. Should Malachowsky Hall receive that status, it will be the only building
on UF's campus to do so.

We applaud the aim of finding solutions to health and environmental questions so complicated many researchers
never dreamed of asking them while still recognizing the need to implement climate solutions today. As clinicians
already caring for patients suffering from the health impacts of a warming climate, we know the need is great.

While Malachowsky Hall and UF's supercomputer, HiPerGator, put UF on the world leaderboard when it comes to
accelerating climate and health solutions research with AI, one wonders why UF has still not publicly examined
how to supply energy to its campus as Malachowsky Hall does - sustainably.

The Rocky Mountain Institute recently published an analysis that shows UF could power its campus by utilizing
energy efficiency upgrades, solar panels and other well-established technologies. While that might sound expensive
to people who don't closely follow climate solutions, it would actually save UF money. A lot of money.

The latest plan announced by UF to supply its own energy - by building the fossil gas-burning Central Energy Plant
on UF's campus - is estimated to cost $115 million more than the RMI sustainable proposal. The significantly more
expensive price is just the up-front difference as it does not include the cost of the gas UF would burn in the CEP or
the health costs from burning fossil fuels next to where people live, study, and work.

Unless UF makes a commitment to provide the same dedication to sustainability it has for Malachowsky Hall to its
campus at large, they will be the very ones driving the climate, environmental and health harms the faculty and
students housed at Malachowsky Hall are working so hard to solve.

                                                                                                         Page 2 of 2
                      Lead into the future with clean energy - The Independent Florida Alligator

According to a study done by the Union of Concerned Scientists, decreasing global greenhouse gas pollution over
the next 13 years will allow Gainesville to avoid experiencing a heat index every summer so high it is literally off the
charts - 127 degrees. It sounds unimaginable, but this expected change to Gainesville's local climate is predicted to
start occurring in just over 10 years should the current trajectory of carbon pollution continue.

The data are clear: when it comes to preventing extreme heat in our lifetimes, the energy supply choices being
made today matter. Fortunately, not only can UF supply its own energy sustainably, it already has a roadmap for
how to do it.

UF halted announcements about the CEP after public outcry locally and across the state, and suggested they could
not change course at the time of the RMI analysis as the past president had announced his resignation and no one
had yet been hired for the position.

Newly installed President Ben Sasse has filled the role and can weigh in. He has already shown leadership through
his support of the sustainable technologies showcased in Malachowsky Hall and by supporting the environmental
and health solutions research being done there. He has a tremendous opportunity to lead on environment and
health by moving forward with a sustainable plan to provide UF its energy.

UF was recently named the #1 Public University in the United States by the Wall Street Journal. That prestigious
ranking is a sign of the forward thinking being done by this university's decision makers. The plan to power the
university using outdated and harmful technologies seems very much at odds with the visionary promise of
Malachowsky Hall.


Load-Date: December 5, 2023


  End of Document

                                                                                                           Page 1 of 2
                                                Mind-boggling implications of AI




                                      Mind-boggling implications of AI
                                                Telegraph Herald (Dubuque, IA)
                                                    July 5, 2023 Wednesday



Copyright 2023 Woodward Communications, Inc. All Rights Reserved

Section: A; Pg. 4
Length: 673 words
Byline: JIM SWENSON for the Telegraph Herald

Body


Nothing in our history better fits the definition of "mind-boggling" than artificial intelligence or AI.

The technology is advancing so quickly that on March 28, an open letter was made public where more 1,100 tech
AI researchers, ethicists, engineers and company executives called for a moratorium on state-of-the-art AI
development.

Since no moratorium had happened by late May, 350 experts - many from among the 1,100 I'm sure - went even
further. They co-signed a simple but scary warning: "Mitigating the risk of extinction from AI should be a global
priority alongside other societal-scale risks such as pandemics and nuclear war."

Other voices in the field quickly downplayed these warnings as exaggerations or self-serving. Yet, aren't we all
supposed to heed similar warnings from climate change experts?

The earlier AI moratorium letter asked some logical questions:

Should we automate away all of the jobs, even the fulfilling ones?

Should we develop nonhuman minds that might eventually outnumber, outsmart, make obsolete and replace us?
Should we risk losing control of our civilization?

I pity the younger generation that now has to worry about eventually facing another life-altering experience.

Researching AI can be exhausting. There is so much out there, and it's constantly changing.

An overwhelming AI positive is in health care. Specific implants already help with things like hearing difficulties,
Parkinson's disease and paralysis.

The technology also is instrumental in early detection and diagnosis of diseases. It helps with redesigning
medications for more effective treatments.

Many of the other "positives" carry with them a consistent negative.

                                                                                                         Page 2 of 2
                                             Mind-boggling implications of AI

It cuts down on human error in every field. (And can replace imperfect humans.)

There are zero injury risks and no need for breaks. (We're already replacing injury-prone, lazy humans on
production lines.)

Digital assistance is fast, clean and perfect. (Who needs humans in your customer service department?)

Unbiased decision-making is insured. (Humans, after all, are driven by emotions; AI is devoid of them.) So far ...

A lot of what inspired me to write about this topic was a recent conversation I had with my brother-in-law, Steve.
He's been ahead of the curve on technology ever since I met him more than 30 years ago.

He's convinced that our species must do whatever it takes to keep up with the advancements in AI, even if that
means becoming more like AI. So, our future could include implanted chips that augment our brains or gene
therapy to supercharge our minds.

In the (near?) future, implanted chips could contain everything you normally would learn from years of education.
You would basically "Google" yourself and know the answers to everything (Why do we need so many imperfect
teachers, anyway?)

My first thought: "Isn't this part of the reason why so many experts want to put a moratorium on this stuff?"

The implications are, well, mind-boggling.

I hope in-person schooling never becomes obsolete, but the chips would certainly reduce the number of years kids
would have to attend.

Would those chips include lessons on perseverance, empathy, teamwork, resilience, compassion and forgiveness
along with the answers to math and science questions?

What about social skills? Studies point out that because of social media, we are becoming a less social species.
The pandemic made it worse. More years alone at home with brain chips instead of in classrooms with other
humans would only make it worse.

Then, there's the future enhancements - which just keep coming at an amazing pace. As programmers get more
savvy, will they insert their AI projects with empathy, compassion and forgiveness?

If not, what would stop AI from taking over and causing the "extinction" that the 350 experts noted in their warning?

I wonder if earth has a better chance of making it through climate change than humankind has of surviving an AI
revolution without boundaries?

It's pretty mind-boggling.

Jim Swenson retired from the Telegraph Herald in 2022 after 37 years in community journalism.


Load-Date: July 6, 2023


  End of Document

                                                                                                        Page 1 of 2
                                      Will Artificial Intelligence ever live up to its hype?




                       Will Artificial Intelligence ever live up to its hype?
                                          The Stute: Stevens Institute of Technology
                                                      April 9, 2021 Friday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1072 words
Byline: John Horgan

Body


When I started writing about science decades ago, artificial intelligence was ascendant. IEEE Spectrum, the
technology magazine for which I worked, produced a special issue on how AI would transform the world. I edited an
article in which computer scientist Frederick Hayes-Roth predicted that AI would soon replace experts in law,
medicine, finance and other professions.

That was 1984. That period of exuberance gave way to a slump known as an "AI winter," when disillusionment set
in and funding declined. In 1998, I tracked Hayes-Roth down to ask how he thought his predictions had held up. He
laughed and replied, "You've got a mean streak." AI had not lived up to expectations, he acknowledged. Our minds
are hard to replicate, because we are "very, very complicated systems that are both evolved and adapted through
learning to deal well and differentially with dozens of variables at one time." Algorithms that can perform a
specialized task, like playing chess, cannot be easily adapted for other purposes. "It is an example of what is called
nonrecurrent engineering," Hayes-Roth explained.

Today, according to some measures, AI is booming once again. Programs such as voice and face recognition are
embedded in cell phones, televisions, cars and countless other consumer products. Clever algorithms help me
choose a Valentine's present for my girlfriend, find my daughter's building in Brooklyn and gather information for
columns like this one. Venture-capital investments in AI doubled between 2017 and 2018 to $40 billion, according
to WIRED. A Price Waterhouse study estimates that by 2030 AI will boost global economic output by more than $15
trillion, "more than the current output of China and India combined."

Some observers fear that AI is moving too fast. New York Times columnist Farhad Manjoo calls an AI-based
reading and writing program, GPT-3, "amazing, spooky, humbling and more than a little terrifying." Someday, he
frets, he might be "put out to pasture by a machine." Elon Musk made headlines in 2018 when he warned that
"superintelligent" AI represents "the single biggest existential crisis that we face." (Really? Worse than climate
change? Nuclear weapons? Psychopathic politicians? I suspect that Musk, who has invested in AI, is trying to
promote the technology with his over-the-top fearmongering.)

Experts are pushing back against the hype, pointing out that many alleged advances in AI are based on flimsy
evidence. Last year, for example, a team from Google Health claimed in Nature that their AI program had

                                                                                                       Page 2 of 2
                                 Will Artificial Intelligence ever live up to its hype?

outperformed humans in diagnosing breast cancer. A group led by Benjamin Haibe-Kains, a computational
genomics researcher, criticized the Google Health paper, arguing that the "lack of details of the methods and
algorithm code undermines its scientific value."

Haibe-Kains complained to Technology Review that the Google Health report is "more an advertisement for cool
technology" than a legitimate, reproducible scientific study. The same is true of other reported advances, he said.
Indeed, artificial intelligence, like biomedicine and other fields, has become mired in a replication crisis.
Researchers make dramatic claims that cannot be tested, because researchers-especially those in industry-do not
disclose their algorithms. One recent review found that only 15 percent of AI studies shared their code.

There are also signs that investments in AI are not paying off. Technology analyst Jeffrey Funk recently examined
40 startup companies developing AI for health care, manufacturing, energy, finance, cybersecurity, transportation
and other industries. Many of the startups were not "nearly as valuable to society as all the hype would suggest,"
Funk reports in IEEE Spectrum. Advances in AI "are unlikely to be nearly as disruptive-for companies, for workers,
or for the economy as a whole-as many observers have been arguing."

The longstanding goal of "general" artificial intelligence, possessing the broad knowledge and learning capacity to
solve a variety of real-world problems, as humans do, remains elusive. "We have machines that learn in a very
narrow way," Yoshua Bengio, a pioneer in the AI approach called deep learning, recently complained in WIRED.
"They need much more data to learn a task than human examples of intelligence, and they still make stupid
mistakes."

Writing in The Gradient, an online magazine devoted to tech, AI entrepreneur and writer Gary Marcus accuses AI
leaders as well as the media of exaggerating the field's progress. AI-based autonomous cars, fake news detectors,
diagnostic programs and chatbots have all been oversold, Marcus contends. He warns that "if and when the public,
governments, and investment community recognize that they have been sold an unrealistic picture of AI's strengths
and weaknesses that doesn't match reality, a new AI winter may commence."

Another AI veteran and writer, Eric Larson, questions the "myth" that one day AI will inevitably equal or surpass
human intelligence. In his new book The Myth of Artificial Intelligence: Why Computers Can't Think the Way We Do,
Larson argues that "success with narrow applications gets us not one step closer to general intelligence." Larson
says "the actual science of AI (as opposed to the pseudo-science of Hollywood and science fiction novelists) has
uncovered a very large mystery at the heart of intelligence, which no one currently has a clue how to solve. Put
bluntly: all evidence suggests that human and machine intelligence are radically different. And yet the myth of
inevitability persists."

When I first started writing about science, I believed the myth of AI. One day, surely, researchers would achieve the
goal of a flexible, supersmart, all-purpose artificial intelligence, like HAL. Given rapid advances in computer
hardware and software, it was only a matter of time. Gradually, I became an AI doubter, as I realized that our
minds-in spite of enormous advances in neuroscience, genetics, cognitive science and, yes, artificial intelligence-
remain as mysterious as ever. Here's the paradox: machines are becoming undeniably smarter-and humans, it
seems lately, more stupid, and yet machines will never equal, let alone surpass, our intelligence. They will always
remain mere machines. That's my guess, and my hope.

John Horgan directs the Center for Science Writings at Stevens. This column is adapted from one originally
published on ScientificAmerican.com.


Load-Date: May 8, 2024


  End of Document

                                                                                                Page 1 of 2
        THE CONVERSATION; Michigan Medicine CTO is engineering health care's efficiency transformation




 THE CONVERSATION; Michigan Medicine CTO is engineering health care's
                    efficiency transformation
                                                     Crain's Detroit Business
                                                          October 23, 2023
                                                            Print Version



Copyright 2023 Crain Communications All Rights Reserved




Section: Pg. 22; Vol. 39
Length: 602 words
Byline: Dustin Walsh

Body


What exactly is the role of a chief transformation officer?

We all know what a CFO does. But the places that have the CTO role; it varies from place to place. I am trained in
operations research. I am faculty in the department of industrial operations and engineering, but I have been doing
health care work for 15 years now. The question we're trying to answer is why health care has not had the same
successes as operational engineering. That's why I started the Center for Healthcare and Patient Safety. My
original training was in airlines and freight. Every problem there sounded like engineering homework. There was
always an optimization. But as engineers, we need to understand the health care system - its language and its
problems. That's where I come in. I am working with clinicians, researchers and students to examine all sorts of
problems. I teach students to work in multi-disciplinary teams. So now I take that same approach, but prioritized
around problems that are the greatest issues at the health system.

How do you solve those problems?

I'm not sure I knew what we were creating when we created it. But we knew there was opportunity here. We knew
we'd find some value. We, like many places, have a disconnect between innovative ideas that can help solve
problems in our health system and a lot of those ideas come from the intersection of disciplines. We're really good
at doing that innovation in an academic setting, but there's a huge gap between having that cool new idea and then
getting it to the doctors or the bedside. I figure out how to bridge that gap. It's always unique to the problem. We
have to weigh how a solution fits into the entire system. Are we fixing one thing, but breaking another? It's never
black or white and all or nothing. We do the deep dive. We figure out, in a complex system, whether fixing this
inpatient care procedure will mess up skilled nursing, etc. We try to have the purview those in the system cannot.

Can you provide an example of this work?

                                                                                               Page 2 of 2
       THE CONVERSATION; Michigan Medicine CTO is engineering health care's efficiency transformation

A current project we did was trying to reduce emails the providers get. It's overwhelming for them and leads to more
burnout. Could we just stop sending those (systemwide) messages? Well, we found the 10 people who get the
most messages and we sent students in to ask questions. Some thought it would be great to get rid of them and
others really wanted them. We discovered providers could pull the reports they wanted in a different way. Some
people got rid of the messages and others got what they wanted with extra data. These are baby steps and seem
easy, but they are important details that get lost in the function of the complex system. It's not about getting rid of
the emails, but finding a strategy to eliminate the burden and give people the right info at the right time.

When we think transformation, we think technology. Isn't that the future of health care?

Technology, wearables, AI, highly specialized cancer regimes, diagnostic imaging; these are all critical to
advancing health care. But how do you get them past the goalpost? What is the context in which you're working
with these technologies? We're lowering the age for a colonoscopy, for instance. That's great until you think about
the people who needed them are now waiting longer. Yes, we need technology to create these solutions. So much
of what we do in a hospital is about duration of time. We need to move faster and I don't believe it's going to look
this way in a decade. But we have to keep framing around what it takes to make it successful in a complicated
system.

READ ALL THE CONVERSATION AT CRAINSDETROIT.COM/THECONVERSATION


Load-Date: October 26, 2023


  End of Document

                                                                                                        Page 1 of 3
                                   How Europe is leading the world in the push to regulate AI




                 How Europe is leading the world in the push to regulate AI
                                                      West Hawaii Today
                                                    June 15, 2023 Thursday



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 West Hawaii Today

Length: 738 words
Byline: KELVIN CHAN AP Business Writer

Body


LONDON - Lawmakers in Europe signed off Wednesday on the world's first set of comprehensive rules for artificial
intelligence, clearing a key hurdle as authorities across the globe race to rein in AI.

The European Parliament vote is one of the last steps before the rules become law, which could act as a model for
other places working on similar regulations.

A yearslong effort by Brussels to draw up guardrails for AI has taken on more urgency as rapid advances in
chatbots like ChatGPT show the benefits the emerging technology can bring.

Here's a look at the EU's Artificial Intelligence Act:

How do the rules work?

The measure, first proposed in 2021, will govern any product or service that uses an artificial intelligence system.
The act will classify AI systems according to four levels of risk, from minimal to unacceptable.

Riskier applications, such as for hiring or tech targeted to children, will face tougher requirements, including being
more transparent and using accurate data.

It will be up to the EU's 27 member states to enforce the rules. Regulators could force companies to withdraw their
apps from the market.

In extreme cases, violations could draw fines of up to 40 million euros ($43 million) or 7% of a company's annual
global revenue, which in the case of tech companies like Google and Microsoft could amount to billions.

What are the risks?

One of the EU's main goals is to guard against any AI threats to health and safety and protect fundamental rights
and values.

That means some AI uses are an absolute no-no, such as "social scoring" systems that judge people based on
their behavior.

                                                                                                        Page 2 of 3
                             How Europe is leading the world in the push to regulate AI

Also forbidden is AI that exploits vulnerable people, including children, or uses subliminal manipulation that can
result in harm, for example, an interactive talking toy that encourages dangerous behavior.

Predictive policing tools, which crunch data to forecast who will commit crimes, is also out.

Lawmakers beefed up the original proposal from the European Commission, the EU's executive branch, by
widening the ban on real-time remote facial recognition and biometric identification in public. The technology scans
passers-by and uses AI to match their faces or other physical traits to a database.

A contentious amendment to allow law enforcement exceptions such as finding missing children or preventing
terrorist threats did not pass.

AI systems used in categories like employment and education, which would affect the course of a person's life, face
tough requirements such as being transparent with users and taking steps to assess and reduce risks of bias from
algorithms.

Most AI systems, such as video games or spam filters, fall into the low- or no-risk category, the commission says.

What about ChatGPT?

The original measure barely mentioned chatbots, mainly by requiring them to be labeled so users know they're
interacting with a machine. Negotiators later added provisions to cover general purpose AI like ChatGPT after it
exploded in popularity, subjecting that technology to some of the same requirements as high-risk systems.

One key addition is a requirement to thoroughly document any copyright material used to teach AI systems how to
generate text, images, video and music that resemble human work.

That would let content creators know if their blog posts, digital books, scientific articles or songs have been used to
train algorithms that power systems like ChatGPT.

Why are the EU rules so important?

The European Union isn't a big player in cutting-edge AI development. That role is taken by the U.S. and China. But
Brussels often plays a trend-setting role with regulations that tend to become de facto global standards and has
become a pioneer in efforts to target the power of large tech companies.

The sheer size of the EU's single market, with 450 million consumers, makes it easier for companies to comply than
develop different products for different regions, experts say.

But it's not just a crackdown. By laying down common rules for AI, Brussels is also trying to develop the market by
instilling confidence among users.

Businesses and industry groups warn that Europe needs to strike the right balance.

Sam Altman, CEO of ChatGPT maker OpenAI, has voiced support for some guardrails on AI and signed on with
other tech executives to a warning about the risks it poses to humankind. But he also has said it's "a mistake to go
put heavy regulation on the field right now."



Graphic


Lawmakers vote on the Artificial Intelligence act Wednesday at the European Parliament in Strasbourg, eastern
France. (AP Photo/Jean-Francois Badias)

                                                                                      Page 3 of 3
                         How Europe is leading the world in the push to regulate AI


Load-Date: December 1, 2023


 End of Document

                                                                                                       Page 1 of 2
                                     PEZA approvals jump 107% to P33-B in Jan-April




                        PEZA approvals jump 107% to P33-B in Jan-April


                                                      ASEAN Tribune
                                                   May 11, 2023 Thursday



Copyright 2023 ASEAN Tribune All Rights Reserved




Length: 341 words

Body


 11 May 2023 (Philippines News agency) The Philippine Economic Zone Authority (PEZA) reported Thursday that
its investment approvals in the first four months of the year jumped by 107.5 percent to PHP33.09 billion from
PHP15.98 billion in the same period in 2022.

In a statement, PEZA Director General Tereso Panga said these pledges came from 60 projects that registered with
the agency from January to April this year.

Panga said these investments are expected to generate additional export revenues of USD1.01 billion and create
7,469 direct jobs.

For April 2023 alone, PEZA registered 14 new and expansion projects -seven came from logistics service
enterprises, four export manufacturing enterprises, and three information technology enterprises.

April 2023 investment pledges surged by 162.37 percent to PHP20.56 billion from PHP7.83 billion in April 2022.

The biggest chunk of the investment approvals came from the PHP19.7-billion manufacturing of biomass fuel
products made from Buyo-buyo (Piper aduncum shrub).

The projected employment from April 2023 pledges is at 2,233 jobs.

'We believe that we are now reaping the results of the ongoing investment missions of President Ferdinand (R.)
Marcos (Jr.) and his administration's investment initiatives and it is now up to us to follow through the pledges,'
Panga said.

The PEZA chief said that with the recent foreign trips of President Marcos, the investment promotion agency
expects to register more foreign investments.

Marcos' recent trip to the United States generated USD1.3 billion in investment leads that could create 6,700 jobs.

                                                                                                               Page 2 of 2
                                   PEZA approvals jump 107% to P33-B in Jan-April

'We hope to attract FDI (foreign direct investment) in advanced manufacturing, EV (electric vehicle) industry, RE
(renewable energy) development, mineral processing, regenerative agriculture, and frontier technologies
particularly in digital health, fintech, blockchain, AI (artificial intelligence) and big data -to boost our mix of industries
and value-adding in the ecozones,' Panga added, citing the Chief Executive's trips to the United Kingdom and
Indonesia.


Load-Date: May 12, 2023


  End of Document

                                                                                                  Page 1 of 2
            Children Who Escaped Boko Haram Captivity Are Tortured In Detention Amnesty International




    Children Who Escaped Boko Haram Captivity Are Tortured In Detention
                          Amnesty International
                                                        The Will (Nigeria)
                                                    May 27, 2020 Wednesday



Copyright 2020 The Will Newspaper All Rights Reserved

Length: 421 words

Body


 SAN FRANCISCO, May 26, (THEWILL) Amnesty International (AI) has revealed that hundreds of children who
escaped from Boko Haram captivity in the north-east are being tortured by the military. It made this known in a 91-
page report, entitled 'We dried our tears', released on Wednesday to commemorate Children's Day addressing the
toll of the Boko Haram war on children, and also examined how the military's detention and torture have
compounded the suffering of the young ones.

 According to AI, these children end up being displaced and are with no access to education. "At worst, they are
arbitrarily detained for years in military barracks, in conditions amounting to torture or other ill-treatment," a
statement by AI read.

  "The UN told Amnesty International it has verified the release of 2,879 children from military detention since 2015,
although it previously cited a higher figure of children detained between 2013 and 2019. "These statistics are likely
to be a vast underestimate, and the UN has said its access to military detention is restricted so it cannot provide the
actual number of children detained in the context of the conflict. "Most such detentions are unlawful children are
never charged or prosecuted for any crime and are denied the rights to access a lawyer, appear before a judge, or
communicate with their families.

The widespread unlawful detentions may amount to a crime against humanity. "Almost everyone fleeing Boko
Haram territory, including children, is 'screened' by the military and Civilian Joint Task Force a process that, for
many, involves torture until the person 'confesses' to affiliation with Boko Haram.

 "Alleged Boko Haram members and supporters are transferred and held, often for months or years, in squalid
conditions in detention centres including Giwa Barracks in Maiduguri and the Kainji military base in Niger state.
"Every former detainee interviewed offered consistent, highly specific descriptions of the conditions: extreme
overcrowding a lack of ventilation amid stifling heat parasites everywhere and urine and faeces on the floor,
because of the lack of toilets.

 "Although there have been some improvements in recent years, many former detainees, including children, also
faced grossly inadequate access to water, food, and health care." AI said many children continue to be held in
such conditions, even after mass releases in late 2019 and early 2020. It estimated that at least 10,000 people,
including many children, have died in detention during the conflict.

                                                                                                Page 2 of 2
          Children Who Escaped Boko Haram Captivity Are Tortured In Detention Amnesty International


Load-Date: June 12, 2020


  End of Document

                                                                                                           Page 1 of 4
                         Biden administration focuses on AI Action comes amid public wariness




    Biden administration focuses on AI; Action comes amid public wariness
                                                      USA Today
                                               December 26, 2023 Tuesday
                                                        1 Edition



Copyright 2023 USA Today All Rights Reserved

Section: NEWS; Pg. A1
Length: 1549 words
Byline: By, Maureen Groppe, USA TODAY

Body


"Government cannot govern AI if it does not understand AI."

Daniel Ho

Stanford law professor who serves on the national committee advising the White House on AI policy

WASHINGTON What if artificial intelligence could prepare the nation for disastrous weather events, root out fraud
and tax cheats, speed up benefit determinations, enforce workplace safety rules and even find illegal rhino horns?

This cutting-edge technology also can undermine privacy, embed discrimination into decision making, erode trust
and create public safety risks.

But now, the federal government has become a proving ground for whether rapidly advancing artificial intelligence -
which President Joe Biden has called "the most consequential technology of our time" will be, or even can be,
embraced by an increasingly wary public.

Biden administration officials, who say they want the federal government to lead by example in the responsible use
of AI, say they're aware how important it is to earn public confidence.

"AI can't build trust. But bad AI can certainly break trust between VA and veterans," Veterans Affairs Secretary
Denis McDonough said in September. "So, we need to get these emerging AI technologies right. If we do,
trustworthy AI can help VA scale our impact, improve our outcomes and speed the delivery of our care."

In October, Biden announced new actions, including proposed rules for how federal agencies can use the
technology, requiring each agency put someone in charge of overseeing AI, and launching a talent search to recruit
AI experts to work for the government.

"Getting technical talent into the federal workforce is the single biggest obstacle for effective regulation," said Daniel
Ho, a law professor at Stanford University who serves on the national committee advising the White House on AI
policy. "Government cannot govern AI if it does not understand AI."

                                                                                                       Page 2 of 4
                         Biden administration focuses on AI Action comes amid public wariness

Ho made that comment at one of the many congressional hearings this year on the uses of AI across the public and
private sectors. Lawmakers are working on legislation to regulate the technology beyond what the administration
can do through executive action.

California Rep. Jay Obernolte, the only member of Congress with an advanced degree in artificial intelligence, said
in March his colleagues needed time to understand the risks of a technology with which few are familiar.

The focus comes as a growing share of Americans are expressing concern about the role AI is playing in daily life.

Only 1 in 10 Americans surveyed this summer by the Pew Research Center said they are more excited than
concerned about the increased use of artificial intelligence. About half (52%) were more concerned than excited, a
14 percentage point increase from eight months earlier.

'Deep accountability challenges'

Researchers at Stanford University and New York University concluded in a 2020 report that AI promises to
transform how government agencies function. But little was known at the time about how the federal government
was using AI beyond a few headline grabbing examples or surface-level descriptions.

And while use was widespread, it was not sophisticated and posed "deep accountability challenges," researchers
warned.

For example, although the law generally requires the government to give a reason for denying a benefit, such as
disability assistance, decisions made by many of the more advanced AI tools are not, by their structure, fully
explainable.

"Even the engineers who design them do not always understand how they reach the conclusions they reach,"
Michigan Sen. Gary Peters, the chairman of the Senate Homeland Security and Governmental Affairs Committee,
said at a March hearing he conducted.

Slow public disclosure

Months after the 2020 report came out, then-President Donald Trump issued an executive order on artificial
intelligence, part of which required agencies to list all nonclassified or nonsensitive uses of AI.

But two years later, about half the large agencies that were known to have used some AI hadn't published the
required inventory, according to a December 2022 study by the Stanford Institute for Human-Centered Artificial
Intelligence.

And some of the published inventories lacked important information. For example, Customs and Border Protection
did not report it was using facial recognition technology to track who is entering and exiting the country.

"The initiative to start cataloging those use cases was an important one, and it's very much work in progress," Arati
Prabhakar, director of the White House Office of Science and Technology Policy, said at a September
congressional hearing when asked about the disclosure rate.

Meanwhile, federal agencies are being inundated with sales pitches from AI companies promising the next big
thing.

"We're hearing from our federal procurement officers that they're basically being bombarded by companies wanting
to demonstrate the promise of their products," Peters said at a September hearing.

Hundreds of AI uses

The government's growing public list of current and planned AI uses includes more than 700 examples. It does not
cover sensitive areas like intelligence gathering and the military. The Defense Department alone has more than 685
unclassified AI projects, according to the nonpartisan Congressional Research Service.

                                                                                                         Page 3 of 4
                        Biden administration focuses on AI Action comes amid public wariness

Disclosures from other agencies show AI is being used to document suspected war crimes in Ukraine, test whether
coughing into a smartphone can detect COVID-19 in asymptomatic people, stop fentanyl smugglers from crossing
the southern border, rescue children being sexually abused and find illegal rhino horns in airplane luggage - among
many other things.

In 2021, the VA became one of the first federal agencies to release an AI strategy. The agency says it's uniquely
suited to advance the use of AI because of its vast data sets of administrative, financial and medical records. And
because many doctors get at least some of their medical training at the VA, the agency can train them in AI as well.

"There's no reason that the VA shouldn't be the world leader in adopting AI into health care practices," Sen. Joe
Manchin, D-W.Va., said at a November hearing on the agency's research.

How the VA is using AI

Early in the coronavirus pandemic, the VA developed a machine learning model to predict how sick a patient would
get from COVID-19.

Another tool uses real-time data to anticipate episodes of post-traumatic stress disorder or the risk of suicide.

For those who've reached out to the Veterans Crisis Line, a natural language processing engine could more quickly
identify and help veterans in crisis.

While the administration touts the benefits of AI, the sweeping executive order that Biden announced in October
tasks federal agencies with roughly 150 action items with urgent deadlines, including proposed new rules to
address issues like privacy and bias.

Well-documented bias in AI

Bias in AI is well-documented, Fei-Fei Li, co-director of the Stanford Institute of Human Centered Artificial
Intelligence, told Congress at a September hearing. For example, predictive tools used to approve or reject loans
are less accurate for low-income minority groups because there's not as much data in their credit histories.

A Stanford study found the IRS audits Black taxpayers at least three times more often than non-Black taxpayers
because of problems in the algorithms used to spot potential tax cheats.

Under the draft policy Biden announced that is still being finalized, safeguards include real-world testing,
independent evaluations and public notification.

If an agency wants to use AI to help determine who qualifies for a social safety net program, officials "would be
required to address algorithmic discrimination and build in an avenue for appeal," Prabhakar, the director of the
White House Office of Science and Technology Policy, said recently. "This is how we get to more responsible use
of AI by government."

Role for Congress regulating AI

Rob Weissman, president of the consumer advocacy organization Public Citizen, said Biden's executive order is
impressive in the breadth and relatively depth of issues it covers.

"However, it's just a first step in that it instructs agencies to take action across a diverse set of areas," he added.
"How impactful the (executive order) is ultimately will depend on those agencies' actions."

It's also, he said, no substitute for Congress putting rules and restrictions into law.

Rep. Nancy Mace, R-S.C., one of the lawmakers working on AI legislation, noted that the administration's recent
guidance to federal agencies arrived two years after the deadline Congress previously set. That makes her
skeptical agencies will meet their new deadlines, "because their track record is pretty useless," she said at a
hearing she chaired this month.

                                                                                                        Page 4 of 4
                       Biden administration focuses on AI Action comes amid public wariness

Rumman Chowdhury, a data and social scientist who has built AI for the past decade, told Mace that AI being used
by the public sector "needs to work for 100% of the people from Day One."

"This is not an Uber for puppies," she said. "These are things that critically matter to individuals. So, we have to be
very careful in how we roll things out so that they're equitable for all."

"Government cannot govern AI if it does not understand AI."

Daniel Ho

Stanford law professor who serves on the national committee advising the White House on AI policy


Load-Date: December 26, 2023


  End of Document

                                                                                                    Page 1 of 2
                                 White Paper Offers Ethics Advice for Government Use of AI




               White Paper Offers Ethics Advice for Government Use of AI
                                                 Government TechNology
                                                 August 16, 2022 Tuesday



Copyright 2022 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 592 words
Byline: Zack Quaintance, Government Technology

Body


Aug. 16—A new white paper seeks to help government and other groups build a responsible future for artificial
intelligence as the technology continues to evolve, specifically stressing the importance of creating redress
mechanisms that can handle flaws as they emerge.

Published by the University of California, Berkeley, the paper is titled AI's Redress Problem, and it joins an
accelerating, cross-sector conversation about how to ensure that ethics and responsibility are part of artificial
intelligence's future. Government is no stranger to this conversation, with New York City, for example, having
released a 116-page strategic vision for how to responsibly benefit from AI. This new white paper encourages all
stakeholders — government among them — to consider potential harm that AI can do, and to plan for addressing
that.

It was authored by Ifejesu Ogunleye, a graduate of the university's Master of Development Practice program, and
Ogunleye conducted this research at the Center for Long-term Cybersecurity's AI Security Initiative.

In a recent conversation about the white paper with Government Technology, Ogunleye discussed some of her key
findings, including the potential for incidental harm, often tied to data sources that have systemic or historical
inequity issues.

"By and large, I don't think you have companies or engineers sitting down and developing things they want to be
biased or harmful," Ogunleye said. "And if you have an AI system that is continuously learning, you haven't mapped
out all the ways it could potentially go wrong, either."

For these reasons, one of Ogunleye's key pieces of advice for government as well as private companies —
including vendors who sell to government — is the idea of redress mechanisms within AI technologies. Essentially,
what that means is that developers include mechanisms in advance that have the ability to stop harmful behaviors
that AI might develop. This, Ogunleye notes, is of increasing importance to society writ large as more sectors
become more reliant on AI, from health care to government to law enforcement to finance.

                                                                                                       Page 2 of 2
                            White Paper Offers Ethics Advice for Government Use of AI

In terms of the practical, the paper goes on to cite some government measures that establish redress mechanisms
in other technologies, specifically within data protection, those being Europe's General Data Protection Regulation
(GDPR) and the California Privacy Rights Act (CPRA), both of which have been much-lauded by advocates for
ethical use of technology.

Higher-level legislation and regulations aside, there are things that lower levels of government can do in this area
as well. For all levels of government, Ogunleye advises that it is important for decision-makers to consider members
of the community as they make use of AI, and to do so in a meaningful way.

"The community is a very important stakeholder that the industry often hasn't kept in touch with or engaged with in a
meaningful way," she said. "It's not just about town hall meetings, it's about taking in feedback in a meaningful way
as you develop these systems."

And, to be sure, these systems have vast potential for government, with proven capabilities to automate tasks
formerly done by humans, improving governmental efficiency and clearing the way for real people to take on higher-
level challenges.

It is not, as of yet, a technology that needs to be feared. Provided, Ogunleye said, it continues to be deployed with
"the proper safeguards and guardrails."

___ (c)2022 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: August 17, 2022


  End of Document

                                                                                                        Page 1 of 3
                  Pausing AI development would be a mistake. Congress shouldn't meddle – for now.




 Pausing AI development would be a mistake. Congress shouldn't meddle –
                               for now.
                                                        USA Today Online
                                                          May 22, 2023



Copyright 2023 Gannett Media Corp All Rights Reserved

Section: US NEWS
Length: 1094 words
Byline: Christopher Koopman and Neil Chilson

Body


Key tech leaders have been worried about artificial intelligence lately. Bill Gates is scared. OpenAI’s Sam Altman
just testified before the Senate Judiciary Committee that Congress should reform liability laws and create a national
or international body to license AI developers. Apple co-founder Steve Wozniak, former presidential hopeful Andrew
Yang and Elon Musk have joined 30,000 others in calling for a six-month pause in AI experiments.

Nonetheless, the U.S. AI industry shouldn’t pause or even ease up. It should extend our lead in the global AI
research race. Our government, on the other hand, should pump the brakes and take a pit stop.

AI could result in the most transformative technologies of our time, a giant engine of growth, and a powerful
example of American ingenuity and global leadership. It is also fraught with challenges. For AI to reach its full
potential and to appropriately address the technology’s challenges, we must learn by doing. That means letting the
technology develop.

Pausing AI research and deployment for six months would squander the technological lead the United States holds
and for little benefit. We would benefit more if Congress committed to pausing its legislative involvement for at least
one year.

Opinions in your inbox:Get exclusive access to our columnists and the best of our columns

Biden should put AI regulation on hold so US can expand innovation lead

Likewise, a hiatus on new regulation across the Biden administration and federal agencies would help the United
States expand its lead in this area. Such a commitment will require all levels of government to exhibit a high level
of restraint and humility, but there is good reason to slow regulatory efforts.

The government doesn’t know enough about AI to regulate it. For example, in Tuesday’s hearing, senators kept
comparing AI with social media. But automated vehicles, AI health diagnostic tools and tech support chatbots have
little in common with each other, let alone with social media. If Congress doesn’t fully understand this technology, it
has no shot at sensible regulation.

                                                                                                         Page 2 of 3
                Pausing AI development would be a mistake. Congress shouldn't meddle – for now.

Link to Image

Furthermore, the rapid pace of AI innovation means policies set today could be out of date by the end of the month.
Worse, misinformed or outdated legislation could block unforeseen and unforeseeable innovations by applying
today’s understanding to tomorrow's technology.

Imagine what would happen if government required licenses and pre-release testing for AI models. The currently
successful companies would have a government-created moat to protect them from competition. In particular, open
source and other decentralized approaches − where some very interesting experimentation is happening − would
be left in the cold.

Can AI write 'Ted Lasso'? Writers strike may open door to ChatGPT-written scripts.

'Godfather of AI' is right: If humans don't get on top of technology, it will destroy us

Some particularly important existing AI applications could suffer as a result. For example, last year, Google
prevented 1.43 million policy-violating apps, and prevented over $2 billion in fraudulent and abusive transactions
leveraging machine learning systems. Apple disabled or blocked more than 400 million fraudulent accounts last
year.

Obviously, this isn’t being done by humans alone. Just last month, Google announced a new AI language model
called Sec-PaLM, which will detect potentially malicious scripts, detect threats and respond instantly. The
cybersecurity threats won't pause. Why should our best efforts to preempt them?

In contrast, when anyone can develop and deploy AI technologies, there is more competition and more ideas are
being tested. More experimentation means more failure but also more success. There are already thousands of AI
applications in the world, and while many might look frivolous or useless, some have already saved lives.

Experimentation with AI can help fulfill technology's potential

And we should welcome more experimentation. The current wave of AI is still new, and we don't yet know all of its
potential.

Not your parents' Google: Why universities should embrace, not fear, ChatGPT and AI

Science fiction come to life? AI holds promise for future generations – but also peril.

We should also be concerned about diversity of thought. No one person’s vision of the future should shape this
technology. Simply because a few voices have risen above the fray does not necessarily mean that their point of
view is correct. But preemptive regulation must reflect something. Without further development of the technology, it
will be a direct reflection of the most prominent and loudest voices in the conversation.

Now, anyone can participate in the development of AI. This brings a wider range of perspectives to the table. We
should continue to welcome those voices rather than stifle attempts to enter the ongoing development of the
technology.

Opinion alerts: Get columns from your favorite columnists + expert analysis on top issues, delivered straight to
your device through the USA TODAY app. Don't have the app? Download it for free from your app store.

Certainly, there are ethical concerns about the various uses of AI. Politicians and regulators should drill down to
actual applications: How will AI be used to make decisions that affect people's lives? Are there new risks from
specific applications of AI? Are those risks addressed under current regulatory framework?

It is only after asking and answering these questions that Congress might consider how it could fill identified gaps.

                                                                                                        Page 3 of 3
                Pausing AI development would be a mistake. Congress shouldn't meddle – for now.

The rapid pace of AI development over the past year has certainly caught Congress by surprise. But that should not
cause Congress to jump straight to legislation. Concern about an issue is not a justification for national policy, and
many new ethical issues are resolved without new legislation.

Instead, we should all be experimenting and learning how to use these technologies. As we do that, we will develop
norms and principles to guide AI use. We can do this without Congress. For at least a year.

Neil Ch i lson is former chief technologist for the Federal Trade Commission. Christopher Koopman is executive
director of the Center for Growth and Opportunity.

You can read diverse opinions from our Board of Contributors and other writers on the Opinion front page, on
Twitter @usatodayopinion and in our daily Opinion newsletter. To respond to a column, submit a comment to
letters@usatoday.com .

This article originally appeared on USA TODAY: Pausing AI development would be a mistake. Congress shouldn't
meddle – for now.


Load-Date: May 22, 2023


  End of Document

                                                                                                        Page 1 of 3
                                   European leaders OK first comprehensive rules for AI




                    European leaders OK first comprehensive rules for AI
                                                Telegraph Herald (Dubuque, IA)
                                                    June 15, 2023 Thursday



Copyright 2023 Woodward Communications, Inc. All Rights Reserved

Section: B; Pg. 6
Length: 833 words
Byline: KELVIN CHAN The Associated Press

Body


BY KELVIN CHAN

The Associated Press

LONDON - Lawmakers in Europe signed off Wednesday on the world's first set of comprehensive rules for artificial
intelligence, clearing a key hurdle as authorities across the globe race to rein in AI.

The European Parliament vote is one of the last steps before the rules become law, which could act as a model for
other places working on similar regulations.

A yearslong effort by Brussels to draw up guardrails for AI has taken on more urgency as rapid advances in
chatbots such as ChatGPT show the benefits the emerging technology can bring - and the new perils it poses.

The European measure, first proposed in 2021, will govern any product or service that uses an artificial intelligence
system. The act will classify AI systems according to four levels of risk, from minimal to unacceptable.

Riskier applications, such as for hiring or tech targeted to children, will face tougher requirements, including being
more transparent and using accurate data.

It will be up to the EU's 27 member states to enforce the rules. Regulators could force companies to withdraw their
apps from the market.

In extreme cases, violations could draw fines of up to 40 million euros ($43 million) or 7% of a company's annual
global revenue, which in the case of tech companies like Google and Microsoft could amount to billions.

One of the EU's main goals is to guard against any AI threats to health and safety and protect fundamental rights
and values.

That means some AI uses are an absolute no-no, such as "social scoring" systems that judge people based on
their behavior.

                                                                                                         Page 2 of 3
                                European leaders OK first comprehensive rules for AI

Also forbidden is AI that exploits vulnerable people, including children, or uses subliminal manipulation that can
result in harm, for example, an interactive talking toy that encourages dangerous behavior.

Predictive policing tools, which crunch data to forecast who will commit crimes, is also out.

Lawmakers beefed up the original proposal from the European Commission, the EU's executive branch, by
widening the ban on real-time remote facial recognition and biometric identification in public. The technology scans
passers-by and uses AI to match their faces or other physical traits to a database.

A contentious amendment to allow law enforcement exceptions such as finding missing children or preventing
terrorist threats did not pass.

AI systems used in categories such as employment and education, which would affect the course of a person's life,
face tough requirements such as being transparent with users and taking steps to assess and reduce risks of bias
from algorithms.

Most AI systems, such as video games or spam filters, fall into the low- or no-risk category, the commission says.

The original measure barely mentioned chatbots, mainly by requiring them to be labeled so users know they're
interacting with a machine. Negotiators later added provisions to cover general purpose AI like ChatGPT after it
exploded in popularity, subjecting that technology to some of the same requirements as high-risk systems.

One key addition is a requirement to thoroughly document any copyright material used to teach AI systems how to
generate text, images, video and music that resemble human work.

That would let content creators know if their blog posts, digital books, scientific articles or songs have been used to
train algorithms that power systems like ChatGPT. Then they could decide whether their work has been copied and
seek redress.

The European Union isn't a big player in cutting-edge AI development. That role is taken by the U.S. and China. But
Brussels often plays a trend-setting role with regulations that tend to become de facto global standards and has
become a pioneer in efforts to target the power of large tech companies.

The sheer size of the EU's single market, with 450 million consumers, makes it easier for companies to comply than
develop different products for different regions, experts say.

But it's not just a crackdown. By laying down common rules for AI, Brussels is also trying to develop the market by
instilling confidence among users.

"The fact this is regulation that can be enforced and companies will be held liable is significant" because other
places like the United States, Singapore and Britain have merely offered "guidance and recommendations," said
Kris Shrishak, a technologist and senior fellow at the Irish Council for Civil Liberties.

"Other countries might want to adapt and copy" the EU rules, he said.

Businesses and industry groups warn that Europe needs to strike the right balance.

"The EU is set to become a leader in regulating artificial intelligence, but whether it will lead on AI innovation still
remains to be seen," said Boniface de Champris, a policy manager for the Computer and Communications Industry
Association, a lobbying group for tech companies.

"Europe's new AI rules need to effectively address clearly defined risks, while leaving enough flexibility for
developers to deliver useful AI applications to the benefit of all Europeans," he said.


Load-Date: June 15, 2023

                                                                         Page 3 of 3
                  European leaders OK first comprehensive rules for AI



End of Document

                                                                                                      Page 1 of 4
             Helping vets. Finding tax cheats and illegal rhino horns. How AI could transform government




      Helping vets. Finding tax cheats and illegal rhino horns. How AI could
                              transform government
                                                        USA Today Online
                                                        December 13, 2023



Copyright 2023 Gannett Media Corp All Rights Reserved

Length: 1546 words
Byline: Maureen Groppe, USA TODAY

Body


WASHINGTON − What if artificial intelligence could prepare the nation for disastrous weather events, root out fraud
and tax cheats, speed up benefit determinations, enforce workplace safety rules − and even find illegal rhino horns?

This cutting-edge technology also can undermine privacy, embed discrimination into decision making, erode trust
and create public safety risks.

But now, the federal government has become a proving ground for whether rapidly advancing artificial intelligence –
which President Joe Biden has called “the most consequential technology of our time” − will be, or even can be,
embraced by an increasingly wary public.

Biden administration officials, who want the federal government to lead by example in the responsible use of AI, say
they’re aware how important it is to earn public confidence.

“AI can’t build trust. But bad AI can certainly break trust between VA and veterans,” Veterans Affairs Secretary
Denis McDonough said in September. “So, we need to get these emerging AI technologies right. If we do,
trustworthy AI can help VA scale our impact, improve our outcomes and speed the delivery of our care.”

Link to Image

Biden's new AI executive order

In October, Biden announced new actions, including proposed rules for how federal agencies can use the
technology, requiring each agency put someone in charge of overseeing AI, and launching a talent search to recruit
AI experts to work for the government.

“Getting technical talent into the federal workforce is the single biggest obstacle for effective regulation,” said Daniel
Ho, a law professor at Stanford University who serves on the national committee advising the White House on AI
policy. “Government cannot govern AI if it does not understand AI.”

                                                                                                    Page 2 of 4
           Helping vets. Finding tax cheats and illegal rhino horns. How AI could transform government

Ho made that comment at one of the many congressional hearings this year on the uses of AI across the public and
private sectors. Lawmakers are working on legislation to regulate the technology beyond what the administration
can do through executive action.

California Rep. Jay Obernolte, the only member of Congress with an advanced degree in artificial intelligence, said
in March his colleagues needed time to understand the risks of a technology with which few are familiar.

The intense focus comes as a growing share of Americans are expressing concern about the role AI is playing in
daily life.

Only 1 in 10 Americans surveyed this summer by the Pew Research Center said they are more excited than
concerned about the increased use of artificial intelligence. About half (52%) were more concerned than excited, a
14 percentage point increase from eight months earlier.

'Deep accountability challenges'

Researchers at Stanford University and New York University concluded in a 2020 report that AI promises to
transform how government agencies function. But little was known at the time about how the federal government
was using AI beyond a few headline grabbing examples or surface-level descriptions.

And while use was widespread, it was not sophisticated and posed “deep accountability challenges,” researchers
warned.

For example, although the law generally requires the government to give a reason for denying a benefit, such as
disability assistance, decisions made by many of the more advanced AI tools are not, by their structure, fully
explainable.

“Even the engineers who design them do not always understand how they reach the conclusions they reach,”
Michigan Sen. Gary Peters, the chairman of the Senate Homeland Security and Governmental Affairs Committee,
said at a March hearing he conducted.

Slow public disclosure

Months after the 2020 report came out, then-President Donald Trump issued an executive order on artificial
intelligence, part of which required agencies to list all non-classified or non-sensitive uses of AI.

But two years later, about half the large agencies that were known to have used some AI hadn’t published the
required inventory, according to a December 2022 study by the Stanford Institute for Human-Centered Artificial
Intelligence.

And some of the published inventories lacked important information. For example, Customs and Border Protection
did not report it was using facial recognition technology to track who is entering and exiting the country.

Link to Image

“The initiative to start cataloging those use cases was an important one, and it’s very much work in progress,” Arati
Prabhakar, director of the White House Office of Science and Technology Policy, said at a September
congressional hearing when asked about the disclosure rate.

Meanwhile, federal agencies are being inundated with sales pitches from AI companies promising the next big
thing.

“We're hearing from our federal procurement officers that they're basically being bombarded by companies wanting
to demonstrate the promise of their products,” Peters said at a September hearing.

                                                                                                     Page 3 of 4
            Helping vets. Finding tax cheats and illegal rhino horns. How AI could transform government

Hundreds of AI uses

The government’s growing public list of current and planned AI uses includes more than 700 examples. It does not
cover sensitive areas like intelligence gathering and the military. The Defense Department alone has more than 685
unclassified AI projects, according to the nonpartisan Congressional Research Service.

Disclosures from other agencies show AI is being used to document suspected war crimes in Ukraine, test whether
coughing into a smartphone can detect COVID-19 in asymptomatic people, stop fentanyl smugglers from crossing
the southern border, rescue children being sexually abused and find illegal rhino horns in airplane luggage – among
many other things.

In 2021, the VA became one of the first federal agencies to release an AI strategy. The agency says it’s uniquely
suited to advance the use of AI because of its vast data sets of administrative, financial and medical records. And
because many doctors get at least some of their medical training at the VA, the agency can train them in AI as well.

“There's no reason that the VA shouldn't be the world leader in adopting AI into health care practices,” Sen. Joe
Manchin, D-W.Va., said at a November hearing on the agency’s research.

How the VA is using AI

Early in the coronavirus pandemic, the VA developed a machine learning model to predict how sick a patient would
get from COVID-19.

Another tool uses real-time data to anticipate episodes of post-traumatic stress disorder or the risk of suicide.

For those who’ve reached out to the Veterans Crisis Line, a natural language processing engine could more quickly
identify and help veterans in crisis.

Link to Image

While the administration touts the benefits of AI, the sweeping executive order that Biden announced in October
tasks federal agencies with roughly 150 action items with urgent deadlines, including proposed new rules to
address issues like privacy and bias.

Well-documented bias in AI

Bias in AI is well-documented, Fei-Fei Li, co-director of the Stanford Institute of Human Centered Artificial
Intelligence, told Congress at a September hearing. For example, predictive tools used to approve or reject loans
are less accurate for low-income minority groups because there’s not as much data in their credit histories.

And a Stanford study found that the IRS audits Black taxpayers at least three times more often than non-Black
taxpayers because of problems in the computer algorithms used to spot potential tax cheats.

Under the draft policy Biden announced that is still being finalized, safeguards include real-world testing,
independent evaluations and public notification.

If an agency wants to use AI to help determine who qualifies for a social safety net program, officials “would be
required to address algorithmic discrimination and build in an avenue for appeal,” Prabhakar, the director of the
White House Office of Science and Technology Policy, said recently. “This is how we get to more responsible use
of AI by government.”

Role for Congress regulating artificial intelligence

Rob Weissman, president of the consumer advocacy organization Public Citizen, said Biden’s executive order is
impressive in the breadth and relatively depth of issues it covers.

                                                                                                     Page 4 of 4
            Helping vets. Finding tax cheats and illegal rhino horns. How AI could transform government

“However, it’s just a first step in that it instructs agencies to take action across a diverse set of areas,” he added.
“How impactful the (executive order) is ultimately will depend on those agencies’ actions.”

It’s also, he said, no substitute for Congress putting rules and restrictions into law.

Rep. Nancy Mace, R-S.C., one of the lawmakers working on AI legislation, noted that the administration’s recent
guidance to federal agencies arrived two years after the deadline Congress previously set. That makes her
skeptical agencies will meet their new deadlines, "because their track record is pretty useless," she said at a
hearing she chaired last week.

Rumman Chowdhury, a data and social scientist who has built AI for the past decade, told Mace that AI being used
by the public sector "needs to work for 100% of the people from Day One."

"This is not an Uber for puppies," Chowdhury said. "These are things that critically matter to individuals. So, we
have to be very careful in how we roll things out so that they’re equitable for all.”

Don't get fooled How to spot artificial intelligence deepfakes

This article originally appeared on USA TODAY: Helping vets. Finding tax cheats and illegal rhino horns. How AI
could transform government


Load-Date: December 21, 2023


  End of Document

                                                                                                          Page 1 of 2
                    UMaine hosts webinar on artificial intelligence and its applications for healthcare




      UMaine hosts webinar on artificial intelligence and its applications for
                                   healthcare
                                            The Main Campus: University of Maine
                                                      October 5, 2020 Monday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 635 words
Byline: David DiMinno

Body


On Oct. 1, 2020, the University of Maine hosted a webinar over Zoom to talk about the practical applications of
artificial intelligence in today's society. The webinar focused on artificial intelligence applications in the fields of
industry, government, healthcare, and the environment. The seminar was the first in the UMaine AI lunch and learn
series. Speaking during the program was Associate Dean of Engineering Mohamad Musavi, President and Co-
founder of MedRhythms Inc. Owen McCarthy and Software Architect at Activas Diagnostics Somayeh Khosroazad.

Musavi opened up as the first speaker, and mainly spoke on the background of artificial intelligence and how it
works. The main purpose of this technology is to act similarly to that of humans, to properly demonstrate how to
learn tasks. The key is using artificial neural networks, which try to mimic similar functions of the human brain. The
human brain is a network of 80-100 billion neurons, and computers try and replicate that with billions of transistors
that can perform trillions of micro-operations in seconds. This wiring is the way to craft artificial neurons that mimic
processing functions and adaptability. By imputing pieces of data, the program can learn over time, and acquires
knowledge to better accomplish tasks. According to Musavi's presentation, four primary functions of artificial
intelligence in industry are classification, clustering, function and prediction. This can range from chromosome
classification in the medical field to predicting brightness and opacity. Several industries can make use of neural
networks to accomplish tasks in an automated and effective fashion.

"Whenever there is data, neural networks can provide insight into an event or process," Musavi stated.

McCarthy took a deeper dive into the benefits of AI in regulated health care. While there are fears that AI has the
potential to make physicians obsolete, McCarthy made the argument for why that isn't the case. AI can serve the
purpose of autonomous actions of treatment, dominantly in radiology as of right now. Programs are able to learn
from imputed data and better diagnose cases for patients. AI has also been helping the United States Food and
Drug Administration as well.

"Products that are FDA approved are ones that have to do with safety and efficacy related to treating, diagnosing
and curing a disease," McCarthy said. She also spoke on how AI is working in the field of dermatology, being able
to detect malignancies in skin abnormalities and deduce whether or not they are detrimental to one's health.

                                                                                                          Page 2 of 2
                    UMaine hosts webinar on artificial intelligence and its applications for healthcare

Khosroazad focused her presentation on AI in healthcare as well. AI works well to categorize problems and better
craft a plan to diagnose issues.

"We categorize AI problems, from a specific view to two groups, some specific problems in which a huge amount of
data is collected and AI, supervised or unsupervised, tries to classify the data to multiple groups by finding by
finding one or more thresholds or some limits, based on all statistical and problematic logics that are predefined for
it. The AI then directly works with that data," Khosroazad said.

The AI can then differentiate the data into either an expected outcome, and try to diagnose it, or can recognize
abnormalities in the data, and bring it to the attention of physicians. AI is also being used in asleep signal analysis
for early detection of Alzheimer's disease and dementia. The AI records sleep signals and is able to recognize what
those signals represent for deteriorating brain activity with the help of physicians.

Artificial intelligence has come a long way in the past decades, and will continue to take steps forward to better aid
society in government, healthcare and the environment. The webinar will be made available to everyone on
UMaine's AI homepage.


Load-Date: October 6, 2020


  End of Document

                                                                                                        Page 1 of 2
                                         Goat Reproduction Clinic to be held on Sept. 25




                          Goat Reproduction Clinic to be held on Sept. 25
                                             Advance-News (Ogdensburg, New York)
                                                      September 19, 2021
                                                          Both Edition



Copyright 2021 Johnson Newspaper Corporation
Distributed by Newsbank, Inc. All Rights Reserved

Section: ADV_NEWS; Pg. A9
Length: 690 words
Byline: JUSTIN TUCKER AgEducator Cornell Cooperative Extension

Body


A Goat Reproduction Clinic is being held at Tucker's Ranch, 299 Hazen Road, North Lawrence, at 10 a.m. Sept.
25.

The most common reasons for breeding goats is for the production of milk, meat and fiber. A male goat is called a
buck, unless it's castrated, and then it's called a wether. Female goat's, also called doe's, will typically give birth
(kidding) in the springtime, usually having one to three kids. Did you know that baby goats are called kids?

 Farmers are trying to keep up with the demand for goat products. Artificial insemination helps farmers maximize
their herd genetics and profits. Keeping good records throughout the year helps to ensure a successful breeding
program. If you're using a buck to breed then be sure to keep records of when the doe's come into cycle. Some
breeders will choose to use a hand selected buck to breed their does and others use artificial insemination (AI).
Both ways have some pros and cons depending on what your goals are and depending on how much time, labor,
and money you want to put into your breeding program.

 There are 14 common breeds in America: Nubian, Alpine, LaMancha, Oberhasli, Saanen, Sable, Toggenburg,
Boer, Nigerian Dwarf, Angora, Pygmy, Myotonic (2 types), and Crossbred breeds. Each breed has some individual
characteristics that compliment their individual qualities. Goats are a hardy, small ruminant breed that can be very
adaptable, fun, and profitable. They are the perfect size for many situations such as raising a few as pets or in
larger numbers for the production of dairy products or meat. Many different products are made from raw goat's milk
such as soaps, lotions, fluid beverage products (low fat, flavored, or fortified), frozen products such as ice cream or
frozen yogurt, and ultra-high temperature (UHT) milk and fermented products such as cheese and yogurt. Many
other products are produced as well.

 There are several reasons for AI which include herd health improvements such as; conception rate, number of
kids (newborn goats) born alive, multiple pregnancies of twins and triplets, number of surviving kids at weaning age,
and their performance at each phase. By breeding with AI, the breeder can use superior sires to maximize genetic
improvements in the herd.

                                                                                                        Page 2 of 2
                                  Goat Reproduction Clinic to be held on Sept. 25

 Using AI also prevents the spread of diseases and helps limit the genetic base by only using a few bucks, in turn
reducing the spread of any unwanted genetic defects. One buck can naturally breed anywhere from 20-30 doe's, if
using AI, the breeder could use semen from one buck to breed an entire herd, eliminating the need for a buck
entirely in some situations. Some breeders will choose to lease their buck to other farms and might trade the use of
the buck during breeding season, in exchange for boarding the animal for the winter months. Sometimes this is a
good option for someone that does not have housing for a buck all year. Bucks can be difficult to keep separate
from the doe's if the correct fencing is not used. They can also be somewhat obnoxious, especially during the
breeding season. They tend to have a very distinct smell of urine during the fall months.

 Determining the health of the doe at breeding time is critical to how the doe might respond to each reproduction
method. Always make sure your bucks and doe's are in optimal health prior to breeding because the health of
each animal will determine the efficiency of your breeding program.

 A doe's estrous cycle is 21 days, usually takes place in the fall and lasts for 24 to 48 hours. Their gestation cycle
lasts 145 to 155 days. Hormones can be used in sequence to stimulate follicular development, control CL function,
and regulate ovulation. Sometimes breeders will choose an Estrus Synchronization protocol to ensure a uniform kid
crop and to properly manage the pregnant doe's. Take good notes throughout the entire process and make the
correct adjustments to your breeding program along the way. Each situation is unique, so try to evaluate what fits
your situation best (Natural or AI). Establish a list of genetic traits you are looking to improve in your herd and see
which method works best for your farm.



Graphic


A Goat Reproduction Clinic is being held at Tucker's Ranch, 299 Hazen Road, North Lawrence, on Sept. 25 at 10
a.m. Pexels


Load-Date: September 19, 2021


  End of Document

                                                                                                        Page 1 of 2
                                   Talking Tech : The biggest tech stories of 2023 (so far)




                   Talking Tech: The biggest tech stories of 2023 (so far)
                                                        USA Today Online
                                                          July 20, 2023



Copyright 2023 Gannett Media Corp All Rights Reserved

Length: 497 words
Byline: Brett Molina, USA TODAY

Body


Happy Thursday, Talking Tech readers! It's Brett Molina ready with your weekly dose of technology news.

It's July, which means we've crossed the halfway point of 2023. Yes, we're six months away from a new year. Hard
to imagine.

With that in mind, let's take a moment to reflect on some of the biggest stories in technology, so far. This could all
likely change by the time we hit Dec. 31, 2023, but here are some of the big topics dominating tech in the first six
months.

The rise of AI

The use of artificial intelligence through tools like ChatGPT is undoubtedly the biggest tech story of 2023. It's
starting to upend how we search online. AI has infiltrated health, education and travel, and it's got a lot of people
worried we'll lose our jobs. So yeah, it's kind of a big deal.

Americans fear AI will make society's ills worse, and want top tech companies to do something about it, said a May
survey from the Anti-Defamation League.

I just have one question: Has anyone working on AI watched "The Terminator"

The (possible) fall of Twitter

A lot has changed since Elon Musk formally took over Twitter last year. They've laid off staff, eased up on content
moderation, and are pushing users to subscribe to Twitter Blue for perks such as blue-check verification. In May,
Twitter hired a new CEO, former NBCUniversal exec Linda Yaccarino, to help turn things around.

But it won't get any easier with the arrival of Threads, the Twitter competitor from Facebook parent company Meta
that drew 100 million users in less than a week.

What will Twitter look like by the end of 2023? Stay tuned.

The end of an era at Netflix

                                                                                                       Page 2 of 2
                               Talking Tech : The biggest tech stories of 2023 (so far)

Breakups are hard, even when it means telling your kids, or parents, or friends they can't use your Netflix account
anymore. In May, Netflix cracked down on password sharing. If you have a Netflix account and want to add
someone outside your household, you have to pay an extra $8 a month. Sorry, kids, but you're going to have to
watch Outer Banks on your dime. (Oh, and Netflix just changed up pricing plans again.)

Apple dives into mixed reality

Tough to revisit the year's biggest tech stories so far without addressing Apple. Their long-rumored mixed reality
headset became official with the introduction of Apple Vision Pro during its annual Worldwide Developers
Conference.

The headset that appears straight out of "Ready Player One" uses both augmented and virtual reality, is controlled
with only your voice, head and hands, and costs a mere $3,499. Safe to say this isn't a tech gadget for the masses.

Thursday tech tip

Got a big trip planned this summer? If it involves hitting the road, make sure to take these seven apps with you.

One more thing

More of us are using payment apps like Venmo or PayPal to receive or give money. That's got the attention of the
Internal Revenue Service. Should you worry? Here's what to know.

Thanks for reading! Until next Thursday.

This article originally appeared on USA TODAY: Talking Tech: The biggest tech stories of 2023 (so far)


Load-Date: August 11, 2023


  End of Document

                                                                                                   Page 1 of 4
  Baltimore competes to be national tech hub Officials hoping to generate an economic boost - upward of $3.2B -
                                           to add 52,000 jobs by 2030




                 Baltimore competes to be national tech hub
  Officials hoping to generate an economic boost - upward of $3.2B - to add
                             52,000 jobs by 2030
                                                       The Baltimore Sun
                                                   August 15, 2023 Tuesday
                                                           First Edition



Copyright 2023 The Baltimore Sun Company All Rights Reserved

Section: MAIN; A; Pg. 1
Length: 1564 words
Byline: Lorraine Mirabella

Body


Baltimore-area leaders aim to be in the running to become a national tech hub similar to Silicon Valley or Boston as
the city competes for a federal designation and billions of dollars in funding.

A 35-member consortium led by the Greater Baltimore Committee is finalizing a bid seeking to become one of 20 or
more cities or regions chosen for the federal Tech Hubs Program.

If it succeeds, federal funding - an estimated $500 million over five years - is expected to generate $3.2 billion in
economic impact and 52,000 jobs by 2030 in a region including Baltimore and seven surrounding counties, GBC
officials say.

"This is a historic, once-in-a-generation type of designation and funding opportunity because of the size of funding,"
said Pothik Chatterjee, GBC's chief economic officer. "We believe the Baltimore region has a strong opportunity to
win based on the strengths of our assets."

The $10 billion economic development initiative, approved as part of the federal CHIPS and Science Act of 2022,
aims to spur technology-related manufacturing and commercialization in parts of the country with potential to
become globally competitive and create jobs in 10 years. Applications are due Tuesday to the U.S. Commerce
Department's Economic Development Administration, which plans to announce selections in September.

The program aims to diversify technology investment and development beyond Silicon Valley, Boston and New
York, which currently attract 80% of tech funding. Others reportedly seeking designations include Richmond,
Virginia; Toledo, Ohio; and Houston, as well as regions of Colorado, Michigan

and North Carolina.

                                                                                                   Page 2 of 4
  Baltimore competes to be national tech hub Officials hoping to generate an economic boost - upward of $3.2B -
                                           to add 52,000 jobs by 2030

Baltimore's group describes its hub as focusing on the intersection of artificial intelligence and biotechnology, an
area still in the early stages of adoption. It refers to the use of artificial intelligence and machine learning on health
data for applications such as diagnostics and drug development.

The consortium says the area is primed to combine artificial intelligence, machine learning and autonomy with
biotech, medical technology, genomics and synthetic biology, and to commercialize technologies that can improve
health at the individual, community and national levels.

"We're saying that our Baltimore region is going to be globally competitive at the intersection of those two tech
focus areas," Chatterjee said.

The technology can be used in areas such as clinical decision-making, bioethics, development of personalized
medicine and new therapeutics. Other goals include developing advanced biomanufacturing capabilities and
developing advanced med-tech manufacturing.

The consortium estimates an economic impact of $3.2 billion in the region by 2030 and a global economic impact of
$600 billion by that year.

The group includes historically Black colleges and universities Morgan State University and Coppin State
University, along with the Johns Hopkins University, Loyola University Maryland, University of Maryland Medical
Center, University of Maryland Baltimore, University of Maryland, Baltimore County, Towson University, Harford
Community College and Cecil College.

Other members are local businesses, workforce development organizations, and state and local governments, and
economic development agencies. Over three months of meetings, the group has identified 40 tech-related projects
requiring $700 million in funding. In addition, 60 area tech firms have offered letters of support for the bid.

Some area companies supporting the effort include Haystack Oncology, which developed testing technology to aid
in early detection of cancer; EpiWatch, which developed an app to help manage epilepsy; and Bullfrog AI, which
uses machine learning to develop pharmaceuticals.

"The world is moving digital, and technology is the backbone to all of that," said Todd Marks, founder, president and
CEO of Baltimore-based Mindgrub Technologies, a consortium member. "By being a tech hub ... [the region] is
going to get that much more attention, and then fast-forward 10, 15, 20 years, it's going to be phenomenal for us."

The Baltimore region already should be recognized for its assets and advances in med tech and other technologies,
but often is not seen that way, he said.

The region - which includes Baltimore City and Anne Arundel, Baltimore, Harford, Howard, Carroll, Cecil and Queen
Anne's counties - has an advantage as home to more than 400 tech startups with access to federal and academic
research and development spending and more than a dozen accelerators supporting companies, Chatterjee said.

The region also has a history of commercialization in medical diagnostics, health care analytics, medical devices,
and gene and drug therapeutics. With a diverse racial population, the region has a chance as well to develop an
equitable and inclusive tech hub, he said.

"With the private institutes we have here and the universities, I think we have the ideal ecosystem for hosting such
a hub," said Willie E. May, vice president of research and economic development and a chemistry professor at
Morgan State. "We think we have all of the components that are necessary to put together an innovative, vibrant
and thriving tech hub to move this country forward in this area."

The bid marks one of the GBC's first big initiatives under the leadership of Mark Anthony Thomas, who steered
economic development in Pittsburgh, New York and Los Angeles before replacing longtime GBC CEO Donald Fry
in December, taking over a group that merged last year with the Economic Alliance of Greater Baltimore. In
unveiling a 10-year strategy for the city and region in May, Thomas said economic expansion could be fueled by

                                                                                                   Page 3 of 4
  Baltimore competes to be national tech hub Officials hoping to generate an economic boost - upward of $3.2B -
                                           to add 52,000 jobs by 2030

more involvement from the private sector, working collaboratively with government and community members, with
GBC as an active leader.

"What has been really inspiring is to see how GBC has stepped into this coalition-building role," said Andrew Coy,
CEO of Digital Harbor Foundation, a consortium member that works to create pathways from the classroom to
future technology careers.

"I'm really encouraged to see how this moment is taking shape," he said, with members thinking broadly about
what's best for the region and making room for each other's ideas.

"It does feel like we're all linking arms and ... bringing this type of energy to the region," Coy said. "There's more
than enough work for everyone to do their piece of it."

The region's proposal outlines several ideas for building the hub, each of which includes collaboration with various
combinations of stakeholders.

One concept involves creating an accelerator and funding program that would invest in AI-based therapeutic
ventures led by minority entrepreneurs, with partners such as Blackbird Labs, Fearless, Johns Hopkins, University
of Maryland, Upsurge and Morgan State. Another proposes building a physical center to anchor the hub.

Morgan State will be developing property near its campus that could house hub-related facilities, May said. And
three of Morgan's state-funded research centers could play a role as well, including the Center for Equitable AI &
Machine Learning Systems, the Cybersecurity Assurance & Policy Center and a new Center for Education and
Research in Microelectronics, where a small chips manufacturing facility will be installed for education and
demonstration purposes.

"We want to be in a position to support the future workforce in this area of advanced chips manufacturing," May
said.

The proposal also calls for bio-manufacturing facilities that could produce biomaterials; lab infrastructure to support
biotech; and life sciences startups and workforce development and training.

Coy said that if the region's bid is successful, he would like to see efforts to "help young people in Baltimore today
see that they can be a part of that picture" of emerging tech careers. Programs, which would be fleshed out later in
the hub designation process, could take many forms, from mentorships to workshops at rec centers hosted by
professionals in emerging industries.

The bid's regional focus means participation from surrounding counties.

"I really feel like Howard County is in a good position to strengthen that application and also benefit from it," said
Jennifer Jones, CEO of the Howard County Economic Development Authority.

The authority already is working to scale up emerging technology through the Maryland Innovation Center in
Columbia, where about 30 incubator tech and other startups are getting help growing and promoting businesses.

A tech hub designation and funding would allow the center to expand its work to more of the county and the broader
region and better cultivate an emerging technology pipeline, Jones said.

Areas selected as hubs in September will be eligible to move on to a second phase to apply for funding for specific
projects. An initial pool of $500 million of the $10 billion has been allocated to distribute among all hubs in the first
phase.

A hub in Baltimore would not only stem the city's declining population and attract businesses and tech jobs, but
could have national implications, helping to control rising health care costs, Chatterjee said.

Studies have shown that broader adoption of AI in health care can lead to cost savings of 5% to 10%, he said.

                                                                                                   Page 4 of 4
  Baltimore competes to be national tech hub Officials hoping to generate an economic boost - upward of $3.2B -
                                           to add 52,000 jobs by 2030

"By growing our AI and biotech ecosystem in Baltimore," he said, "we can help contribute to national priorities
around reining in health care spending."


Load-Date: August 15, 2023


  End of Document

                                                                                                        Page 1 of 2
                       UChicago expands relationship with Weizmann Institute of Science in Israel




 UChicago expands relationship with Weizmann Institute of Science in Israel
                                       The Pulse: Finch University of Health Sciences
                                                December 7, 2022 Wednesday



University Wire
Copyright 2022 UWIRE via U-Wire All Rights Reserved

Section: LATESTSTORIES; Pg. 1
Length: 645 words
Byline: Emily Ayshford and Marie Bejarano

Body


The University of Chicago and the Weizmann Institute of Science in Israel will support collaborative research in
quantum information sciences and artificial intelligence, in a partnership that also includes the Toyota Technological
Institute at Chicago.

This expanded partnership builds on the existing Marshall and Arlene Bennett Family Research Program, which
funds research between UChicago and the Weizmann Institute of Science in life sciences, physical sciences, and
engineering. Led by UChicago's Office of Science, Innovation, National Laboratories, and Global Initiatives, the
partnership will prioritize new research that leverages AI for new discoveries in biology and materials science, and it
will promote fundamental discoveries in quantum information sciences and engineering. The collaboration among
institutions has the potential to build solutions that can scale globally to benefit humanity.

In a first step, the expanded partnership has awarded more than $1 million in research funding for three
collaborative projects that advance the scientific domain and have significant impact in science and technology and
travel grants for three additional research teams. Research topics for the funded projects include applications of
artificial intelligence in medicine and materials science, as well as quantum information sciences with applications to
communication networks.

"The University of Chicago's commitment to scholarly work that shapes and defines fields of study is strengthened
through international and cross-institutional collaborations like this," said University of Chicago President Paul
Alivisatos. "The Weizmann Institute of Science is a world-class partner, and together we can forge a much deeper
understanding of the foundations of data science and artificial intelligence and develop new beneficial uses."

"The Weizmann Institute has a long history of international collaborations that have inspired scientists to make a
collective impact on global challenges," said Alon Chen, president of the Weizmann Institute. "We look forward to
continue to partner with the University of Chicago to combine our strengths in this new era of artificial intelligence
and quantum science."

"I am thrilled to see that my family's research program has inspired a global initiative between these three renowned
institutions," said Bija Bennett, director and president of the Bennett Family Foundation.

                                                                                                           Page 2 of 2
                     UChicago expands relationship with Weizmann Institute of Science in Israel

The Weizmann Institute of Science in Israel, one of the world's leading basic research institutions, is composed of
250 experimental and theoretical research groups across five faculties-biology, biochemistry, chemistry,
mathematics and computer science, and physics.

The Toyota Technological Institute at Chicago is an academic computer science institute dedicated to basic
research and graduate education. The institute is located on the UChicago campus and has a close affiliation with
the University of Chicago's Department of Computer Science.

The AI projects in health and biology will seek to use artificial intelligence to improve our ability to understand the
rules of life-from the molecular scale to multicellular organisms and ecosystems. In materials science, researchers
will explore how to leverage AI to predict the properties and guide the design and synthesis of new materials.

"Artificial intelligence and quantum information science have the potential to propel innovations that will cut across
multiple domains," said Juan de Pablo, executive vice president for science, innovation, national laboratories, and
global initiatives at the University of Chicago. "It is with trans-institutional efforts like these that true advancements
emerge. We are honored to work with these institutions, and these grants are the first step in what we hope will be
a long and fruitful partnership that results in exciting, field-defining breakthroughs."


Load-Date: December 8, 2022


  End of Document

                                                                                                        Page 1 of 2
                          BofA acquisition makes its health care payments business more nimble




    BofA acquisition makes its health care payments business more nimble
                                                       americanbanker.com
                                                       April 5, 2021 Monday



Copyright 2021 SourceMedia LLC d/b/a Arizent All Rights Reserved




Section: Vol. 1; No. 1
Length: 803 words
Byline: John Adams

Body


Bank of America is big in health care - more than 2,000 hospital clients in the U.S. and more than 17,000
relationships with health care providers - and now it's focusing on being faster to market.

In buying AxiaMed, the bank is avoiding a complex IT project to upgrade health care payments and other merchant
services. It can now provide a digital payments gateway to these clients immediately.

"We would have had to build the tech ourselves and then get certified with the software providers," said Guy Harris,
head of merchant services for Bank of America.

Axia's platform is "fundamentally a health care payment system, but we are also gaining domain expertise that we
can gain from in other industries," Harris said.

Financial terms of the deal, which closed April 1, weren't disclosed. The Santa Barbara, Calif.-based-based
AxiaMed works through independent software vendors to sell SaaS-based patient payment technology. Its branded
product, Payment Fusion, uses an API to integrate into electronic health records systems, practice management
and revenue cycle management systems at health care providers.

Payment Fusion uses point-to-point encryption to take providers out of scope for PCI compliance, and it also is
HIPAA compliant, addressing a regulation that doesn't accompany payment processing for most industries.

The deal is part of Bank of America's strategy to build its own merchant services/card issuing combo following the
end of itsjoint venturewith First Data, which was dismantled in 2019 following Fiserv's acquisition of First Data.

"Health care is a major vertical for us, and payments are a critical part of that relationship," Harris said. "When we
decided 18 months ago to exit our venture with First Data to build our own platform, part of that is having a platform
that can work with as many partners as possible."

                                                                                                         Page 2 of 2
                       BofA acquisition makes its health care payments business more nimble

The AxiaMed acquisition comes as payment companies focus more on health care providers, which had been slow
to modernize due to the complexity of hospital billing systems. Among health care providers there is a demand for
a range of merchant services tied to payment credential onboarding, or acting as apayment facilitator.

"There has been a lot of innovation happening, but maybe not to the scale and pace required as the innovation has
not happened with acquiring and processing as a key piece of the solution," said Michael Trilli, a research director
for Aite Group's insurance practice. "The pandemic has pushed health care further into a retail, digital, consumer
driven market."

Health care is the more-complicated cousin for mainstream payment processing. Health payments for years have
remained more manual than automated because of complicated funding sources and compliance.

While most merchant transactions involve a consumer drawing from an account to funnel money that eventually
winds up in the merchants' account, health care in most cases involves an insurer that acts as a third party, paying
some but not all of the bill. The role of the Affordable Care Act, the pandemic and the rise of consumer-directed
health care payments add complications.

National health care spending in the U.S. is expected to grow at an average annual rate of more than 5% between
2019 and 2028, reaching $6.2 trillion, according to theCenters for Medicaid and Medicare Services. National health
expenditures will grow 1.1% faster than GDP, causing health care's share of the economy to reach 19.7% in 2028
from 1.7% in 2019, according to the CMS.

In the banking industry, most innovation has come via commercial payments through treasury services, with some
basic retail capabilities, according to Trilli. Several banks, such asFifth ThirdandJPMorgan Chase, have partnered
with fintechs to improve banking and payment services for consumers and health care providers.

In the technology industry, the need to simplify transaction rails in the eyes of the consumers and merchants has
drawn dozens of technology companies offering payment innovation. In many cases, the developers are adapting
payment technology for other purposes, such asWaystar'suse of P2P-style text messaging
orMastercard'sdeployment of blockchain to improve risk management for health care providers. AndGoogle's
venture armrecently invested $16.5 million in Nym Health to expand AI-driven health care payment processing,
another trend imported from mainstream retail payments.

"So the fact that BofA bought AxiaMed and their acquiring capabilities is a strong signal the bank is positioning itself
with these trends," Trilli said.

Writing forPaymentsSource, Florian Otto, co-founder and CEO of Cedar, a health care engagement platform, said
the pandemic has caused spikes in surprise medical bills and COVID-related fees, necessitating advancements in
compassionate billing, transaction transparency and price transparency.


https://www.americanbanker.com/payments/news/bofa-acquisition-makes-its-health-care-payments-business-
more-nimble


Load-Date: June 2, 2021


  End of Document

                                                                                                      Page 1 of 2
                                  Southeast Texas hospitals employ new stroke technology




                 Southeast Texas hospitals employ new stroke technology
                                              The Beaumont Enterprise (Texas)
                                                September 27, 2022 Tuesday



Copyright 2022 The Beaumont Enterprise (Beaumont, Texas)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 407 words
Byline: Kaitlin Bain, The Beaumont Enterprise, Texas

Body


Sep. 27—Southeast Texans experiencing a stroke may now see better outcomes.

Christus Southeast Texas has implemented new technology across its properties to provide 24/7 access to
neurologists with experience treating strokes and utilize artificial intelligence to improve communication across an
individual's care team and mobile image viewing.

According to a Christus news release, TeleSpecialists TeleStroke begins as soon as a patient with stroke-like
symptoms goes to the emergency room in an ambulance.

The technology connects the clinical team to a board-certified neurologist.

"Mounted on a mobile cart, the telemedicine technology allows a neurologist to participate in all aspects of the
neurological exam — from the CT scan to the physical exam and patient interview — before recommending a
course of treatment," the release said.

Stroke Facts by the Numbers:

5th Leading Cause of Death and Disability

400 Stroke Patients: Average number of stroke patients treated each year at CHRISTUS St. Elizabeth

3 Hours: From the onset of symptoms, this is the window of time in which a clot-busting medication can be given for
a better chance of recovery

45 Minutes: This is the national standard of time in which a patient, once arriving at the hospital, should be
diagnosed and administered a clot-busting medicine like Alteplase

35 Minutes: Exceeding national standards, CHRISTUS Southeast Texas St. Elizabeth Hospital's current year-to-
date time in which a patient comes in the door and receives medication is 10 minutes below the national goal

                                                                                                        Page 2 of 2
                             Southeast Texas hospitals employ new stroke technology

Information from Christus Southeast Texas Health System

Viz.ai technology, which will be in use by Christus for the first time in the Southeast Texas region, picks up stroke-
related information "instantaneously" and sends it to physicians at stroke centers across the state.

"This is a cutting-edge and life-saving technology that's making a difference in the lives of many here in Southeast
Texas," Paul Trevino, President and CEO of CHRISTUS Southeast Texas Health System, said in the release.
"We're giving people a second chance at life, a smoother recovery and ensuring we have the modern technology
and resources available for all those we have the privilege to serve."

kaitlin.bain@beaumontenterprise.com

twitter.com/KaitlinBain

___ (c)2022 the Beaumont Enterprise (Beaumont, Texas) Visit the Beaumont Enterprise (Beaumont, Texas) at
www.beaumontenterprise.com Distributed by Tribune Content Agency, LLC.


Load-Date: September 28, 2022


  End of Document

                                                                                                          Page 1 of 2
                                                    New CEO at Black Girls Code




                                           New CEO at Black Girls Code
                                               Our Time Press (Brooklyn, New York)
                                                         27 October 2023



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Our Time Press

Section: EDUCATION
Length: 284 words

Body


Black Girls Code has announced the appointment of Cristina Jones as CEO. In accepting the appointment, Ms.
Jones responded:

Dear BGC Community,

It's a joy and honor to introduce myself: I'm Cristina Jones, the new CEO of Black Girls Code.

I come to this position as a longtime supporter of this organization, and a lifelong believer in the ingenuity, ambition,
and underrecognized promise of Black girls, girls of color, and gender-nonconforming youth of color around the
world.

The mission of Black Girls Codeto place one million girls of color in tech by 2040means more than career
development. The skills, training, and resources we offer are the tools to make the future more innovative, inclusive,
and equitable.

Because if there's one thing I've seen to be true throughout my career in tech and media, it's that girls and women
of color hold the visionary power to revolutionize our industries, economies, and culture.

As I step into this role, we'll expand the curriculum to address workforce development by including AI, leadership,
and mental health. We're increasing the age limits to support this community well into job placement. We're
establishing sponsorships and inclusive partnerships focused on equityfrom recruitment to hiring to advancement.
Finally, we're assembling our BGC alumnae and the larger community for networking and professional
development.

Thank you for journeying this far, and I'm thrilled to continue alongside you as we accelerate our mission.

Gratefully,

Cristina

Most recently, Cristina served as Chief Engagement Officer and Chief Marketing Officer for Salesforce.org, where
she worked to humanize tech and elevate the mission and impact through authentic storytelling.

                                                            Page 2 of 2
                              New CEO at Black Girls Code


Load-Date: October 27, 2023


  End of Document

                                                                                                     Page 1 of 3
           Algorithms used in tracking OD risk rating AI may influence whether one can receive pain meds




                         Algorithms used in tracking OD risk rating
                     AI may influence whether one can receive pain meds
                                                       The Baltimore Sun
                                                  September 29, 2023 Friday
                                                        Lifestyles Edition



Copyright 2023 The Baltimore Sun Company All Rights Reserved

Section: OTHER; L; Pg. 2
Length: 1281 words
Byline: Andy Miller and Sam Whitehead KFF Health News
Highlight: Narx Scores and an algorithm-generated overdose risk rating are produced by Bamboo Health's
NarxCare platform. Dreamstime

Body


Elizabeth Amirault had never heard of a Narx Score. But she said she learned last year the tool had been used to
track her medication use.

During an August 2022 visit to a hospital in Fort Wayne, Indiana, Amirault told a nurse practitioner she was in
severe pain, she said. She received a puzzling response.

"Your Narx Score is so high, I can't give you any narcotics," she recalled the man saying, as she waited for an MRI
before a hip replacement.

Tools like Narx Scores are used to help medical providers review controlled substance prescriptions. They influence
- and can limit - the prescribing of painkillers, similar to a credit score influencing the terms of a loan. Narx Scores
and an algorithm-generated overdose risk rating are produced by health care technology company Bamboo Health
(formerly Appriss Health) in its NarxCare platform.

Such systems are designed to fight the nation's opioid epidemic, which has led to an alarming number of overdose
deaths. The platforms draw on data about prescriptions for controlled substances that states collect to identify
patterns of potential problems involving patients and physicians. State and federal health agencies, law
enforcement officials, and health care providers have enlisted these tools, but the mechanics behind the formulas
used are generally not shared with the public.

Artificial intelligence is working its way into more parts of American life. As AI spreads within the health care
landscape, it brings familiar concerns of bias and accuracy and whether government regulation can keep up with
rapidly advancing technology.

The use of systems to analyze opioid-prescribing data has sparked questions over whether they have undergone
enough independent testing outside of the companies that developed them, making it hard to know how they work.

                                                                                                    Page 2 of 3
          Algorithms used in tracking OD risk rating AI may influence whether one can receive pain meds

Lacking the ability to see inside these systems leaves only clues to their potential impact. Some patients say they
have been cut off from needed care. Some doctors say their ability to practice medicine has been unfairly
threatened. Researchers warn that such technology - despite its benefits - can have unforeseen consequences if it
improperly flags patients or doctors.

"We need to see what's going on to make sure we're not doing more harm than good," said Jason Gibbons, a
health economist at the Colorado School of Public Health at the University of Colorado's Anschutz Medical
Campus. "We're concerned that it's not working as intended, and it's harming patients."

Amirault, 34, said she has dealt for years with chronic pain from health conditions such as sciatica, degenerative
disc disease and avascular necrosis, which results from restricted blood supply to the bones.

The opioid Percocet offers her some relief. She'd been denied the medication before, but never had been told
anything about a Narx Score, she said.

In a chronic pain support group on Facebook, she found others posting about NarxCare, which scores patients
based on their supposed risk of prescription drug misuse. She's convinced her ratings negatively influenced her
care.

"Apparently being sick and having a bunch of surgeries and different doctors, all of that goes against me," Amirault
said.

Database-driven tracking has been linked to a decline in opioid prescriptions, but evidence is mixed on its impact on
curbing the epidemic. Overdose deaths continue to plague the country, and patients like Amirault have said the
monitoring systems leave them feeling stigmatized as well as cut off from pain relief.

The Centers for Disease Control and Prevention estimated that in 2021 about 52 million American adults suffered
from chronic pain, and about 17 million people lived with pain so severe it limited their daily activities. To manage
the pain, many use prescription opioids, which are tracked in nearly every state through electronic databases
known as prescription drug monitoring programs, or PDMPs.

The last state to adopt a program, Missouri, is still getting it up and running.

More than 40 states and territories use the technology from Bamboo Health to run PDMPs. That data can be fed
into NarxCare, a separate suite of tools to help medical professionals make decisions. Hundreds of health care
facilities and five of the top six major pharmacy retailers also use NarxCare, the company said.

The platform generates three Narx Scores based on a patient's prescription activity involving narcotics, sedatives
and stimulants. A peer-reviewed study showed the "Narx Score metric could serve as a useful initial universal
prescription opioid-risk screener."

NarxCare's algorithm-generated "Overdose Risk Score" draws on a patient's medication information from PDMPs -
such as the number of doctors writing prescriptions, the number of pharmacies used, and drug dosage - to help
medical providers assess a patient's risk of opioid overdose.

Bamboo Health did not share the specific formula behind the algorithm or address questions about the accuracy of
its Overdose Risk Score but said it continues to review and validate the algorithm behind it, based on current
overdose trends.

Guidance from the CDC advised clinicians to consult PDMP data before prescribing pain medications. But the
agency warned that "special attention should be paid to ensure that PDMP information is not used in a way that is
harmful to patients."

This prescription-drug data has led patients to be dismissed from clinician practices, the CDC said, which could
leave patients at risk of being untreated or undertreated for pain. The agency further warned that risk scores may
be generated by "proprietary algorithms that are not publicly available" and could lead to biased results.

                                                                                                    Page 3 of 3
          Algorithms used in tracking OD risk rating AI may influence whether one can receive pain meds

Bamboo Health said that NarxCare can show providers all of a patient's scores on one screen, but that these tools
should never replace decisions made by physicians.

Some patients say the tools have had an outsize impact on their treatment.

Bev Schechtman, 47, who lives in North Carolina, said she has occasionally used opioids to manage pain flare-ups
from Crohn's disease. As vice president of the Doctor Patient Forum, a chronic pain patient advocacy group, she
said she has heard from others reporting medication access problems, many of which she worries are caused by
red flags from databases.

Some doctors who treat chronic pain patients say they, too, have been flagged by data systems and then lost their
license to practice and were prosecuted.

Lesly Pompy, a pain medicine and addiction specialist in Monroe, Michigan, believes such systems were involved in
a legal case against him.

His medical office was raided by a mix of local and federal law enforcement agencies in 2016 because of his
patterns in prescribing pain medicine. A year after the raid, Pompy's medical license was suspended. In 2018, he
was indicted on charges of illegally distributing opioid pain medication and health care fraud.

"I knew I was taking care of patients in good faith," he said. A federal jury in January acquitted him of all charges.
He said he's working to have his license restored.

Prosecutions against doctors through the use of prescribing data have attracted the attention of the American
Medical Association.

"These unknown and unreviewed algorithms have resulted in physicians having their prescribing privileges
immediately suspended without due process or review by a state licensing board," said Bobby Mukkamala, chair of
the AMA's Substance Use and Pain Care Task Force.

Even critics of drug- tracking systems and algorithms say there is a place for data and artificial intelligence systems
in reducing the harms of the opioid crisis.

"It's just a matter of making sure that the technology is working as intended," health economist Gibbons said.


Load-Date: October 4, 2023


  End of Document

                                                                                                      Page 1 of 3
            Algorithms used in tracking OD risk rating AI may influence whether one can receive pain meds




                          Algorithms used in tracking OD risk rating
                      AI may influence whether one can receive pain meds
                                                        Daily News (New York)
                                                      September 24, 2023 Sunday
                                                            1STAR Edition



Copyright 2023 Daily News, L.P. All Rights Reserved

Section: LIFESTYLE; CS; Pg. 44
Length: 1281 words
Byline: Andy Miller and Sam Whitehead KFF Health News
Highlight: Narx Scores and an algorithm-generated overdose risk rating are produced by Bamboo Health's
NarxCare platform. Dreamstime

Body


Elizabeth Amirault had never heard of a Narx Score. But she said she learned last year the tool had been used to
track her medication use.

During an August 2022 visit to a hospital in Fort Wayne, Indiana, Amirault told a nurse practitioner she was in
severe pain, she said. She received a puzzling response.

"Your Narx Score is so high, I can't give you any narcotics," she recalled the man saying, as she waited for an MRI
before a hip replacement.

Tools like Narx Scores are used to help medical providers review controlled substance prescriptions. They influence
- and can limit - the prescribing of painkillers, similar to a credit score influencing the terms of a loan. Narx Scores
and an algorithm-generated overdose risk rating are produced by health care technology company Bamboo Health
(formerly Appriss Health) in its NarxCare platform.

Such systems are designed to fight the nation's opioid epidemic, which has led to an alarming number of overdose
deaths. The platforms draw on data about prescriptions for controlled substances that states collect to identify
patterns of potential problems involving patients and physicians. State and federal health agencies, law
enforcement officials, and health care providers have enlisted these tools, but the mechanics behind the formulas
used are generally not shared with the public.

Artificial intelligence is working its way into more parts of American life. As AI spreads within the health care
landscape, it brings familiar concerns of bias and accuracy and whether government regulation can keep up with
rapidly advancing technology.

The use of systems to analyze opioid-prescribing data has sparked questions over whether they have undergone
enough independent testing outside of the companies that developed them, making it hard to know how they work.

                                                                                                    Page 2 of 3
          Algorithms used in tracking OD risk rating AI may influence whether one can receive pain meds

Lacking the ability to see inside these systems leaves only clues to their potential impact. Some patients say they
have been cut off from needed care. Some doctors say their ability to practice medicine has been unfairly
threatened. Researchers warn that such technology - despite its benefits - can have unforeseen consequences if it
improperly flags patients or doctors.

"We need to see what's going on to make sure we're not doing more harm than good," said Jason Gibbons, a
health economist at the Colorado School of Public Health at the University of Colorado's Anschutz Medical
Campus. "We're concerned that it's not working as intended, and it's harming patients."

Amirault, 34, said she has dealt for years with chronic pain from health conditions such as sciatica, degenerative
disc disease and avascular necrosis, which results from restricted blood supply to the bones.

The opioid Percocet offers her some relief. She'd been denied the medication before, but never had been told
anything about a Narx Score, she said.

In a chronic pain support group on Facebook, she found others posting about NarxCare, which scores patients
based on their supposed risk of prescription drug misuse. She's convinced her ratings negatively influenced her
care.

"Apparently being sick and having a bunch of surgeries and different doctors, all of that goes against me," Amirault
said.

Database-driven tracking has been linked to a decline in opioid prescriptions, but evidence is mixed on its impact on
curbing the epidemic. Overdose deaths continue to plague the country, and patients like Amirault have said the
monitoring systems leave them feeling stigmatized as well as cut off from pain relief.

The Centers for Disease Control and Prevention estimated that in 2021 about 52 million American adults suffered
from chronic pain, and about 17 million people lived with pain so severe it limited their daily activities. To manage
the pain, many use prescription opioids, which are tracked in nearly every state through electronic databases
known as prescription drug monitoring programs, or PDMPs.

The last state to adopt a program, Missouri, is still getting it up and running.

More than 40 states and territories use the technology from Bamboo Health to run PDMPs. That data can be fed
into NarxCare, a separate suite of tools to help medical professionals make decisions. Hundreds of health care
facilities and five of the top six major pharmacy retailers also use NarxCare, the company said.

The platform generates three Narx Scores based on a patient's prescription activity involving narcotics, sedatives
and stimulants. A peer-reviewed study showed the "Narx Score metric could serve as a useful initial universal
prescription opioid-risk screener."

NarxCare's algorithm-generated "Overdose Risk Score" draws on a patient's medication information from PDMPs -
such as the number of doctors writing prescriptions, the number of pharmacies used, and drug dosage - to help
medical providers assess a patient's risk of opioid overdose.

Bamboo Health did not share the specific formula behind the algorithm or address questions about the accuracy of
its Overdose Risk Score but said it continues to review and validate the algorithm behind it, based on current
overdose trends.

Guidance from the CDC advised clinicians to consult PDMP data before prescribing pain medications. But the
agency warned that "special attention should be paid to ensure that PDMP information is not used in a way that is
harmful to patients."

This prescription-drug data has led patients to be dismissed from clinician practices, the CDC said, which could
leave patients at risk of being untreated or undertreated for pain. The agency further warned that risk scores may
be generated by "proprietary algorithms that are not publicly available" and could lead to biased results.

                                                                                                    Page 3 of 3
          Algorithms used in tracking OD risk rating AI may influence whether one can receive pain meds

Bamboo Health said that NarxCare can show providers all of a patient's scores on one screen, but that these tools
should never replace decisions made by physicians.

Some patients say the tools have had an outsize impact on their treatment.

Bev Schechtman, 47, who lives in North Carolina, said she has occasionally used opioids to manage pain flare-ups
from Crohn's disease. As vice president of the Doctor Patient Forum, a chronic pain patient advocacy group, she
said she has heard from others reporting medication access problems, many of which she worries are caused by
red flags from databases.

Some doctors who treat chronic pain patients say they, too, have been flagged by data systems and then lost their
license to practice and were prosecuted.

Lesly Pompy, a pain medicine and addiction specialist in Monroe, Michigan, believes such systems were involved in
a legal case against him.

His medical office was raided by a mix of local and federal law enforcement agencies in 2016 because of his
patterns in prescribing pain medicine. A year after the raid, Pompy's medical license was suspended. In 2018, he
was indicted on charges of illegally distributing opioid pain medication and health care fraud.

"I knew I was taking care of patients in good faith," he said. A federal jury in January acquitted him of all charges.
He said he's working to have his license restored.

Prosecutions against doctors through the use of prescribing data have attracted the attention of the American
Medical Association.

"These unknown and unreviewed algorithms have resulted in physicians having their prescribing privileges
immediately suspended without due process or review by a state licensing board," said Bobby Mukkamala, chair of
the AMA's Substance Use and Pain Care Task Force.

Even critics of drug- tracking systems and algorithms say there is a place for data and artificial intelligence systems
in reducing the harms of the opioid crisis.

"It's just a matter of making sure that the technology is working as intended," health economist Gibbons said.


Load-Date: September 25, 2023


  End of Document

                                                                                                     Page 1 of 3
           Algorithms used in tracking OD risk rating AI may influence whether one can receive pain meds




                         Algorithms used in tracking OD risk rating
                     AI may influence whether one can receive pain meds
                                                       The Baltimore Sun
                                                September 21, 2023 Thursday
                                                           First Edition



Copyright 2023 The Baltimore Sun Company All Rights Reserved

Section: SPORTS; D; Pg. 9
Length: 1281 words
Byline: Andy Miller and Sam Whitehead KFF Health News
Highlight: Narx Scores and an algorithm-generated overdose risk rating are produced by Bamboo Health's
NarxCare platform. Dreamstime

Body


Elizabeth Amirault had never heard of a Narx Score. But she said she learned last year the tool had been used to
track her medication use.

During an August 2022 visit to a hospital in Fort Wayne, Indiana, Amirault told a nurse practitioner she was in
severe pain, she said. She received a puzzling response.

"Your Narx Score is so high, I can't give you any narcotics," she recalled the man saying, as she waited for an MRI
before a hip replacement.

Tools like Narx Scores are used to help medical providers review controlled substance prescriptions. They influence
- and can limit - the prescribing of painkillers, similar to a credit score influencing the terms of a loan. Narx Scores
and an algorithm-generated overdose risk rating are produced by health care technology company Bamboo Health
(formerly Appriss Health) in its NarxCare platform.

Such systems are designed to fight the nation's opioid epidemic, which has led to an alarming number of overdose
deaths. The platforms draw on data about prescriptions for controlled substances that states collect to identify
patterns of potential problems involving patients and physicians. State and federal health agencies, law
enforcement officials, and health care providers have enlisted these tools, but the mechanics behind the formulas
used are generally not shared with the public.

Artificial intelligence is working its way into more parts of American life. As AI spreads within the health care
landscape, it brings familiar concerns of bias and accuracy and whether government regulation can keep up with
rapidly advancing technology.

The use of systems to analyze opioid-prescribing data has sparked questions over whether they have undergone
enough independent testing outside of the companies that developed them, making it hard to know how they work.

                                                                                                    Page 2 of 3
          Algorithms used in tracking OD risk rating AI may influence whether one can receive pain meds

Lacking the ability to see inside these systems leaves only clues to their potential impact. Some patients say they
have been cut off from needed care. Some doctors say their ability to practice medicine has been unfairly
threatened. Researchers warn that such technology - despite its benefits - can have unforeseen consequences if it
improperly flags patients or doctors.

"We need to see what's going on to make sure we're not doing more harm than good," said Jason Gibbons, a
health economist at the Colorado School of Public Health at the University of Colorado's Anschutz Medical
Campus. "We're concerned that it's not working as intended, and it's harming patients."

Amirault, 34, said she has dealt for years with chronic pain from health conditions such as sciatica, degenerative
disc disease and avascular necrosis, which results from restricted blood supply to the bones.

The opioid Percocet offers her some relief. She'd been denied the medication before, but never had been told
anything about a Narx Score, she said.

In a chronic pain support group on Facebook, she found others posting about NarxCare, which scores patients
based on their supposed risk of prescription drug misuse. She's convinced her ratings negatively influenced her
care.

"Apparently being sick and having a bunch of surgeries and different doctors, all of that goes against me," Amirault
said.

Database-driven tracking has been linked to a decline in opioid prescriptions, but evidence is mixed on its impact on
curbing the epidemic. Overdose deaths continue to plague the country, and patients like Amirault have said the
monitoring systems leave them feeling stigmatized as well as cut off from pain relief.

The Centers for Disease Control and Prevention estimated that in 2021 about 52 million American adults suffered
from chronic pain, and about 17 million people lived with pain so severe it limited their daily activities. To manage
the pain, many use prescription opioids, which are tracked in nearly every state through electronic databases
known as prescription drug monitoring programs, or PDMPs.

The last state to adopt a program, Missouri, is still getting it up and running.

More than 40 states and territories use the technology from Bamboo Health to run PDMPs. That data can be fed
into NarxCare, a separate suite of tools to help medical professionals make decisions. Hundreds of health care
facilities and five of the top six major pharmacy retailers also use NarxCare, the company said.

The platform generates three Narx Scores based on a patient's prescription activity involving narcotics, sedatives
and stimulants. A peer-reviewed study showed the "Narx Score metric could serve as a useful initial universal
prescription opioid-risk screener."

NarxCare's algorithm-generated "Overdose Risk Score" draws on a patient's medication information from PDMPs -
such as the number of doctors writing prescriptions, the number of pharmacies used, and drug dosage - to help
medical providers assess a patient's risk of opioid overdose.

Bamboo Health did not share the specific formula behind the algorithm or address questions about the accuracy of
its Overdose Risk Score but said it continues to review and validate the algorithm behind it, based on current
overdose trends.

Guidance from the CDC advised clinicians to consult PDMP data before prescribing pain medications. But the
agency warned that "special attention should be paid to ensure that PDMP information is not used in a way that is
harmful to patients."

This prescription-drug data has led patients to be dismissed from clinician practices, the CDC said, which could
leave patients at risk of being untreated or undertreated for pain. The agency further warned that risk scores may
be generated by "proprietary algorithms that are not publicly available" and could lead to biased results.

                                                                                                    Page 3 of 3
          Algorithms used in tracking OD risk rating AI may influence whether one can receive pain meds

Bamboo Health said that NarxCare can show providers all of a patient's scores on one screen, but that these tools
should never replace decisions made by physicians.

Some patients say the tools have had an outsize impact on their treatment.

Bev Schechtman, 47, who lives in North Carolina, said she has occasionally used opioids to manage pain flare-ups
from Crohn's disease. As vice president of the Doctor Patient Forum, a chronic pain patient advocacy group, she
said she has heard from others reporting medication access problems, many of which she worries are caused by
red flags from databases.

Some doctors who treat chronic pain patients say they, too, have been flagged by data systems and then lost their
license to practice and were prosecuted.

Lesly Pompy, a pain medicine and addiction specialist in Monroe, Michigan, believes such systems were involved in
a legal case against him.

His medical office was raided by a mix of local and federal law enforcement agencies in 2016 because of his
patterns in prescribing pain medicine. A year after the raid, Pompy's medical license was suspended. In 2018, he
was indicted on charges of illegally distributing opioid pain medication and health care fraud.

"I knew I was taking care of patients in good faith," he said. A federal jury in January acquitted him of all charges.
He said he's working to have his license restored.

Prosecutions against doctors through the use of prescribing data have attracted the attention of the American
Medical Association.

"These unknown and unreviewed algorithms have resulted in physicians having their prescribing privileges
immediately suspended without due process or review by a state licensing board," said Bobby Mukkamala, chair of
the AMA's Substance Use and Pain Care Task Force.

Even critics of drug- tracking systems and algorithms say there is a place for data and artificial intelligence systems
in reducing the harms of the opioid crisis.

"It's just a matter of making sure that the technology is working as intended," health economist Gibbons said.


Load-Date: September 21, 2023


  End of Document

                                                                                                           Page 1 of 3
                            AI and work 7 jobs that don't exist today but will in the next 5 years




                                          AI and work
                   7 jobs that don't exist today but will in the next 5 years
                                                      The Hartford Courant
                                                      May 28, 2023 Sunday
                                                             1 Edition



Copyright 2023 The Hartford Courant Company All Rights Reserved

Section: LOCAL; B; Pg. 4
Length: 931 words
Byline: Megan O'Connor | Inc.
Highlight: Alexandersikov/Dreamstime

Body


For years, we've been warned by studies touting alarming headlines about the future of work, like the 2017 report
from Dell and Institute for the Future that "85% of jobs that will exist in 2030 haven't been invented yet."

But for those of us who were living in blissful ignorance of generative artificial intelligence until the public launch of
ChatGPT in late 2022, these reports failed to provoke a sense of urgency. Until now.

It no longer seems like an exaggeration that the world of work is going to look markedly different in just a few short
years, as IBM's recent announcement to replace nearly 8,000 jobs with AI over the next few years makes clear.

Everyone - from chief people officers at Fortune 500 companies whose headcount plans have been upended to
incoming college students wondering if their planned majors are going to prepare them for a job that will even exist
when they graduate - is justified in thinking that we need to get a better grip on what this future might look like.

While it can help to be reminded that it's nothing new for the job landscape to be entirely upended every couple of
generations (after all, software engineers and digital marketers never coexisted with lamp-lighters or knocker-
uppers - essentially human alarm clocks), it's still been hard to imagine a world in which the jobs that seem so
critical to both doing business and living life might be supplanted.

That's why I turned to Kristin Fracchia, who runs a team of product marketers and analysts at Chegg Skills, and
who spent countless hours analyzing trends in the job market. Kristin and her team have a pulse on what is going to
change in the job market better than anyone.

When I asked Kristin what are the jobs that don't exist today, but chief human resource officers and training
managers should be aware are just around the corner, here is what she shared as a sampling across various
industries.

Prompt engineer

                                                                                                          Page 2 of 3
                          AI and work 7 jobs that don't exist today but will in the next 5 years

First, this job is already here, but it warrants a mention because of how quickly it's exploding in popularity across a
wide range of industries. It's our first example of how quickly generative AI is changing jobs. In 2021 and early
2022, prompt engineers were found mainly at AI companies. But according to LinkedIn, the number of job posts
that refer to generative AI has increased by 36-fold since last year. A search of online job boards now pulls up
postings for prompt engineers across multiple verticals, everything from defense contracting to hospitals, with
salaries up to $300,000.

Human-machines teaming manager

As AI and other technologies become more integrated into the workplace and companies increasingly rely on
human-machine collaboration to achieve business objectives, enter the human-machines teaming manager: an
upgrade from the people manager, one whose job is to make sure all intelligences work well together, even the
artificial ones.

AI ethicist

Like prompt engineers, the job of the AI ethicist has existed but largely in tech companies focusing on AI or at
research institutions. In the coming years, we are likely to see this role expand either as an internal job req or as a
consultative service to most companies who use AI to do work, especially where the output has a critical impact on
the physical, psychological or ethical well-being of humans.

Digital detox therapist

With the rise of virtual therapy during the COVID-19 pandemic, meaning that it's no longer necessary to have a
critical mass of clientele in a geographic area, niche therapy practices have also been on the rise. As AI expands
the presence of technology in everyday life, digital detox may morph from just a suggestion to unplug to a specific
branch of therapeutic practice.

AI personality designer

Siri, Alexa and Cortana all had glam squads behind them carefully crafting their interactive personalities.

As AI expands into various industries - and notably as it becomes more common for individuals to be generating
their own digital twins or likenesses - AI personality designers are going to become a hot commodity for both
corporations to engage their customers and for individuals to pursue their own virtual fame.

Biotech AI engineer

One of the most life-changing applications of generative AI technology is in health care, where it can be deployed
to identify diseases or genetic disorders. As a result, roles that require training in both machine learning and biology
are likely to emerge as the pace of scientific discovery accelerates.

Smart city designer

With the rise of AI, we might see urban planning evolve into smart city design, where cities are built specifically
around the need for humans to use AI and other technologies in their day-to-day lives. Smart city designers would
also actively leverage AI in their work as they collaborate with engineers, architects, city leaders and citizens to plan
more user-friendly and sustainable cities.

Throughout this coming decade, we all need to be prepared that the next one is going to look incredibly different,
with our own jobs re-imagined and the jobs of those we lead evaporating or emerging seemingly in an instant.

AI is impacting not only the future of work but the "now" of work. As the recently released Future of Jobs Report
from the World Economic Forum states, AI is now the No. 3 priority in company training strategies and the No. 1
priority for companies with more than 50,000 employees.

                                                                                                        Page 3 of 3
                         AI and work 7 jobs that don't exist today but will in the next 5 years

Leaders in every industry need to start thinking about how they will train and re-train their workforce into jobs like
the ones sampled here. Six months ago, they may have sounded like sci-fi but not anymore.


Load-Date: May 28, 2023


  End of Document

                                                                                                           Page 1 of 3
                            AI and work 7 jobs that don't exist today but will in the next 5 years




                                          AI and work
                   7 jobs that don't exist today but will in the next 5 years
                                                       The Baltimore Sun
                                                     May 28, 2023 Sunday
                                                    AdvanceBulldog Edition



Copyright 2023 The Baltimore Sun Company All Rights Reserved

Section: MAIN; A; Pg. 1
Length: 931 words
Byline: Megan O'Connor | Inc.
Highlight: Alexandersikov/Dreamstime

Body


For years, we've been warned by studies touting alarming headlines about the future of work, like the 2017 report
from Dell and Institute for the Future that "85% of jobs that will exist in 2030 haven't been invented yet."

But for those of us who were living in blissful ignorance of generative artificial intelligence until the public launch of
ChatGPT in late 2022, these reports failed to provoke a sense of urgency. Until now.

It no longer seems like an exaggeration that the world of work is going to look markedly different in just a few short
years, as IBM's recent announcement to replace nearly 8,000 jobs with AI over the next few years makes clear.

Everyone - from chief people officers at Fortune 500 companies whose headcount plans have been upended to
incoming college students wondering if their planned majors are going to prepare them for a job that will even exist
when they graduate - is justified in thinking that we need to get a better grip on what this future might look like.

While it can help to be reminded that it's nothing new for the job landscape to be entirely upended every couple of
generations (after all, software engineers and digital marketers never coexisted with lamp-lighters or knocker-
uppers - essentially human alarm clocks), it's still been hard to imagine a world in which the jobs that seem so
critical to both doing business and living life might be supplanted.

That's why I turned to Kristin Fracchia, who runs a team of product marketers and analysts at Chegg Skills, and
who spent countless hours analyzing trends in the job market. Kristin and her team have a pulse on what is going to
change in the job market better than anyone.

When I asked Kristin what are the jobs that don't exist today, but chief human resource officers and training
managers should be aware are just around the corner, here is what she shared as a sampling across various
industries.

Prompt engineer

                                                                                                          Page 2 of 3
                          AI and work 7 jobs that don't exist today but will in the next 5 years

First, this job is already here, but it warrants a mention because of how quickly it's exploding in popularity across a
wide range of industries. It's our

first example of how quickly generative AI is changing jobs. In 2021 and early 2022, prompt engineers were found
mainly at AI companies. But according to LinkedIn, the number of job posts that refer to generative AI has
increased by 36-fold since last year. A search of online job boards now pulls up postings for prompt engineers
across multiple verticals, everything from defense contracting to hospitals, with salaries up to $300,000.

Human-machines teaming manager

As AI and other technologies become more integrated into the workplace and companies increasingly rely on
human-machine collaboration to achieve business objectives, enter the human-machines teaming manager: an
upgrade from the people manager, one whose job is to make sure all intelligences work well together, even the
artificial ones.

AI ethicist

Like prompt engineers, the job of the AI ethicist has existed but largely in tech companies focusing on AI or at
research institutions. In the coming years, we are likely to see this role expand either as an internal job req or as a
consultative service to most companies who use AI to do work, especially where the output has a critical impact on
the physical, psychological or ethical well-being of humans.

Digital detox therapist

With the rise of virtual therapy during the Covid-19 pandemic, meaning that it's no longer necessary to have a
critical mass of clientele in a geographic area, niche therapy practices have also been on the rise. As AI expands
the presence of technology in everyday life, digital detox may morph from just a suggestion to unplug to a specific
branch of therapeutic practice.

AI personality designer

Siri, Alexa and Cortana all had glam squads behind them carefully crafting their interactive personalities.

As AI expands into various industries - and notably as it becomes more common for individuals to be generating
their own digital twins or likenesses - AI personality designers are going to become a hot commodity for both
corporations to engage their customers and for individuals to pursue their own virtual fame.

Biotech AI engineer

One of the most life-changing applications of generative AI technology is in health care, where it can be deployed
to identify diseases or genetic disorders. As a result, roles that require training in both machine learning and biology
are likely to emerge as the pace of scientific discovery accelerates.

Smart city designer

With the rise of AI, we might see urban planning evolve into smart city design, where cities are built specifically
around the need for humans to use AI and other technologies in their day-to-day lives. Smart city designers would
also actively leverage AI in their work as they collaborate with engineers, architects, city leaders and citizens to plan
more user-friendly and sustainable cities.

Throughout this coming decade, we all need to be prepared that the next one is going to look incredibly different,
with our own jobs re-imagined and the jobs of those we lead evaporating or emerging seemingly in an instant.

AI is impacting not only the future of work but the "now" of work. As the recently released Future of Jobs Report
from the World Economic Forum states, AI is now the No. 3 priority in company training strategies and the No. 1
priority for companies with more than 50,000 employees.

                                                                                                        Page 3 of 3
                         AI and work 7 jobs that don't exist today but will in the next 5 years

Leaders in every industry need to start thinking about how they will train and re-train their workforce into jobs like
the ones sampled here. Six months ago, they may have sounded like sci-fi but not anymore.


Load-Date: May 28, 2023


  End of Document

                                                                                                           Page 1 of 3
                             AI and work 7 jobs that don't exist today but will in the next 5 years




                                          AI and work
                    7 jobs that don't exist today but will in the next 5 years
                                                      Daily News (New York)
                                                      May 28, 2023 Sunday
                                                         1STAR Edition



Copyright 2023 Daily News, L.P. All Rights Reserved

Section: MAIN; CS; Pg. 33
Length: 931 words
Byline: Megan O'Connor Inc.
Highlight: Alexandersikov/Dreamstime

Body


For years, we've been warned by studies touting alarming headlines about the future of work, like the 2017 report
from Dell and Institute for the Future that "85% of jobs that will exist in 2030 haven't been invented yet."

But for those of us who were living in blissful ignorance of generative artificial intelligence until the public launch of
ChatGPT in late 2022, these reports failed to provoke a sense of urgency. Until now.

It no longer seems like an exaggeration that the world of work is going to look markedly different in just a few short
years, as IBM's recent announcement to replace nearly 8,000 jobs with AI over the next few years makes clear.

Everyone - from chief people officers at Fortune 500 companies whose headcount plans have been upended to
incoming college students wondering if their planned majors are going to prepare them for a job that will even exist
when they graduate - is justified in thinking that we need to get a better grip on what this future might look like.

While it can help to be reminded that it's nothing new for the job landscape to be entirely upended every couple of
generations (after all, software engineers and digital marketers never coexisted with lamp-lighters or knocker-
uppers - essentially human alarm clocks), it's still been hard to imagine a world in which the jobs that seem so
critical to both doing business and living life might be supplanted.

That's why I turned to Kristin Fracchia, who runs a team of product marketers and analysts at Chegg Skills, and
who spent countless hours analyzing trends in the job market. Kristin and her team have a pulse on what is going to
change in the job market better than anyone.

When I asked Kristin what are the jobs that don't exist today, but chief human resource officers and training
managers should be aware are just around the corner, here is what she shared as a sampling across various
industries.

Prompt engineer

                                                                                                          Page 2 of 3
                          AI and work 7 jobs that don't exist today but will in the next 5 years

First, this job is already here, but it warrants a mention because of how quickly it's exploding in popularity across a
wide range of industries. It's our first example of how quickly generative AI is changing jobs. In 2021 and early
2022, prompt engineers were found mainly at AI companies. But according to LinkedIn, the number of job posts
that refer to generative AI has increased by 36-fold since last year. A search of online job boards now pulls up
postings for prompt engineers across multiple verticals, everything from defense contracting to hospitals, with
salaries up to $300,000.

AI ethicist

Like prompt engineers, the job of the AI ethicist has existed but largely in tech companies focusing on AI or at
research institutions. In the coming years, we are likely to see this role expand either as an internal job req or as a
consultative service to most companies who use AI to do work, especially where the output has a critical impact on
the physical, psychological or ethical well-being of humans.

Digital detox therapist

With the rise of virtual therapy during the Covid-19 pandemic, meaning that it's no longer necessary to have a
critical mass of clientele in a geographic area, niche therapy practices have also been on the rise. As AI expands
the presence of technology in everyday life, digital detox may morph from just a suggestion to unplug to a specific
branch of therapeutic practice.

AI personality designer

Siri, Alexa and Cortana all had glam squads behind them carefully crafting their interactive personalities.

As AI expands into various industries - and notably as it becomes more common for individuals to be generating
their own digital twins or likenesses - AI personality designers are going to become a hot commodity for both
corporations to engage their customers and for individuals to pursue their own virtual fame.

Biotech AI engineer

One of the most life-changing applications of generative AI technology is in health care, where it can be deployed
to identify diseases or genetic disorders. As a result, roles that require training in both machine learning and biology
are likely to emerge as the pace of scientific discovery accelerates.

Smart city designer

With the rise of AI, we might see urban planning evolve into smart city design, where cities are built specifically
around the need for humans to use AI and other technologies in their day-to-day lives. Smart city designers would
also actively leverage AI in their work as they collaborate with engineers, architects, city leaders and citizens to plan
more user-friendly and sustainable cities.

Throughout this coming decade, we all need to be prepared that the next one is going to look incredibly different,
with our own jobs re-imagined and the jobs of those we lead evaporating or emerging seemingly in an instant.

AI is impacting not only the future of work but the "now" of work. As the recently released Future of Jobs Report
from the World Economic Forum states, AI is now the No. 3 priority in company training strategies and the No. 1
priority for companies with more than 50,000 employees.

Leaders in every industry need to start thinking about how they will train and re-train their workforce into jobs like
the ones sampled here. Six months ago, they may have sounded like sci-fi but not anymore.

Human-machines teaming manager

As AI and other technologies become more integrated into the workplace and companies increasingly rely on
human-machine collaboration to achieve business objectives, enter the human-machines teaming manager: an

                                                                                                Page 3 of 3
                       AI and work 7 jobs that don't exist today but will in the next 5 years

upgrade from the people manager, one whose job is to make sure all intelligences work well together, even the
artificial ones.


Load-Date: May 28, 2023


  End of Document

                                                                                                           Page 1 of 3
                            AI and work 7 jobs that don't exist today but will in the next 5 years




                                          AI and work
                   7 jobs that don't exist today but will in the next 5 years
                                                       The Baltimore Sun
                                                     May 28, 2023 Sunday
                                                           First Edition



Copyright 2023 The Baltimore Sun Company All Rights Reserved

Section: MAIN; B; Pg. 6
Length: 931 words
Byline: Megan O'Connor | Inc.
Highlight: Alexandersikov/Dreamstime

Body


For years, we've been warned by studies touting alarming headlines about the future of work, like the 2017 report
from Dell and Institute for the Future that "85% of jobs that will exist in 2030 haven't been invented yet."

But for those of us who were living in blissful ignorance of generative artificial intelligence until the public launch of
ChatGPT in late 2022, these reports failed to provoke a sense of urgency. Until now.

It no longer seems like an exaggeration that the world of work is going to look markedly different in just a few short
years, as IBM's recent announcement to replace nearly 8,000 jobs with AI over the next few years makes clear.

Everyone - from chief people officers at Fortune 500 companies whose headcount plans have been upended to
incoming college students wondering if their planned majors are going to prepare them for a job that will even exist
when they graduate - is justified in thinking that we need to get a better grip on what this future might look like.

While it can help to be reminded that it's nothing new for the job landscape to be entirely upended every couple of
generations (after all, software engineers and digital marketers never coexisted with lamp-lighters or knocker-
uppers - essentially human alarm clocks), it's still been hard to imagine a world in which the jobs that seem so
critical to both doing business and living life might be supplanted.

That's why I turned to Kristin Fracchia, who runs a team of product marketers and analysts at Chegg Skills, and
who spent countless hours analyzing trends in the job market. Kristin and her team have a pulse on what is going to
change in the job market better than anyone.

When I asked Kristin what are the jobs that don't exist today, but chief human resource officers and training
managers should be aware are just around the corner, here is what she shared as a sampling across various
industries.

Prompt engineer

                                                                                                          Page 2 of 3
                          AI and work 7 jobs that don't exist today but will in the next 5 years

First, this job is already here, but it warrants a mention because of how quickly it's exploding in popularity across a
wide range of industries. It's our first example of how quickly generative AI is changing jobs. In 2021 and early
2022, prompt engineers were found mainly at AI companies. But according to LinkedIn, the number of job posts
that refer to generative AI has increased by 36-fold since last year. A search of online job boards now pulls up
postings for prompt engineers across multiple verticals, everything from defense contracting to hospitals, with
salaries up to $300,000.

Human-machines teaming manager

As AI and other technologies become more integrated into the workplace and companies increasingly rely on
human-machine collaboration to achieve business objectives, enter the human-machines teaming manager: an
upgrade from the people manager, one whose job is to make sure all intelligences work well together, even the
artificial ones.

AI ethicist

Like prompt engineers, the job of the AI ethicist has existed but largely in tech companies focusing on AI or at
research institutions. In the coming years, we are likely to see this role expand either as an internal job req or as a
consultative service to most companies who use AI to do work, especially where the output has a critical impact on
the physical, psychological or ethical well-being of humans.

Digital detox therapist

With the rise of virtual therapy during the Covid-19 pandemic, meaning that it's no longer necessary to have a
critical mass of clientele in a geographic area, niche therapy practices have also been on the rise. As AI expands
the presence of technology in everyday life, digital detox may morph from just a suggestion to unplug to a specific
branch of therapeutic practice.

AI personality designer

Siri, Alexa and Cortana all had glam squads behind them carefully crafting their interactive personalities.

As AI expands into various industries - and notably as it becomes more common for individuals to be generating
their own digital twins or likenesses - AI personality designers are going to become a hot commodity for both
corporations to engage their customers and for individuals to pursue their own virtual fame.

Biotech AI engineer

One of the most life-changing applications of generative AI technology is in health care, where it can be deployed
to identify diseases or genetic disorders. As a result, roles that require training in both machine learning and biology
are likely to emerge as the pace of scientific discovery accelerates.

Smart city designer

With the rise of AI, we might see urban planning evolve into smart city design, where cities are built specifically
around the need for humans to use AI and other technologies in their day-to-day lives. Smart city designers would
also actively leverage AI in their work as they collaborate with engineers, architects, city leaders and citizens to plan
more user-friendly and sustainable cities.

Throughout this coming decade, we all need to be prepared that the next one is going to look incredibly different,
with our own jobs re-imagined and the jobs of those we lead evaporating or emerging seemingly in an instant.

AI is impacting not only the future of work but the "now" of work. As the recently released Future of Jobs Report
from the World Economic Forum states, AI is now the No. 3 priority in company training strategies and the No. 1
priority for companies with more than 50,000 employees.

                                                                                                        Page 3 of 3
                         AI and work 7 jobs that don't exist today but will in the next 5 years

Leaders in every industry need to start thinking about how they will train and re-train their workforce into jobs like
the ones sampled here. Six months ago, they may have sounded like sci-fi but not anymore.


Load-Date: May 28, 2023


  End of Document

                                                                                                     Page 1 of 2
                              Chatbots Bring Buzz, but the Real Money Will Come From APIs




            Chatbots Bring Buzz, but the Real Money Will Come From APIs
                                                        New York Observer
                                                     February 24, 2023 Friday



Copyright 2023 The New York Observer, L.P. All Rights Reserved

Length: 700 words
Byline: Alex Kantrowitz

Body


This story is syndicated from the Substack newsletter Big Technology; subscribe for free here.

The chatbots did their job. They inspired awe, mockery, and even some fear. Most importantly, they drew attention.
Front-page headlines, cover stories, and word of mouth caused millions to try them, leading businesses and
developers to ask how they could put the technology to use.

The APIs, of course, were always the point. ChatGPT and Bing's chatbot were never the end product. They were
demos meant to sell other companies on tools they could use to build their own. And it worked. Now, the war to
build the leading generative AI platform is underway.

"For OpenAI, the vast majority of the money they will ever make will come from developers," Ben Parr, president
of Octane AI, told me via phone Thursday. "ChatGPT is just the entry road into everything else."

Even before this wave of AI chatbots reached the public, the companies behind them prepared APIs for developers.
When ChatGPT gained momentum in January, OpenAI president Greg Brockman teased an API "coming soon."
That same week, Microsoft made OpenAI models available through Azure. On the day Google introduced its BARD
chatbot, CEO Sundar Pichai promised to make some of the underlying technology available by March. And this
week, just a bit late, Amazon announced it would partner with Hugging Face to make a generative language tool
available through AWS.

"Everybody who develops software is either alerted, or shocked into alert, or actively working on something that is
like ChatGPT to be integrated into their application, or integrated into their service," NVIDIA CEO Jensen Huang
said during his company's earnings call Wednesday. NVIDIA provides the chips the tech runs on, so it stands to
benefit too. Its stock jumped 14% Thursday.

Finding broad, useful applications for generative AI will be challenging, but some obvious early applications stand
out. Customer service departments, for instance, could use chatbots that can hold a conversation. Gaming
companies could build intelligent characters and make NPCs a thing of the past. And marketers could attempt to
use generative language models to forge deeper bonds with customers.

                                                                                                       Page 2 of 2
                          Chatbots Bring Buzz, but the Real Money Will Come From APIs

This is all moving fast. On Tuesday, OpenAI announced it had partnered with Bain to help clients build on its API.
Zack Kass, OpenAI's chief customer officer, said in a launch video that OpenAI couldn't keep up with the interest in
its technology. "We are inundated at this point with enterprise demand that we sort of waited for, for a long time,
and here it is," he said. "Now we just need to figure out how we field it."

Later in the video, Coca-Cola executives said they planned to use the tech in their marketing efforts "to deliver
creative content at speed." Coca-Cola CEO James Quincey also mentioned he believed the tech would change
knowledge work, but without going into specifics.

Coca-Cola is a fitting launch partner. In a recent presentation, investor Chamath Palihapitiya mentioned that Coke
succeeded thanks to another invention: refrigeration. Coca-Cola made more money than the people that invented
the refrigerator, he said, and that could happen here too. "If AI/LLMs are the refrigeration," he asked. "Who will be
the next Coca-Cola?"

The companies that enable successful AI applications-the refrigeration, in Palihapitiya's analogy-still stand to
benefit tremendously though. And so those developing the underlying technology are doing what they can to help
launch the next big thing on their platform, and perhaps take a chunk of it too. OpenAI, for instance, has a $100
million startup fund meant to work with AI companies in health care, climate, education, and elsewhere. "Look at
some of the companies that OpenAI's invested in," said Parr. "There are real use cases."

The APIs, amid the commotion, are what matter. They're why Microsoft was willing to release an unproven chatbot
into Bing, even when it knew it was a bit crazy. And why the company didn't seem to mind when the bot's
flaws exploded into public view. It was never about Bing or ChatGPT, but about the potential future they previewed.
And now, given the demos' success, the race to enable that future is underway.


Load-Date: February 28, 2023


  End of Document

                                                                                                      Page 1 of 2
                          BofA acquisition makes its health care payments business more nimble




    BofA acquisition makes its health care payments business more nimble
                                                          American Banker
                                                       April 6, 2021 Tuesday



Copyright 2021 SourceMedia LLC d/b/a Arizent All Rights Reserved




Section: Vol. 186; No. 64
Length: 832 words
Byline: John Adams

Body

    •     For more content like this, from the industry leader in global payments coverage, please visit
          PaymentsSource.com.

Bank of America is big in health care - it has more than 2,000 hospital clients in the U.S. and more than 17,000
relationships with health care providers - and now it's focusing on being faster to market.

In buying AxiaMed, the bank is avoiding a complex IT project to upgrade health care payments and other merchant
services. It can now provide a digital payments gateway to these clients immediately.

"We would have had to build the tech ourselves and then get certified with the software providers," said Guy Harris,
head of merchant services for Bank of America.

Axia's platform is "fundamentally a health care payment system, but we are also gaining domain expertise that we
can gain from in other industries," Harris said.

Financial terms of the deal weren't disclosed, and AxiaMed operates as a subsidiary of Bank of America effective
April 1. The Santa Barbara, Calif.-based-based AxiaMed works through independent software vendors to sell SaaS-
based patient payment technology. Its branded product, Payment Fusion, uses an API to integrate into electronic
health records systems, practice management and revenue cycle management systems at health care providers.

Payment Fusion uses point-to-point encryption to take providers out of scope for PCI compliance, and it also is
HIPAA compliant, addressing a regulation that doesn't accompany payment processing for most industries.

The deal is part of Bank of America's strategy to build its own merchant services/card issuing combo following the
end of itsjoint venturewith First Data, which was dismantled in 2019 following Fiserv's acquisition of First Data.

                                                                                                         Page 2 of 2
                       BofA acquisition makes its health care payments business more nimble

"Health care is a major vertical for us, and payments are a critical part of that relationship," Harris said. "When we
decided 18 months ago to exit our venture with First Data to build our own platform, part of that is having a platform
that can work with as many partners as possible."

The AxiaMed acquisition comes as payment companies focus more on health care providers, which had been slow
to modernize due to the complexity of hospital billing systems. Among health care providers there is a demand for
a range of merchant services tied to payment credential onboarding, or acting as apayment facilitator.

"There has been a lot of innovation happening, but maybe not to the scale and pace required as the innovation has
not happened with acquiring and processing as a key piece of the solution," said Michael Trilli, a research director
for Aite Group's insurance practice. "The pandemic has pushed health care further into a retail, digital, consumer
driven market."

Health care is the more-complicated cousin for mainstream payment processing. Health payments for years have
remained more manual than automated because of complicated funding sources and compliance.

While most merchant transactions involve a consumer drawing from an account to funnel money that eventually
winds up in the merchants' account, health care in most cases involves an insurer that acts as a third party, paying
some but not all of the bill. The role of the Affordable Care Act, the pandemic and the rise of consumer-directed
health care payments add complications.

National health care spending in the U.S. is expected to grow at an average annual rate of more than 5% between
2019 and 2028, reaching $6.2 trillion, according to theCenters for Medicaid and Medicare Services. National health
expenditures will grow 1.1% faster than GDP, causing health care's share of the economy to reach 19.7% in 2028
from 1.7% in 2019, according to the CMS.

In the banking industry, most innovation has come via commercial payments through treasury services, with some
basic retail capabilities, according to Trilli. Several banks, such asFifth ThirdandJPMorgan Chase, have partnered
with fintechs to improve banking and payment services for consumers and health care providers.

In the technology industry, the need to simplify transaction rails in the eyes of the consumers and merchants has
drawn dozens of technology companies offering payment innovation. In many cases, the developers are adapting
payment technology for other purposes, such asWaystar'suse of P2P-style text messaging
orMastercard'sdeployment of blockchain to improve risk management for health care providers. AndGoogle's
venture armrecently invested $16.5 million in Nym Health to expand AI-driven health care payment processing,
another trend imported from mainstream retail payments.

"So the fact that BofA bought AxiaMed and their acquiring capabilities is a strong signal the bank is positioning itself
with these trends," Trilli said.

Writing forPaymentsSource, Florian Otto, co-founder and CEO of Cedar, a health care engagement platform, said
the pandemic has caused spikes in surprise medical bills and COVID-related fees, necessitating advancements in
compassionate billing, transaction transparency and price transparency.


https://www.americanbanker.com/news/bofa-acquisition-makes-its-health-care-payments-business-more-nimble


Load-Date: April 6, 2021


  End of Document

                                                                                                      Page 1 of 2
                          BofA acquisition makes its health care payments business more nimble




    BofA acquisition makes its health care payments business more nimble
                                                       americanbanker.com
                                                       April 5, 2021 Monday



Copyright 2021 SourceMedia LLC d/b/a Arizent All Rights Reserved




Section: Vol. 1; No. 1
Length: 832 words
Byline: John Adams

Body

    •     For more content like this, from the industry leader in global payments coverage, please visit
          PaymentsSource.com.

Bank of America is big in health care - it has more than 2,000 hospital clients in the U.S. and more than 17,000
relationships with health care providers - and now it's focusing on being faster to market.

In buying AxiaMed, the bank is avoiding a complex IT project to upgrade health care payments and other merchant
services. It can now provide a digital payments gateway to these clients immediately.

"We would have had to build the tech ourselves and then get certified with the software providers," said Guy Harris,
head of merchant services for Bank of America.

Axia's platform is "fundamentally a health care payment system, but we are also gaining domain expertise that we
can gain from in other industries," Harris said.

Financial terms of the deal weren't disclosed, and AxiaMed operates as a subsidiary of Bank of America effective
April 1. The Santa Barbara, Calif.-based-based AxiaMed works through independent software vendors to sell SaaS-
based patient payment technology. Its branded product, Payment Fusion, uses an API to integrate into electronic
health records systems, practice management and revenue cycle management systems at health care providers.

Payment Fusion uses point-to-point encryption to take providers out of scope for PCI compliance, and it also is
HIPAA compliant, addressing a regulation that doesn't accompany payment processing for most industries.

The deal is part of Bank of America's strategy to build its own merchant services/card issuing combo following the
end of itsjoint venturewith First Data, which was dismantled in 2019 following Fiserv's acquisition of First Data.

                                                                                                         Page 2 of 2
                       BofA acquisition makes its health care payments business more nimble

"Health care is a major vertical for us, and payments are a critical part of that relationship," Harris said. "When we
decided 18 months ago to exit our venture with First Data to build our own platform, part of that is having a platform
that can work with as many partners as possible."

The AxiaMed acquisition comes as payment companies focus more on health care providers, which had been slow
to modernize due to the complexity of hospital billing systems. Among health care providers there is a demand for
a range of merchant services tied to payment credential onboarding, or acting as apayment facilitator.

"There has been a lot of innovation happening, but maybe not to the scale and pace required as the innovation has
not happened with acquiring and processing as a key piece of the solution," said Michael Trilli, a research director
for Aite Group's insurance practice. "The pandemic has pushed health care further into a retail, digital, consumer
driven market."

Health care is the more-complicated cousin for mainstream payment processing. Health payments for years have
remained more manual than automated because of complicated funding sources and compliance.

While most merchant transactions involve a consumer drawing from an account to funnel money that eventually
winds up in the merchants' account, health care in most cases involves an insurer that acts as a third party, paying
some but not all of the bill. The role of the Affordable Care Act, the pandemic and the rise of consumer-directed
health care payments add complications.

National health care spending in the U.S. is expected to grow at an average annual rate of more than 5% between
2019 and 2028, reaching $6.2 trillion, according to theCenters for Medicaid and Medicare Services. National health
expenditures will grow 1.1% faster than GDP, causing health care's share of the economy to reach 19.7% in 2028
from 1.7% in 2019, according to the CMS.

In the banking industry, most innovation has come via commercial payments through treasury services, with some
basic retail capabilities, according to Trilli. Several banks, such asFifth ThirdandJPMorgan Chase, have partnered
with fintechs to improve banking and payment services for consumers and health care providers.

In the technology industry, the need to simplify transaction rails in the eyes of the consumers and merchants has
drawn dozens of technology companies offering payment innovation. In many cases, the developers are adapting
payment technology for other purposes, such asWaystar'suse of P2P-style text messaging
orMastercard'sdeployment of blockchain to improve risk management for health care providers. AndGoogle's
venture armrecently invested $16.5 million in Nym Health to expand AI-driven health care payment processing,
another trend imported from mainstream retail payments.

"So the fact that BofA bought AxiaMed and their acquiring capabilities is a strong signal the bank is positioning itself
with these trends," Trilli said.

Writing forPaymentsSource, Florian Otto, co-founder and CEO of Cedar, a health care engagement platform, said
the pandemic has caused spikes in surprise medical bills and COVID-related fees, necessitating advancements in
compassionate billing, transaction transparency and price transparency.


https://www.americanbanker.com/news/bofa-acquisition-makes-its-health-care-payments-business-more-nimble


Load-Date: June 2, 2021


  End of Document

                                                                                                   Page 1 of 2
    Mobile health care brings home visits to North County residents Partnership provides nonemergency medical
                                                        care




          Mobile health care brings home visits to North County residents;
                 Partnership provides nonemergency medical care
                                                 The San Diego Union-Tribune
                                                    March 31, 2022 Thursday
                                                            Final Edition



Copyright 2022 The San Diego Union-Tribune All Rights Reserved

Section: LOCAL; Part B; Pg. 1
Length: 598 words
Byline: Linda McIntosh

Body


Nonemergency in-home medical visits to older adults in North County started in February through a partnership
between DocGo, a New York-based provider of last-mile Mobile Health services and the nonprofit San Marcos-
based Gary and Mary West program known as PACE, which stands for Program of All-Inclusive Care for the
Elderly.

The partnership increases access to care outside the traditional hospital setting for residents age 55 and older who
might find it difficult or risky because of COVID-19 to go in person for a nonemergency medical visit. The aim is to
bridge the gap between physical and virtual care.

DocGo's partnership with West PACE is its first such collaboration in Southern California, according to DocGo.

West PACE's nursing team can dispatch DocGo clinicians to patients' homes via the company's Mobile Health
program, which combines AI-powered dispatch technology and concierge medical services from credentialed
health care professionals. The team can treat a variety of nonemergency conditions in the home and offers
services ranging from rapid and pre-op testing, ultrasounds, wound care, cardiac and blood pressure monitoring to
COVID-19 testing and vaccinations, physicals, oral and IV treatments.

West PACE is known as a specialized health care program for older adults of all income levels who want to live as
independently as possible in their own homes. West PACE's services include medical, dental, mental health,
medication management, nutrition, physical and occupational therapy and social activities, run from their center in
San Marcos.

The West PACE program was established through a grant from the Gary and Mary West Foundation and meets
state requirements for nursing home level of care as covered by Medicare and Medi-Cal, according to West PACE
officials.

                                                                                                  Page 2 of 2
   Mobile health care brings home visits to North County residents Partnership provides nonemergency medical
                                                       care

West PACE connected with DocGo last spring through a joint research collaboration with West Health, a family of
nonprofit organizations working on lowering health care costs to support successful aging. The groups studied how
Mobile Health services and business-to-business relationships can streamline care and reduce avoidable
emergency department visits.

DocGo, which was founded in 2015 under the name "Ambulnz," is now a publicly traded company with the goal of
providing high-quality, affordable care to patients across the U.S. and in the U.K. through its staff of more than
3,500 health care providers.

"Not only have the health systems experienced significant cost savings and reductions in nonemergency visits, but
the patient experience and feedback has been overwhelming," said Caroline Hodge, vice president of clinical
growth and strategy at DocGo.

In response to ongoing industry staffing shortages, the company started two full-service, tuition-free programs for
health care professionals to advance their careers and for entry-level workers to get into the health care industry.

"Our partnership with DocGo will enable us to reach even more participants who may have difficulty getting to their
medical appointments or our facilities in San Marcos," said Dr. Ross Colt, medical director of Gary and Mary West
PACE.

In order to get DocGo services through the West PACE partnership, patients have to be West PACE participants.
Patients who are eligible for both Medicare and MediCal, or for MediCal only, are not charged co-payments for
DocGo services, and others who want to pay privately can also enroll in the program, according to West PACE.

To apply or learn more about eligibility, call Gary and Mary West PACE at (760) 280-2230 or visit westpace.org.

linda.mcintosh@sduniontribune.com


Load-Date: April 1, 2022


  End of Document

                                                                                                       Page 1 of 3
                                           TECH ROLE GROWS IN DIABETES CARE




                                TECH ROLE GROWS IN DIABETES CARE
                                                  Star Tribune (Minneapolis, MN)
                                                    October 29, 2023 Sunday
                                                        METRO EDITION



Copyright 2023 Star Tribune All Rights Reserved

Section: BUSINESS; Pg. 1D
Length: 1310 words
Byline: NICK WILLIAMS; STAFF WRITER, STAR TRIBUNE (Mpls.-St. Paul)
Highlight: Mpls. firm's app helps patients monitor, control blood sugar levels

Body


At the Hennepin Healthcare Center of Diabetes and Endocrinology in downtown Minneapolis, 66-year-old Mark
Harris tries to recall his medication intake and sleep schedule from the past week.

Laura LaFave, an endocrinologist at the center, listens attentively while seated at a computer desk, looking at
metrics of Harris' blood sugar levels extracted from the Bluetooth-connected continuous glucose monitor (CGM) he
wears daily. Harris' glucose levels are low, which leads LaFave to pry deeper into how his insulin pump is
functioning.

At the center, as many as 70% of patients with diabetes wear some sort of glucose monitoring, insulin-administering
technology, LaFave said. It's vital the device works properly for Harris, a Type 1 diabetic, meaning his body
produces little to no insulin. The combination of an insulin pump and CGM allows the pump to adjust insulin
automatically injected into his abdomen through a slender plastic tube. The CGM tests his glucose levels through
sensors patched to his skin.

For the roughly 500,000 Minnesotans diagnosed with diabetes, technology that automates the formerly manual
finger-pricking and shot-giving has been an essential development and a relief for many who now can trust
technology instead of just themselves to help manage a disease that was the seventh-leading cause of death in the
U.S. in 2019, according to the

American Diabetes Association.

Nationwide, more than 10 million Americans diagnosed with diabetes use insulin and benefit from CGM devices,
per the association. That's out of 133 million currently living with diabetes or prediabetes in the U.S.

"The technology is new, and we are still learning how all the pieces fit together, but there's no question that we're
starting to see treatments and technology that can transform the lives of people with diabetes," said Francisco
Prieto, chair of the National Advocacy Committee within the American Diabetes Association.

                                                                                                      Page 2 of 3
                                   TECH ROLE GROWS IN DIABETES CARE

A tech solution

For so long, the burden was on the patient to know their medication doses and glucose levels, said LaFave, who's
worked with diabetics for 16 years. The finger prick remains a barrier, as some are reluctant to do it.

With technology, the ability to remotely download a patient's data from a CGM and conduct follow-up consultations
has changed the delivery of care, LaFave said.

"There's good studies showing that when patients are able to see that data laid out, and they can go through what
happened in this period of time, that really increases engagement of their care," she said.

That's the premise of CGM innovation at companies like Abbott, said Jared Watkin, senior vice president of the
Illinois-based medical technology company's diabetes care business. Abbott is one of four major providers of CGMs
along with Medtronic, whose operational headquarters are in Fridley; Dexcom; and Senseonics.

Watkin worked on the research and development team that created the company's first generation FreeStyle Libre
CGM, first launched in Europe in 2014. Now on its third version, more than 5 million users wear it worldwide,
including 2 million in the U.S. A companion smartphone app allows friends, family and caregivers to follow care
remotely.

Abbott recently won FDA breakthrough designation for a new sensor that would measure glucose and ketones at
the same time, Watkin said. Ketones are acidic and can cause major disruptions to the body's biochemistry.

Before having a CGM, Harris was in the intensive care unit for ketoacidosis, a condition that develops when the
body can't transfer glucose into cells, and broken-down fat creates ketones. He was homeless at the time, and
insulin was hard to find.

A year after that in 2010, he received his first CGM through a medical-assistance program.

"We think this can be a very powerful new tool, certainly in Type 1 diabetes management in children and adults,
because it tells you when you need to do something about it and need to contact a health care professional,"
Watkin said. "In the past, they wouldn't have necessarily been doing that."

Adding other measurables to sensors, not just a single sensor for glucose in Type 1 diabetics, could offer more
benefits to people, Watkin said. That includes sensors for people who might be prediabetic or not yet in full Type 2
diabetes who can use readings from sensors for pharmaceutical or diet-based prevention.

More innovation needed

A Minneapolis tech company is working with the Centers for Disease Control and Prevention (CDC) to engage
millions of prediabetic people.

In September, the CDC awarded AmVentureX a $12.5 million grant to help scale the health organization's national
diabetes prevention program. AmVentureX's app, called BioCoach, focuses on metabolic lifestyle management
through subscription-based content and curated meals shipped to users' homes.

The company also makes and sells a variety of take-home test kits and devices, including a ketone monitor that
users can connect to the app for better health management.

AmVentureX will use the funding through the next five years to market the CDC's program and partner with
community organizations, insurance companies and health systems to reach people at risk of developing Type 2
diabetes. The funding also helps AmVentureX drive people to the BioCoach app, chief executive Matt Payne said.

Through the app, users upload and monitor their metabolic health information. A multilingual team of health
experts provide meal suggestions, fitness tips and other daily routines based on a person's health data, Payne
said. The cost for a subscription is $35 per month.

                                                                                                       Page 3 of 3
                                      TECH ROLE GROWS IN DIABETES CARE

By the end of 2024, Payne expects to have as many as 30,000 users on the app, more than double what it has
now.

Though medical device companies developed CGMs for Type 1 diabetics, and thus those are the majority of users,
95% of people with diabetes are Type 2, meaning they are insulin resistant.

With research, more tech-focused solutions are in the pipeline for those with Type 2, Watkin said.

"The great news is we've got 5 million people using FreeStyle Libre, and a fair number of them around the world
now have Type 2 diabetes, and we're able to analyze that data, and it shows that these sensors are really just as
effective in Type 2 diabetes as they are in Type 1," he said. "Those lessons of ease of use, affordability and
accessibility, you've got to put that on steroids for the Type 2 market because it's such a large group of people."

The use of artificial intelligence would accelerate the ability to deliver care through CGMs, Watkin said. AI, Watkin
said, introduces an opportunity to determine personalized care using not only data on glucose levels but a person's
overall health picture, where AI systems can recommend insulin doses, exercises and evening meals to keep blood
sugar at certain levels.

A new ally

Harris received his Type 1 diagnosis more than 40 years ago. In the 1970s, glucose test strips that required urine or
blood samples were his only options, along with having to inject himself with insulin.

With his previous CGM, Harris had to manually input glucose readings. And while Harris still pricks his finger - just
to double check his CGM - that practice could be obsolete in many parts of the world within a decade, Watkin said.

"There are children diagnosed with diabetes who never pricked their finger," Watkin said. "Would I say they're going
to disappear across the world? Probably not because there's going to be certain barriers. But from large parts of the
population around the world, they will not be putting any children on blood testing. It will be CGM as a standard
care."

Harris lives alone, so having technology to manage his illness enables him to live a somewhat normal life with less
fear of having a diabetic episode.

"I don't have to rely on myself," he said, "if I'm having low blood sugar."

Nick Williams · 612-673-4021

SEE MICROFILM OR PDF FOR CHART.


Load-Date: October 29, 2023


  End of Document

                                                                                                         Page 1 of 2
                        A Room With a View: Will artificial intelligence send us to hell or create it?




  A Room With a View: Will artificial intelligence send us to hell or create it?
                                           The Daily Free Press: Boston University
                                                      April 4, 2021 Sunday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: OPINION; Pg. 1
Length: 657 words
Byline: Antonia Lehnert

Body


This year marks the 700th anniversary of Dante Alighieri's death, but his masterpiece, "The Divine Comedy,"
transcends time.

The poem is an encyclopedia of human nature, especially human fallacy, which Dante explores in the afterworld as
the main character. His cathartic journey is characterized by countless encounters with fantastical and historical
figures, each of them representing a great learning opportunity for him and the reader.

In the fictional landscape of Hell, Dante borrows Homer's hero from the "Odyssey" to enlighten his audience on a
specific subject: the limits of human knowledge.

Odysseus is portrayed as a sinner because of the excessive curiosity he demonstrated during his trip back to
Ithaca. His quest for adventure causes him to have experiences beyond what nature set as reasonably knowable,
such as hearing the Sirens sing and crossing the Pillars of Hercules.

Humans "were not made to live as brutes, but to follow virtue and knowledge," hence his thirst for the unknown,
according to Dante.

His condemnation of the character for such a reason appears rather confusing and outdated in today's society.

We tend to conceive human knowledge as something that should be continuously furthered and deepened. We
always keep our curiosity alive because learning more means emancipating ourselves from our mind's limits.

Even the boundaries that were previously set by empirical evidence in some fields are now being overcome thanks
to our fast-paced technological development.

Overall, we would tend to disagree with Dante's placement of Odysseus in Hell and consider Odysseus an
admirable paradigm of how having an inquisitive spirit can enhance wisdom.

Alexia Nizhny/DFP STAFF

But perhaps we shouldn't instinctively discredit the author's opinion.

                                                                                                           Page 2 of 2
                      A Room With a View: Will artificial intelligence send us to hell or create it?

Although never-ending research and improvement can be extremely beneficial for most fields of study, the
possibility of setting limits could be a useful preventative measure for others. For instance, there is one modern
domain in which the debate of how far humans should go still has no definitive answer: artificial intelligence.

AI has been expanding rapidly over the past decade and is showing no signs of slowing down any time soon. Apart
from the introduction of actual human functions in AI, the improvement of deepfake technology has caused
concern.

People are seriously starting to fear AI, not only because of the more obvious consequences it might have on the
unemployment rate, but also because it could become a potential threat for humankind.

There are two main case scenarios that could result in dangerous AI-related situations. Firstly, AI can be
programmed with the goal of destruction. Weapons that successfully cause mass casualties can be easily
developed with modern technology, and it can become quite hard to control who comes into possession of the
machines.

Secondly, even technology designed to be advantageous for us can be responsible for harm. If a machine is
programmed for one specific purpose, it will achieve it at all costs. If it encounters something in its way - whether it's
a person or the environment - it could automatically overpower it.

Even those whose career and success are based on similar research - such as Elon Musk or Bill Gates - have been
increasingly outspoken about its potential negative impact.

At this point, it is nearly impossible to draw a line between the technology that can help us and that which can harm
us, but being more mindful about what we decide to develop could ensure our safety.

If applied to health care, AI can gift us with incredible improvements: from more accurate diagnoses to faster
vaccine development. However, do we really need robots that compete with our cognitive and physical abilities?
Probably not.

Although Odysseus was certainly right in encouraging us to never stop learning, we should also take Dante's advice
into consideration and pay attention to what we do with the knowledge we acquire.


Load-Date: April 5, 2021


  End of Document

                                                                                                        Page 1 of 3
                                  How Europe is leading the world in the push to regulate AI




                How Europe is leading the world in the push to regulate AI
                                                    Chicago Daily Herald
                                                  June 15, 2023 Thursday
      WEB EditioneBlast EditionCLFM EditionMC1 EditionMC3 EditionMD1 EditionMF12 EditionML2 EditionNC
     EditionNC1 EditionNC14 EditionNC14C EditionNC2 EditionNC3 EditionNC4 EditionNL1 EditionNM1 Edition



Copyright 2023 Paddock Publications, Inc.

Section: NEWS; Pg. 0
Length: 1114 words
Byline: By KELVIN CHAN AP Business Writer

Body


LONDON — Lawmakers in Europe signed off Wednesday on the world's first set of comprehensive rules for
artificial intelligence, clearing a key hurdle as authorities across the globe race to rein in AI. The European
Parliament vote is one of the last steps before the rules become law, which could act as a model for other places
working on similar regulations. A yearslong effort by Brussels to draw up guardrails for AI has taken on more
urgency as rapid advances in chatbots like ChatGPT show the benefits the emerging technology can bring — and
the new perils it poses. Here's a look at the EU's Artificial Intelligence Act: HOW DO THE RULES WORK?

 The measure, first proposed in 2021, will govern any product or service that uses an artificial intelligence system.
The act will classify AI systems according to four levels of risk, from minimal to unacceptable. Riskier applications,
such as for hiring or tech targeted to children, will face tougher requirements, including being more transparent and
using accurate data. It will be up to the EU's 27 member states to enforce the rules. Regulators could force
companies to withdraw their apps from the market. In extreme cases, violations could draw fines of up to 40 million
euros ($43 million) or 7% of a company's annual global revenue, which in the case of tech companies like Google
and Microsoft could amount to billions. WHAT ARE THE RISKS? One of the EU's main goals is to guard against
any AI threats to health and safety and protect fundamental rights and values. That means some AI uses are an
absolute no-no, such as "social scoring" systems that judge people based on their behavior. Also forbidden is AI
that exploits vulnerable people, including children, or uses subliminal manipulation that can result in harm, for
example, an interactive talking toy that encourages dangerous behavior. Predictive policing tools, which crunch
data to forecast who will commit crimes, is also out. Lawmakers beefed up the original proposal from the European
Commission, the EU's executive branch, by widening the ban on real-time remote facial recognition and biometric
identification in public. The technology scans passersby and uses AI to match their faces or other physical traits to
a database. A contentious amendment to allow law enforcement exceptions such as finding missing children or
preventing terrorist threats did not pass. AI systems used in categories like employment and education, which
would affect the course of a person's life, face tough requirements such as being transparent with users and taking
steps to assess and reduce risks of bias from algorithms. Most AI systems, such as video games or spam filters, fall
into the low- or no-risk category, the commission says. WHAT ABOUT CHATGPT? The original measure barely
mentioned chatbots, mainly by requiring them to be labeled so users know they're interacting with a machine.

                                                                                                           Page 2 of 3
                              How Europe is leading the world in the push to regulate AI

Negotiators later added provisions to cover general purpose AI like ChatGPT after it exploded in popularity,
subjecting that technology to some of the same requirements as high-risk systems. One key addition is a
requirement to thoroughly document any copyright material used to teach AI systems how to generate text, images,
video and music that resemble human work. That would let content creators know if their blog posts, digital books,
scientific articles or songs have been used to train algorithms that power systems like ChatGPT. Then they could
decide whether their work has been copied and seek redress. WHY ARE THE EU RULES SO IMPORTANT? The
European Union isn't a big player in cutting-edge AI development. That role is taken by the U.S. and China. But
Brussels often plays a trendsetting role with regulations that tend to become de facto global standards and has
become a pioneer in efforts to target the power of large tech companies. The sheer size of the EU's single market,
with 450 million consumers, makes it easier for companies to comply than develop different products for different
regions, experts say. But it's not just a crackdown. By laying down common rules for AI, Brussels is also trying to
develop the market by instilling confidence among users. "The fact this is regulation that can be enforced and
companies will be held liable is significant" because other places like the United States, Singapore and Britain have
merely offered "guidance and recommendations," said Kris Shrishak, a technologist and senior fellow at the Irish
Council for Civil Liberties. "Other countries might want to adapt and copy" the EU rules, he said. Businesses and
industry groups warn that Europe needs to strike the right balance. "The EU is set to become a leader in regulating
artificial intelligence, but whether it will lead on AI innovation still remains to be seen," said Boniface de Champris, a
policy manager for the Computer and Communications Industry Association, a lobbying group for tech companies.
"Europe's new AI rules need to effectively address clearly defined risks, while leaving enough flexibility for
developers to deliver useful AI applications to the benefit of all Europeans," he said. Sam Altman, CEO of ChatGPT
maker OpenAI, has voiced support for some guardrails on AI and signed on with other tech executives to a warning
about the risks it poses to humankind. But he also has said it's "a mistake to go put heavy regulation on the field
right now." Others are playing catch up on AI rules. Britain, which left the EU in 2020, is jockeying for a position in
AI leadership. Prime Minister Rishi Sunak plans to host a world summit on AI safety this fall. "I want to make the
U.K. not just the intellectual home but the geographical home of global AI safety regulation," Sunak said at a tech
conference this week. WHAT'S NEXT? It could be years before the rules fully take effect. The next step is three-
way negotiations involving member countries, the Parliament and the European Commission, possibly facing more
changes as they try to agree on the wording. Final approval is expected by the end of this year, followed by a grace
period for companies and organizations to adapt, often around two years. Brando Benifei, an Italian member of the
European Parliament who is coleading its work on the AI Act, said they would push for quicker adoption of the rules
for fast-evolving technologies like generative AI. To fill the gap before the legislation takes effect, Europe and the
U.S. are drawing up a voluntary code of conduct that officials promised at the end of May would be drafted within
weeks and could be expanded to other "like-minded countries." This story has been corrected to show that Kris
Shrishak's last name was misspelled.



Notes
Eds: UPDATES: Updates with comment from tech industry group. With AP Photos. Eds: UPDATES: Updates with
higher maximum amounts for fines of 40 million euros or 7% of global revenue. With AP Photos.



Graphic


Associated Press/May 18, 2023 Authorities worldwide are racing to rein in artificial intelligence, including in the
European Union, where groundbreaking legislation is set to pass a key hurdle.


Load-Date: June 15, 2023

                                                                               Page 3 of 3
                  How Europe is leading the world in the push to regulate AI


End of Document

                                                                                                     Page 1 of 2
                            Ripping the band-aid off: Why Canadians resist health care reforms




        Ripping the band-aid off: Why Canadians resist health care reforms
                                         Macdonald-Laurier Institute For Public Policy
                                                   January 18, 2022 Tuesday



Copyright 2022 Content Engine, LLC.
All Rights Reserved
Copyright 2022 Macdonald-Laurier, Canada All Rights Reserved

Length: 758 words
Byline: Ai-Men Lau

Body



As Canada grapples with an increasingly unsustainable health care system, Jeffrey Simpson examines how
Canadians' deep affection for the status quo poses barriers to reforms.

Despite evidence to the contrary, many Canadians still cling to the myth that our health care system is among the
world's fairest and most effective. However, with the COVID-19 pandemic giving the lie to this fantasy, will
Canadian policy-makers finally embrace needed reforms?

In a new commentary titled, "How Canadians' deep affection for the status quo blocks health care reform efforts
like the Mazankowski report," author Jeffrey Simpson examines how Canadians remain wedded to an inadequate
status quo that is prohibiting reform. Indeed, the pandemic notwithstanding, Canadians generally show few signs of
letting go of the misguided views about our health care system.

A variety of reports have for decades warned about the issues facing Canadians' health care. The Canadian
Medical Association (CMA) in 2010 concluded that the system was not delivering value for money. Despite Canada
being among the highest per-capita spenders of health care, our outcomes for patients are subpar. Additionally, in
2000, a World Health Organization (WHO) report warned that our heath system funding was bound to create deep
structural challenges, and recommended changing the ways in which health care is paid for.

"Canada's health care spending was among the highest for countries with largely public systems," notes Simpson.
Yet despite the inflated spending, "international comparisons long after the 2000 WHO report consistently showed
Canadian medicare to be a poor-to-average system when compared to largely public health care systems in
advanced industrial countries."

The Mazankowski report, which examined Alberta's health care system, had reached similar conclusions many
years ago. The report recommended a substantial overhaul of the system, including new methods of financing
medicare as overspending in health care risks squeezing out precious fiscal resources needed for other social
programs while creating unsustainable fiscal drags for provinces. The Mazankowski report pointed to the benefits of
allowing more private payments, a proposal that would prove far too controversial in Canada.

                                                                                                       Page 2 of 2
                        Ripping the band-aid off: Why Canadians resist health care reforms

For Simpson, the challenge is rooted in a misconception that private payments would make our system too similar
to the American system. Despite being a common practice throughout much of the developed world, including in
countries that have equitable and universal systems, the idea never resonated with Canadians.
Despite clear challenges, the majority of Canadians remain satisfied with the system, notes Simpson. Those able to
endure long waits tend to find good quality of care. Yet citizens from other countries - including Germans, Swiss,
and Australians - report higher levels of satisfaction when it comes to their systems, which have private payment
elements. Simpson also points to the lack of political will in Canada to dare to question the essential structure and
method of financing medicare, and importantly very few think tanks or academics are willing to shake up the status
quo.
For Simpson, these perspectives remain entrenched and shine light as to why recommendations for wholesale
changes, as in the Mazankowski report, have fallen flat.

"Some day, maybe, the already stretched Canadian health care system will so alarm enough Canadians who wait
too long for access that Mazankowski-type changes in the private/public mix might find some receptivity," writes
Simpson. "Alberta and the rest of Canada are not there yet."
Simpson's commentary is the second in a three-part series on the 20th anniversary of the Mazankowski Report.
You can read part one, former Saskatchewan finance minister Janice MacKinnon's commentary, here.

Next week: Jack Mintz on reforming Canada's health care funding.
To read the full commentary, click the button below.

***

Jeffrey Simpson is an Officer of the Order of Canada and was The Globe and Mail's national affairs columnist
during which time he wrote about almost all the major Canadian public policy issues, and many international
questions.
For more information, media are invited to contact:
Brett Byers
 Communications and Digital Media Manager
 613-482-8327 x105

 brett.byers@macdonaldlaurier.ca
In producing this publication, Simpson has worked independently is solely responsible for the views presented in
the publication.

MLI would not exist without the support of its donors. Please consider making a small contribution today.


Load-Date: January 19, 2022


  End of Document

                                                                                                        Page 1 of 2
                           Amazon 's creepy new health wearable analyzes your voice and body




       Amazon's creepy new health wearable analyzes your voice and body
                                                 Chicago Daily Herald
                                               August 30, 2020 Sunday
WEB EditionNC1 EditionNC2 EditionMF12 EditionNC3 EditionNM1 EditionNC EditionNC14 EditionMC1 EditionMC3
       EditionMD1 EditionML2 EditionNL1 EditionNC14C EditionNC4 EditionCLFM EditioneBlast Edition



Copyright 2020 Paddock Publications, Inc.

Section: BUSINESS; Pg. 0
Length: 973 words
Byline: Geoffrey A. Fowler The Washington Post

Body


I couldn't pick just one crazy thing to say about the Halo, Amazon's new wearable health gadget. So here are three:
1. Mirror, mirror on the wall, Amazon thinks you're fat. 2. The artificial intelligence would like you to stop sounding
overwhelmed now. 3. That nagging voice inside your head is now on your wrist.

The Halo is a $100 wrist-worn device that, among other functions, listens to your conversations so you can
understand how you sound to others. And it comes with a companion app that 3D-scans your body to track your
progress at gaining your quarantine-15. Amazon is upfront about these invasive functions, which users of the Halo
have to opt into using. What's revealing is that one of tech's biggest companies thinks consumers in 2020 might
want them. Amazon CEO Jeff Bezos owns The Washington Post, but I review all tech with the same critical eye.
Amazon declined to let me speak with an executive about the product, nor did it offer me the chance to get my
hands on one for first impressions. (Anyone can sign up for the product's waiting list, and I did. Hope they pick me!)
It makes sense that Amazon wants to push into health. This year in particular, tech companies are trying to
transition their body-worn devices from fitness trackers into health and wellness assistants. Earlier this week, Fitbit
launched a new $330 smartwatch called the Sense that includes a temperature sensor, an electrocardiogram app
and an electrodermal activity sensor to detect the body's response to stress. In September, Apple is expected to
unveil a new version of its Watch with more health bells and whistles. The makers of Fitbits, Oura rings and other
wearables have also been participating in clinical studies to see if the data they gather can be used to predict the
onset of covid-19 symptoms before patients even realize they're sick. In some ways, Amazon's Halo is a me-too
health tracker. There's no screen, but like Fitbits it has sensors that collect data about your activity, sleep,
temperature and heart activity. Covered in fabric or silicone, the water-resistant Halo Band looks like a style of
bracelet that might have been popular in high school in the 1980s. Its accompanying app and paid service nudge
you to healthier habits with content from companies including Headspace and Orangetheory Fitness. Unlike the
Apple Watch and other devices, Amazon's Halo hasn't received Food and Drug Administration clearance for any of
its functions. It doesn't count as a medical device. But the Halo and Amazon's $4-per month service attempt to use
AI to be a more "comprehensive" wellness guide — and that's where things get weird. The Halo can't track your
weight on its own, but it asks you to take photos of your body (wearing minimal, tight clothing) with its app so it can
estimate your body fat percentage. A motivational slider in the app shows you what you would look like if you lost

                                                                                                        Page 2 of 2
                       Amazon 's creepy new health wearable analyzes your voice and body

weight. And then there's the tone-monitoring. Amazon says understanding emotion is key to overall health, so it
uses AI to analyze "energy and positivity" in a customer's voice recorded from microphones on the band. (It knows
your voice, as opposed to those around you, by making a profile of you speaking.) Amazon says tone results may,
for example, "reveal that a difficult work call leads to less positivity in communication with a customer's family, an
indication of the impact of stress on emotional well-being." Say what? Why would you want to know what an AI
thinks about your tone? Are you supposed to make behavior changes — or seek counseling? Amazon says you
could use it for feedback on public speaking, or to understand how sleep impacts your tone. Amazon spokeswoman
Molly Wade said its tech does not make "judgments" about tone, but determinations such as "friendly," "hesitant,"
and "overwhelmed" sure sound like judgments to me. Also, why should we trust what AI has to say about this? The
whole idea of "tone" is fraught with ideas about gender, ethnicity and class. Will it judge women more harshly than
men? Amazon's Wade says the company trained its system with data from "all demographic groups." Privacy is
also clearly a stumbling block. Many owners of Amazon's popular Echo speakers are, rightly, concerned the Alexa
assistant is eavesdropping on their conversations. (Police are increasingly turning to those recordings for evidence.)
Unlike Echo speakers, the Halo doesn't send Amazon the words you say — instead, it listens on the band itself,
where it runs an analysis of your tone and then deletes the files. (You can press a button on the band to deactivate
its microphone.) Amazon says body scan images are sent to its cloud but are deleted from its computers after
processing. But using the Halo does mean Amazon is going to learn even more about you. Amazon says no one
can view your health data without your explicit permission, and it won't sell it. The giant retailer also says it won't
use the data gathered by the Halo to sell you things. But it has already announced a partnership with health
insurance company John Hancock to share your data for savings. Amazon has a long history of being the try-
anything company in consumer tech. It doesn't have its own smartphone on the market, so it has to think outside
the box. Over the years, I've reviewed Amazon products including a closet camera that judges your fashion sense
(the now defunct Echo Look), a TV streaming box you operate via voice (the FireTV Cube), and most recently
glasses that let you have private conversations with Alexa everywhere you go (the Echo Frames). Like many of
those other Amazon product launches, you can't just buy the Halo directly — at least not yet. Customers in the U.S.
can sign up on Amazon's website to request "early access" that includes the device and six months of service for
an introductory price of $65.



Graphic


Amazon's Halo Band and app track the wearer's fitness, health and even emotional state. Courtesy of AmazonThe
Halo app uses photos you take of your body in minimal, tight clothing to estimate your body fat composition.
Courtesy of AmazonThe Halo uses microphones on its band to listen to snippets of conversation and analyze how it
thinks you come across to others. Courtesy of Amazon


Load-Date: August 31, 2020


  End of Document

                                                                                                        Page 1 of 3
                    Former New York City Mayor Bill de Blasio talks AI and urban technology at Ford




 Former New York City Mayor Bill de Blasio talks AI and urban technology at
                                   Ford
                                      Michigan Daily: University of Michigan-Ann Arbor
                                                      October 30, 2023 Monday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS-; Pg. 1
Length: 1103 words
Byline: Samantha Rich Mary Corey

Body


Bill de Blasio, former New York City mayor, traveled to Ann Arbor Monday afternoon for a conversation at the Ford
School of Public Policy with Shobita Parthasarathy, director of the Science, Technology, and Public Policy program,
on the policy considerations involved in the rollout of smart cities and the growing prevalence of artificial
intelligence.

De Blasio served as New York City's 109th mayor from 2014 to 2021. During his tenure as mayor, de Blasio
advocated for New York City to reopen following the COVID-19 pandemic and he worked to provide free preschool
in the city. De Blasio also pushed for progressive policies like a $15 minimum wage and affordable housing
initiatives. After his 2020 presidential run, de Blasio made the switch from politics to the classroom when he started
teaching at Harvard and New York University. De Blasio continues to be an influential figure within the national
Democratic Party.

In an interview with The Michigan Daily before the event, de Blasio talked about the future of technology in the U.S.,
which was the main topic of his discussion at the School of Public Policy on Monday. De Blasio told The Daily that
he believes current AI and technology policies are not representative of public opinion.

"Right now, big tech is calling the tune and the public is not a part of this discussion," de Blasio said. "There's no
real democracy here. It's dangerous for our future."

President Joe Biden issued an executive order Monday morning to increase and standardize AI regulation. The
order requires future AI technology to be tested for possible public safety concerns and to share the results of those
tests with the federal government. This order was made under the 1950 Defense Production Act, which allows the
president to expand federal power in the interest of national security.

De Blasio told attendees he is pleased to see federal implementation of AI regulation, but would like to see more
specific and expansive AI legislation in the future.

                                                                                                        Page 2 of 3
                 Former New York City Mayor Bill de Blasio talks AI and urban technology at Ford

"(The executive order) is a good start because having an AI executive order is a major, major step," de Blasio said.
"For the President of the United States to say I am laying down some law, some structure, some order, I
commended him ... but what is the mechanism going to be? What are the consequences going to be? I didn't see
so far in the executive order a clear illustration of consequence because I think something we can all say about
corporate America is that if there is no consequence, good luck getting them to comply."

Biden's executive order also aims to mitigate algorithmic biases and set standards for AI use in education, health
care and criminal law. De Blasio told The Daily he believes AI bias is a growing issue that will continue to become
more severe as technology develops.

"Biases inhabit the technology because the technology is programmed by the humans with biases," de Blasio said.
"And we've got to really acknowledge that. I mean basically what we're seeing from big tech is just baking in our
broken status quo and their attempts to address that have been pretty feeble, and not overly sincere."

De Blasio told The Daily that he believes community organizing and activism will be critical to addressing AI issues.

"The only way the world's ever changed is through grassroots activism and social movements," de Blasio said. "I
mean, you want to talk about civil rights, women's rights, environment, climate - the whole history of this country is
undergirded by this notion that social movements, grassroots activism, people raising their voice spontaneously,
alters the course of things. The political class alone rarely will get there, but they can be pushed."

During the talk, de Blasio also detailed the potential employment impacts of increased automation. He told
attendees he wishes he had done more to protect jobs during his tenure as mayor.

"I wish I had prioritized more of these issues when I took office almost 10 years ago because I now see how hugely
this will affect our lives," de Blasio said. "We've got to start grappling with this question around employment. We
didn't feel it a lot in the time I was mayor - the displacement in terms of employment - but we could see it over the
horizon. I wish we had moved more aggressively then, but there's still time to do it."

De Blasio said he is not confident that the creators of new technology are considering the potential future effects on
other Americans when they release AI projects and automated machinery.

"Do I trust executives in Silicon Valley to think about the truck driver in Michigan, and whether that person is going
to have a livelihood once an autonomous vehicle takes over their routes?" De Blasio said. "I don't have any reason
to trust that tech executives could even think what the life of a truck driver is like."

Towards the end of the discussion, de Blasio told attendees that he is prepared to participate in political discourse
around AI, even if he doesn't fully understand how the technology works.

"I can't explain the nuances of AI, but I damn well belong in the discussion because it's going to affect me; that's
democracy," de Blasio said. "If someone tells me you don't belong in this discussion, you don't belong in this room,
you don't belong at this table, that's the table I need to be at."

In an interview after the event, Public Policy junior Audrey Melillo, who helped facilitate the discussion, told The
Daily that the topics of de Blasio's talk corresponded closely with what she was learning in some of her classes at
the Public Policy School.

"What we're right now looking at in my classes is different legislation that can be adopted that will help regulate and
control the potential harms of AI as far as the workplace goes," Melillo said. "So definitely directly relevant to what
we're talking about here."

LSA freshman Alexander Richmond told The Daily he attended the event because he admires de Blasio's previous
work as mayor in the areas of urban technology. Richmond also said he hopes to see more young people engage
in conversations around AI in the future.

                                                                                                      Page 3 of 3
                    Former New York City Mayor Bill de Blasio talks AI and urban technology at Ford

"We have somebody who's had a pretty long track record of creating the building blocks to the path that we're
heading down and addressing these key issues that I think the leaders of tomorrow need to address," Richmond
said. "I think it's extremely important that those who come next are heavily equipped to deal with these issues that
are going to pertain to tens of millions of people, potentially"

Daily News Editor Samantha Rich can be reached at sammrich@umich.edu Daily Staff Reporter Mary Corey can
be reached at mcorey@umich.edu


Load-Date: October 31, 2023


  End of Document

                                                                                                             Page 1 of 6
                  IU faculty to help shape the future at Luddy School's new artificial intelligence center




         IU faculty to help shape the future at Luddy School's new artificial
                                 intelligence center
                                              Herald-Times (Bloomington, Indiana)
                                                      August 9, 2021 Monday



Copyright 2021 The Herald-Times (Bloomington, Ind.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 2941 words
Byline: Tristan Jackson, Herald-Times, Bloomington, Ind.

Body


Aug. 9—From the technology that helps self-driving cars recognize stop signs, to medical advancements that help
produce COVID-19 vaccines, to studying the unconscious bias found in algorithms, the Luddy School of
Informatics, Computing and Engineering is involved in all parts of AI development.

As artificial intelligence continues to infiltrate everyday life, IU's researchers are focused on developing these
technologies, while working to ensure their research is safe and ethical. The Luddy Center for Artificial Intelligence
is set to open this month, providing researchers a place to focus on the intersection of robotics, complex networks,
health and social media.

Kay Connelly, Luddy School's associate dean of research, studies proactive health and AI technologies that can
help the terminally ill and older people as they age, specifically wearable devices. She said proactive health is like
"Fitbit before Fitbit."

Her work is key in one of IU's Grand Challenges, and it tackles how to get the right treatment to patients at the right
time. To research how to treat gestational diabetes, women are given wearable devices to track their heart rate,
sleep and physical activity. The hope is to prevent development of the disease and stop it from becoming Type 2
diabetes.

Gestational diabetes diagnoses come during a woman's pregnancy, according to mayoclinic.org, and the data
collected from these wearable devices allows researchers to detect which women are at higher risk to develop
gestational diabetes.

Former Luddy School dean Raj Acharya's work in AI also influences the medical community, especially as variants
of COVID-19 continue to arise. Acharya currently has a National Science Foundation grant dedicated to
reconstructing the genome of viruses using DNA and RNA sequencing, which is essential to the vaccine
development process.

                                                                                                          Page 2 of 6
               IU faculty to help shape the future at Luddy School's new artificial intelligence center

He takes short, cut-up strands of DNA and RNA, then uses the information they contain to solve questions about
the full strands, which scientists are not able to fully read.

He said viruses want to fool the immune system — this is why viruses mutate — so AI and machine-learning
techniques are used to reconstruct viruses to understand the structure and order of characters which make them
up.

He said the interaction between our immune system and viruses is a type of game theory. When a virus enters our
body, our immune system learns and stores a sequence of the virus so it can fight it, but recombination of its
character makeup allows the virus to trick our immune system.

While Acharya uses sequencing for developments in the medical field, AI can also help researchers understand the
evolutionary process called phylogenetic analysis, which is used to construct evolutionary trees showing which
animals evolved from another.

IU computer scientist David Crandall's expertise is computer vision, the part of AI that tries to get computers to
recognize things and make decisions based on what they see. Self-driving cars use this kind of research because
they need to recognize things like stop signs and be able to make the decision to stop.

This process uses machine learning, which trains computers to recognize things based on a large data set.
Machine learning is an important development because in the past it would take months or even years to program
specific commands, but now machine learning can expedite the process by having the computer teach itself,
Crandall said.

Crandall said studying how children learn has been influential to this type of research. In the same way children
begin to understand things by observing them over and over, so do the programmed machines.

This is also how programs like Alexa learn to respond to a person's command. Amazon engineers have given the
computers powering Alexa thousands of collected audio clips and taught the algorithm how to recognize certain
commands, Crandall said. These are examples of the black box model, which is a system used to study the inputs
something is given and what outputs it gives back.

Beth Plale, a professor and executive director of the Pervasive Technology Institute at IU, does research in data
provenance, which is essentially data auditing. Her job is to study algorithms and their similarities to unconscious
human bias, which can be encoded because of structural issues in our society, she said.

Plale said studying the outcomes of AI is important because if their work can be misused, people can use machine-
learning algorithms to teach robots to be bigoted and do bad things. She brought up Microsoft's conversational bot
Tay, which was pulled from Twitter because just hours into its launch users had taught it to be racist and use
inflammatory political speech.

AI needs to be accountable, she said, and her work is focused on looking into issues that arise and mitigating them,
like unconscious biases in algorithms or people's ability to manipulate outcomes. She says while trust in science is
still high, transparency in the work researchers are doing is critical. Researchers need to jump on the important
conversations early so they don't become politicized.

"There's only so much a researcher — an academic researcher — there's only so much we can do or say because
there are forces that squelch our voices," Plale said.

As Michael McRobbie's tenure as Indiana University's president was coming to an end this June, one of his final
moves was to dedicate the Luddy Center for Artificial Intelligence, a new "state of the art" facility for advanced AI
research and machine learning.

The $35 million center is part of a $60 million gift from alumnus Fred Luddy, who is the namesake of IU's school of
informatics, computing and engineering. Construction began in February 2020 and it is set to open this month.

                                                                                                           Page 3 of 6
                IU faculty to help shape the future at Luddy School's new artificial intelligence center

According to a news release from IU, the center's initial focus will be robotics, complex networks, health and social
media.

"The explosion worldwide of the uses and applications of AI, building on decades of steady research progress,
made this the perfect time for IU to establish a major holistic initiative in artificial intelligence," McRobbie said.

During McRobbie's tenure he also launched the Grand Challenges program, a $300 million investment into solving
some of Indiana's most pressing issues. These challenges include research into precision medicine, environmental
change and addiction crises.

While artificial intelligence research can lead to breakthroughs that make people's lives easier, IU's faculty also is
concerned about what consequences it will have and what conversations need to be had as the field develops.

Both Plale and Crandall point to automated military drone strikes as an example of ethical problems society will
have to grapple with. This discussion is particularly relevant in Crandall's field of study, because computer vision
would be used in such drones, and he said AI is notoriously bad at understanding things out of context.

"I think they struggle in certain circumstances. For example we know that they struggle often when they encounter
situations that they've never encountered before," Crandall said.

For example, a sticker on a stop sign may cause an autonomous car to not recognize it or act accordingly. The
stakes are even higher when considering autonomous drones having the power to kill people without human
intervention, and Plale said the ethical implications of whether military drones should have the power to do so is a
problem society will have to face.

She tied this in with the conversation of the moral considerations a sentient AI robot would be given if researchers
are able to develop one. The moral considerations are broad questions that AI researchers should contribute to the
discussion of, she said, but ultimately society will be responsible for coming up with the answers.

However, Connelly believes IU and universities in general are a good place for ethical discussions because there
are diverse voices at the table and the structure of funding and research is different compared with a corporation.

"You find that people who are advocating for the ethics often get pushed aside, or pushed out completely because it
doesn't fit in that profit model," she said.

Corporations also tend to ignore the populations Connelly's research is focused on because there's less profit
incentive in low-income communities. Her research is specifically targeted to making sure people with increased
risk of health disparities get access.

In addition to the less-profit-based research IU is able to engage in, Connelly believes the university setting is
perfect because diverse voices will be heard and be able to point out when research is short-sighted or
developments don't take into account their communities.

She mentioned problems with facial recognition not working for people of color in some cases as a potential way
more diverse voices can shape the future of AI. She believes IU does a good job mentoring students from all
backgrounds, including first-generation or students with a non-English primary language, because IU's
apprenticeship-style research helps students learn the "nitty gritty" of the field.

"They are bringing their perspectives to the table, so students are critical," Connelly said.

In terms of research resources, IU is well situated thanks to top-notch researchers in all fields of AI and having
medical professionals and experts within other schools at IU, Acharya said. He said with IU's Grand Challenges
there is a lot of cross pollination between the Luddy School and IU Health faculty in Indianapolis.

In the three ways of looking at AI — algorithmic or computer science, cognitive science and hardware — IU has
great people in all three, Acharya said. Plale also pointed out IU's well positioned infrastructure, including Big Red

                                                                                                           Page 4 of 6
                IU faculty to help shape the future at Luddy School's new artificial intelligence center

200, a supercomputer designed to support research in artificial intelligence, machine learning and data analytics,
which was installed in January 2020.

Plale noted Crandall's research in the cognitive science department is a collaborative effort with the psychology
department, where studies are looking at how babies learn, which allows the cognitive science department of the
Luddy School to apply those methods to machine learning development.

"I think what it suggests is that the collaborative activity that goes on in the academic setting can infuse new
thinking," Plale said.

Another collaborative effort Connelly brought up was IU's Observatory on Social Media, a joint project between the
Luddy School, The Media School and Network Science Institute. This project unites data scientists and journalists
to study the role of media and technology in society.

Connelly worries about manipulation of entire segments of the population, which she believes algorithms on social
media can propagate. She sees it as a direct threat to democracy. She said people fall into silos of information and
when that happens you're not exposed to a breadth of information and alternative viewpoints.

In 2017, former FBI agent and cybersecurity expert Clint Watts testified before Senate Intelligence Committee about
the role Russian bots played in the 2016 presidential election. He said Russians used "armies" of Twitter bots to
spread misinformation about the election, and in 2017 he'd already been tracking this kind of activity for more than
three years.

Connelly said everyone is susceptible to this regardless of their views, and she thinks social networks can enforce
seeking approval and conforming to whichever way you lean on issues. When you start to sway on issues, those
silos are an effective way to pull you back in.

Artificial intelligence has been a part of science fiction media since at least the 19th century, and in the same way
science fiction has had different portrayals of how AI will become part of our lives, IU's researchers have different
attitudes toward the depiction of AI in literature and film.

Crandall, for example, rolls his eyes at a lot of the depictions of AI in the media because it's very dramatic,
especially concerning things like an AI ignoring its programming and thinking for itself.

For example, recent movies like "Ex Machina" and "Her" explore the potential relationships between humans and
sentient forms of AI. "Ex Machina" (2015) ponders the idea of the creation surpassing the creator and whether an
AI can escape the black box, and "Her" (2013) explores whether humans can fall in love with an AI.

"The state of robotics is that just doing something like folding a piece of clothing is like, beyond what any robot is
able to do right now in any reasonable amount of time," he said.

While the more dramatic depictions of AI are a bit laughable to him, Crandall recognizes the more subtle ways AI
can control parts of people's lives, such as using Facebook to influence elections. He said it seems innocent, but it
can become something that controls what people see. While this is much more subtle, Crandall said conversations
are needed about these negative impacts and where AI goes from here.

Plale did not want to speculate too much about media representation, but she is also skeptical about some of the
sci-fi portrayals of AI. She said from what she's seen, AI in the media has been given much more sentience than
what exists today, and while robots in factories are very well developed, the ability to get them to process things
and react the way a human brain does is limited.

Acharya is a bit more optimistic about the role of sci-fi in the development of AI, and thinks in many ways the genre
helps researchers be more imaginative.

"I think in a way that the media people might be ahead," he said. "The science fiction is probably ahead because
the scientists are constrained by what can happen today. Media people can imagine."

                                                                                                               Page 5 of 6
                 IU faculty to help shape the future at Luddy School's new artificial intelligence center

As artificial intelligence continues to carve out a role in our lives, IU's researchers are determined to make the future
of AI a positive influence on the lives of Hoosiers. To make sure they usher in technology as a social good, Plale
believes the conversations on ethics and the research being conducted need to move forward simultaneously.

Acharya brought up deepfakes, which use a form of artificial intelligence called deep learning to make realistic-
looking images of fake events, as an example of AI being abused by people with bad intentions. In September
2019, AI firm Deeptrace found that 96% of deepfake videos were pornographic, and Boston University law
professor Danielle Citron said "Deepfake technology is being weaponized against women" because it can fuel
things such as hate porn.

Still, Acharya is optimistic about the role AI will play in the lives of people moving forward. He said continued AI
research in the medical field will be important in the lives of retired people, as it will allow more of them to live more
fully as they age and develop medical problems. Human and machine becoming one is the ultimate goal, he said, in
the sense that research into artificial limbs and organs can extend and have a positive impact on people's lives.

Also, hypothesis generation, a new type of AI application which speeds up the process of developing hypotheses
and comes up with new ones researchers might have overlooked, helps make research more efficient, Acharya
said. Overall, his outlook on the future of AI is positive.

For research as a whole, one issue Crandall sees is some researchers' eagerness to present things without full
context because they want their work to seem like a breakthrough. It's not anyone's fault, he said, and it might not
even be a bad thing because it gets people talking about the work, but the hype about some developments in AI
aren't always centered in reality.

"The reality is much more boring," he said.

People have also blown the hype around AI's impact on the job market out of proportion, Crandall said, and he
compared it with the same type of hype around the internet being a job killer when it came out. Forbes reported that
in a Gallup poll from 2018, 73% of Americans believed AI would be a net job destroyer, but only 23% of them were
worried about it, partially because they didn't believe their jobs would be affected.

"It's hard for me now to really predict what really the impact will be of AI," Crandall said. "Except that like, I think it
really is something that we have under our control."

He brought up self-driving trucks as an example of something that could push people out of certain jobs, but he's
curious what effect that will have on the job market as a whole. Automating 99.9% of what goes into driving is easy,
he said, but in the 0.1% of cases where unexpected things happen, AI is not good at anticipating and reacting the
way a human would.

He said he's comfortable with the current situation of trusting the people around him to make responsible and
rational decisions while he's driving.

"Somehow we've grown accustomed and we've grown comfortable with this situation, which when you think about it
that way is quite terrifying," he said. "Every time you get on the road you have to trust everyone else who's driving
to do the right thing."

He thinks on one hand AI is good because you can program it to make decisions, but problems arise because
society has to grapple with what decisions it should make. What or who an automated car should focus on
protecting when a crash can't be avoided altogether is one example of the discussions Crandall says need to be
had.

"I think the tricky part is we're going to have to decide, 'What is the right thing for it to do?'" he said.

___ (c)2021 the Herald-Times (Bloomington, Ind.) Visit the Herald-Times                            (Bloomington,   Ind.)     at
www.heraldtimesonline.com Distributed by Tribune Content Agency, LLC.

                                                                                                          Page 6 of 6
               IU faculty to help shape the future at Luddy School's new artificial intelligence center


Load-Date: August 10, 2021


  End of Document

                                                                                                        Page 1 of 8
                                                 How is AI changing the world?




                                        How is AI changing the world?
                                                        The Deseret News
                                                  October 4, 2023 Wednesday



Copyright 2023 The Deseret News Publishing Co. All Rights Reserved

Length: 4410 words
Byline: Deseret Magazine

Body


In the opening scenes of Walt Disney's "Pinocchio," Geppetto, a lonely woodcarver, puts the finishing touches on
the eponymous marionette puppet, wishing that it might - he might - come to life.

Geppetto's wish is granted, and chaos ensues. Despite a wise cricket standing in as an acting guide to better
consciousness, Pinocchio learns as he goes, often going the way of danger and trouble. Man and puppet are
reunited in the belly of a monster, tasked with saving themselves - and, perhaps, one other - in a quest to become
"real."

As artificial intelligence becomes more present in our lives, have we found ourselves in the belly of a monster? Or
are we still at the part of the story where we marvel at our handiwork and fall asleep wishing for more?

One thing we know for certain is that AI isn't just the stuff of lore anymore. Pandora's box is open. Everywhere you
look or click, there are headlines. There are social media posts. There are algorithms bringing us headlines
describing the AI issues we're trying to talk about. Some might say it feels like an invasion. Maybe it's what the
myths, stories and Hollywood warned us about. And yet we created the invasion ourselves.

AI isn't the first time we've been promised that technology is going to make things easier, so it's OK to harbor
skepticism this time around. Technology has a tendency to outpace our understanding of it, and cultural convention
encourages us to create, utilize said creation and then figure out the consequences later. But what if we can learn
from the past?

There are big, philosophical questions billowing around AI right now. Can or will machines become sentient? Could
they replace humans? Will our souls be distinguished from machines or lost to them? But through the culling of
these pages, we found that the bigger question may be: Will we allow ourselves to find out? The only way to know
the answers to our biggest questions is to move forward with developing this technology ... or not. Right now, we
are at a crossroads where humanity can draw lines in the sand, morally and legislatively. AI is an undeniable force
in the global human experience. And it's not on its way. It's here. This is the time to question. To explore. To learn.
And to decide - perhaps not so much what AI is, but what it isn't.

Living in a world of AI

                                                                                                          Page 2 of 8
                                            How is AI changing the world?

Artificial intelligence isn't a new technology that - seemingly out of nowhere - makes it possible for machines to think
and do the work of humans. In reality, AI has been around for decades in the form of machine learning.

That learning process allows a computer to analyze data sets, such as images or phrases, and observe patterns to
predict what the expected outcome will be in a new scenario.

Carolyn Penstein Rose, professor of language technologies and human-computer interaction at Carnegie Mellon
University and director of the Generative AI Innovation Incubator, says that machine learning hasn't allowed AI to
completely mimic human learning, but "that doesn't mean that it can't do something useful; it's just that doing
something useful doesn't require human intelligence."

Most people around the globe are already familiar with (or using) AI to some degree. It's present in the social media
algorithms that give you a new recipe for dinner, the facial recognition technology that opens your phone and the
targeted ads that suggest the perfect gift for your kid's birthday. Regina Barzilay, distinguished professor at the MIT
School of Engineering for AI and Health in the Electrical Engineering and Computer Science Department, points
out that "there is a lot of AI in various industries that we just don't even see. They are just part of the technology we
are provided with."

In the world of AI, everything is a data point. "So for example, Google, they serve a lot of ads. ... Every time
someone clicks or doesn't click, that's a data point," says David Wingate, associate professor of computer science
at Brigham Young University. Those data points are what artificial intelligence uses in order to create better apps or
better recommendations in an effort to improve a user's experience. So when we define AI, we are not talking about
a new technology that thinks for itself. It's a tool that's been in development for decades and it allows computers to
observe patterns and learn from them. "You can use AI to help and to make our life better, to solve problems that
we cannot solve for ourselves. But on the other hand, it can also result in very bad outcomes," says Barzilay. "So
the question that we, as a society, need to decide is what are appropriate uses of AI? And what is inappropriate?" -
Thabata Nunes de Freitas

The human labor powering AI

For a decade, Venezuela has endured ceaseless financial turmoil. The often-desperate state of affairs has made
the South American nation an ideal recruiting ground for a type of labor seldom discussed amid the explosion of
generative AIs like ChatGPT and DALL-E: A phenomenon called "ghost work." For DALL-E to understand what a
cat is, it needs to parse thousands of images of cats through a process called "deep learning." This process is
made possible by ghost workers, who manually label those pictures of cats, among many other things. They're
often based in the "global south" - places like Venezuela, India and Pakistan, as well as in rural America. Ghost
work is often unregulated and unguaranteed, which makes it ripe for exploitation.

In Kenya, a Time magazine investigation found the company behind ChatGPT paid laborers less than $2 per hour
to sift through harmful imagery in order to purge it from the platform. "My knee-jerk response to (that investigation)
is, 'Maybe I shouldn't use AI,'" says Angela Wentz Faulconer, an assistant professor of philosophy at Brigham
Young University. Her expertise is medical ethics, and she sees parallels. Consider the moral implications of selling
a kidney; how many people would do it if there are other ways to make impactful amounts of money? In the case of
ghost work, that leads her to conclude that the work in itself, however horrible, is not morally wrong. The difficulty
comes in that no one should be in a position where they do not freely consent to doing the work. And are the people
in Venezuela really free to choose ghost work?

Ghost workers have been around since at least the turn of the millenium, when a nascent Amazon hired them to
help sort the information it had scraped from the web about books. Newer products like ChatGPT, Julian Posada, a
member of Yale Law School's Information Society Project, says, "would not be possible" without ghost workers.
Saiph Savage, director of Northeastern University's Civic AI Lab, is trying to build tools to help improve their
working conditions while also promoting labeling infrastructure so that AI users can better understand how the
technology really works - and how it's made. "The platforms have freedom in being able to manipulate and harm
workers," she says, because there's no regulatory infrastructure. "You have this big industry pushing a narrative

                                                                                                          Page 3 of 8
                                            How is AI changing the world?

that AI is mystical, that it's an existential risk, and that we should direct more funding toward that, instead of paying
people more," Posada adds. "That's what I think people should reflect on." - Ethan Bauer

Geoffrey Hinton: The 'Godfather of AI' looks back on his life's work

He's been called a godfather of artificial intelligence, but Geoffrey Hinton has mixed feelings now about his life's
work, which focused on machine learning and neural networks, among related fields.

Neural networks in computer systems are based on how the human brain learns, allowing deep learning that is
layered and builds on experience. In 2018, Hinton shared Turing Award honors - a crowning achievement in the
computer science world - with two others for work on computer deep learning. Artificial intelligence has improved
dramatically in part because of his work.

The cognitive psychologist and computer scientist quit Google Brain this year, citing both his age (75) and the
desire to be able to speak freely about the dangers he believes AI run amok could pose. "I've come to the
conclusion that the kind of intelligence we're developing is very different from the intelligence we have," he recently
told BBC.

"So it's as if you had 10,000 people and whenever one person learned something, everybody automatically knew it.
And that's how the chatbots can know so much more than any one person."

"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as
pandemics and nuclear war."

In other interviews, he has expressed concerns that the result of AI-focused competition between Microsoft, which
incorporated a chatbot into its Bing search engine, and Google could be harmful - an unstoppable competition that
could lead to an internet flooded with fake images, videos and text, what's true being obscured. "I was not
convinced we would always be in control, but I thought it would be 50 to 100 years before digital intelligence was
smarter than us," Hinton told Deseret. The recent dramatic pace of AI development has shortened that timeline.

He's also openly worried about what could happen with AI as a tool for unscrupulous people. Hinton, in fact, is the
first of more than 180 signers of a one-sentence statement tech and other leaders issued about AI's potential
harms: "Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such
as pandemics and nuclear war." - Lois M. Collins

What's the problem with humans making AI?

Sen. Richard Blumenthal opened the first judiciary hearing for Oversight of Artificial Intelligence in May with a party
trick. He stared ahead, into the Capitol chamber, at witnesses that included AI pioneers and scholars, then spoke.
But he never opened his mouth.

"We have seen how algorithmic biases can perpetuate discrimination and prejudice, and how the lack of
transparency can undermine public trust," he said, as if telepathically, while swallowing a smirk. "This is not the
future we want."

After fooling most people in the room, the Connecticut Democrat revealed his remarks were not his own, but a
script courtesy of ChatGPT. The source of his disembodied voice was a cloning software trained to mimic the
senator's cadence. The scene was made to sound trustworthy. Reliable. But it wasn't. That was the problem he had
set out to address. Can flawed humans create flawless AI systems?

Algorithms and technologies that make actions like imitating politicians possible are crafted by humans, trained by
humans, used by humans. Which means they can also regurgitate human biases. As the National Institute of
Standards and Technology demonstrated in a 2022 report with a proverbial illustration of an iceberg, statistical and
computational biases - errors caused by skewed math or insufficient data - make up only some (the tip) of biases
found in AI. The majority come from the humans and institutions behind the technology. "Part of the issue here is

                                                                                                         Page 4 of 8
                                            How is AI changing the world?

that it's difficult to disentangle the biases in the AI system from the systemic biases in society," says Cynthia Rudin,
a computer science and engineering professor who directs the Interpretable Machine Learning Lab at Duke
University. She received the most prestigious AI award - the Squirrel AI Award for Artificial Intelligence for the
Benefit of Humanity - last year.

Rudin points out some algorithms have already been found to carry human faults. Amazon's AI recruitment tool
discriminated against women applicants. The Correctional Offender Management Profiling for Alternative Sanctions,
an assessment tool used in courtroom sentencing, misclassified Black defendants as high risk about twice as often
as their white counterparts. Social media algorithms amplified hate speech in Myanmar that helped fuel genocide.
And the risks, already mighty, may continue to compound. A statement published by the Center for AI Safety in
May, signed by hundreds of scientists, professors and politicians (including Geoffrey Hinton, as reported), suggests
flawed technology could even prompt human extinction.

Yet there is an opportunity for course correction. Scientists are beginning to stray from "black box" models -
algorithms with processes that cannot be traced or understood by humans - toward more interpretable and
controllable methods. "There were no centers for AI safety or AI equity at all until recently," Rudin says. "It used to
be a free-for-all where companies could impose black box models with almost no oversight for high-stakes
decisions. We've definitely wised up since then."

We know AI that rivals human intelligence is possible. We know the risks associated with it. What remains unclear
is whether we can create technology that understands fairness and objectivity better than we do, as well as what we
will chance to get there. As Stephen Hawking said in 2016: "In short, the rise of powerful AI will be either the best,
or the worst thing, ever to happen to humanity. We do not yet know which." - Natalia Galicza

Data Mining: How much do we really understand?

We talk a lot about AI - the numbers show it.

But as we attempt to learn about it, it is also learning about us - through data points acquired in email spam filters,
GPS navigation systems, online recommendations and even the ads we don't click on. A poll from Pew Research
conducted last year asked Americans how they felt about the increased use of AI in daily life. It seems that we're
not sure how we feel. - Alexandra Rain

Andrew Yang: A forward party leader calls for a halt

When tech industry experts launched a letter to get companies working on artificial intelligence to pause so
regulation can catch up, some big names signed. They included Elon Musk, founder of SpaceX, Tesla and the
chairman of X (formerly Twitter); Steve Wozniak, co-founder of Apple; and Andrew Yang, the tech-savvy former
presidential candidate and co-chair of the Forward Party.

The letter cited "widely-endorsed Asilomar Principles," which note: "Advanced AI could represent a profound
change in the history of life on earth and should be planned for and managed with commensurate care and
resources."

Yang, in particular, has been outspoken on his concerns. "The development of AI will bring many unforeseen
consequences and our institutions are largely unprepared," he told Deseret in an interview conducted on X. "These
tools are very powerful and in the wrong hands could lead to rampant identity theft and other problems."

"We're not at the level where we can ensure that our AI systems will always keep us safe."

Some AI industry leaders have promised voluntary safeguards. Amazon, Google, Meta, Microsoft and OpenAI (the
maker of ChatGPT) promised the White House they'd identify images AI created. Some of those same companies
(along with others) have formed the Frontier Model Forum, described by The Washington Post as seeking to
"advance AI safety research and technical evaluations" to manage emerging, increasingly powerful AI. But Yang is

                                                                                                         Page 5 of 8
                                            How is AI changing the world?

doubtful this could be a meaningful solution. "Companies self-regulating is not a viable approach in an environment
that will reward competition and adoption," he says.

He supports creating "an agency dedicated solely to AI and a Cabinet-level official similarly dedicated." Without
oversight, "photos, videos, audio recordings - all of them can be reproduced and replicated by AI," which can lead
to widespread issues like this summer's writers and actors strike in Hollywood. It's an ironic example, as Yang
warns that without regulation, the consequences could look a lot like a silver screen script. On Fox's "Cavuto: Coast
to Coast" he said that "science fiction-type scenarios are here with us." - Lois M. Collins

The politics of AI

At a Senate Judiciary Committee hearing in May, Sen. John Kennedy questioned AI leaders on how the United
States should attempt to regulate the industry. "This is your chance, folks, to tell us how to get this right," Kennedy,
a Louisiana Republican, said. "Talk in plain English and tell us what rules to implement."

With AI advancements reaching the general public and threatening to upend entire industries, the U.S. is lagging
behind the rest of the world when it comes to regulating Big Tech and AI. Currently, there is no comprehensive
federal legislation dedicated solely to AI regulation.

That isn't to say there are no levers in place - it's just more of a hodgepodge of sector-specific laws. Self-driving
cars would fall under the National Highway Transportation Safety Administration, for example. Or if AI was being
used in relation to an oil pipeline, it would be the Department of Energy.

The recently released White House Blueprint for an AI Bill of Rights - which outlines a set of principles to help guide
the design and use of artificial intelligence - may signal government action to come. Seven leading AI companies
(including Google and Meta) also agreed to voluntary safeguards on the technology's development at a meeting
with President Joe Biden in July.

But Frank Pasquale thinks it could just amount to a PR move for the companies. A professor at Cornell University,
he also currently serves on the U.S. National Artificial Intelligence Advisory Committee, which advises the
president.

"The question becomes: Where is the penalty if the companies deviate? As soon as it becomes a compelling
business proposition to defect, they probably will and we're back to square one," Pasquale says. "The real answer
here is regulation by established agencies rather than a voluntary commitment."

U.S. reluctance to regulate Big Tech is nothing new. "The U.S., for better or worse, tends to take a pretty hands-off
approach to business except in certain categories when it gets big enough that it requires notice," says Steven M.
Bellovin, a distinguished professor of computer science at Columbia University and a public policy expert. "It's a
particularity of the American economic and cultural legal system."

In 1990, the Federal Trade Commission first opened an investigation into Microsoft. A decade later, a federal court
ruled the company engaged in unlawful monopolization. So Microsoft simply amended some of its business
practices. More recently, a handful of bills attempting to curb the anticompetitive business practices of Apple,
Amazon, Facebook and Google ultimately failed last year.

Could things be different with AI? Bellovin is doubtful. Unlike stem cell research or election reform, legislation
against big tech has implications for an industry that contributed nearly two trillion U.S. dollars to the country's GDP
in 2022. "A push against new regulations is seen as a huge economic driver. Most of the big tech companies are
American," Bellovin says. "Why kill the goose that lays the golden egg?" - James Walker

Data Mining: Where are the women?

We know that data biases exist in AI, so how do these significant biases create wider gender gaps? A world already
shaped by largely homogenous leadership is currently shaping another, with one study from the Journal of Global

                                                                                                           Page 6 of 8
                                            How is AI changing the world?

Health concluding that algorithms used in health care may not only reflect back inequities but may worsen them. -
Alexandra Rain

Is this the beginning? The end? It's both.

It's a classic Hollywood plotline. Artificial intelligence becomes sentient and goes rogue - spelling disaster, or even
human extinction. There's "Blade Runner." "Westworld." "Ex Machina." "I, Robot." The list goes on.

Recent rapid advancements in generative AI - hat tip to ChatGPT, in particular - have thrust that idea into the
limelight. Is AI the beginning of a new era of human evolution? Or could it actually threaten life as we know it?

Nisarg Shah, a professor of computer science at the University of Toronto who signed the industry open letter
previously mentioned, is of two minds. "My view is that we don't fully understand these AI systems yet. ... Today,
we're not at the level where we can ensure that our AI systems will always keep us safe," he says. This is where
that "threat of extinction" that so many people are discussing comes into play: AI could soon be making more and
more critical decisions - including at nuclear power plants - where a mistake could be so terrible that it's irreversible.
"There is a serious potential of AI doing something so terrible, not because it was trained to, but just because it kind
of saw that as the right way forward. And because of the incorrect data that it was fed. Then it actually leads
to serious disaster." This is where the fallibility of human creators (and our biases) can create unintended
consequences.

"A push against new regulations is seen as a huge economic driver. Most of the big tech companies are American.
'Why kill the goose that lays the golden egg?'"

But it's also AI's ability to improve our lives that should be under the microscope, adds Shah - from already
automating routine tasks like booking flights and paying bills online to helping doctors diagnose diseases and
offering treatments based on patient history. "(A) capable system is going to come with just as many benefits as
potential harms. So the main goal is to keep the benefits without having those harms," he says.

Professor Brent Mittelstadt, director of research at the University of Oxford's Internet Institute, thinks that focusing
on the existential risk of AI in the distant future may prevent us from addressing its disruptive dangers to society
today - including mass surveillance, its potential for bias, and, particularly, the threat it poses for industry and
replacing people's jobs. "Every new technology tends to be disruptive," he says. "It transforms existing jobs either
by using the technology in tandem, or by making that job irrelevant. With AI, I think we will see both happen."

And as for which industries will be impacted, few seem entirely safe.

A research report from Goldman Sachs predicts that AI systems could expose 300 million full-time jobs to
automation worldwide. In the U.S., they estimate that roughly two-thirds of all occupations are also exposed to
some degree. Not even doctors are secure, to the chagrin of patients across the country.

Earlier this year, Google unveiled an AI medical diagnosis program that can diagnose medical conditions with
incredible accuracy. A Swedish study this year from Lund University also found that an AI program could spot
breast cancer at a "similar" accuracy of two radiologists.

Perhaps, then, the risk AI poses is more like Disney's "Wall-E." With AI taking our jobs and catering to our every
whim, we slowly degenerate into helplessness, cocooned in a spaceship as the world below us turns into a desolate
wasteland.

But what does ChatGPT think about all of this? Well, when asked a variety of questions as to whether it believes AI
will turn out to be a positive or negative development in the history of humanity, one quote stands out: "AI is a tool
created by humans, and its development and use are under human control." - James Walker

This story appears in the October issue of Deseret Magazine. Learn more about how to subscribe.

Timeline of artificial intelligence

                                                                                                        Page 7 of 8
                                           How is AI changing the world?

1637

French philosopher René Descartes publishes the seminal epistemological work "Discourse on Method." It contains
his famous phrase, "I think, therefore I am." For possibly the first time in philosophical history, Descartes grapples
with the idea of artificial intelligence or "automata."

1726

The idea of artificial intelligence enters the popular imagination thanks to Irish satirist Jonathan Swift and the
publication of "Gulliver's Travels," featuring "the engine," a sort of super-computer that allows "the most ignorant
person, at a reasonable charge, and with a little bodily labor, (to) write books ... without the least assistance from
genius or study."

1921

Czech playwright Karel Capek introduces the world to the word "robot" in his play, "Rossum's Universal Robots,"
about a factory that produces replicant humans.

1949

American computer scientist Edmund Berkeley publishes "Giant Brains, or Machines that Think," which explores
the emerging field of "mechanical brains." Echoing Descartes, Berkeley concludes, "A machine, therefore, can
think."

1950

British mathematician and computer scientist Alan Turing publishes "Computing Machinery and Intelligence." A key
idea in the book is "the imitation game" - a scenario in which a person and a machine are both interviewed by an
interrogator, whose job is to determine which is man and which is machine. This became known as the "Turing
test."

1964

Daniel Bobrow, a Ph.D. student at MIT, publishes his thesis: A computer program called STUDENT, which can
solve high school-level algebra word problems.

1966

MIT computer science professor Joseph Weizenbaum creates ELIZA, a chatbot therapist. Many people, he
observed at the time, had trouble accepting that they were not, in fact, interacting with a human.

1968

Stanley Kubrick's pioneering sci-fi film, "2001: A Space Odyssey," introduces the world to Hal, a computer with
superintelligence designed to assist a team of human astronauts on a space voyage. Hal deduces that it must kill
the human crew in order to give the mission its greatest chance of success. One astronaut manages to defy Hal's
murderous plan and shuts it down, even as Hal pleads with him: "I'm afraid. I'm afraid, Dave. Dave, my mind is
going. I can feel it."

1970s

AI enters what scholars call an "AI winter," in which mainstream sentiment toward the technology sours as
promises of its potential are left unfulfilled.

1973

                                                                                                        Page 8 of 8
                                           How is AI changing the world?

British mathematician James Lighthill authors "Artificial Intelligence: A General Survey," concluding that "in no part
of the field have the discoveries made so far produced the major impact that was then promised." The British
government defunds AI research.

1984

Arnold Schwarzenegger brings "The Terminator" to the silver screen, launching one of the most successful AI-
centered franchises ever.

1994

Jeff Bezos founds Amazon, which begins by selling books on the World Wide Web. Since 1998, Amazon's
recommendation algorithms have been powered by AI.

2009

Facebook begins using algorithms to sort posts appearing in users' feeds, rather than presenting them
chronologically.

2011

Siri, the first digital virtual assistant, is released. Apple quickly buys the rights and ushers in an era of intense
competition in the digital virtual assistant marketplace - from Google Now to Microsoft's Cortana to Amazon's Alexa.


Load-Date: October 4, 2023


  End of Document

                                                                                                Page 1 of 2
    Groupon co-founder Lefkofsky's Tempus raises more funding The precision medicine company said it raised
                              $275M in a combination of equity and debt financing




Groupon co-founder Lefkofsky's Tempus raises more funding; The precision
medicine company said it raised $275M in a combination of equity and debt
                                financing
                                                    Crain's Chicago Business
                                                         October 31, 2022
                                                           Print Version



Copyright 2022 Crain Communication All Rights Reserved




Section: Pg. 20; Vol. 45
Length: 537 words
Byline: Katherine Davis

Body


Chicago biotech company Tempus has raised more funding from investors, a move it says will help it expand its
precision medicine technology platform.

Tempus, launched by Groupon co-founder Eric Lefkofsky, raised about $275 million in a combination of equity and
debt financing, the company said in a statement. Tempus said it sold shares to its existing investors for the same
price per share as its previous fundraising round at the end of 2020, when it raised $200 million at an $8.1 billion
valuation.

Tempus investors from other funding rounds include Baillie Gifford, Franklin Templeton, Google, venture-capital
fund NEA and Novo Holdings.

The debt financing came from Ares Management, a Los Angeles-based private-equity firm that's also put funds into
local health care companies like TAG-The Aspen Group and physician group Duly Health & Care. Altogether, the
new financing brings Tempus' total funding to more than $1.3 billion.

DATA LIBRARY

Tempus, which has 1,700 employees, about 900 of whom are in Chicago, says it will use the new funds to scale
operations and build out new capabilities for its platform. The company, founded in 2015, started out by providing
genomic-sequencing services to treat different cancers. Since then, it has expanded to treat other conditions, like
cardiology, diabetes and infectious diseases such as COVID-19. Now the company says it owns one of the world's

                                                                                               Page 2 of 2
   Groupon co-founder Lefkofsky's Tempus raises more funding The precision medicine company said it raised
                             $275M in a combination of equity and debt financing

largest libraries of clinical and molecular data. Using this information, Tempus says it can provide "contextualized"
results for each specific patient, insights that help physicians tailor and personalize treatment plans.

"In the last seven years, we've made great strides in developing and deploying smarter diagnostics not only in
oncology, but neuropsychiatry, infectious disease, and cardiology," Lefkofsky said in a statement. "We are
committed to achieving our mission in applying AI to health care broadly with a focus on deploying solutions at
scale that have real impact on patient care today and research in the future."

Last fall, it was reported that Tempus was exploring going public as soon as the first half of 2022. But that was
before a turbulent public market this year resulted in one of the weakest IPO markets in years. Earlier this year,
Tempus acquired San Francisco-based Highline Sciences, a full-service clinical contract research organization that
manages and executes early- and late-stage clinical trials.

Tempus' fundraise comes near the end of a slow venture-capital market this year, according to data from PitchBook
and the National Venture Capital Association. About $43 billion was invested in U.S. companies in the third quarter,
a nine-quarter low. Like Tempus, many of the companies still raising funding are going back to existing investors for
cash.

Despite the slowdown in VC, health care companies in Illinois and across the country are attracting capital at a
higher rate than some of their peers in other industries. Of the 10 largest VC deals in Illinois during the third quarter,
seven were with health care companies that spanned across pharmaceutical, medical device and health care
services subsectors, PitchBook and NVCA data shows. A similar trend is taking place across the country.


Load-Date: November 3, 2022


  End of Document

                                                                                                       Page 1 of 2
                                                  Ishrak-led firm seeks $750M IPO




                                        Ishrak-led firm seeks $750M IPO
                                                  Star Tribune (Minneapolis, MN)
                                                    January 21, 2021 Thursday
                                                         METRO EDITION



Copyright 2021 Star Tribune All Rights Reserved

Section: BUSINESS; Pg. 1D
Length: 407 words
Byline: NICOLE NORFLEET; STAFF WRITER, STAR TRIBUNE (Mpls.-St. Paul)
Highlight: Medtronic interested in buying 1.5 million shares of the company, Compute Health.

Body


Former Medtronic CEO and current Intel Chairman Omar Ishrak is one of the leaders of a new health-tech
company that has filed for a $750 million initial public offering.

Compute Health Acquisition Corp. is what is called a "blank check" company, hoping to build itself by investing or
buying businesses that are "at the intersection of computation and health care."

Compute Health could start with strong ties to the company Ishrak led as CEO from 2011 to last spring. Medtronic
has expressed interest in buying 1.5 million units in the IPO, according to a filing with the Securities and Exchange
Commission.

Compute Health expects to sell 75 million units priced at $10 each and pursue an acquisition of a company,
according to the SEC filing. Advancements in data access and artificial intelligence are helping to push innovation,
the filing said.

Ishrak is chairman of Compute Health's board.

One of its co-chief executives also has ties to Medtronic, which is run out of Fridley. Jean Nehme helped found
artificial-intelligence startup Digital Surgery Ltd. and sold it to Medtronic. The other co-CEO is Joshua Fink, who
runs investment firm Ophir Holdings LLC and is the son of BlackRock Inc.'s Larry Fink, according to Bloomberg
News.

"We see the application of this growing computational power and AI to health care as ubiquitous, from the home to
primary and secondary care services," Compute Health

said in the filing. "Many companies and services have adopted mobile and cloud computing and are moving quickly
to computational intelligence, or CI, often at the point of care, or 'edge.' "

The company said it did not select any specific target business or have substantive discussions with any business
regarding a merger or acquisition.

                                                                                                   Page 2 of 2
                                        Ishrak-led firm seeks $750M IPO

Medtronic's interest isn't a binding agreement, but the company has increased the number of connected devices it
has introduced. For example, more of its cardiac and diabetes management products can now be remotely
monitored or programmed.

Geoff Martha, Ishrak's successor as Medtronic's chief executive, said last week at this year's J.P. Morgan Health
Care Conference that the pandemic increased demand for those products, and he believes it will continue. More
connected products are in the pipeline.

Ishrak stepped down in December as chairman of Medtronic's board of directors. Since 2017, Ishrak has also
served on the board of Intel Corp. and he is currently the chairman.

Nicole Norfleet · 612-673-4495


Load-Date: January 22, 2021


  End of Document

                                                                                                            Page 1 of 2
              "Even if you can do it, should you?" Researchers talk combating bias in artificial intelligence




    "Even if you can do it, should you?" Researchers talk combating bias in
                               artificial intelligence
                                            The Stanford Daily: Stanford University
                                                      February 4, 2021 Thursday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 810 words
Byline: Patricia Wei

Body


As artificial intelligence becomes increasingly common in several areas of public life - from policing to hiring to
healthcare - AI researchers Timnit Gebru, Michael Hind, James Zou and Hong Qu came together to criticize Silicon
Valley's lack of transparency and advocate for greater diversity and inclusion in decision making.

The event, titled "Race, Tech & Civil Society: Tools for Combating Bias in Datasets and Models," was sponsored by
the Stanford Center on Philanthropy and Civil Society, the Center for Comparative Studies in Race and Ethnicity
and the Stanford Institute for Human-Centered Artificial Intelligence.

Qu, the moderator of the panel and a CCSRE Race & Technology Practitioner Fellow who developed a tool called
AI Blindspot that discovers bias in AI systems, opened the conversation by discussing how there are two definitions
of combating bias: ensuring that algorithms are "de-biased" and striving for equity in a historical and cultural
context.

Gebru '08 M.S. '10 Ph.D. '15 said that she was introduced to these issues as they relate to machine learning in AI
after seeing a ProPublica article about recidivism algorithms, and a TED Talk by Joy Buolamwini, a graduate
researcher at MIT, who discovered that an open-source facial recognition software did not detect her face unless
she wore a white mask.

As Gebru moved higher up in the tech world, she noticed a severe lack of representation - a pressing inequity she
is working to redress. "The moment I went to grad school, I didn't see any Black people at all," Gebru said.

"What's important for me in my work is to make sure that these voices of these different groups of people come to
the floor," she added.

Michael Hind is an IBM Distinguished Researcher who leads work on AI FactSheets and AI Fairness 360, which
promote transparency in algorithms. Hind agreed with Gebru, noting the importance of "having multiple disciplines
and multiple stakeholders at the table."

                                                                                                          Page 2 of 2
            "Even if you can do it, should you?" Researchers talk combating bias in artificial intelligence

But not everyone has affirmed Gebru's mission of inclusion. Last month, Google fired Gebru from her role as an AI
ethics researcher after she had co-written a paper on the risks of large language models. Her paper touched on
bias in AI and how social linguists, who study how language relates to power, culture, and society, were left out of
the process.

Since the news of her firing broke, computer science educators and students showed their support and solidarity for
Gebru and her work. When Qu asked the panelists how to increase racial literacy, Gebru responded, "I tried to do it
and I got fired."

She cited the "high turnover" of employees tasked to spearhead diversity initiatives, whose efforts to enact
institutional change were often dismissed.

"They don't have any power," Gebru said. "They're miserable. They leave." Despite Google's many ethics
committees, "there's just no way that this will work if there's no incentive to change," she added

Citing this culture of complacency as one of the reasons he left Silicon Valley, Zou said, "For me, I believe it's more
pernicious to be passively complicit than even to be intentionally malicious."

In many cases, technology companies may even step beyond passive complicity, Gebru said. She cited Microsoft's
partnership with the New York Police Department to develop predictive policing algorithms. Because these
technological tools rely on historical data, some researchers say they may reinforce existing racial biases.

"For any Black person in the United States who has had experiences with police," Gebru said, "you would
understand, you know, why predictive policing would be an issue."

Zou, however, remained optimistic about the use of AI for social good. He noted that because of the pandemic, the
need for telehealth has exploded. Doctors are now relying on patients on images from patients to help diagnose
them, and computer vision technology can help patients take better photos, he said.

Even cases of algorithmic bias can present valuable learning opportunities, Zou added. Pointing to language
models he worked on as a member of Microsoft Research, Zou said that the models' gender biases offered a way
to "quantify our stereotypes."

However, Zou was reluctant to place too much faith in AI.

"If it's a scenario that affects someone's health or safety, AI should not be the sole decision maker," he said.

As the conversation ended, the researchers agreed on the need to continue questioning the role of using AI in tools
that affect our daily lives.

"A lot of features certainly should not be ones a data scientist or engineer should be deciding," Hind said.

He referred to how the virtual interviewing company HireVue used AI to analyze applicants' videos to measure skills
such as empathy and communication.

"Even if you can do it, should you?" Gebru asked.

Contact Patricia Wei at patwei 'at' stanford.edu and Jared Klegar at jkklegar 'at' stanford.edu.


Load-Date: February 4, 2021


  End of Document

                                                                                                       Page 1 of 2
                       NYSOFA brings ELLiQ Proactive Care Companion Technology to older adults




     NYSOFA brings ELLiQ Proactive Care Companion Technology to older
                                  adults
                                                    The Daily Mail (Catskill, New York)
                                                          June 7, 2022 Tuesday
                                                               Print Edition



Copyright 2022 Johnson Newspaper Corporation
Distributed by Newsbank, Inc. All Rights Reserved

Section: H_HEALTH; Pg. A7
Length: 750 words
Dateline: ALBANY

Body


Building on its comprehensive effort to battle social isolation and support aging-in-place, NYSOFA is delivering
voice-operated smart technology into the homes of over 800 older adults.

Under the program, NYSOFA will work with local offices for the aging and partners to identify older adults who
would most benefit from the technology: ElliQ by Intuition Robotics, which is the first-ever proactive and empathetic
care companion.

ElliQ is designed to foster independence and provide support for older adults through daily check-ins, assistance
with wellness goals and physical activities, connection to family and friends, and more using voice commands
and/or on-screen instructions. The technology, which recently launched commercially after years of pilots and early
production deployments, has shown unprecedented engagement levels with older adults. Users have an average of
20 daily interactions.

Distinct from other smart technologies, ElliQ is made specifically for older adults to support independence at home.
While other technologies are reactive to commands, ElliQ proactively suggests activities and initiates conversations,
building context through artificial intelligence (AI) to inform follow-up conversations that create a sense of
relationship with the AI. To support health and wellness, ElliQ offers sleep relaxation exercises, physical activity
exercises, in-depth nutrition-related conversations, and medication reminders for each user's unique condition(s).

In 2017, the U.S. Surgeon General declared social isolation to be a "global epidemic" - one that has only worsened
in the COVID-19 health emergency. According to the AARP Public Policy Institute, social isolation drives $6.7
billion in additional associated Medicare spending per year. The health consequences of loneliness and isolation
are equivalent to smoking almost a pack of cigarettes daily. At a time when older adults are at increased risk for
loneliness and social isolation, ElliQ offers another form of companionship, supplementing traditional, in-person
support.

                                                                                                        Page 2 of 2
                    NYSOFA brings ELLiQ Proactive Care Companion Technology to older adults

New York State Office for the Aging Director Greg Olsen said: "We are so pleased to partner with Intuition Robotics
and make ElliQ available to older adults in New York. This product does so many things to improve health, combat
isolation, and improve overall well-being and independence. Designed with input from older adults, the future of
supporting and serving older adults includes technology. The future is here."

He added: "Despite misconceptions and generalizations, older adults embrace new technology, especially when
they see it is designed by older adults to meet their needs. For those who experience some form of isolation and
wish to age in place, ElliQ is a powerful complement to traditional forms of social interaction and support from
professional or family caregivers."

Intuition Robotics CEO and Co-Founder Dor Skuler said: "We've long believed that connecting older adults with
local communities via ElliQ will add an important element in providing holistic support to older adults aging in place.
This partnership with NYSOFA helps us further that mission through an innovative initiative that we are incredibly
proud to be part of."

He added: "We're thrilled to be working with New York State as our first state government partner and believe ElliQ
will be able to effectively engage and encourage older adults in New York to be more independent, healthy and
happy."

Association on Aging in New York (AgingNY) Executive Director Becky Preve said: "The Association on Aging in
New York is thrilled to offer additional technology services to combat social isolation and loneliness. We are so
thankful for NYSOFA's continued commitment to older New Yorkers and the opportunity to partner on innovative
solutions that support aging in place."

The newly enacted Fiscal Year 2023 State Budget includes $2.9 million in funding for pioneering NYSOFA
initiatives to combat social isolation and offer new or expanded innovations in aging service provision at multiple
levels. In addition to ElliQ, this includes: NYSOFA's animatronic pet initiative, which provides lifelike companion
pets for older adults and is proven to reduce self-reported loneliness by 70 percent; statewide access to Trualta's
family caregiver support platform offering expert-led training across critical care competencies; ride-sharing services
designed exclusively for older adults; and online communities that provide facilitator-led classes and services.


Load-Date: June 7, 2022


  End of Document

                                                                                                       Page 1 of 2
                       NYSOFA brings ELLiQ Proactive Care Companion Technology to older adults




     NYSOFA brings ELLiQ Proactive Care Companion Technology to older
                                  adults
                                                    Register-Star (Hudson, New York)
                                                         June 7, 2022 Tuesday
                                                              Print Edition



Copyright 2022 Johnson Newspaper Corporation
Distributed by Newsbank, Inc. All Rights Reserved

Section: H_HEALTH; Pg. A7
Length: 750 words
Dateline: ALBANY

Body


Building on its comprehensive effort to battle social isolation and support aging-in-place, NYSOFA is delivering
voice-operated smart technology into the homes of over 800 older adults.

Under the program, NYSOFA will work with local offices for the aging and partners to identify older adults who
would most benefit from the technology: ElliQ by Intuition Robotics, which is the first-ever proactive and empathetic
care companion.

ElliQ is designed to foster independence and provide support for older adults through daily check-ins, assistance
with wellness goals and physical activities, connection to family and friends, and more using voice commands
and/or on-screen instructions. The technology, which recently launched commercially after years of pilots and early
production deployments, has shown unprecedented engagement levels with older adults. Users have an average of
20 daily interactions.

Distinct from other smart technologies, ElliQ is made specifically for older adults to support independence at home.
While other technologies are reactive to commands, ElliQ proactively suggests activities and initiates conversations,
building context through artificial intelligence (AI) to inform follow-up conversations that create a sense of
relationship with the AI. To support health and wellness, ElliQ offers sleep relaxation exercises, physical activity
exercises, in-depth nutrition-related conversations, and medication reminders for each user's unique condition(s).

In 2017, the U.S. Surgeon General declared social isolation to be a "global epidemic" - one that has only worsened
in the COVID-19 health emergency. According to the AARP Public Policy Institute, social isolation drives $6.7
billion in additional associated Medicare spending per year. The health consequences of loneliness and isolation
are equivalent to smoking almost a pack of cigarettes daily. At a time when older adults are at increased risk for
loneliness and social isolation, ElliQ offers another form of companionship, supplementing traditional, in-person
support.

                                                                                                        Page 2 of 2
                    NYSOFA brings ELLiQ Proactive Care Companion Technology to older adults

New York State Office for the Aging Director Greg Olsen said: "We are so pleased to partner with Intuition Robotics
and make ElliQ available to older adults in New York. This product does so many things to improve health, combat
isolation, and improve overall well-being and independence. Designed with input from older adults, the future of
supporting and serving older adults includes technology. The future is here."

He added: "Despite misconceptions and generalizations, older adults embrace new technology, especially when
they see it is designed by older adults to meet their needs. For those who experience some form of isolation and
wish to age in place, ElliQ is a powerful complement to traditional forms of social interaction and support from
professional or family caregivers."

Intuition Robotics CEO and Co-Founder Dor Skuler said: "We've long believed that connecting older adults with
local communities via ElliQ will add an important element in providing holistic support to older adults aging in place.
This partnership with NYSOFA helps us further that mission through an innovative initiative that we are incredibly
proud to be part of."

He added: "We're thrilled to be working with New York State as our first state government partner and believe ElliQ
will be able to effectively engage and encourage older adults in New York to be more independent, healthy and
happy."

Association on Aging in New York (AgingNY) Executive Director Becky Preve said: "The Association on Aging in
New York is thrilled to offer additional technology services to combat social isolation and loneliness. We are so
thankful for NYSOFA's continued commitment to older New Yorkers and the opportunity to partner on innovative
solutions that support aging in place."

The newly enacted Fiscal Year 2023 State Budget includes $2.9 million in funding for pioneering NYSOFA
initiatives to combat social isolation and offer new or expanded innovations in aging service provision at multiple
levels. In addition to ElliQ, this includes: NYSOFA's animatronic pet initiative, which provides lifelike companion
pets for older adults and is proven to reduce self-reported loneliness by 70 percent; statewide access to Trualta's
family caregiver support platform offering expert-led training across critical care competencies; ride-sharing services
designed exclusively for older adults; and online communities that provide facilitator-led classes and services.


Load-Date: June 7, 2022


  End of Document

                                                                                                        Page 1 of 2
                                               40 UNDER FORTY Eric Schwartz




                                      40 UNDER FORTY; Eric Schwartz
                                                     Crain's Detroit Business
                                                          November 1, 2021
                                                            Print Version



Copyright 2021 Crain Communications All Rights Reserved




Section: Pg. 20; Vol. 37
Length: 268 words
Byline: Kirk Pinho

Body


Eric Schwartz

Co-founder Blue Conduit Associate Professor of Marketing Stephen M. Ross School of Business, University of
Michigan

Age: 35

Career trajectory: After receiving his undergraduate degree in mathematics and Ph.D. in marketing from the
University of Pennsylvania in 2008 and 2013, respectively, Schwartz packed his bags and moved west to Ann
Arbor, where he was assistant professor of marketing from 2013 to 2020 and then became a tenured associate
professor last year. After working in Flint with U-M students on lead issues in the water system, Blue Conduit - an
AI startup that helps identify lead pipes - was officially founded in 2019. It has done work in Flint, Detroit, Benton
Harbor and Toledo.

Proudest achievement: Developing Blue Conduit, which has received grant funding from Google.org, the California-
based Internet giant's charitable arm; Troy-based The Kresge Foundation; and the New York City-based
Rockefeller Foundation. Schwartz said Blue Conduit is expanding to "dozens of other cities" beyond Flint. The
company has grown from no revenue and one employee in 2019 to just shy of $1 million in revenue this year and
more than a dozen full-time employees, Schwartz said.

What's next: Getting Blue Conduit "in the hands of as many communities as possible," Schwartz said. A second
goal is developing a second line of business applying AI to other public health issues, such as tracking legionella
bacteria in water, for example.

Words of wisdom: "When you get that burning gut feeling that you should be doing something that you're not doing
yet, you probably should do it," Schwartz said.

                                                             Page 2 of 2
                              40 UNDER FORTY Eric Schwartz


Load-Date: November 4, 2021


 End of Document

                                                                                                        Page 1 of 2
                                     MACHINES CAN LEARN HOW TO HEAL YOU




                            MACHINES CAN LEARN HOW TO HEAL YOU
                                              Pittsburgh Post-Gazette
                                             June 1, 2022 Wednesday
                                                 SOONER EDITION



Copyright 2022 P.G. Publishing Co.

Section: OPINION; Pg. A-9
Length: 684 words

Body


It's 2045, and American troops are engaged in a firefight in a remote desert. A soldier is down, unconscious,
struggling to breathe -- and there's not a medic in sight. A fellow infantryman reaches for a special backpack. Inside
is TRACIR, which stands for Trauma Care In A Rucksack.

It's an inflatable vest that uses artificial intelligence algorithms to measure heart rate, blood pressure and blood
oxygen. The wounded soldier is placed on the TRACIR vest, and it quickly finds a collapsed lung. The vest detects
where the collapse is located, and then automatically inserts a needle between his ribs to re-inflate his lung. He can
breathe again. It may be just enough to allow him to survive until he can be evacuated.

TRACIR is a real project at the University of Pittsburgh and Carnegie Mellon University, funded with millions of
dollars in research money from the Department of Defense. It's just one of dozens of examples cited at a recent
conference on the emerging use of artificial intelligence and machine learning in healthcare. Hosted by Pitt's Center
for Military Medicine Research, the event was funded by the Jewish Healthcare Foundation and DSF Charitable
Foundation.

Using machine learning algorithms, AI can discern patterns in huge arrays of data - and nothing produces data like
the nation's healthcare system - and learn new ways to detect, diagnose and treat disease. Besides TRACIR, here
are just a few of the other projects the conference highlighted:

When carbon monoxide gets into the bloodstream, it latches onto the hemoglobin in red blood cells, and prevents
them from carrying oxygen. Dr. Jason Rose, a researcher in Pitt's Division of Pulmonary, Allergy and Critical Care
Medicine, and his team have developed compounds that serve as CO magnets, so the poisonous gas latches onto
them rather than hemoglobin. They use an AI program that predicts what shape proteins will assume, based on
their amino acids, to craft antidotes that are stable and highly attractive to CO molecules.

One of the biggest risks to injured soldiers is hemorrhaging, where sudden bleeding can cause blood pressure to
crash beyond a patient's ability to recover. Victor Convertino, a Ph.D. researcher at the U.S. Army Institute of
Surgical Research, has done carefully controlled lab studies using a negative pressure chamber. While lying flat,
people's lower bodies are encased in an airtight chamber which draws blood away from their heads and torsos,
mimicking what happens during a blood loss injury.

                                                                                                         Page 2 of 2
                                   MACHINES CAN LEARN HOW TO HEAL YOU

An algorithm that learned more than 130 million data points based on real-time measurements allows a new device
to assess how well each person is able to compensate for their plummeting blood pressure. This can help identify
who is most likely to go into circulatory shock.

Several studies have shown that AI algorithms can do a better job than human doctors at detecting signs of disease
in X-rays and MRI scans. Shandong Wu heads up the Center for Artificial Intelligence Innovation in Medical
Imaging, which encompasses more than 100 researchers from Pitt, CMU and UPMC. Among their research
initiatives: breast cancer imaging, liver disease, heart disease, lower back pain and mental health.

The use of AI/ML algorithms is still in its formative stages and may be several years away from widespread use. But
research leaders believe many of these computer techniques are on the verge of a breakthrough.

Michael Pinsky, a pioneering critical care medicine researcher at Pitt, helped develop a course in AI/ML for Pitt
medical students. It focuses on the three major uses of such algorithms in medicine: detecting whether you're sick,
identifying what's making you sick and tracking whether you're getting better. Students who show a strong interest
in the topic can go on to get specialized computer science training after taking the elective.

"Machine learning is not some special thing," he said, "but will be a big part of medicine going forward."

Mark Roth is a retired staff writer and editor at the Pittsburgh Post-Gazette and freelance writer, writing primarily on
scientific and medical topics.


Load-Date: June 1, 2022


  End of Document

                                                                                                         Page 1 of 6
                  Rising health care reformer charts a path for young professionals and policy reforms




Rising health care reformer charts a path for young professionals and policy
                                  reforms
                                               Texas Public Policy Foundation
                                               October 11, 2023 Wednesday



Copyright 2023 Content Engine, LLC.
All Rights Reserved
Copyright 2023 TPPF, USA All Rights Reserved

Length: 3495 words
Byline: Tanner Aliff

Body

America needs health care innovation and principled policy reform more than ever.
Rising costs, sicker patients, and doctor shortages plague an overburdened and needlessly complicated system.
Patients fear rising insurance premiums and astronomical medical bills. Crippling, top-down regulations imposed by
broken laws, poor bureaucrat interpretation, and special interest lobbying prevent doctors from giving patients the
best care possible.

Fortunately, solutions to these problems are within grasp.

Tanner Aliff is one of the many policy and health experts transforming our health care system, starting in
the states. As the Policy Director for Right on Healthcare at the Texas Public Policy Foundation, Tanner researches
reforms addressing price transparency, state employee health plans, anti-competitive health care regulations,
hospital financing, and telehealth, among other issues affecting patients and medical providers.

Stand Together Trust invests in health care changemakers like the Texas Public Policy Foundation to ensure
Americans have greater access and better health care.

Stand Together Trust spoke with Tanner about the need for reform, his research and policy work, and what ideas
stand to innovate health care.

You've dedicated your career to health care, focusing on fixing a broken system. Can you tell us why you
are compelled to work for health care reform?

When I realized the financing and administration of health care often hurt patients more than their own illnesses or
injuries, I knew it was health care policy that needed the most "curing." As an undergrad, I planned to have a
career in neuropsychology but changed course after working as a Constant Observer at Providence Health. While
at Providence, I worked graveyard shifts in the emergency department (ED) and monitored the conditions of at-risk
patients. Nothing crazy, just keeping an eye on patients, taking notes, and flagging the attending physician or
nurses if a complication popped up.

                                                                                                          Page 2 of 6
                Rising health care reformer charts a path for young professionals and policy reforms

One night the police brought in a patient suspected to be under the influence and had jumped off a roof in a nearby
neighborhood. The ED team took care of the bodily injuries, but a Doctor of Psychology (PsyD) was called in due to
suspicion of substance abuse. I chatted with the PsyD who conducted the psych evaluation. The patient was
transient, had a long family history of mental health issues, had a smorgasbord of diagnosable disorders, and
seemed to pose a continued risk to themselves. The PsyD wanted the patient committed to an inpatient facility, but
my hospital didn't have a psychiatric ward, meaning the PsyD could only make a referral. Consequently, the patient,
who didn't own a car, was "referred" to an outpatient facility about 13 miles away. Long story short, I had a sinking
feeling the patient wasn't going, or able, to get treatment.

Once the patient was patched up and discharged, a seasoned nurse mentioned that it was the seventh or ninth time
they saw the patient in the ED that month. That shocked me. However, what shocked me more, was that the patient
was enrolled in Oregon Medicaid. Essentially, the state was spending thousands of taxpayer dollars on emergency
services, that didn't address the root mental health issues repeatedly bringing the patient back to the emergency
room. It was in that instance I realized how the health care system was hurting patients more than their own
ailments.

It wasn't one person's or organization's fault that the patient didn't get the care they needed; it was simply the
consequences of bad laws and incentives baked into a broken system. When I looked at that patient, I saw my
siblings, friends, family, and other loved ones. And the thought of them not getting the care they needed while
wasting thousands of dollars in the process, made me sick. After Providence, I ditched my clinical aspirations and
decided to get involved in fixing health care policy.

You recently took the position as the head of the Texas Public Policy Foundation's Right on Health. Can
you share a little about your work priorities in that role?

The first priority is seeing Texas become a key health care leader that other states and the federal government can
follow. Because, to me, if you can get health care right in Texas, you can get it right everywhere else.

Besides building reforms on price transparency, telehealth, ending doctor shortages, and disincentivizing anti-
competitive contracting, the cornerstone of my agenda will be focused on empowering free enterprise and
conservative advocates to ensure low-income and middle-class patients get access to health care.

I think folks right of center have savvy ideas on how to fix health care, but there is some long overdue work on
highlighting how those ideas will directly enable our most vulnerable populations, especially folks in rural regions, to
access health care, with or without insurance. There are many strong-armed government plans floating around that
worry me. Price controls, monopsonies, and unfettered Medicaid expansion may sound appealing, but they don't
resolve the core issues exacerbating health care access and costs. Corralling Americans onto government
insurance will not fix health professional shortages, encourage more medical centers be built, improve the quality of
health care, prevent nurse burnout, stop crony billing practices, drive innovation, or remove the middlemen in-
between the patient-doctor relationship.

My work will be dedicated to restructuring incentives so that all health care players determine success not based
on market share, revenue, or control, but on the number of positive outcomes they can produce for patients.

Restructuring Texas charity care is a first step in living up to my vision of holding accountability over poor incentives
baked into our health care system and placing agency back into the hands of doctors and patients.

What are some of the core problem areas policymakers and social entrepreneurs should focus on?
Policymakers and entrepreneurs ought to focus on two things:
    •   Enforcing accountability over laws that incentivize private actors to be exploitative; like the Affordable Care
        Act making insurers spend 85% of their premium revenue on patients', which encourages providers to jack
        up their prices to whatever insurers can payout opposed to setting prices based on what a patient can
        spend out of their paycheck. Or Texas law that encourages non-profit hospitals to sell patient medical debt
        instead of offering middle-class families charity care.

                                                                                                        Page 3 of 6
                Rising health care reformer charts a path for young professionals and policy reforms

    •   Placing agency back into the hands of patients and health care professionals.

In the last 50 years, many laws and middlemen got in between the patient-doctor relationship. The result? America
spends nearly $4.3 trillion on a crisis-centric health care system that begets scattered-shot health outcomes. It still
has insured Americans wondering if they will see a life-ruining bill balance in their patient portal.

Patients struggle to understand how health care is paid for and are expected to trust entities that often don't have a
patient’s unique health care needs in mind. Consequently, most Americans now rely on their employer or the
government to offer them health benefits. Such an expectation limits Americans from knowing all the financing
options in the market that could better serve them, and it fuels the lie "that health care spending is too complicated
for Americans to understand or participate in."

Right now, many patients fear rising insurance premiums and the chance of outrageous medical bills coming to
haunt them. This is happening because Americans are convinced, pressured, or duped into capitulating their
agency over health financing and care decisions to third-parties that the patients don't know, don't understand, or
shouldn't trust.

Additionally, doctors and nurses are facing a wide swath of laws and industry pressures, compelling them to worry
about things that have nothing to do with ensuring patients get the best care possible. For example, health care
professionals are wasting time on bill coding, navigating lopsided hospital employee contracts, dealing with
encumbering licensing hoops that restrict their freedom to move their practice, and are getting held back from
practicing their trade to their fullest ability. Patients need help to reclaim their agency over their health care
financing. But health care professionals need assistance getting freed from burdensome laws and administrative
tasks taking away their focus from solely putting patients' health first.

What are some ideas for solutions to these problems you identify?
Policymakers and social entrepreneurs can help improve accountability and place agency back into patients' and
doctors' hands in a few ways.
    •   Make price transparency actually functional for patients.

For decades Americans have gotten health coverage for peace of mind and to ensure they don't pay the lion's
share of unexpected medical bills. Subsequently, insurance companies have been negotiating health care prices
on our behalf and deciding which health providers a patient should see based on the insurance companies'
interest, not the patients' need. All this to say, millions of patients are unaccustomed to interacting with prices or
browsing for shoppable health care.
Making sure prices are visible is important. But policymakers need to realize that simply requiring prices be posted
isn't going to magically change the behavior of Americans who have been relatively alienated from worrying about
prices for decades. It's time to focus on giving patients incentives to start browsing and interacting with prices.

The first major step in price transparency was getting providers to share prices. There is still work that needs to be
done. We need to ensure hospitals comply with the law, and we are encouraging more health providers than just
hospitals to share their prices. However, the second, and more important step, is ensuring that patients and
employers have resources to easily and effectively use emerging pricing data.
Policymakers should remove the barriers preventing payers from rewarding patients who take the time to browse
for better priced, high-quality care. Also, price transparency cannot be approached in a lukewarm fashion.
Policymakers need to ensure compliance is high and that providers share prices consistently.

Additionally, as price transparency initiatives continue, entrepreneurs can seize the opportunity to develop new
products and services that leverage price data for employers to pick quality health insurers or make the process of
patients browsing for services far easier.
    •   Give Americans a real reason to not want or rely on government health insurance.

Free market advocates and conservatives are notoriously known for saying no to Medicaid Expansion, Obamacare,
and pushes for a government-run health care system, without offering a likable and comprehensive replacement.

                                                                                                        Page 4 of 6
                Rising health care reformer charts a path for young professionals and policy reforms

The battle over the future and betterment of the American health care system hinges on whether low-income and
middle-class Americans can get access to health care without needing government intervention.

It's time policymakers and entrepreneurs turn their attention to revamping an overlooked private health care safety
net, hospital charity care. Two-thirds of our nation's hospitals are nonprofits that enjoy considerable tax breaks
eclipsing over $25 - $28 billion annually. These hospitals get tax exemptions because they are expected to use
those tax savings to cover or discount low-income patients' care, with and without health insurance. Some
hospitals collecting more revenue than a for-profit Fortune 500 company are only spending about 1.4 percent of that
revenue on charity care-all the while, patients eligible for charity care are getting sent to debt collectors and 4 in
10 Americans are strapped with medical debt.

Policymakers can reshape expectations for charity care while entrepreneurs can build tools to help hospitals verify
and dispense charity care to Americans that need it most. With hospital prices and insurance premiums rising at an
unsustainable rate, the nation needs to focus on ensuring that the uninsured, the barely non-eligible Medicaid
population, and middle-class families stuck in coverage gaps have recourse to get health care without needing to
enroll in lackluster government-run programs.
    •   Start empowering patients and employers to browse around for health insurance and shoppable medical
        services. One potential solution is to expand the utility of individual coverage health reimbursement
        arrangements (ICHRAs) and Health Savings Accounts (HSAs).

Hospital consolidation, network adequacy requirements, and the Affordable Care Act have made it difficult for many
health insurers to negotiate the best rates for high-quality services. Research is showing that cash prices (e.g.,
when patients pay doctors directly) for medical services are often lower than what insurers can negotiate with
health providers. This means that employers and patients could save millions if they invested in programs that
make it easier to pick the health insurance that suits them best or use tools that make it feasible to pay out-of-
pocket for more affordable cash rates. Whether it be selecting insurance or engaging in a more dynamic cash
market, the overarching goal should be putting patients in control of their health care.
    •   Increase health professional mobility and supply. A simple fact exacerbating health care prices, costs, and
        poor outcomes is that there are not enough providers to serve patients. State tailored interstate or
        international licensure reciprocity can help bring in new doctors and reshuffle the current health
        professional supply from areas with surpluses to the many rural communities grappling with severe
        shortages.

For example, interstate telehealth registration (not compacts) would allow doctors in surplus supply states, like
Massachusetts or New York, to offer streamlined telehealth services in states with severe doctor shortages, like
Arizona or Texas. There are many licensing and processing barriers that disincentivize health care professionals
from offering their service across state lines. Mitigating interstate licensing barriers can encourage doctors to seize
opportunities and serve communities with the most need.
America is a great country meaning we should be welcoming the greatest doctors across the globe to come here.
The Cicero Institute has done great work supporting Tennessee in removing redundant residency requirements that
detoured skilled international doctors from immigrating to the United States. There is still a wide range of
international and domestic licensing processes that can be optimized in the states. No American should feel like
they need to leave the country to get the best medical care. Waiting for Washington D.C., to subsidize more
hospital training programs isn't going to cut it. Americans need care now and states are more than capable to roll
out the red carpet.
    •   Put patients and doctors first over anti-competitive industry contracting.

Many folks say the "health care market is failing." I disagree. The American health care market isn't failing. Why?
Because there is no real market in our health care system, to begin with. Part of the reason why our health care
system doesn't have a market is because we allow anti-competitive contract provisions to stop real market forces
from taking place.

                                                                                                          Page 5 of 6
                Rising health care reformer charts a path for young professionals and policy reforms

For example, insurers are struggling to structure their reimbursement based on quality health care. Hospitals have
market leverage to dictate all-or-nothing, anti-steering, and anti-tiering clauses. This means insurers, the de facto
financial health care stewards for most Americans, are unable to design plans that steer patients towards the best
quality care for the best price.

But insurers are not innocent either. Suppose one insurer has a majority of patients enrolled in their plans in a
specific region. In that case, providers know they must contract with that insurance company, or they risk forgoing
all possible business and steady reimbursement from those policyholders - to say "no" could put providers out of
business. Many health care providers are stuck dealing with most favored nation clauses, which prohibit them from
offering any other entity, patient, or competing insurer a lower price than what is offered to the dominant insurance
companies.
Bottom line, under cover of complicated contract negotiations, the importance of patients and doctors have taken a
backseat to insurers' and hospitals' interests as they fight to shut out competition and extort one another. It's not the
hospitals' or insurers' fault. They are just responding to incentives in the status quo. We need policymakers and
entrepreneurs to change those incentives.

What are some of the most innovative solutions to fix health care that you've seen in action in policy or the
private sector?

We're seeing many innovative policies at the state level that are increasing transparency, engendering healthy
competition amongst providers, and empowering patients to make better decisions both for their health and wallet.
Luckily some private sector actors have seized the opportunity here and are building tools that will change the way
Americans think about health care.

Companies are empowering patients with pricing data so they can make more informed care decisions. Turquoise
Health, Healthcare Bluebook, and Sidecar Health, have built tools that help patients and employers navigate cash
prices, understand negotiated insurance rates, and make health insurance more transparent.

Companies like CrowdHealth, Curative, and Taro Health are departing from traditional health insurance models by
creating products that give people more options for how their care is paid for, integrate with independent doctors
who charge extremely affordable cash prices, and maximize preventive health care services.

Nest Health is leveraging technological advancements to improve the patient experience and bring primary care
directly into folks' homes.

Artificial Intelligence seems to be the hot tech phrase of this year and there are many discussions on how AI could
help health providers do their job better. However, while predictive health AI models are interesting, it would be
nice to see more entrepreneurs focus on building AIs tools to assist with care navigation, browsing providers,
and comparing prices for services in city markets. I am sure patients and employers would benefit greatly.

You're a fellow in the Health Reformers Academy (another grantee of Stand Together Trust). Can you share
why you decided to participate in that program and how it's been valuable to you and your work?

When thinking about potential solutions for fixing the health care system, it seems the only phrase people my age
can say is, "single-payer or Medicare for All." And truth be told, I haven't encountered any formal educational
program offering realistic and feasible free-market alternatives. That was until I enrolled in the Health Reformers
Academy (HRA). I primarily applied to HRA because I loved health policy and the opportunity to get plugged into a
greater network of experts was hard to pass up.

What makes health care policy seem so complex is that there are multiple actors and special interests all
intersecting at the same time over a wide variety of issues. HRA did a phenomenal job of mapping out how all the
players interact with one another: insurers, hospitals, associations, doctors, drug manufacturers, pharmacists, state
legislators, congress, governors, presidents, and agencies. Oh my.
The program was the best policy education and talent incubator I have been a part of. There are hardly any
programs out there that will teach you "the know-how" and then work on placing you into a role where you can

                                                                                                      Page 6 of 6
               Rising health care reformer charts a path for young professionals and policy reforms

apply your newly gained policy knowledge. The alumni community is great and truly keeps an eye out for one
another, sharing job opportunities and inviting members to collaborate on interesting projects.

The best part of the program? Once HRA broke down the health care system into comprehensible learning units,
they connected you with leading policy and industry experts to become mentors. For me, that connection was
Marylin Bartlett, former Administrator of the Montana State Employee Health Plan. Marylin has now become a good
friend and trusted ally that has helped me navigate hospital financing in my policy work at the Texas Public Policy
Foundation.

The icing on the cake? HRA connected me to an amazing cohort of aspiring health policy professionals who have
all helped me in my current work. The cohort was diverse and included folks working in think tanks, the public
sector, entrepreneurship, journalism, and public affairs. The mix kept conversations interesting and offered a wide
variety of perspectives.
Post HRA fellowship, the biggest value add is that I have a wide selection of peers and mentors who are only one
phone call away if I need anything for work.




Load-Date: October 12, 2023


  End of Document

                                                                                                         Page 1 of 4
                                                         From the Future: AI




                                                 From the Future: AI
                                           The Observer: University of Notre Dame
                                                      February 2, 2023 Thursday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1834 words
Byline: Spencer Kelly

Body


Maggie Klaers | The Observer

Artificial intelligence may seem like a distant technology, confined to Terminator-style sci-fi stories for the
foreseeable future. But the rapid advances in AI capabilities, as exhibited recently with tools like DALL-E and
ChatGPT, demonstrate that AI is already here and impacting our everyday lives. While AI holds the promise of
advancing society and shaping the world for the better, it also has the potential to be harmful or outright destructive.
Ensuring responsible AI deployment is imperative to securing a flourishing future for humanity, or securing a future
for humanity at all.

In this inaugural edition of From the Future - a new series highlighting transformative research occurring at Notre
Dame - we profile three researchers who are investigating ways to tackle philosophical, political and practical
challenges as humans attempt to implement AI into our society.

Novel frameworks for AI philosophy:

Carolina Villegas-Galaviz, Postdoctoral Research Associate, Technology Ethics Center

Courtesy of Carolina Villegas-Galaviz

Carolina Villegas-Galaviz studies the philosophical implications of AI through the framework of ethics of care.

As a philosophy student in her native Spain, Carolina Villegas-Galaviz discovered the 20th-century German
philosopher Hans Jonas. Jonas observed that in approaching philosophical issues with technology, people were
trying to apply theories from thousands of years ago. These ancient theories, Jonas argued, were no longer
applicable. Instead, humanity needs new ethics for the technological age.

"When I heard his idea, I knew it was true," Villegas-Galaviz said. "Right now what we need to do is to adapt the
moral frameworks of the past that Aristotle and others more than 2,000 years ago proposed, and relate those to the
new era."

                                                                                                        Page 2 of 4
                                                 From the Future: AI

Among the myriad technologies that permeate modern society, AI presents perhaps the most profound
philosophical problems. As a postdoctoral research associate at the Notre Dame Technology Ethics Center,
Villegas-Galaviz is moving beyond standard approaches like deontology or epistemology and employing novel
ethical frameworks to meet the unique demands of AI.

One of Villegas-Galaviz's main areas of research is the "ethics of care." She finds four aspects of the ethics of care
framework especially useful for thinking about AI.

First, ethics of care is grounded in a view of individuals as existing in a web of interdependent relationships, and
these relationships must be considered when designing AI systems.

Second, ethics of care emphasizes the importance of context and circumstances. For Villegas-Galaviz, this means
that AI algorithms shouldn't be applied universally, but should be tailored with the local culture, customs and
traditions in mind.

Third, Villegas-Galaviz notes that humans should be aware of the vulnerabilities of certain people or populations
and ensure that AI does not exploit these vulnerabilities, purposely or inadvertently.

Lastly, ethics of care holds that giving a voice to everyone is essential. Understanding all perspectives is imperative
for AI, a technology that promises to be truly universal.

Beyond the ethics of care, Villegas-Galaviz received a grant from Microsoft to study the intersection of AI and
empathy. Her research so far has focused on how empathy relates to the problem of "moral distance," where
concern for others diminishes when people don't have to directly interact with those affected by their actions. This is
a pertinent problem for AI, where developers deploy algorithms in a detached fashion.

"It's interesting to see how empathy can help to ameliorate this problem of moral distance," Villegas-Galaviz said.
"Just to know there's a problem with lack of empathy with AI ... we'll be in line to solve it. Those who design,
develop and deploy [AI] will know that 'I need to work on this.'"

Villegas-Galaviz says her research is grounded in a critical approach to AI. However, she noted that this does not
mean she is against AI; she believes humans can solve the philosophical issues she is studying.

"I always try to say that AI is here to stay and we need to make the best out of it," Villegas-Galaviz said. "Having a
critical approach does not mean being a pessimist. I am optimistic that we can make this technology better."

Finding balance with AI regulation:

Yong Suk Lee, Assistant Professor of Technology, Economy and Global Affairs, Keough School of Global Affairs

Courtesy of Yong Suk Lee

Yong Suk Lee researches the effects of AI on the business sector.

While promoting new philosophical frameworks for AI will help ensure responsible use to an extent, humanity will
likely need to create concrete legal strategies to regulate AI.

Such is the research focus for Yong Suk Lee, assistant professor of Technology, Economy and Global Affairs in the
Keough School. Lee notes that the rapid progress AI has made in recent years is making governance challenging.

"The pace of technological development is way ahead and people, the general public especially, but also people in
governance - they're not aware of what these technologies are and have little understanding," Lee said. "So with
this wide discrepancy between how fast technology is evolving in the applications and the general public not even
knowing what this is - with this delay, I think it's a big issue."

An economist by training, Lee's research has primarily focused on the effects of AI on the business sector.

                                                                                                               Page 3 of 4
                                                    From the Future: AI

In a 2022 study, Lee and fellow researchers conducted a randomized control trial where they presented business
managers with proposed AI regulations. The goal was to determine how regulations influence managers' views on
AI ethics and adoption.

The study concluded that "exposure to information about AI regulation increases how important managers consider
various ethical issues when adopting AI, but increases in manager awareness of ethical issues are offset by a
decrease in manager intent to adopt AI technologies."

Lee is currently researching the ramifications of AI adoption on jobs in the banking industry.

To some extent, Lee's research aligns with the common assumption that "AI is stealing our jobs." He is finding that
as banks adopt AI, demand for "front-end" jobs like tellers decreases. However, demand for analysts and other
technical roles is actually increasing. So, while AI isn't taking all of our jobs just yet, according to Lee, "it is definitely
changing the skills demanded of workers."

In thinking about what successful AI governance might look like, Lee considers two facets critical. For one, Lee
would like to see more upfront regulation or supervision determining how AI is deployed.

"I think there needs to be some way where regulation or agencies or academia can play a role in thinking about
whether it's good for these types of technologies to be out in the public," Lee said.

However, Lee doesn't want regulation to stifle innovation. Lee noted that AI is a geopolitical issue as the U.S.,
China and other countries "race" to develop advanced AI faster than others.

"With this in mind, you think 'OK, we do want to regulate to some degree, but also we don't want to stifle
innovation,'" Lee said. "So how we balance that I think is going to be a key thing to consider going forward."

Though the challenges are significant, Lee feels that successful AI regulation can be achieved.

"I think we will find a way," Lee said. "There's going to be trial and error. But we won't let AI destroy humanity."

Collaborating to create AI for good:

Nitesh Chawla, Frank M. Freimann Professor of Computer Science and Engineering, College of Engineering;
Director, Lucy Family Institute for Data and Society

Courtesy of Nitesh Chawla

Nitesh Chawla runs the Lucy Family Institute for Data and Society and coordinates projects focused on the potential
benefits of AI.

Assuming humans overcome the above philosophical and political issues (and, of course, that AIs and other
advancements don't destroy humanity), what is the potential for AI in helping our society?

Nitesh Chawla, Frank M. Freimann professor of computer science and engineering and director of the Lucy Family
Institute for Data and Society, is focused on finding applications where AI can be used for good.

"We are advancing the field [of AI], we are developing new algorithms, we are developing new methods, we are
developing new techniques. We're really pushing the knowledge frontier," Chawla said. "However, we also ask
ourselves the question: How do we take the big leap, the translational leap? Can we imagine these innovations in a
way that we can implement them, translate them to the benefit of a single person's life or to the benefit of a
community?"

For Chawla, the quest to find the most impactful AI applications is not, and should not be, an endeavor only for
computer scientists. Though a computer scientist himself, Chawla believes that advancing AI for good is an
interdisciplinary effort.

                                                                                                        Page 4 of 4
                                                 From the Future: AI

"A lot of these societal challenges are at the intersection of domains where different faculties or different expertise
have to come together," Chawla said. "It could be a social science piece of knowledge, it could be a humanist
approach ... and then the technologist could say, 'Let me take that into account as I'm developing the technology so
the end user, the person I'm interested in making an impact for, actually benefits from it.'"

Embracing this interdisciplinary mindset, Chawla's work at the Lucy Family Institute involves a range of applications
in a variety of locations.

Chawla discussed a project here in South Bend, where the Institute is working with community partners and using
AI to help address childhood lead poisoning. In another health-related study, AI is being used to analyze and
propose solutions for healthcare disparities in Mexico. Further south in Colombia, the Lucy Family Institute and the
Kroc Institute for Peace Studies have teamed up to apply AI toward understanding peace accords processes.

"The institute is committed 200% to leveraging data, AI [and] machine learning towards the benefit of society and
enabling teams of faculty, students and staff on campus to get together to take on some of these wicked problems
and address them," Chawla said.

Like Villegas-Galaviz and Lee, Chawla is optimistic about AI. Chawla envisions a future where humans don't just
passively deploy AI, but where humans and AIs work together to solve the world's most pressing problems.

"It's going to be a human-machine collaboration, where the humans would still be necessary for certain higher-order
decision-making, but the machine just makes it easier," Chawla said. "It's going to be a partnership, in many ways."

Chawla said that AI will not be a substitute for human work.

"I don't believe [AI] is going to be displacing mankind," Chawla added. "I believe that top scholars and practitioners
can come together to enable progress in technology while also thinking about how we democratize its use and
access in an ethical way."

Contact Spencer Kelly at [email protected].


Load-Date: February 6, 2023


  End of Document

                                                                                                         Page 1 of 4
                             From the Future: AI - Philosophical, political and practical issues




           From the Future: AI - Philosophical, political and practical issues
                                           The Observer: University of Notre Dame
                                                      January 31, 2023 Tuesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1834 words

Body


Artificial intelligence may seem like a distant technology, confined to Terminator-style sci-fi stories for the
foreseeable future. But the rapid advances in AI capabilities, as exhibited recently with tools like DALL-E and
ChatGPT, demonstrate that AI is already here and impacting our everyday lives. While AI holds the promise of
advancing society and shaping the world for the better, it also has the potential to be harmful or outright destructive.
So, ensuring responsible AI deployment is imperative to securing a flourishing future for humanity, or securing a
future for humanity at all.

In this inaugural edition of From the Future - a new series highlighting transformative research occurring at Notre
Dame - we profile three researchers who are investigating ways to tackle philosophical, political and practical
challenges as humans attempt to implement AI into our society.

Novel frameworks for AI philosophy:

Carolina Villegas-Galaviz, Postdoctoral Research Associate, Technology Ethics Center

Carolina Villegas-Galaviz studies the philosophical implications of AI through the framework of ethics of care. |
Courtesy of Carolina Villegas-Galaviz

As a philosophy student in her native Spain, Carolina Villegas-Galaviz discovered the 20th-century German
philosopher Hans Jonas. Jonas observed that in approaching philosophical issues with technology, people were
trying to apply theories from thousands of years ago. These ancient theories, Jonas argued, were no longer
applicable. Instead, humanity needs new ethics for the technological age.

"When I heard his idea, I knew it was true," Villegas-Galaviz said. "Right now what we need to do is to adapt the
moral frameworks of the past that Aristotle and others more than 2,000 years ago proposed, and relate those to the
new era."

Among the myriad technologies that permeate modern society, AI presents perhaps the most profound
philosophical problems. As a postdoctoral research associate at the Notre Dame Technology Ethics Center,
Villegas-Galaviz is moving beyond standard approaches like deontology or epistemology and employing novel
ethical frameworks to meet the unique demands of AI.

                                                                                                        Page 2 of 4
                          From the Future: AI - Philosophical, political and practical issues

One of Villegas-Galaviz's main areas of research is the "ethics of care." She finds four aspects of the ethics of care
framework especially useful for thinking about AI.

First, ethics of care is grounded in a view of individuals as existing in a web of interdependent relationships, and
these relationships must be considered when designing AI systems.

Second, ethics of care emphasizes the importance of context and circumstances. For Villegas-Galaviz, this means
that AI algorithms shouldn't be applied universally, but should be tailored with the local culture, customs and
traditions in mind.

Third, Villegas-Galaviz notes that humans should be aware of the vulnerabilities of certain people or populations
and ensure that AI does not exploit these vulnerabilities, purposely or inadvertently.

Lastly, ethics of care holds that giving a voice to everyone is essential. Understanding all perspectives is imperative
for AI, a technology that promises to be truly universal.

Beyond the ethics of care, Villegas-Galaviz received a grant from Microsoft to study the intersection of AI and
empathy. Her research so far has focused on how empathy relates to the problem of "moral distance," where
concern for others diminishes when people don't have to directly interact with those affected by their actions. This is
a pertinent problem for AI, where developers deploy algorithms in a detached fashion.

"It's interesting to see how empathy can help to ameliorate this problem of moral distance," Villegas-Galaviz said.
"Just to know there's a problem with lack of empathy with AI ... we'll be in line to solve it. Those who design,
develop and deploy [AI] will know that 'I need to work on this.'"

Villegas-Galaviz says her research is grounded in a critical approach to AI. However, she noted that this does not
mean she is against AI; she believes humans can solve the philosophical issues she is studying.

"I always try to say that AI is here to stay and we need to make the best out of it," Villegas-Galaviz said. "Having a
critical approach does not mean being a pessimist. I am optimistic that we can make this technology better."

Finding balance with AI regulation:

Yong Suk Lee, Assistant Professor of Technology, Economy and Global Affairs, Keough School of Global Affairs

Yong Suk Lee researches the effects of AI on the business sector. | Courtesy of Yong Suk Lee

While promoting new philosophical frameworks for AI will help ensure responsible use to an extent, humanity will
likely need to create concrete legal strategies to regulate AI.

Such is the research focus for Dr. Yong Suk Lee, Assistant Professor of Technology, Economy and Global Affairs in
the Keough School. Lee notes that the rapid progress AI has made in recent years is making governance
challenging.

"The pace of technological development is way ahead and people, the general public especially, but also people in
governance - they're not aware of what these technologies are and have little understanding," Lee said. "So with
this wide discrepancy between how fast technology is evolving in the applications and the general public not even
knowing what this is - with this delay, I think it's a big issue."

An economist by training, Lee's research has primarily focused on the effects of AI on the business sector.

In a 2022 study, Lee and fellow researchers conducted a randomized control trial where they presented business
managers with proposed AI regulations. The goal was to determine how regulations influence managers' views on
AI ethics and adoption.

                                                                                                               Page 3 of 4
                            From the Future: AI - Philosophical, political and practical issues

The study concluded that "exposure to information about AI regulation increases how important managers consider
various ethical issues when adopting AI, but increases in manager awareness of ethical issues are offset by a
decrease in manager intent to adopt AI technologies."

Lee is currently researching the ramifications of AI adoption on jobs in the banking industry.

To some extent, Lee's research aligns with the common assumption that "AI is stealing our jobs." He is finding that
as banks adopt AI, demand for "front-end" jobs like tellers decreases. However, demand for analysts and other
technical roles is actually increasing. So, while AI isn't taking all of our jobs just yet, according to Lee, "it is definitely
changing the skills demanded of workers."

In thinking about what successful AI governance might look like, Lee considers two facets to be critical. For one,
Lee would like to see more up-front regulation or supervision determining how AI is deployed.

"I think there needs to be some way where regulation or agencies or academia can play a role in thinking about
whether it's good for these types of technologies to be out in the public," Lee said.

However, Lee doesn't want regulation to stifle innovation. Lee noted that AI is a geopolitical issue as the US, China
and other countries "race" to develop advanced AI faster than others.

"With this in mind, you think 'okay, we do want to regulate to some degree, but also we don't want to stifle
innovation,'" Lee said. "So how we balance that I think is going to be a key thing to consider going forward."

Though the challenges are significant, Lee feels that successful AI regulation can be achieved.

"I think we will find a way," Lee said. "There's going to be trial and error. But we won't let AI destroy humanity."

Collaborating to create AI for good:

Nitesh Chawla, Frank M. Freimann Professor of Computer Science and Engineering, College of Engineering;
Director, Lucy Family Institute for Data and Society

Nitesh Chawla runs the Lucy Family Institute for Data and Society and coordinates projects focused on the potential
benefits of AI. | Courtesy of Nitesh Chawla

Assuming humans overcome the above philosophical and political issues (and, of course, that AIs and other
advancements don't destroy humanity), what is the potential for AI in helping our society?

Nitesh Chawla, Frank M. Freimann Professor of Computer Science and Engineering and Director of the Lucy
Family Institute for Data and Society, is focused on finding applications where AI can be used for good.

"We are advancing the field [of AI], we are developing new algorithms, we are developing new methods, we are
developing new techniques. We're really pushing the knowledge frontier," Chawla said. "However, we also ask
ourselves the question: how do we take the big leap, the translational leap? Can we imagine these innovations in a
way that we can implement them, translate them to the benefit of a single person's life or to the benefit of a
community?"

For Chawla, the quest to find the most impactful AI applications is not, and should not be, an endeavor only for
computer scientists. Though a computer scientist himself, Chawla believes that advancing AI for good is an
interdisciplinary effort.

"A lot of these societal challenges are at the intersection of domains where different faculties or different expertise
have to come together," Chawla said. "It could be a social science piece of knowledge, it could be a humanist
approach ... and then the technologist could say, 'let me take that into account as I'm developing the technology so
the end user, the person I'm interested in making an impact for, actually benefits from it.'"

                                                                                                        Page 4 of 4
                          From the Future: AI - Philosophical, political and practical issues

Embracing this interdisciplinary mindset, Chawla's work at the Lucy Family Institute involves a range of applications
in a variety of locations.

Chawla discussed a project here in South Bend, where the Institute is working with community partners and using
AI to help address childhood lead poisoning. In another health-related study, AI is being used to analyze and
propose solutions for healthcare disparities in Mexico. Further south in Colombia, the Lucy Family Institute and the
Kroc Institute for Peace Studies have teamed up to apply AI toward understanding peace accords processes.

"The institute is committed 200 percent to leveraging data, AI [and] machine learning towards the benefit of society
and enabling teams of faculty, students and staff on campus to get together to take on some of these wicked
problems and address them," Chawla said.

Like Villegas-Galaviz and Lee, Chawla is optimistic about AI. Chawla envisions a future where humans don't just
passively deploy AI, but where humans and AIs work together to solve the world's most pressing problems.

"It's going to be a human-machine collaboration, where the humans would still be necessary for certain higher-order
decision-making, but the machine just makes it easier," Chawla said. "It's going to be a partnership, in many ways."

Chawla said that AI will not be a substitute for human work.

"I don't believe [AI] is going to be displacing mankind," Chawla added. "I believe that top scholars and practitioners
can come together to enable progress in technology while also thinking about how we democratize its use and
access in an ethical way."

Contact Spencer Kelly at skelly25@nd.edu


Load-Date: January 31, 2023


  End of Document

                                                                                                       Page 1 of 3
                                  Deals may be down, but the city's tech industry is still up




                 Deals may be down, but the city's tech industry is still up
                                                   Crain's New York Business
                                                          October 9, 2023
                                                           Print Version



Copyright 2023 Crain Communications All Rights Reserved




Section: Pg. 1; Vol. 39
Length: 1033 words
Byline: Jack Grieve

Body


There's a flawed narrative that New York City's tech industry is receding. After a decade of embracing a growth-at-
all-costs mindset, according to this narrative, the sector peaked in 2022 and it's now feeling the hangover.

There's some merit to that storyline. Venture capital investment in tech is shrinking, and there's no sign of when it
will bounce back. Meanwhile, IPOs are almost nonexistent, and some of the biggest names in tech are bleeding on
Wall Street.

A look under the deal sheets, however, paints a more nuanced picture. The city is overflowing with available tech
talent. Artificial intelligence is in the early stages of what could be a dot-com-level boom. C-suite executives are
confident in their companies' growth in New York, according to a new survey, and more tech firms are choosing to
do business here than ever before.

"Tech in New York City feels super optimistic right now," said Julie Samuels, founder and president of Tech:NYC,
which acts as a booster for local tech firms. "Obviously the industry has faced some headwinds-you've seen that
internationally-but it feels like we've really navigated that quite well."

Touting tech talent

Perhaps New York's biggest selling point when it comes to the state of tech is its abundance of talent. There are
now more than 370,000 tech workers across New York, according to the latest data from real estate firm CBRE.
That means there are more jobs in tech than on Wall Street.

"The city is benefiting a lot from the exodus from San Francisco," said Jordan Fliegel, managing director at
TechStars NYC, one of the industry's leading local accelerators. "It might not be as good as tax-free startup places
like Austin, Texas, and to a lesser extent Miami, but New York is already a top two or three tech hub in the country
and is moving to No. 1."

                                                                                                         Page 2 of 3
                              Deals may be down, but the city's tech industry is still up

It's not just out-of-town talent. New York is now producing a tech workforce of its own.

"We are just doing a much better job of spinning up tech talent locally," Samuels said. "The tech sector here has
really doubled down on supporting workforce development efforts, supporting computer science education in
schools, and we're really starting to see that investment pay off."

There's perhaps no better example of that than the Cornell Tech campus on Roosevelt Island. The school launched
in 2012 as a collaboration between the Mayor Michael Bloomberg administration, Cornell University and the
Technion-Israel Institute of Technology and almost immediately began producing homegrown tech talent.

Firms are following

Industry leaders have long believed that if a startup wanted to be taken seriously, it had to be in Silicon Valley. A
Manhattan office could come second, but home base for a U.S. firm had to be California. That belief has faded in
recent years, and much of that has to do with New York's people.

A survey published today from Tech:NYC and Accenture, "Tech Talent Hiring Trends Survey," shows that company
leaders are overwhelmingly optimistic about tech talent in New York. Ninety-nine percent of employers surveyed
this past summer said they are confident in their ability to secure needed tech skills in 2023 from the talent pool in
the city. The survey included 350 C-level executives working across 11 industries for organizations with at least one
work location in the city.

That confidence is breeding growth. This past winter, New York edged out Silicon Valley with the most early-stage
startups in the U.S., according to equity management platform Carta. There are now more than 25,000 tech
startups in the region, and Google is expanding its New York footprint.

Funding fright

While employees and employers alike are bullish on tech in New York, the industry is far from immune to the dry-up
of venture capital activity across the economy. Investments are down in nearly every sector, and tech has been hit
harder than most.

VC activity peaked in 2021 with roughly $55.8 billion flowing to New York-area startups, according to data provided
by PitchBook. Software firms were on the receiving end of nearly half of that. Then VC activity began to dip in 2022,
and the city's overall VC investment fell to $34.7 billion, PitchBook reported. Still, about 50% of VC funding went to
tech firms.

Now, at the close of the third quarter of 2023, investment to date looks bleak for both the city writ large and tech in
particular. City startups have seen $14.3 billion in funding rounds thus far; for tech firms, that number is just $5.5
billion.

"The narrative of 2021 was that capital was really just falling out of the sky, there was more capital to be put to work
from investors than startups even needed," said PitchBook VC analyst Vincent Harrison.

Investors were more willing to back a pre-product tech company in favor of growth potential, he said. Now, the
focus has switched to profitability and cash flow.

"That has obviously shifted dramatically, and there is now a lot more capital that startups need than investors are
able to supply," Harrison said. "These software companies are not able to rely on just growth prospects when they
are seeking out investments."

Much of that remaining investment is being directed toward the development of AI, which has managed to buck the
slowdown in deal activity. There were 26 deals that totaled $565 million in the first quarter of 2023 alone, according
to an analysis from Deloitte. The analysis showed that climate tech and health care tech firms continue to fundraise
relatively well.

                                                                                                       Page 3 of 3
                              Deals may be down, but the city's tech industry is still up

"If you're building in AI or health care or a few other categories, it's hot," Fliegel said. "For everyone else, it's
certainly down compared to the first half of last year and way down from the year prior. But those were like the
greatest years ever, so it's still a relatively healthy correction."

The people interviewed for this story were uncertain about the immediate future. No one wanted to make
predictions. One big question, it seems, is whether AI will be more like crypto-fast growth then a crash-or more
sustainable like the dot-com boom. Also, there are a lot of questions around venture capital.

"AI, large language models, everything around that are super hot," Fliegel said. "VCs are throwing money at that
pre-product, pre-revenue."


Load-Date: October 12, 2023


  End of Document

                                                                                                       Page 1 of 2
                                     Helping older adults combat loneliness, social isolation




                   Helping older adults combat loneliness, social isolation
                                                    The Malone Telegram (New York)
                                                        May 26, 2022 Thursday
                                                             Both Edition



Copyright 2022 Johnson Newspaper Corporation
Distributed by Newsbank, Inc. All Rights Reserved

Section: MT_EVENTS; Pg. A3
Length: 728 words

Body


Building on its comprehensive effort to battle social isolation and support aging-in-place, NYSOFA is delivering
voice-operated smart technology into the homes of over 800 older adults.

Under the program, NYSOFA will work with local offices for the aging and partners to identify older adults who
would most benefit from the technology: ElliQ by Intuition Robotics, which is the first-ever proactive and empathetic
care companion.

ElliQ is designed to foster independence and provide support for older adults through daily check-ins, assistance
with wellness goals and physical activities, connection to family and friends, and more using voice commands
and/or on-screen instructions. The technology, which recently launched commercially after years of pilots and early
production deployments, has shown unprecedented engagement levels with older adults. Users have an average of
20 daily interactions.

Distinct from other smart technologies, ElliQ is made specifically for older adults to support independence at home.
While other technologies are reactive to commands, ElliQ proactively suggests activities and initiates conversations,
building context through artificial intelligence (AI) to inform follow-up conversations that create a sense of
relationship with the AI. To support health and wellness, ElliQ offers sleep relaxation exercises, physical activity
exercises, in-depth nutrition-related conversations, and medication reminders for each user's unique condition(s).

In 2017, the U.S. Surgeon General declared social isolation to be a "global epidemic" - one that has only worsened
in the COVID-19 health emergency. According to the AARP Public Policy Institute, social isolation drives $6.7
billion in additional associated Medicare spending per year. The health consequences of loneliness and isolation
are equivalent to smoking almost a pack of cigarettes daily. At a time when older adults are at increased risk for
loneliness and social isolation, ElliQ offers another form of companionship, supplementing traditional, in-person
support.

New York State Office for the Aging Director Greg Olsen said: "We are so pleased to partner with Intuition Robotics
and make ElliQ available to older adults in New York. This product does so many things to improve health, combat
isolation, and improve overall well-being and independence"

                                                                                                        Page 2 of 2
                               Helping older adults combat loneliness, social isolation

He added: "Despite misconceptions and generalizations, older adults embrace new technology, especially when
they see it is designed by older adults to meet their needs. For those who experience some form of isolation and
wish to age in place, ElliQ is a powerful complement to traditional forms of social interaction and support from
professional or family caregivers."

Intuition Robotics CEO and Co-Founder Dor Skuler said: "We've long believed that connecting older adults with
local communities via ElliQ will add an important element in providing holistic support to older adults aging in place.
This partnership with NYSOFA helps us further that mission through an innovative initiative that we are incredibly
proud to be part of."

He added: "We're thrilled to be working with New York State as our first state government partner and believe ElliQ
will be able to effectively engage and encourage older adults in New York to be more independent, healthy and
happy."

Association on Aging in New York (AgingNY) Executive Director Becky Preve said: "The Association on Aging in
New York is thrilled to offer additional technology services to combat social isolation and loneliness. We are so
thankful for NYSOFA's continued commitment to older New Yorkers and the opportunity to partner on innovative
solutions that support aging in place."

The newly enacted Fiscal Year 2023 State Budget includes $2.9 million in funding for pioneering NYSOFA
initiatives to combat social isolation and offer new or expanded innovations in aging service provision at multiple
levels. In addition to ElliQ, this includes: NYSOFA's animatronic pet initiative, which provides lifelike companion
pets for older adults and is proven to reduce self-reported loneliness by 70 percent; statewide access to Trualta's
family caregiver support platform offering expert-led training across critical care competencies; ride-sharing services
designed exclusively for older adults; and online communities that provide facilitator-led classes and services.


Load-Date: May 28, 2022


  End of Document

                                                                                                             Page 1 of 2
                          FDA-approved algorithms can inform clinicians of heart abnormalities




      FDA-approved algorithms can inform clinicians of heart abnormalities
                                     Daily Californian: University of California - Berkeley
                                                      February 3, 2020 Monday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 518 words
Byline: Olivia Buccieri

Body


Eko, a Berkeley-based cardiac screening and monitoring company founded by UC Berkeley alumni, gained
approval from the Food and Drug Administration for algorithms that screen heart murmurs and atrial fibrillation,
which will pair with its artificial intelligence-powered, or AI, stethoscope.

Jason Bellet, Eko co-founder and chief operations officer, said about 40,000 physicians across 4,000 hospitals
currently use Eko's stethoscope technology to amplify heart sounds and better capture digital recordings. The new
algorithms allow Eko's AI technology to provide health advice to clinicians.

About 4 million clinicians in the United States and 30 million clinicians globally use generic stethoscopes for
physical exams, according to Bellet.

"There's so much subjectivity and variability when doctors have to listen for abnormalities," Bellet said. "We wanted
to help doctors detect disease and abnormal heart sounds and lung sounds using a stethoscope that would actually
give advice to the clinician."

Eko co-founders Bellet, Connor Landgraf and Tyler Crouch founded Eko with the idea to create a stethoscope that
could help doctors and nurses better understand and detect heart diseases when listening to a patient's heart
during a physical exam in 2014 during their senior year on campus, according to Bellet.

After six years of development and collaboration with health systems across the country, Eko's new algorithms
have been approved by the FDA, according to Bellet. Now, Eko is in the process of piloting the algorithms at
several clinics and hopes to roll out the final product within the next couple of months.

"We're really the first to provide a platform that allows clinicians, using their stethoscope, to get real-time insight into
what they're listening to using FDA-cleared algorithms," Bellet said. "We really see our competition as ushering in
this new era and showing clinicians the value of having supported these amplifications."

The current AI found in Eko's digital stethoscope connects to a mobile app, which clinicians can use to visualize
heart, lung or bowel sounds and electrocardiogram rhythms, according to Eko's website.

                                                                                                          Page 2 of 2
                        FDA-approved algorithms can inform clinicians of heart abnormalities

Bellet said Eko's plans for the future include developing the technology to expand upon the types of diseases the
stethoscope AI can detect.

He added that Eko is working with the Mayo Clinic on a newer algorithm for screening heart failure that recently
gained a "breakthrough indication" from the FDA, meaning its approval is in the process of being fast-tracked but
has yet to be cleared.

"With a tool that has the accuracy of the cardiologist in being able to pick up disease, and really elevates your
physician's ability to hear, it ... puts the patient's mind at ease," Bellet said. "It's all about patient enablement and
access to great care and it's about fighting disease earlier so that patients can optimize their options to treat it."

Olivia Buccieri is the lead business and economy reporter. Contact her at[email protected]and follow her on Twitter
at@obuccieri_dc?.

Artificial Intelligence,Connor Landgraf,Eko,FDA,Jason Bellet,Mayo Clinic,Tyler Crouch


Load-Date: April 16, 2020


  End of Document

                                                                                                           Page 1 of 2
                        Professor on using AI to detect medical errors, the future of AI in medicine




  Professor on using AI to detect medical errors, the future of AI in medicine
                                            The Stanford Daily: Stanford University
                                                  August 26, 2020 Wednesday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 545 words
Byline: Amanda Zhu

Body


Scripps Professor of Molecular Medicine Eric Topol gave a talk on the future of artificial intelligence in medicine at
the Stanford Artificial Intelligence in Medicine & Imaging Symposium on Aug. 5, where he discussed developing
medicine that is much more accurate than it is now. According to Topol, there are over 12 million serious medical
errors per year, leading to added costs and other complications.

In one sense, machines are much more capable than humans at detecting errors, Topol said. Machines are able to
find different medical complications that doctors themselves may not be able to find, such as tumor nodules, and
can advance medical technology, as with mammographies.

"If you show this picture [of a retina] to retinal authorities, their chance of getting [the gender] right is 50%," Topol
said. "But interestingly, an AI algorithm can be trained to be 97 to 98% accurate."

Machines can identify many other aspects of a patient simply from the retina, including one's possibility of kidney
disease, Alzheimer's and diabetes and age and sex. Topol said applications of AI are not limited to images of the
retina: AI can interpret all sorts of slides and images that pathologists cannot see or make conclusions.

"This is going to affect, in the future, every medical discipline," he said. "There's no exception here. And it's not just
those in the hospital. It's paramedics, it's all the paraprofessionals, pharmacists - the works."

Topol said AI would transform the health and medical field with tasks such as interpreting scans, selecting embryos
for in vitro fertilization and predicting death in hospitals. AI will also greatly improve the resolution and quality of
medical scans.

"Machines will not replace physicians," Topol said, quoting professor and neurosurgeon Antonio Di Leva. "But
physicians using AI will soon replace those not using it."

Even with the tremendous potential of AI applications, Topol still emphasized that humanistic medicine is important
in the long-term advancement of AI in medicine.

                                                                                                       Page 2 of 2
                       Professor on using AI to detect medical errors, the future of AI in medicine

Even now, Topol said that patients often feel rushed during their doctor visits. It's not uncommon to see physicians
typing on computers or facing their screens, without making eye contact with patients during doctor visits.

Topol said in medicine there is a lack of empathy, which companies and institutions should focus on improving.

"We want to restore the humanistic side - the critical component - of what is medicine," Topol said.

Contact Amanda Zhu at amandaz9888 'at' gmail.com.

.css-10w0hkr{margin:0 auto;width:100%;}@media (min-width:1100px){.css-10w0hkr{width:650px;}}

While you're here...

We're a student-run organization committed to providing hands-on experience in journalism, digital media and
business for the next generation of reporters. Your support makes a difference in helping give staff members from
all backgrounds the opportunity to develop important professional skills and conduct meaningful reporting. All
contributions are tax-deductible. Support the Daily $50$200$1,000OtherMake my donation a monthly donation. Get
Our EmailsDigest Amanda ZhuAmanda Zhu is a high schooler writing as part of The Daily's Summer Journalism
Workshop..css-qmqbsq{margin:0 auto;width:100%;}@media (min-width:1100px){.css-qmqbsq{width:600px;}}


Load-Date: August 26, 2020


  End of Document

                                                                                                        Page 1 of 3
                                             What will the U.S. look like in 2030?




                                   What will the U.S. look like in 2030?
                                                Telegraph Herald (Dubuque, IA)
                                                  February 6, 2020 Thursday



Copyright 2020 Woodward Communications, Inc. All Rights Reserved

Section: A; Pg. 19
Length: 771 words
Byline: TODD LINK

Body


Having written for various publications for the past 30 years, I have - for the most part - avoided extending
predictions or trends beyond the coming year or two.

But as we close out the decade and move into the new, I've taken some time to reflect on the past 10 years and
look ahead to what I believe are exciting things to come.

Making predictions might be best summarized by being either naive or foolish. Perhaps today, you get a bit of both.
But I believe these technological advancements will significantly impact our lives during the next decade.

Artificial intelligence

AI is growing at a pace perhaps not previously seen in human history.

Not only will AI impact the obvious areas - predictive analytics and computer-assisted living devices in the home
and workplace - but even more critically in the field of Â­medicine.

Humans, by 2030, will be helped through computer-assisted living.

Just as contact lenses can monitor diabetic insulin levels, AI will lead to a host of invasive and non-invasive sensors
to collect and interpret tens of thousands of human body data points. The information can be shared against a
database of millions of other patients to detect anomalies (while never compromising individual privacy).

The shared economy taking root in health care will enable AI to make "determinations" faster and more mobile.

AI will detect potential issues long before the patient feels sick. And it also will enable providers to create custom
treatment plans specific to each patient and his or her symptoms based on the best outcome of treatment by
aggregating the non-identifiable data of millions of other individuals.

Lab-grown meat

Lab-grown meat is a dangerous prediction, being both from Iowa and personally loving a quality steak.

                                                                                                        Page 2 of 3
                                         What will the U.S. look like in 2030?

That said, with a population that could reach almost 9 billion by 2030, lab-grown meat (from the stem cells of real
animals) has the chance to:

Reduce the environmental impact of raising animals.

Reduce the energy input required to raise a pound of fresh meat.

Use tiny spaces to grow significantly large quantities that can feed the world - especially calorie-rich food products
in countries where raising animals is not a viable option.

The U.S. could be a laggard in this regard, but lab-grown meat has the potential to play a significant role in feeding
the world.

Technology in our day-to-day life

The smartphone, or the smart device we carry, will become the go-to for all things technology.

During the next 10 years, we will continue to see the mass deployment of thousands, if not tens of thousands, of
micro-satellites that will enable individuals to be as connected to the web as if they were at their desktop at the
office - regardless of world locale.

The "phone" will continue to play a less and less significant role in the device. Added features will help run the
household, collect volumes of health-related data points and, coupled with AI, "suggest" products, services and
appointments based on complex algorithms.

By 2030, we will indeed have a significant time-saving device at our disposal. Think Siri and Alexa to a power of 10.

Higher education

Higher education will see a considerable shift in delivery during the upcoming decade.

Some futurists predict as many as 50% of all higher education schools could close, merge or reinvent themselves
before 2030. While I believe this prediction is high, I see higher education undergoing the most radical reinvention it
has endured since its modern-day existence.

School debt is not sustainable. And some large countries are reporting wages for new graduates to be marginally
better than the monthly earnings of unskilled labor.

The upcoming decade will press higher education to deliver knowledge and skills that are immediately transferable
to the workplace, and job-training programs will continue to expand. Four-year brick and mortars will continue to be
challenged by three-year online programs and, in some cases, 2.5-year programs.

Open-source education will gain increased value with employers by 2030. The cost will put downward pressure on
the amount of time necessary to obtain an undergraduate, graduate and terminal degree.

Fortune 500s

Finally, be prepared to say goodbye to dozens of Fortune 500 companies.

The staying power of a Fortune 500 company has never been shorter. We are in a period of massive disruption.

A dozen or more of the top 100 companies in 2030 have yet to form as a company. And some of the names we
trust and hold dear will quietly work their way into obsolescence.

Change is constant, and these predictions highlight the speed at which businesses, organizations and people are
expected to change.

                                                                      Page 3 of 3
                              What will the U.S. look like in 2030?


Load-Date: February 6, 2020


  End of Document

                                                                                                    Page 1 of 3
    Wearable tech may someday cloak us in greater public health Data could aid larger swath of society beyond
                                                    users




  Wearable tech may someday cloak us in greater public health; Data could
                 aid larger swath of society beyond users
                                                       USA Today
                                               December 28, 2022 Wednesday
                                                        1 Edition



Copyright 2022 USA Today All Rights Reserved

Section: NEWS; Pg. A7
Length: 951 words

Body


The marketing for the Apple Watch says it all: "A healthy leap ahead." "Here's to a healthier you." "The future of
health never looked so good." The Apple Watch, like countless other digital health apps and wearables, is selling
itself with an implicit promise of individual empowerment: that we can use this health information to take specific
actions - exercising so that your heart rate reaches a certain elevated threshold, for example - that will directly lead
to better health.

But in pitching and promising health to the individual, companies that make apps and wearables, and the
customers who buy them, are focusing on the trees - and missing the rest of the forest.

In truth, we have less control over our own health than we like to think. In fact, our health is heavily influenced by
our surroundings - including the health of the people around us.

What this might mean for the ever-growing market of wearables is a new focus beyond the individual, to those in
their household, their friends, even their whole community.

Mapping exercises - or diseases

By incorporating social and community factors, digital health products could better capture what goes into public
health. Communitywide data from fitness trackers and other digital data already feed into some public health
models.

Fitbit publishes reports that show, for example, communities where people exercise the most. Cellphone location
data is sometimes used to map disease outbreaks. These models and their underlying datasets could prove to be a
boon to those people and agencies responsible for protecting and improving all of our health.

Aggregated health data that reflects communitywide factors has for centuries now aided public health practitioners,
allowing them to make seemingly simple improvements that nonetheless greatly impact people's lives.

                                                                                                   Page 2 of 3
   Wearable tech may someday cloak us in greater public health Data could aid larger swath of society beyond
                                                   users

Returning home from the hospitals of the mid-19th century Crimean War filled with sick and injured British soldiers,
Florence Nightingale sought to use data she had meticulously collected to demonstrate the impact that community
factors had on soldiers' health.

Nightingale famously employed powerful graphics to convince Britain's leaders that measures to improve sanitation
- such as cleaning the air water, and sewer systems - could prevent disease and dramatically decrease deaths.

The new Nightingales

The world still faces enormous public health challenges, including the ongoing COVID-19 pandemic. But we also
have new cards to play, such as the vast repositories of health sensor data and powerful artificial intelligence
techniques that can help us make sense of it.

Using these tools to improve health devices and apps could be a major opportunity to tackle these massive
community challenges.

Among the most troubling recent public health concerns is the teen mental health crisis. Seeking to address rising
suicides, a Harvard-led research project pools health data from many people and uses artificial intelligence to make
it more useful, like combining smartphone and Fitbit data to understand indicators of suicide.

The hope is that marrying AI and health sensor data could help build an early warning system for people at risk of
suicide. For now, this research remains academic.

And a major challenge is that suicide is still relatively rare, generating little data that algorithms can use to make
predictions. But like many other health events, suicide risk doesn't occur in a vacuum.

Suicides might seem like isolated acts, but they often occur in clusters - what researchers call suicide contagion.
What if suicide prediction algorithms, like the one being built at Harvard, could incorporate a social element from
health sensor data like your friend network?

Digital health products could feed into social network algorithms that help identify when people need mental health
resources. A wearable that tracks only your mood and sleep might intervene only based on those metrics. But a
social-enabled algorithm might be able to go several steps further, recognizing troubling trends among one's close
contacts - such as social media posts suggesting self-harm, and thus when someone might themselves be at
greater risk for suicide.

Privacy concerns

There are, to be sure, many hurdles to using social and community data in digital health products. Some users may
have privacy concerns about sharing data with companies or public health agencies.

Overcoming these hurdles could involve developing open source standards for transparency about data
management, or ensuring that people can control when, and with which agencies, to share personal data.

Even so, the opportunity remains too great to ignore. Although digital health products can, and already do, benefit
individuals, by far the greatest benefits could one day come when these products operate in tandem with
information about the community and beyond the individual.

Right now, it is likely a wealthier and thus already-healthier set of people that tend to purchase digital health
products. This fits a historical pattern, where new technologies such as computers cater to select individuals, only
later expanding to serve broader communities.

For digital health companies to credibly claim to improve people's health - to truly, as they promise, become "the
future of health" - their next step could be an increased willingness to look beyond an individualized notion of
health and to work with public health agencies.

                                                                                                   Page 3 of 3
   Wearable tech may someday cloak us in greater public health Data could aid larger swath of society beyond
                                                   users

In doing so, digital health products stand to benefit a far greater swath of society, even those who aren't wearing
wearables.

Douglas Yeung, a senior behavioral scientist at the nonprofit, nonpartisan RAND Corporation, is a faculty member
of the Pardee RAND Graduate School.

Douglas Yeung

RAND Corporation



Graphic


The Apple Watch is marketed as "The future of health," but Douglas Yeung says a focus beyond the user may be
the real future.

Marcio Jose Sanchez/AP


Load-Date: December 28, 2022


  End of Document

                                                                                                      Page 1 of 6
                                    Candidate Q&A: Walla Walla School District Position 4




                    Candidate Q&A: Walla Walla School District Position 4
                                             Walla Walla Union-Bulletin (Washington)
                                                       July 13, 2023 Thursday



Copyright 2023 Walla Walla Union-Bulletin (Walla Walla, Wash.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 2966 words
Byline: Loryn Kykendall, Walla Walla Union-Bulletin, Wash.

Body


Jul. 13—Read more

Candidate Q&A: Walla Walla School District Position 4

Here's what to expect in the Walla Walla County primary election

Alayna Brinton

Age: 36

Occupation: Small business owner, nonprofit executive director and chief clinical officer

Education: Alayna Marie Brinton has a B.S. in psychology and B.A. in sociology from Washington State University
(2007-2010). She obtained a master's degree in clinical social work from Walla Walla University (2011-2013).
Currently pursuing a master's in business administration with an emphasis on organizational psychology at Eastern
Washington University.

Previous elected offices: National Association of Social Workers, Washington State Regional Representative (2017-
2019); Blue Mountain Health Cooperative Executive Board chairwoman (2020-present); Walla Walla Community
Health Advisory Board member (2022-present); Community Development Block Grant Advisory Board member for
Walla Walla (2023-2025).

Leadership service: Alayna actively contributes to multiple professional associations and serves on local county and
city advisory boards. Other professional experience includes roles such as a hospital advocate and crisis responder
at the Benton County Sexual Assault Response Center (2005-2007). Served as the treasurer for the Student
Disabilities Association at Walla Walla University (2013-2014). Chairs the Fundraising Committee for the Blue
Mountain Health Cooperative. Participated in the search committee for the program director of the Bachelor of
Social Work program at Washington State University (2022). Engaged in various community service initiatives,

                                                                                                        Page 2 of 6
                               Candidate Q&A: Walla Walla School District Position 4

including organizing a seminar to support veterans and their families. Engaged in Sherwood Leadership training
and advocacy work related to improving access to books representing people of color (2019-2020).

Zana Carver

Carver declined to answer questions for the U-B's candidate questionnaire. Below is information provided by Carver
to the Secretary of State.

Occupation: Associate professor of biology, Columbia Basin College.

Education: Ph.D. in environmental and natural resource sciences, Washington State University; M.S. in biology,
University of Saint Joseph.

Community service: Women in Science: Removing Obstacles and Believing in Yourself for the League of United
Latin American Citizens Club at Columbia Basin College; Community Engagement Board (WWPS truancy
guidance); preschool/Sunday school teacher; Pacific Northwest Department of Energy Regional Science Bowl;
Robert Frost Elementary School Science Fair judge.

Professional experience: Associate professor of biology at Columbia Basin College, 13 years with two Exceptional
Faculty Awards, two years on Faculty Senate, chaired Financial Affairs Committee, Peer Review Committee chair.

Eric Rindal

Age: 62

Occupation: Founder and former owner, Waterbrook Winery, 25 years; founder and partner, Ingio Winery ERP
Accounting Software, 22 years.

Education: Two years college, multiple institutions in Washington, Oregon and California with studies in wine and
computer science.

Previous elected offices: WWPS director, Position 4.

Leadership service: Walla Walla Parks Advisory Board member and past Chair; past president, Washington Wine
Institute; the Michael and Susan Dell Foundations Ed-Fi Alliance Advisory Group, a non-profit grant organization
promoting data interoperability in K-12 Schools.

Three candidates are vying for Position 4 on the Walla Walla School Board in the upcoming primary election with
incumbent Eric Rindal being challenged by newcomers Alayna Brinton and Zana Carver for a four-year term on the
school board.

These candidates will appear on the ballot for the Tuesday, Aug. 1, primary election. Mail-in ballots must be
postmarked by Aug. 1.

Below are Q&A responses from Rindal and Brinton. Carver declined to answer the U-B's candidate questionnaire.

Why do you want to continue as (or become) a school board member?

Rindal: Serving as a board member for the first time, it takes a minimum of a couple of years to learn the policies as
well as the less public insights into the district institutional knowledge base that are required components to be a
competent and contributing school board member. In my fourth year I am still learning new things every month.

Our district represents a moderately sized public agency that presides over more than $100 million annually,
including its general fund and capital debt repayment fund — fully 47% of our community tax base. Not continuing
in a second term necessitates board turnover that then requires someone new to start this daunting process once
again.

                                                                                                        Page 3 of 6
                               Candidate Q&A: Walla Walla School District Position 4

Much of what is done on any school board requires a considerable investment of time to become functionally
proficient in terms of the district programs and finances. No one is born a school board member. I would hope to
continue to use what I have learned in the past 3 1/2 years to continue to serve as a fully contributing member of
our board.

One of the misconceptions of school boards is that board members are focused on all the latest cultural catch
phrases and declare for one side of the culture war or the other. Listening to the community comment section of a
board meeting I am often struck by the obvious divide. Whether that be pro equity, LGBTQIA2S+, student rights or
being against CRT, sex ed or lack of parental rights, the list is endless when it comes to taking up sides.

Yet in actuality board members have almost nothing to do with any of those issues down at the teaching core.
Curriculum standards are set at the state level. Staff decides which curriculum best teaches those state standards
and the board effectively rubber stamps those decisions in almost every case.

When it comes to our teaching culture, our district teachers span the entire spectrum with those coming from both
the left and right. Boards can't dictate culture any more than we could change the opinions of our community
commenters — nor should we.

What we actually do is to make sure a lot of little details are being properly attended to by the administration to
assure all students are learning. It's not all that complicated conceptually yet decidedly complicated in practice.

A lot of this is ministerial such as approving the check run every couple weeks, but we do have influence on what
gets funded through the annual budget process. Learning how schools are funded is extremely complex yet in the
end comes down to a simple count of the number of students. What a board has discretion over is a very small part
of the budget as around 80% is dedicated to staff salaries.

This last year we spent an enormous amount of time on building a new strategic plan that will guide the district over
the next five years. Significant public input was taken from which the board's role was to distill that down to a few
core ideals that will ultimately assure all students learn and become competent citizens as they grow to become our
new adult community members.

K-12 schools have and continue to experience rapid change in pedagogy. This is the result of teaching processes
moving from a one size fits all, "we taught it; some learn, and some do not" model, to one where individualized
mastery for all is the required standard. The new model promises a minimum set of attested competencies at each
grade level. With this approach we now collect far more data to assure these promises are being met, yet we must
do so without it leading to a system where students and teachers spend more time testing than learning.

Key to this challenge is to integrate collection of data by leveraging the data in the systems we already have — not
create yet more data collection overhead. Districts now possess immense quantities of data on far more than just a
student's address, grades and test scores. That data is actually growing is scope each year, yet much of it is
isolated in hundreds of separate single purpose systems that don't exchange data between themselves.

Much of the data we collect is for state compliance reporting yet we often fail to maximize its real time value to our
teachers at the classroom level. Students are far more than their test scores. What is occurring emotionally in a
student's life can be just as critical to learning and student success than are test scores. Measures of other school
and community engagement are often more predictive of student success. How well we integrate all these discrete
systems over the next few years will be a key component in improving student outcomes and something I hope to
be able to continue to contribute to.

A third reason I want to continue relates to critical climate change. Our students need to understand the effects of
both current, as well as those climate change effects still to come as the earth continues to warm over their
lifetimes.

                                                                                                            Page 4 of 6
                                Candidate Q&A: Walla Walla School District Position 4

I have been the lone voice on the board to move the district to become a zero net energy district. I have been
responsible for bringing electric buses to our district this past year. I will push to include renewable energy in all new
district projects.

Solving a large worldwide problem often comes down to tackling the problem right in your own community and I
hope to continue as a part of the solution.

Brinton: I want to be a school board member to further contribute my professional expertise and drive positive
change in education, prioritizing student well-being and equitable access to resources. As a licensed independent
clinical social worker with a strong commitment to mental health, I have dedicated my career to providing mental
health care and advocating for individuals of all ages. I opened Anchor Point Counseling as a private practice and
founded the nonprofit Blue Mountain Health Cooperative.

Both of these experiences allowed me to make a tangible impact on redirecting mental health clients to appropriate
care and supporting the development of student clinicians, both of which are critical to the maintenance of our
system of behavioral health care in the Valley. Additionally, through my active participation in professional
associations and service on local advisory boards, I have gained valuable insights into community needs. By
combining my clinical knowledge and community engagement, I am motivated to become a school board member
to utilize my expertise, contribute to positive changes in education and ensure student well-being and equitable
access to resources.

What makes you the best candidate for this position?

Rindal: I point to my record of accomplishments.

During the period of remote learning during COVID, I alone focused on finding a way to test students and staff.
Though many said we did not have the capacity or funds I was able to find the Binaxnow pilot program for schools
and was able to assist in getting WWPS to be part of the pilot. Within days of testing start, students returned to in-
school instruction.

I was instrumental in finding and promoting a grant to fund three new battery powered buses for our district. These
new buses are far less costly to operate and yield significant health benefits to students through reduction in
exposure to diesel particulates.

I personally wrote a successful $200,000 grant to fund a new data engineer position in the district.

Brinton: My dual role as a parent of current WWPS students and a dedicated advocate for mental health makes me
the best candidate for this position. I have the insight and passion needed to make informed decisions that prioritize
the well-being and academic achievement of all students. I understand many of the hopes and concerns of parents
and am committed to learning about the challenges I do not yet understand. I am committed to creating an
educational environment that nurtures the growth and development of every child.

What are your thoughts on the proposed levy to update athletic facilities?

Rindal: In comparing WWPS to any of the Tri-City schools the committee used as sports complex examples, we
actually differ significantly in scale. It is important to remain cognizant of the differences in our relative district
budgets. That said, levy dollars per thousand at WWPS are among the lowest in all the southeast Washington area
by a significant margin.

An issue still unresolved is providing for a maintenance fund to maintain any new sports facilities our citizens may
approve. We have not spent significantly out of our existing general fund budget to maintain what we have now and
"new" tends to become "used" very quickly. The source of the required funds to maintain any new capital projects
will need to be identified.

Bottom line: The facility need is clear. Funding it responsibly is what is still less clear to me. If that can be resolved,
I'm all for it as we all want the best for our Walla Walla kids.

                                                                                                         Page 5 of 6
                               Candidate Q&A: Walla Walla School District Position 4

Brinton: It is important for our school district to provide well-rounded opportunities for our students. While academic
achievement is crucial, extracurricular activities, including athletics, also play a significant role in the overall
development of our kids.

The proposed levy to upgrade athletic facilities warrants careful consideration. Upgraded facilities can enhance the
student experience, promote physical fitness and foster a sense of community pride. However, it is essential to
weigh this investment against other pressing needs within our district, ensuring a balanced allocation of resources
that benefits all students.

Additionally, community input and thorough financial analysis should guide the decision-making process to ensure
long-term sustainability and equitable access to upgraded facilities.

How do you feel about the use of artificial intelligence in schools?

Rindal: I feel the same way about AI as I do about social media. Clearly social media's original promise had
surpassed its reality, especially with respect to young girls and issues surrounding mental health and self-worth.

AI's promise is almost unlimited but without any guardrails being provided to guide its use, it will likely be used as
much for socially inappropriate purposes as it is for human good.

We know from many studies that the best learning outcomes are generated out of a 1:1 teacher to student relation.
AI has the potential to bring us closer to that notion than anything prior, yet given our prior experiences, we need to
do better job this time to make sure the good substantially exceeds the bad.

Brinton: There are potential benefits and significant challenges associated with the use of artificial intelligence (AI)
in schools. AI technology has the capacity to enhance educational experiences, personalize learning and provide
valuable insights for teachers and administrators. It can support adaptive learning platforms, streamline
administrative tasks and promote innovative teaching approaches.

However, it is crucial to approach AI implementation with caution, ensuring student privacy and data security are
safeguarded. Additionally, ethical considerations, transparency and human oversight should be prioritized to
maintain a balanced and equitable learning environment. Collaboration with educators, parents and experts is vital
to navigate the opportunities and challenges that AI presents in schools.

What are your thoughts on the recent efforts to ban certain books from school libraries?

Rindal: Banning books is wrong. Knowledge, even of the type we may personally disagree with, has value — even
if only to support why we might disagree with it. Any Socratic discussion requires students be equipped with
multiple perspectives if they are to adequately defend their own ideals. Having a broad base of perspectives to draw
upon often leads to more complex and nuanced conclusions and is the basis for critical thinking skills.

Banning books is about control of thought by some, over freedom of thought that is being exercised by others. A
small step further is being forced to read propaganda to enforce specific ideals.

Society and our students are best served by having a broad set of ideas represented in our libraries and online. We
have staff trained to guide our students and we also provide web access for parents and guardians to monitor as
well as limit what their student consumes from our libraries. Parental choice is always the final arbiter.

I voted with the rest of the board to affirm keeping the books that were challenged this past year based on our
current policy of reviewing them with "Consideration of the entire work, rather than extracting passages or parts;
weighing the values and faults against each other and weighing the conflicting opinions based on the materials as a
whole."

Conversely, I was the sole vote to affirm the request to add a few conservative titles that were suggested as
counterpoint.

                                                                                                      Page 6 of 6
                              Candidate Q&A: Walla Walla School District Position 4

As I said, banning any book is wrong regardless of how it might be viewed through any current political lens. In my
opinion, knowledge is only dangerous when access to it is restricted.

Brinton: As a prospective school board member, I strongly believe in promoting intellectual freedom and fostering a
culture of open-mindedness in our schools. It is crucial to provide students with access to a diverse range of books
and materials that encourage critical thinking, empathy and exploration of different perspectives.

Rather than focusing on banning books, I believe in implementing thoughtful selection processes that consider age
appropriateness and align with the values and educational goals of our community. It is essential to engage in open
dialogues with educators, parents and students to ensure a well-rounded collection of books in our school libraries.

Editor's note: This article was updated to include the complete response from the candidates.

___ (c)2023 Walla Walla Union-Bulletin (Walla Walla, Wash.) Visit Walla Walla Union-Bulletin (Walla Walla, Wash.)
at union-bulletin.com Distributed by Tribune Content Agency, LLC.


Load-Date: July 14, 2023


  End of Document

                                                                                                        Page 1 of 3
                                             What will the U.S. look like in 2030?




                                   What will the U.S. look like in 2030?
                                                Telegraph Herald (Dubuque, IA)
                                                  February 6, 2020 Thursday



Copyright 2020 Woodward Communications, Inc. All Rights Reserved

Section: A; Pg. 20
Length: 771 words
Byline: TODD LINK

Body


Having written for various publications for the past 30 years, I have - for the most part - avoided extending
predictions or trends beyond the coming year or two.

But as we close out the decade and move into the new, I've taken some time to reflect on the past 10 years and
look ahead to what I believe are exciting things to come.

Making predictions might be best summarized by being either naive or foolish. Perhaps today, you get a bit of both.
But I believe these technological advancements will significantly impact our lives during the next decade.

Artificial intelligence

AI is growing at a pace perhaps not previously seen in human history.

Not only will AI impact the obvious areas - predictive analytics and computer-assisted living devices in the home
and workplace - but even more critically in the field of Â­medicine.

Humans, by 2030, will be helped through computer-assisted living.

Just as contact lenses can monitor diabetic insulin levels, AI will lead to a host of invasive and non-invasive sensors
to collect and interpret tens of thousands of human body data points. The information can be shared against a
database of millions of other patients to detect anomalies (while never compromising individual privacy).

The shared economy taking root in health care will enable AI to make "determinations" faster and more mobile.

AI will detect potential issues long before the patient feels sick. And it also will enable providers to create custom
treatment plans specific to each patient and his or her symptoms based on the best outcome of treatment by
aggregating the non-identifiable data of millions of other individuals.

Lab-grown meat

Lab-grown meat is a dangerous prediction, being both from Iowa and personally loving a quality steak.

                                                                                                        Page 2 of 3
                                         What will the U.S. look like in 2030?

That said, with a population that could reach almost 9 billion by 2030, lab-grown meat (from the stem cells of real
animals) has the chance to:

Reduce the environmental impact of raising animals.

Reduce the energy input required to raise a pound of fresh meat.

Use tiny spaces to grow significantly large quantities that can feed the world - especially calorie-rich food products
in countries where raising animals is not a viable option.

The U.S. could be a laggard in this regard, but lab-grown meat has the potential to play a significant role in feeding
the world.

Technology in our day-to-day life

The smartphone, or the smart device we carry, will become the go-to for all things technology.

During the next 10 years, we will continue to see the mass deployment of thousands, if not tens of thousands, of
micro-satellites that will enable individuals to be as connected to the web as if they were at their desktop at the
office - regardless of world locale.

The "phone" will continue to play a less and less significant role in the device. Added features will help run the
household, collect volumes of health-related data points and, coupled with AI, "suggest" products, services and
appointments based on complex algorithms.

By 2030, we will indeed have a significant time-saving device at our disposal. Think Siri and Alexa to a power of 10.

Higher education

Higher education will see a considerable shift in delivery during the upcoming decade.

Some futurists predict as many as 50% of all higher education schools could close, merge or reinvent themselves
before 2030. While I believe this prediction is high, I see higher education undergoing the most radical reinvention it
has endured since its modern-day existence.

School debt is not sustainable. And some large countries are reporting wages for new graduates to be marginally
better than the monthly earnings of unskilled labor.

The upcoming decade will press higher education to deliver knowledge and skills that are immediately transferable
to the workplace, and job-training programs will continue to expand. Four-year brick and mortars will continue to be
challenged by three-year online programs and, in some cases, 2.5-year programs.

Open-source education will gain increased value with employers by 2030. The cost will put downward pressure on
the amount of time necessary to obtain an undergraduate, graduate and terminal degree.

Fortune 500s

Finally, be prepared to say goodbye to dozens of Fortune 500 companies.

The staying power of a Fortune 500 company has never been shorter. We are in a period of massive disruption.

A dozen or more of the top 100 companies in 2030 have yet to form as a company. And some of the names we
trust and hold dear will quietly work their way into obsolescence.

Change is constant, and these predictions highlight the speed at which businesses, organizations and people are
expected to change.

                                                                      Page 3 of 3
                              What will the U.S. look like in 2030?


Load-Date: February 6, 2020


  End of Document

                                                                                                    Page 1 of 3
    Wearable tech may someday cloak us in greater public health Data could aid larger swath of society beyond
                                                    users




  Wearable tech may someday cloak us in greater public health; Data could
                 aid larger swath of society beyond users
                                                      USA Today
                                               December 27, 2022 Tuesday
                                                       1 Edition



Copyright 2022 USA Today All Rights Reserved

Section: OPINION; Pg. A7
Length: 951 words

Body


The marketing for the Apple Watch says it all: "A healthy leap ahead." "Here's to a healthier you." "The future of
health never looked so good." The Apple Watch, like countless other digital health apps and wearables, is selling
itself with an implicit promise of individual empowerment: that we can use this health information to take specific
actions - exercising so that your heart rate reaches a certain elevated threshold, for example - that will directly lead
to better health.

But in pitching and promising health to the individual, companies that make apps and wearables, and the
customers who buy them, are focusing on the trees - and missing the rest of the forest.

In truth, we have less control over our own health than we like to think. In fact, our health is heavily influenced by
our surroundings - including the health of the people around us.

What this might mean for the ever-growing market of wearables is a new focus beyond the individual, to those in
their household, their friends, even their whole community.

Mapping exercises - or diseases

By incorporating social and community factors, digital health products could better capture what goes into public
health. Communitywide data from fitness trackers and other digital data already feed into some public health
models.

Fitbit publishes reports that show, for example, communities where people exercise the most. Cellphone location
data is sometimes used to map disease outbreaks. These models and their underlying datasets could prove to be a
boon to those people and agencies responsible for protecting and improving all of our health.

Aggregated health data that reflects communitywide factors has for centuries now aided public health practitioners,
allowing them to make seemingly simple improvements that nonetheless greatly impact people's lives.

                                                                                                   Page 2 of 3
   Wearable tech may someday cloak us in greater public health Data could aid larger swath of society beyond
                                                   users

Returning home from the hospitals of the mid-19th century Crimean War filled with sick and injured British soldiers,
Florence Nightingale sought to use data she had meticulously collected to demonstrate the impact that community
factors had on soldiers' health.

Nightingale famously employed powerful graphics to convince Britain's leaders that measures to improve sanitation
- such as cleaning the air water, and sewer systems - could prevent disease and dramatically decrease deaths.

The new Nightingales

The world still faces enormous public health challenges, including the ongoing COVID-19 pandemic. But we also
have new cards to play, such as the vast repositories of health sensor data and powerful artificial intelligence
techniques that can help us make sense of it.

Using these tools to improve health devices and apps could be a major opportunity to tackle these massive
community challenges.

Among the most troubling recent public health concerns is the teen mental health crisis. Seeking to address rising
suicides, a Harvard-led research project pools health data from many people and uses artificial intelligence to make
it more useful, like combining smartphone and Fitbit data to understand indicators of suicide.

The hope is that marrying AI and health sensor data could help build an early warning system for people at risk of
suicide. For now, this research remains academic.

And a major challenge is that suicide is still relatively rare, generating little data that algorithms can use to make
predictions. But like many other health events, suicide risk doesn't occur in a vacuum.

Suicides might seem like isolated acts, but they often occur in clusters - what researchers call suicide contagion.
What if suicide prediction algorithms, like the one being built at Harvard, could incorporate a social element from
health sensor data like your friend network?

Digital health products could feed into social network algorithms that help identify when people need mental health
resources. A wearable that tracks only your mood and sleep might intervene only based on those metrics. But a
social-enabled algorithm might be able to go several steps further, recognizing troubling trends among one's close
contacts - such as social media posts suggesting self-harm, and thus when someone might themselves be at
greater risk for suicide.

Privacy concerns

There are, to be sure, many hurdles to using social and community data in digital health products. Some users may
have privacy concerns about sharing data with companies or public health agencies.

Overcoming these hurdles could involve developing open source standards for transparency about data
management, or ensuring that people can control when, and with which agencies, to share personal data.

Even so, the opportunity remains too great to ignore. Although digital health products can, and already do, benefit
individuals, by far the greatest benefits could one day come when these products operate in tandem with
information about the community and beyond the individual.

Right now, it is likely a wealthier and thus already-healthier set of people that tend to purchase digital health
products. This fits a historical pattern, where new technologies such as computers cater to select individuals, only
later expanding to serve broader communities.

For digital health companies to credibly claim to improve people's health - to truly, as they promise, become "the
future of health" - their next step could be an increased willingness to look beyond an individualized notion of
health and to work with public health agencies.

                                                                                                   Page 3 of 3
   Wearable tech may someday cloak us in greater public health Data could aid larger swath of society beyond
                                                   users

In doing so, digital health products stand to benefit a far greater swath of society, even those who aren't wearing
wearables.

Douglas Yeung, a senior behavioral scientist at the nonprofit, nonpartisan RAND Corporation, is a faculty member
of the Pardee RAND Graduate School.

Douglas Yeung

RAND Corporation



Graphic


The Apple Watch is marketed as "The future of health," but Douglas Yeung says a focus beyond the user may be
the real future.

Marcio Jose Sanchez/AP


Load-Date: December 27, 2022


  End of Document

                                                                                                         Page 1 of 4
                      Educators embrace usefulness of artificial intelligence, note potential problems




      Educators embrace usefulness of artificial intelligence, note potential
                                 problems
                                                 Enid News & Eagle (Oklahoma)
                                                     August 17, 2023 Thursday



Copyright 2023 The Enid News & Eagle (Enid, Okla.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 1612 words
Byline: Enid News & Eagle, Enid News & Eagle, Okla.

Body


Aug. 17—Editor's note: The applications of artificial intelligence — AI — are growing exponentially and will continue
to do so as the technology advances even more. Today, CNHI and the Enid News & Eagle begin an ongoing series
looking at AI and its potential benefits and concerns in various parts of everyday life. This series starts today with a
look at AI's impact in education, offering a glimpse at benefits and challenges. Over the course of the next few
months, CNHI reporters will look at AI's use in health care, business, travel, social media, emergency response,
the military and more.

Richland High School Principal Timothy Regan tries to keep up with emerging technologies so he knows what his
students are using — and to prepare them for life outside the classroom.

That approach has taken the Johnstown, Pa., educator into the ever-expanding world of artificial intelligence (AI),
on the rise as companies jockey for the top spot with new programs that do everything from write emails to
generate term papers.

"My focus is really driven toward how to use this to have a better educational experience for our students," Regan
said.

The use of AI in education is evolving at every level of academia. Educators and administrators seek ways to
determine programs' potential use in the classroom and whether using the technology could be detrimental to
students' work, possibly leading to plagiarism and other forms of cheating.

The U.S. Department of Education's AI focus has been largely on how it allows students and educators to have
new forms of interactions, enhances feedback loops and makes teachers' jobs easier.

That doesn't mean there aren't concerns with the use of AI in learning.

There have been numerous reports about AI programs potentially replacing teachers well as data privacy issues,
fear of unwanted or unsuspected bias and the consequences of inaccurate or fake information.

                                                                                                         Page 2 of 4
                      Educators embrace usefulness of artificial intelligence, note potential problems

The Federal Trade Commission has opened an investigation into ChatGPT, a prominent AI application, to
determine if the tool has harmed people by generating incorrect details about them.

The Department of Education's Office of Educational Technology report "Artificial Intelligence and the Future of
Teaching and Learning" highlights the need for greater student surveillance, discrimination from algorithmic bias —
for example, a voice recognition system that doesn't work well with regional dialects — and achievement gaps
widening because the software could speed delivery of information for some and slows it for others.

Regan pointed out that AI has existed for years. He said services including Grammarly, which provides help for
writing, are a good example of existing learning software. Regan said he's toyed with programs such as Magic
Eraser for image alteration and Tetra, which takes notes during virtual meetings.

"All these things are a way to make people more efficient," Regan said. That could apply to teachers creating
lesson plans or scoring tests, he said, leading to more time to focus on students' school experience.

Influx in education

UNESCO cautions that rapid technology developments could lead to "multiple risks and challenges, which have so
far outpaced policy debates and regulatory frameworks."

That's Mount Aloysius College assistant professor Danny Anderson's main concern. Although he finds AI "fun and
fascinating" the professor at the college located in Cresson, Pa., expressed reservations about the "arms race" of
companies trying to best each other with newer products to catch cheaters.

Mark DiMauro, a University of Pittsburgh at Johnstown humanities professor, also questioned information gathered
by these systems and who has access to them using the phrase "garbage in, garbage out," meaning if the source
material for AI isn't quality it won't produce quality content.

"I do think we run the risk of over-trusting," DiMauro said.

He added that now he will be putting more emphasis on students needing to double- or triple-check research to
make sure sources back each other up.

Anderson said he isn't concerned with the technology's recent influx in education. He says he thinks it's obvious
when a student uses a program, such as ChatGPT, to complete an assignment.

The work often lacks a personal touch and the writer's voice, Anderson said.

Disciplinary measures still are being determined for how to deal with AI use in assignments. Regan pointed out that
"kids who wanted to find a way to cheat found a way to cheat since school started" and there are tools available to
check their work. He pointed to Turnitin, which checks for plagiarism, and now includes an AI indicator.

Other options could include having students demonstrate their comprehension of the work in person instead of
writing papers or taking tests, he said.

The inclusion of AI, Anderson said, may cause him to rethink some of his assignments to be absolutely sure the
work is original.

On the policy side, Regan added that said he and his administrative team are examining options that may require
AI citations, and address consequences for misuse.

'Original' work?

David Haschak, vice president for academic affairs at Mount Aloysius College, said numerous conversations on the
subject are underway at the administrative level.

                                                                                                            Page 3 of 4
                     Educators embrace usefulness of artificial intelligence, note potential problems

Starting this fall, the college added a section to the academic integrity policy that'll address unauthorized artificial
intelligence use. UNESCO reported that fewer than 10% of the 450 universities it surveyed had formal guidance on
AI as of this summer.

"In some classrooms, it may be a tool," Haschak said. "In others, they want all original work."

For Gavin Moore, a junior at Bucknell University in Lewisburg, Pa., AI is something useful in coding for personal
projects or school, but he notes its limitations become apparent.

"They aren't miracle tools that do everything for you. You still need to do all the 'heavy lifting' yourself," he said.
"With something like ChatGPT, it can be like having a very elaborate search engine/online assistant at your
disposal. The biggest thing it does is make it easier to resolve issues in code or provide insight into small problems I
might have with a given topic I need to understand."

Mount Aloysius is incorporating the conversation on artificial intelligence into student orientation, to engage parents
in seeing how their children may be using such programs.

At Susquehanna University in central Pennsylvania, no official guidance has been issued. The university is
scheduled to host a series of workshops ahead of the start of classes on Aug. 28.

"It's just an overview about how AI systems work, limitations, and how and when, as a university, do we need to
develop a university-wide policy," Nabeel Siddiqui, assistant professor of digital media and director of SU's Center
for Teaching and Learning, said. "Do faculty need to determine a policy in their classrooms now? As a faculty, there
are some that have concerns and some that are excited."

Richland High School world history and character and leadership teacher Jacob St. Clair and DiMauro share a
similar approach on the matter.

St. Clair said he has experimented with some programs, including ChatGPT and image-generating software, as well
as face mapping, and considers AI to be another "tool in the toolbox" of teachers and students.

"It's like a calculator," St. Clair said.

DiMauro said he has heard a lot of "doom and gloom" about the technology but doesn't believe any of it.

He argued that students writing with chatbots may be a good use because that'll allow them time to focus on other
endeavors, such as research or other classes.

"There's just so many fascinating things you can do with this thing if applied properly," DiMauro said.

DiMauro said the cross-section of AI and education is in a "weird place." He said understands people can be put off
by the technology. He doesn't think people have been taught to use the tools correctly — programs such as
ChatGPT aren't "Super Google," he noted.

"I do absolutely think once people get their heads around it, they'll be more open and willing," DiMauro said.
"Educate yourself about it ... and it will suddenly not seem as dangerous as before and you'll start seeing the
possibilities."

St. Clair cited the example of bringing still pictures to life or creating mini-movies with historic paintings to add a new
dimension to education.

Looking ahead, he said he thinks the technology will help teach students critical thinking and problem-solving skills
as well as connect them to the subjects they're studying.

DiMauro said he is hoping "we end up in a situation where AI is commonplace in classrooms" and there are ways to
manipulate and use the tools available to perform helpful tasks including checking sources and learning to write.

                                                                                                       Page 4 of 4
                    Educators embrace usefulness of artificial intelligence, note potential problems

To avoid issues moving forward, the federal Department of Education recommends emphasizing humans in the
loop in regard to AI implementation, informing and involving educators in the conversation, and enhancing trust and
safety, among other suggestions to build the tech into the future of learning.

"We envision a technology-enhanced future more like an electric bike and less like robot vacuums," the agency
website says. "On an electric bike, the human is fully aware and fully in control, but their burden is less and their
effort is multiplied by a complementary technological enhancement."

Byers writes for the Johnstown (Pa.) Tribune-Democrat.

Have a question about this story? Do you see something we missed? Do you have a story idea for the News &
Eagle? Send an email to enidnews@enidnews.com

___ (c)2023 the Enid News & Eagle (Enid, Okla.) Visit the Enid News & Eagle (Enid, Okla.) at www.enidnews.com
Distributed by Tribune Content Agency, LLC.


Load-Date: August 18, 2023


  End of Document

                                                                                                    Page 1 of 1
                                         HEALTH TRACKERS LOOK TO AI TOOLS




                              HEALTH TRACKERS LOOK TO AI TOOLS
                                                 Wall Street Journal Abstracts
                                                     April 20, 2020 Monday



Copyright 2020 The New York Times Company: Abstracts All Rights Reserved

Section: A; Pg. 6
Length: 46 words
Byline: DANIELA HERNANDEZ

Body


ABSTRACT

Tech companies, insurers and governments are turning to artificial intelligence to flag potential coronavirus
outbreaks and people at greatest risk, which could be critical in absence of widespread accurate testing, but some
scientists question reliability of strategy (M)


Load-Date: April 21, 2020


  End of Document

                                                                                                  Page 1 of 3
             Study finds 8,500 COVID deaths may have been avoided if more Missourians were vaccinated




Study finds 8,500 COVID deaths may have been avoided if more Missourians
                             were vaccinated
                                     The Griffon News: Missouri Western State College
                                                      June 2, 2022 Thursday



University Wire
Copyright 2022 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1116 words
Byline: Tessa Weinberg

Body


In Missouri, an estimated 8,585 deaths could have been avoided if 100% of adults were vaccinated, the analysis
found (Photo by Tessa Weinberg/Missouri Independent).

If all of Missouri's adults were vaccinated against COVID-19, more than half of the over 14,000 deaths attributed to
the virus since January 2021 may have been prevented, a new analysis concluded.

The analysis, performed by researchers at the Brown School of Public Health, Brigham and Women's Hospital,
Harvard T.H. Chan School of Public Health and Microsoft AI for Health, aims to explore an alternate scenario if
demand for the COVID-19 vaccine had continued at peak levels.

Using data from the New York Times and Centers for Disease Control and Prevention that spanned January 2021
through April 2022, researchers found that nationwide, if every state had been able to vaccinate the entirety of their
adult populations, an estimated 318,981 deaths could have been averted.

In Missouri, an estimated 8,585 deaths could have been avoided if 100% of adults were vaccinated - ranking
Missouri seventh-highest when calculating vaccine preventable deaths per 1 million. That number drops to 6,595 if
90% were vaccinated and 5,571 if 85% were vaccinated.

"It's not surprising, but it's still sad to see those numbers," said Lynelle Phillips, president of the Missouri
Immunization Coalition and vice president of the Missouri Public Health Association.

There were 14,289 COVID-19 deaths during the span of the analysis. Altogether amid the pandemic, there have
been over 20,600 COVID-19 deaths in Missouri according to state data. More than 1 million died of the virus
nationwide - although experts say thousands of COVID deaths across the country went unreported.

"The state and the country have a choice to make about using a very effective tool we've been able to make
available fairly quickly in this pandemic," said Stefanie Friedhoff, a Brown University School of Public Health
professor and one of the analysis' authors. "If they choose not to, more people will die that don't have to die. That's
just very clear."

                                                                                                Page 2 of 3
           Study finds 8,500 COVID deaths may have been avoided if more Missourians were vaccinated

Friedhoff said the dashboard displaying vaccine-preventable deaths will continue to be updated.

In Missouri, vaccination rates have remained largely stagnant since the start of the year. As of Wednesday, nearly
66% of adults in Missouri were fully vaccinated - putting the state at the 10th lowest vaccination rate nationwide by
that measure, according to the CDC.

The state and the country have a choice to make about using a very effective tool we've been able to make
available fairly quickly in this pandemic. If they choose not to, more people will die that don't have to die. That's just
very clear.

- Stefanie Friedhoff, a Brown University School of Public Health professor

With COVID cases once again ticking upwards as more infectious variants of the coronavirus spread, the state's
leaders have yet to make a renewed push for vaccinations. In March, Gov. Mike Parson declared COVID-19 would
begin to be treated as endemic, similar to the seasonal flu. With the change came less frequent reporting of COVID
statistics, decreased contact tracing and vaccination data is no longer available on the state's dashboard.

Paula Nickelson, director of Missouri's health department, said during a press conference in March that the state
expects to see surges of cases and hospitalizations in the future, but that transitioning to an endemic phase will
allow the state to ramp back up as needed.

More from this section

HEALTH MINUTE: TOOLS TO HELP MIGRAINE SUFFERERS

Missouri university blames pandemic isolation for failing grades, mental health issues

Missouri sets up refunds of gas tax increase

"To be clear when we say 'ramp back up,' we will still not advocate for masks or vaccine mandates," Nickelson said
at the time. "We will not advocate for lockdowns."

Asked about the analysis' findings, Lisa Cox, a spokeswoman for the Department of Health and Senior Services,
said the state remains committed to making vaccines widely available and is making additional plans to provide
messaging regarding the benefits of staying up-to-date on vaccinations.

"It's been an extraordinary effort to make as much progress as we have in Missouri with COVID-19 vaccinations,"
Cox said, noting more than 9 million doses have been administered in just over 18 months.

Missouri's vaccine rollout faced a rocky start, with confusion and chaos marring the first months of the vaccine's
availability. Accusations swirled that rural areas were receiving more than their proportionate share as residents
from the state's metro areas drove hours to try to secure a shot. Meanwhile, disparities persisted with vaccine slow
to reach Black residents and the state trailing the nation in terms of nursing home staff vaccinations.

SUPPORT NEWS YOU TRUST. DONATE

The delta variant quickly tore through southern Missouri over the summer as some communities with low
vaccination rates largely resisted the vaccine. Roughly a dozen counties in rural areas of the state still have less
than 40% of their adult populations fully vaccinated.

In Missouri, efforts to provide financial incentives to encourage vaccinations saw limited success, with local gift card
incentives inspiring distrust from residents in some rural areas that viewed them as a form of government-
sponsored bribery.

Friedhoff said states that were more successful in vaccinating more of their residents and therefore had fewer
vaccine-preventable deaths were able to vaccinate their most vulnerable populations, like the eldery,

                                                                                                Page 3 of 3
           Study finds 8,500 COVID deaths may have been avoided if more Missourians were vaccinated

immunocompromised and communities of color. They have also more widely used mitigation measures, "and have
overall applied sort of a whole toolkit," Friedhoff said.

Missouri has never had a statewide mask mandate, and the attorney general has frequently sued cities, counties
and school districts who have imposed restrictions.

Phillips said the pandemic exposed holes in access to primary care, leaving residents with fewer trusted health
care providers to turn to for counseling on their vaccination decisions. Friedhoff said funding and investing in trusted
messengers and community organizations is especially important to make inroads on vaccination rates.

"Even though the public health system is discouraged, we should not give up," Phillips said. "We need to keep
pressing for these vaccines and need to make sure that especially people at highest risk are getting vaccinated."

GET THE MORNING HEADLINES DELIVERED TO YOUR INBOX SUBSCRIBE

The post Study finds 8,500 COVID deaths may have been avoided if more Missourians were vaccinated appeared
first on Missouri Independent.

Originally published on missouriindependent.com, part of the TownNews Content Exchange.


Load-Date: June 3, 2022


  End of Document

                                                                                                        Page 1 of 8
       Smart Machines: AI technology's impact on Florida 's business sectors Arificial intelligence hasn't quite
                           replaced humans, but the technology is making business....




   Smart Machines: AI technology's impact on Florida's business sectors;
   Arificial intelligence hasn't quite replaced humans, but the technology is
                             making business better.
                                                        Tampa Bay Times
                                                  February 16, 2021 Tuesday



Copyright 2021 Times Publishing Company All Rights Reserved

Section: NEWS; Business
Length: 3867 words
Byline: Amy Keller|Florida Trend

Body


Editor's note: This article originally was published in theFebruary issue of Florida Trend magazine.

AI can't replace humans, but the technology is making inroads in more and more business sectors.

In an oft-quoted interview with Life magazine in 1970, Marvin Minsky, an MIT researcher and pioneer in artificial
intelligence, predicted that scientists were about three to eight years away from creating a machine as intelligent as
the average human. Such a machine would "be able to read Shakespeare, grease a car, play office politics, tell a
joke, have a fight," Minksy said, and it would learn at such a "fantastic speed" that it would reach genius level within
just a few months.

Fifty years later, Minksy's vision of a machine on par with the human brain still hasn't been realized - but popular AI
tools, such as Google's search engine and Apple's Siri, have become part of everyday life, and machines are
learning how to master an array of complex tasks, from operating self-driving cars to spotting tumors to monitoring
crops.

"It's no longer, 'is artificial intelligence going to work?' It does work, and there's numerous applications that are out
there - medical imaging, credit fraud detection, movie selections - that use sophisticated artificial intelligence
algorithms to make business better," says Jeff McFadden, chief technology officer for Xonar Technology, a Largo-
based company that designed an AI-enabled security surveillance system to detect weapons. "It's really moved out
of that research area and moved into where it's really a commercially viable technology set."

The leaps forward have been made possible by powerful computer processing engines and advances in machine
learning techniques. Computers with enough horsepower can crunch large data sets and use a series of algorithms
to extract patterns and glean insights from that information. In Al recommendation systems, like that employed by
Netflix, the algorithm looks at an individual's viewing history, considers the preferences of other members with
similar tastes and evaluates other information to come up with a viewing suggestion. An algorithm in an intelligent

                                                                                                       Page 2 of 8
      Smart Machines: AI technology's impact on Florida 's business sectors Arificial intelligence hasn't quite
                          replaced humans, but the technology is making business....

credit card fraud detection service, on the other hand, flags suspect purchases by looking for outliers or anomalies
that depart from a consumer's normal purchasing behavior.

McFadden's Xonar uses an algorithm to spot concealed weapons based on their ultra-wide band radar signature.
The system transmits an electromagnetic pulse toward a person as they walk through it. The pulse bounces back to
a receiver. That reflected wave is then analyzed by machine's algorithm to see if it matches the shape, density and
other characteristics of various weapons in its learning library. It's more discriminating than traditional technologies,
which rely primarily on metal detection, and Xonar can differentiate between a knife or handgun and other harmless
metal items, such as keys or money clips, making for fewer "false positives." It's also less obtrusive. McFadden
says friends who've breezed through the system in place at the entrances of Ruth Eckerd Hall in Clearwater didn't
even realize it was there.

Inspired by neural networks in the brain, these "deep learning" systems can remember and build on observational
patterns they find in data. In essence, they become smarter over time, but it's vital to control what data the systems
receive. "The big AI in general, deep-learning specifically, learns everything. It learns what you want it to learn, but
it learns what you don't want it to learn," McFadden cautions.

In some cases, AI can outperform its human counterparts. A recent study in the journal Nature found that a Google
AI system did a better job in predicting breast cancer from mammograms than radiologists did. And a new AI
software engineered by the British company DeepMind has created a system of algorithms called AlphaFold that
can rapidly and reliably predict the 3-D shape of proteins - a task that usually takes months or years. The
breakthrough is expected to speed up and reduce the costs of pharmaceutical development.

Here's a closer look what companies and researchers across Florida are doing with AI technology and why the
experts say it will never completely replace humans.

AGRICULTURE

Gaps in Groves

Designer: Yiannis Ampatzidis (UF spinoff Agriculture Intelligence)

Product: Agroview, citrus tree counter

UF technology is helping orange growers count their trees and optimize tree growth.

Orange trees were easier to count before citrus greening struck. Fields were relatively uniform then, and farmers
who had planted 160 trees per acre on 10 acres knew with reasonable certainty that they had about 1,600 trees.
But when greening swept through Florida about a decade ago, groves became riddled with gaps where diseased
and dead trees once stood. To get an accurate count, growers had to hire workers to drive through their groves,
counting each tree, one by one, with a clicker.

"It was very time consuming and very expensive," says Yiannis Ampatzidis, a University of Florida scientist
stationed in Immokalee. To address the problem, Ampatzidis and his research team developed a system called
Agroview that uses special images taken from drones and the ground to count the trees and assess their
conditions. The method isn't perfect, but it's close. It tallied 175,977 citrus trees at one Hendry County farm with
close to 98% accuracy. It's also quick, taking about 10% as long as a manual count.

Florida growers seized on the technology in the aftermath of Hurricane Irma, when the U.S. Department of
Agriculture began requiring them to submit accurate tree inventories to maintain insurance coverage. Others have
used Agroview to pinpoint gaps in groves so they can replant where dead trees once stood. Growers can also use
the technology to detect disease and optimize the health of plants.

Agroview combines multispectral imaging and leaf analysis. The drones carry special cameras that capture image
data of the trees across a broad portion of the electromagnetic spectrum, including wavelengths invisible to the eye.

                                                                                                       Page 3 of 8
      Smart Machines: AI technology's impact on Florida 's business sectors Arificial intelligence hasn't quite
                          replaced humans, but the technology is making business....

Data from those images are then fed into Agroview's AI software, where they're cross-referenced with data from
leaves that have been analyzed in labs to identify plants with nutrient deficiencies, diseases or other types of stress.
Armed with that information, growers can fine-tune their application of fertilizer, pesticide and other inputs. If the
system indicates low levels of nitrogen or phosphorus, for instance, the grower can increase his application of those
nutrients in the affected areas. If nutrient levels are high, the grower can ease up. If disease is detected, the grower
can apply a treatment early, before it spreads through the entire crop.

Farmers can purchase Agroview through a UF spinoff company called Agriculture Intelligence. The company will
also collaborate with drone operators if growers don't have their own drone to collect the data. "Right now, we're
working mainly with citrus, but tomato and other crops, other profiles, will come soon," Ampatzidis says.

UF researchers are also collaborating with a farm equipment company in Clewiston called Chemical Containers to
develop a "smart sprayer" that uses AI and "sensor fusion" for precise application of insecticides and weed killer. "If
you have a traditional sprayer, it will spray everywhere with the same amount, but that doesn't make sense,"
Ampatzidis says. "If you have a big tree, you need more chemicals to be sprayed, but if it's small, half the size, in
theory you need half. If it's a gap, you don't spray at all."

THE ARTS

Dali, Resurrected

Designer: Goodby Silverstein & Partners

Product: Dali Lives, a re-creation of the artist

Salvador Dali, the Spanish surrealist painter, died in 1989 at age 84. But visitors to the Dali Museum in St.
Petersburg can interact with a life-like version of the artist that's been re-created using artificial intelligence.
Unveiled in 2019 on what would have been Dali's 115th birthday, Dali Lives was created using AI and a faces-
wapping technique known as a deep-fake. Using archived interview footage and other historical materials, an AI
algorithm designed by San Francisco-based Goodby Silverstein & Partners was able to master Dali's mannerisms.

Following 1,000 hours of machine learning, the AI tool generated a likeness of Dali's face that was superimposed
over an actor's body and synced with a voice impressionist to create a talking digital replica of the flamboyant artist.
The resulting exhibit includes 125 interactive videos, with 190,512 possible combinations depending on user
response, meaning no two visitors are likely to have exactly the same experience. Museum visitors are treated to a
selfie taken by the digital Dali that they can receive via a text message before they leave the museum.

EDUCATION & RESEARCH

Super Partnership

Designer: Nvidia/University of Florida

Product: HiPerGator supercomputer upgrade

Nvidia and UF are partnering to create "higher education's most powerful AI supercomputer" (rendering). All
colleges at the university are building AI courses related to their area of expertise.

After graduating from the University of Florida in 1980 with his engineering degree, Chris Malachowsky landed his
first job at Hewlett-Packard in California, where he designed a central processing unit, or CPU chip. He leveraged
that experience into his second job at Sun Microsystems, where he worked on computer graphics until 1993, when
he and some colleagues decided to start their own company, Nvidia.

In the years since, Nvidia has transformed visual computing and come to dominate the artificial intelligence
landscape with its graphics processing unit, or GPU, technology. Now, the Silicon Valley company is partnering with

                                                                                                        Page 4 of 8
       Smart Machines: AI technology's impact on Florida 's business sectors Arificial intelligence hasn't quite
                           replaced humans, but the technology is making business....

the University of Florida to supply an AI supercomputer that works with UF's existing HiPerGator system to create
"higher education's most powerful AI supercomputer," which will be capable of delivering 700 petaflops of AI
performance, or 1 quadrillion operations per second.

The public-private partnership is anchored by a $60-million donation - including $25 million from Malachowsky and
$25 million in technology, training and services from Nvidia. UF will contribute $20 million. The school has also
committed to hiring 100 faculty members focused on AI and plans to incorporate AI broadly across its curriculum.

While the school already offers courses in machine learning and AI ethics, each college at the university is building
AI courses related to its area of expertise. UF's College of Business, for instance, is working on an AI course that
will focus on AI in financial technologies. "We want to make it possible for every student who graduates from the
University of Florida and who'd like to learn about AI the opportunity to either become acquainted with it, to become
competent in it or become an expert in it," says Joe Glover, UF's provost and senior vice president of academic
affairs.

Glover says anyone in the State University System will be able to use its new supercomputer for educational
purposes to teach students about machine learning and AI. Researchers at all the State University System schools
will have access to the new supercomputer for educational purposes at no charge to teach students about machine
learning and AI. UF will also provide limited support and training for using its computer resources.

The partnership comes at a critical moment, with the federal government warning that United States is lagging in
churning out AI-trained workers. "We think we have a unique approach here to helping to solve that issue. We
intend to create the next generation of the AI-enabled workforce at scale, graduating 5,000 to 10,000 people who
are going to pour into the economy and bring those skills with them to whatever their chosen occupation is," says
Glover.

RESEARCH

COVID, Cancer & Cats

Designer: Ulas Bagci

Product: Predictive health care software

Ulas Bagci, an assistant professor in University of Central Florida's department of computer science, has been
working with an international team of researchers to develop AI tools that are helping doctors and nurses across the
globe manage COVID-19 patients.

Using images from chest CT scans, their algorithm is able to predict which patients have COVID-19 and the
infection's severity, helping health care providers identify which patients need to go to ICU, which are likely to need
intensive care or die and which ones can go home based on inflammation it detects in the lungs.

The AI technology has proved especially helpful in countries such as Italy, Japan, China and the U.S. "The
hospitals are full of COVID patients. They need to manage them in the optimal way," Bagci says.

Bagci has developed similar predictive algorithms to diagnose lung cancer and pancreatic cancer from CT scans
and MRI images. He says the algorithms can accomplish in seconds what it takes radiologists "ages to do." But he
says the AI tools are not a replacement for their expertise, but rather an enhancement to lend them support and
point them to the problem. "A human should always be in the loop for a trustworthy AI," he says.

In the classroom, Bagci likes to use the "cat behind the tree" example for his students. "Let's say there's a cat
behind a tree and on one side you see the head and the other side you see the tail. You understand, as a human,
that there is only one cat. But artificial intelligence is too artificial. It allows for two cats. It will give labels like cat 1,
tree, and cat 2," he explains. "With high-level knowledge, we are much better than AI, and for high-risk applications,

                                                                                                       Page 5 of 8
      Smart Machines: AI technology's impact on Florida 's business sectors Arificial intelligence hasn't quite
                          replaced humans, but the technology is making business....

none of these deep-learning algorithms give you reason. It's good. It's really helpful, but it's not going to replace
humans. True intelligence is not there."

HEALTH CARE

AI-Powered Patient Monitoring

Designer: Chakri Toleti (Care.ai)

Product: Care.ai, patient monitoring software

Chakri Toleti, a serial entrepreneur from the Orlando area, was taking a sabbatical "in between companies" in 2018
when he learned that his 78-year-old mother had fallen in a bathroom in India. She was stranded there for nearly 30
minutes before a caregiver found her. She recovered, but the incident motivated Toleti to create a company called
Care.ai that makes AI-powered autonomous patient monitoring systems for hospitals, nursing homes and other
health care facilities.

Toleti says the system was inspired by his experience building motion capture systems at Disney 25 years earlier
and sensor technology like that used in self-driving cars. Care.ai relies on similar tools - including sensors and an
AI-powered "learning library" of behaviors and movements - to predict when a patient is at risk of falling or
wandering off. If it senses something worrisome, it alerts nurses. It can also detect whether workers are washing
their hands, delivering medications or coming in to check on patients when they should, in effect creating a "self-
aware" room.

When COVID-19 hit last year, Care. ai tweaked its platform to screen hospital visitors for signs of infection. The
touch-free screening tool - which is used at Tampa General Hospital, Rush University Medical Center in Illinois and
other facilities across the nation - has a contact-free thermal sensor to detect feverish visitors, sending a message
to staff if a person's temperature exceeds 100 degrees.

REAL ESTATE/DEVELOPMENT

Real Estate Modeling

Designer: Olivia Ramos (Deepblocks)

Product: Deepblocks, early property analysis software

Growing up in Cuba, where she lived until she was 10 years old, Olivia Ramos spent lots of time in the office where
her mother worked as an architect. "At the time, they had no computers, so it was all a bunch of pencils and rulers,
and I fell in love with all the little gadgets," she recalls.

Two decades later, Ramos is perfecting her own gadget - a high-tech software application called Deepblocks that
uses data and deep learning to streamline and automate the process of early property analysis. Developers using
the software can zoom in to a specific parcel, set their building parameters - square footage, number of units,
parking, etc. - and the program spits out a 3-D visual of the project and an analysis with a projected return on
investment that takes into account everything from market demographics (such as rent-to-income ratios) to local
zoning rules.

"Zoning data, the rules of the city, are usually 400- page PDFs and are really expensive to go through and
understand," says Ramos, who has a master's degree in architecture from Columbia University and a master's in
real estate development from the University of Miami. "We developed models that understand that data and extract
that data from those documents. You just select a piece of land, and it tells you what you can do."

                                                                                                        Page 6 of 8
       Smart Machines: AI technology's impact on Florida 's business sectors Arificial intelligence hasn't quite
                           replaced humans, but the technology is making business....

The software can shave considerable time off development planning. It took one customer a year to do 21 iterations
of a particular parcel that Deepblocks can help do in a few hours, and users can do as many models as they want,
Ramos says. It currently includes parcel data for more than 1,000 U.S. cities and zoning data for 30 cities.

The Miami startup has a staff of six, including CEO and founder Ramos, and has raised $2 million through two
funding rounds. It's raising $3 million in a third round. Real estate pros can buy a subscription to Deepblocks for
$1,620 a month or $12,600 for a year. The software has seen a "big growth in adoption" amid the COVID-19
pandemic because people can't travel as easily to visit potential markets, Ramos says.

The goal is for the software to make suggestions on opportunities in the market and determine the highest and best
use of any property, Ramos says. When that happens, she believes Deepblocks will help tackle even bigger
problems, such as a lack of affordable housing.

"It's really, really hard to make an affordable housing project profitable, and it requires a lot of government help, so if
we use the inefficiencies and understand what to build and how to build and where to build it, then that projects a lot
of savings on the front end," she says. "Every single penny you save in affordable housing in cost, it's going to
make that project more likely to happen."

LAW

Legal AI

Designer: Holland & Knight /Joe Dewey

Product: Draft responses software

Joe Dewey, a financial services and real estate attorney and "innovation partner" at Holland & Knight, says his firm
has built an AI system that can generate about a dozen draft responses to pleadings for cases in high-volume
practice areas. While a human must still sign off on the final version of a document, the law firm has been able to
shave about two to three hours off the process of preparing a pleading. "With 50 to 100 cases a month, that starts
to add up," he says.

Dewey sees bigger things on the AI horizon for the legal world - such as a deep-learning tool that could help an
attorney draft a motion based on prior decisions issued by a particular judge, or an algorithm that could synthesize
all existing case law on a topic and create a memorandum. "If you could get something that could do that at 70% to
80% accuracy, that would be a very valuable tool," he says. "The technology will need to evolve, but I think that's
the direction we're headed."

The Miami lawyer is skeptical that any machine could rival the human brain in a broad way. "For the most part, the
machine learning models are good at one task. It's just a statistical model at the end of the day, and it applies the
statistics to make a prediction about something," Dewey says. "They're very powerful with the tasks they're trained
to do, but very limited, usually to a very narrow task. Beyond that, they're fairly dumb."

Automation

An increasing number of companies are leveraging AI to automate more mundane business tasks.

The Tampa Bay Rays and Rowdies use an AI-power contract management system called IntelAgree, created by
the Tampa-based startup CoLabs, to streamline their contract process.

A 4-year-old Miami company called Chirrp has developed a platform that harnesses IBM Watson's conversation
technology to create more "human-like" chatbots for businesses.

Vinsa, a company that grew out of the AI-consulting firm Levatas in Palm Beach Gardens, uses its computer vision
models along with robots created by Boston Dynamics to automate "labor-intensive" tasks such as reading and

                                                                                                        Page 7 of 8
       Smart Machines: AI technology's impact on Florida 's business sectors Arificial intelligence hasn't quite
                           replaced humans, but the technology is making business....

monitoring analog utility gauges at electric, oil and gas sites. Vinsa has also built computer vision models that can
see whether workers on construction sites are wearing masks and complying with other safety requirements.

AI Milestones

Florida Atlantic University's College of Engineering and Science is implementing AI-oriented degree programs,
including a master of science with a major in AI (the first such degree in Florida), a multi-disciplinary master of
science in data and analytics and a joint degree that funnels honors students into a master's of science in data
science.

Researchers at FAU's College of Engineering and Computer Science recently landed a five-year, $2.4-million grant
from the National Science Foundation to train graduate students in data science technologies and applications.

With a $1-million gift from Rubin and Cindy Gruber, FAU is building a 3,400-sq.-ft. artificial intelligence lab within its
Wimberly Library.

Workforce Impacts

When Ivan Garibay was invited to Washington, D.C., a few years ago to talk to lawmakers about artificial
intelligence, many quizzed him about "the singularity" - a theoretical point in time when AI will surpass human
intellect - and inquired about whether smart machines will be job killers.

Garibay, founding director of the University of Central Florida's Complex Adaptive Systems Laboratory, told them
the age of AI will be like other industrial revolutions. "Some types of jobs disappear, but it also brings new types of
jobs," he said. "A few years down the road, we probably won't need Uber drivers or taxi drivers or truck drivers
because AI's getting better and better at guiding cars, but that doesn't mean that many jobs won't appear in that
new AI economy." As traditionally, retraining people with new skills, he says, will be key to weathering the
disruption.

A 2019 report from the Brookings Institution suggests that the impacts of AI won't be evenly felt. Those in "better-
paid, white-collar occupations" are among the "most exposed" to AI, although the "most elite workers - such as
CEOs - appear to be somewhat protected," according to Brookings' analysis. The report says that jobs involving
"pattern-oriented or predictive work" may be "especially susceptible," whereas low-paying "rote" jobs involving food
preparation, health care and personal care may be less affected.

As for the notion of the singularity - "we're very, very far away," Garibay surmises. "That is something I don't even
see in generations, having true intelligent machines that could replace or be a threat to humankind. It's almost like
the Wizard of Oz. It's always amazing when you see the results, but when you see behind the curtain, you realize
what's there is not as impressive. It's just mathematics and fast computers. I don't see it coming. Not in our lifetime
at least."



Graphic


See image link
Jeff McFadden, chief technology officer for Xonar Technology, stands between company sensors installed at Ruth
Eckerd Hall to screen visitors and check their temperatures.

See image link
Yiannis Ampatzidis, UF assistant professor, Precision Agriculture and Smart Machines

See image link

                                                                                                       Page 8 of 8
      Smart Machines: AI technology's impact on Florida 's business sectors Arificial intelligence hasn't quite
                          replaced humans, but the technology is making business....

Goodby Silverstein & Partners relied on hundreds of interviews, quotes and footage of Dali to train an AI algorithm
to "Learn" aspects of the artist's face.

See image link

Nvidia and UF are partnering to create "higher education's most powerful AI supercomputer."

See image link
UCF assistant professor Ulas Bagci and his team created an algorithm that can predict the progression of COVID
patients.

See image link

After a fall stranded his mother, Chakri Toleti (second from right) decided to create AI technology that could locate
and identify individuals and their behaviors in real-time, "minimizing risks before they happen."

See image link
Olivia Ramos' software gives developers a 3-D peek at what a building will look like on a parcel.


Load-Date: February 18, 2021


  End of Document

                                                                                                     Page 1 of 7
         Regulatory Comments Before the U.S. Copyright Office Library of Congress In the Matter of Artificial
                                          Intelligence and Copyright




 Regulatory Comments Before the U.S. Copyright Office Library of Congress
             In the Matter of Artificial Intelligence and Copyright
                                                             R Street Institute
                                                       October 27, 2023 Friday



Copyright 2023 Content Engine, LLC.
All Rights Reserved
Copyright 2023 R Street Institute, USA All Rights Reserved

Length: 3696 words

Body

Before theU.S. Copyright OfficeLibrary of Congress
 October 30, 2023
In the Matter of
Artificial Intelligence and Copyright
Notice and Request for Public Comment
)
)
) Docket No. 2023-6
)
)

Submitted byWayne T. Brough and Ahmad Nazeri

On Behalf of theR Street Institute

The R Street Institute (R Street) is pleased to submit these comments on the Artificial Intelligence and Copyright
Notice and Request for Public Comment to the U.S. Copyright Office. R Street is a nonprofit, nonpartisan public
policy research organization ("think tank") whose mission is to engage in policy research and outreach to promote
free markets and limited, effective government. Our organization regularly advocates on copyright policy in a digital
world. In this capacity, we welcome the opportunity to provide comments on the disruptive innovation brought on by
the introduction of artificial intelligence (AI) and machine learning.

 Understanding the inherent tension between the principles of copyright and freedom of expression is paramount.
The First Amendment declares, "Congress shall make no law... abridging the freedom of speech." This stands in
contrast to copyright article, U.S. Const. Art. 1, § 8, cl. 8, which mandates, "[The Congress shall have Power] To...
promote the Progress of Science and useful Arts, by securing for limited Times to Authors... the exclusive Right to
their respective Writings..."

 To navigate this dichotomy, we must adopt a narrow interpretation of copyright, ensuring it imposes minimal
constraints on the freedom of expression. To this end, we believe that existing copyright law is suitably flexible to

                                                                                                    Page 2 of 7
        Regulatory Comments Before the U.S. Copyright Office Library of Congress In the Matter of Artificial
                                         Intelligence and Copyright

address ongoing concerns with respect to copyright and the implications of AI, and we urge prudence in the
introduction of new copyright rules or regulations.

Artificial Intelligence and Creative Arts

AI promises to bolster the American economy, amplify the capabilities of creatives and catalyze advancements in
science and the arts.[1] Recognizing that contemporary copyright doctrine has evolved to embrace a myriad of
transformative technologies is crucial. Existing copyright law is adeptly poised to address the genuine concerns of
creators. Within the existing legal framework, the judiciary is ideally positioned to contextualize and apply these
principles in the face of the multifaceted challenges presented by AI.

AI has great potential to solve complex math calculations, detect cancer early, create new art and much more. In
light of these capabilities, some advocate for stricter copyright rules that could hinder AI's potential and contradict
the original purpose of copyright law-promoting "progress in science and useful arts"-by restricting freedom of
expression.[2] Maintaining a balanced copyright framework is vital to keep the United States at the forefront of art
and technology.

In the dynamic realm of AI, increasing copyright regulations could undermine the technology's prospective
advantages significantly. Tighter restrictions might impede AI's growth by restricting access to necessary training
data.[3] Such limitations risk diminishing AI's capacity to address complex challenges, innovate across sectors and
contribute to artistic endeavors. By constricting the data from which AI learns, we inadvertently limit the spectrum of
expression and creativity it can manifest. Our comments are anchored in the belief that while safeguarding creators'
rights is paramount, it should not stifle innovation or encroach upon our foundational liberties. While the request for
comments is extensive, R Street has focused on the questions we believe to be most significant with respect to our
work on copyright and AI.

Question 8. "Under what circumstances would the unauthorized use of copyrighted works to train AI
models constitute fair use?"

The copyright dichotomy between idea and expression is a foundational principle in copyright law.[4] This distinction
clarifies that while the unique way something is expressed (its expression) can be copyrighted, the general idea or
concept behind it cannot be. When it comes to training AI models, this principle becomes pivotal. If an AI model is
trained using copyrighted materials, determining the purpose of the use becomes crucial. If the intention is merely
to understand the foundational concepts or ideas presented by a copyrighted work (e.g., general themes, topics,
knowledge), then it might be seen as fair use.[5] However, if the goal is to make the AI replicate or reproduce the
specific way those ideas are articulated or expressed in the copyrighted work, then it could be a copyright violation.
For example, when a machine learning (ML) system processes images of stop signs, its primary objective is to
recognize the sign's universal features, not to replicate the unique artistic nuances of each photograph. Similarly, a
natural language processing system analyzing written content aims to understand general linguistic structures and
patterns rather than to reproduce or capitalize on the distinct expressive qualities of the prose.[6]

The fair use doctrine should be interpreted in a manner that supports AI technology advancement. Allowing ML
systems to train on comprehensive datasets, even if they include copyrighted works, serves the broader societal
interest. Such access ensures that AI systems are safer, more accurate and unbiased. Conversely, restricting AI
training to smaller, proprietary datasets due to copyright constraints can result in suboptimal, potentially biased AI
outputs.

A pivotal consideration in this context is the concept of "fair learning." This principle posits that if an AI's primary
objective in accessing a work is to learn from its non-copyrightable elements rather than to appropriate its
copyrightable aspects, then such use should be deemed inherently fair under the first factor of the fair use analysis.

Question 8.5. "Under the fourth factor of the fair use analysis, how should the effect on the potential market
for or value of a copyrighted work used to train an AI model be measured?"

                                                                                                    Page 3 of 7
        Regulatory Comments Before the U.S. Copyright Office Library of Congress In the Matter of Artificial
                                         Intelligence and Copyright

In the realm of copyright law, the fourth factor of "fair use" analysis examines the impact of a copyrighted material's
use on its potential market value.[7] When applying this factor to the training of AI models, it is important to consider
the original intent behind the creation of copyrighted works like books or photographs. Typically, authors or
photographers do not create these works with the expectation of selling them for AI use. Therefore, training an AI
model on such materials does not inherently detract from the work's intended market or its value because AI
learning models were never the target audience or consumer. In essence, the usage by AI does not replace the
need for humans to purchase or access the original, nor does it directly compete with the core market intended by
the copyright holder.[8] As such, even if the use aligns with the educational ethos of "fair learning," it is essential to
recognize that AI's utilization is unlikely to undermine the creator's ability to benefit from their work in its intended
market.

Question 10 and Its Sub Questions. "If copyright owners' consent is required to train generative AI models,
how can or should licenses be obtained?"

The process of acquiring individual licenses for the vast amount of data required for AI training is not only
burdensome, but also potentially unachievable. Navigating licensing agreements for each piece of data can give
rise to various challenges, including disputes over rights and the logistical nightmare of ensuring compliance for
extensive datasets.[9]

Moreover, the costs associated with obtaining these licenses could make AI projects excessively expensive, thus
impeding innovation and hindering industry growth. This approach may render many AI-driven projects
unattainable, particularly for smaller entities or researchers with limited resources.

Although direct voluntary licensing may appear feasible in certain creative sectors, implementing it across all
sectors presents significant challenges. For example, while structures exist to protect works as unified entities in
sectors like music, the complexities of obtaining licenses for each individual piece of content can give rise to
numerous challenges. It would be impractical for a company to negotiate licenses with all copyright owners due to
the large number of works. When contemplating the future of work, particularly in AI and data utilization, such a
licensing approach could render many projects unachievable. Considering the vast amount of data required for AI
training, obtaining licenses for every piece of copyrighted content can be burdensome and potentially unattainable.
While a compulsory licensing regime may appear to address the challenges posed by voluntary licensing, it is
essential to consider the broader implications. Although there are existing compulsory licenses in certain areas of
copyright, the evidence does not necessarily support the notion that these licenses promote creativity or fair
use.[10] Establishing a compulsory licensing regime is neither desirable nor effective in promoting creative activity.

Question 13. "What would be the economic impacts of a licensing requirement on the development and
adoption of generative AI systems?"

Introducing a licensing requirement for the development and adoption of generative AI systems would have
profound economic implications.
    •    Barrier to Entry: Given the vast number of works an AI training dataset might need to use-and the fact
         that thousands or millions of individuals might own those works-obtaining licenses for all underlying content
         becomes a significant challenge. This could act as a barrier to entry for smaller companies or startups that
         lack the resources to negotiate and secure such licenses.
    •    Increased Costs: The process of identifying, negotiating and securing licenses for every individual piece
         of content in a dataset would be resource-intensive. These increased costs could be passed on to
         consumers or could deter companies from pursuing certain AI-driven projects altogether.
    •    Stifling Innovation: The sheer complexity and cost associated with obtaining licenses might discourage
         innovation. Companies might opt for safer, less ambitious projects to avoid potential copyright pitfalls,
         thereby limiting the advancement of AI technologies.
    •    Monopoly Concerns: Only large entities, like tech giants, that have the resources to navigate the
         licensing landscape or have already amassed vast amounts of data might be able to compete effectively in

                                                                                                    Page 4 of 7
        Regulatory Comments Before the U.S. Copyright Office Library of Congress In the Matter of Artificial
                                         Intelligence and Copyright

         the AI space. This could lead to a monopolistic environment where only a few players dominate, thereby
         reducing competition and potentially stifling innovation.
    •    Economic Incentives for Litigation: Given the structure of copyright remedies, even small-value
         infringements can lead to lawsuits due to the potential for statutory damages. This could encourage
         opportunistic lawsuits, further increasing costs for AI developers.
    •    Potential Negative Outcomes: While broader access to data can help mitigate some of the negative
         outcomes associated with AI (e.g., biases), restricting access through licensing could exacerbate these
         issues. For instance, limited data access might hinder the ability of AI systems to be trained on diverse
         datasets and lead to biased outcomes.
    •    Impact on Broader Economy: The ripple effects of these challenges could extend beyond the AI industry.
         Reduced innovation in AI could slow advancements in sectors across the economy that rely on AI, such as
         health care, finance and transportation.

Question 18. "Under copyright law, are there circumstances when a human using a generative AI system
should be considered the ''author'' of material produced by the system?"

As AI continues to evolve and integrate more deeply into our creative and professional processes, the lines
between human-led creations and those generated by AI blur. Recognizing and understanding these different
scenarios can provide clarity on how to approach this intricate issue.
    •    The Role of the Software Programmer: The original designer or programmer of an AI system provides it
         with foundational algorithms, logic and structures.[11] If the final output predominantly aligns with this initial
         framework without significant external influence, it can be argued that the programmer, having set the AI's
         course, should be considered the author. Think of it as setting the initial conditions for a complex chain
         reaction-even if the subsequent events are unpredictable, they all stem from those initial conditions.
    •    Direct Influence by the User: In many scenarios, the end user or operator of an AI system plays a pivotal
         role in shaping its output. This can be achieved by selecting specific training datasets or by guiding the AI
         through a series of iterative commands or prompts. Here, the AI system is more akin to a musical
         instrument-while it has the potential to create, the direction, tone and final output depend heavily on the
         user. Thus, when the user's influence is significant, the user can be considered the primary author.
    •    Collaborative Creation: Often, the final output is neither solely a result of the AI's initial programming nor
         the user's guidance. It is a symbiotic relationship in which the AI's design and the user's real-time inputs
         collaboratively shape the end product. This can be seen as a partnership or collaboration between the AI's
         inherent capabilities and the user's creative intent, resulting in both parties potentially being regarded as
         joint authors.
    •    AI Operates Autonomously: Conversely, there are times when AI, armed with its algorithms and learned
         behaviors, produces content with little to no human intervention.[12] In these cases, the output can be so
         unpredictable and detached from human input that claiming human authorship becomes challenging.

In the first three scenarios, we can consider a human as the author of an outcome work. There are instances in
which AI serves purely as a tool, much like a canvas and brush for a painter. In these cases, the AI merely aids in
translating the human's specific vision into reality without adding its unique flair or direction. Even if the AI speeds
up the process or simplifies complex tasks, the creative essence and primary direction come from the human. Thus,
in such scenarios, the human remains the sole author.

In the final scenario, with AI operating autonomously, the concept of human authorship does not apply. Similarly,
the use of copyright law to spur innovation does not apply in this case, making it difficult to justify a role for copyright
law in such an instance. Indeed, it may be that such works fall within the public domain as stipulated by existing
copyright law.

                                                                                                    Page 5 of 7
        Regulatory Comments Before the U.S. Copyright Office Library of Congress In the Matter of Artificial
                                         Intelligence and Copyright

Question 19. "Are any revisions to the Copyright Act necessary to clarify the human authorship
requirement or to provide additional standards to determine when content including AI-generated material
is subject to copyright protection?"

There is no pressing need for revisions to the Copyright Act to address AI-generated content. The current
framework is equipped to handle the challenges posed by AI and ML. As previously discussed, when there is
significant human intervention and the output from the ML system aligns with the human's intended creative vision,
it can be protected under existing copyright provisions. Historically, humans have employed various technological
tools to aid in their creative processes, and AI can be viewed as a continuation of this trend. Just as the use of
these tools did not necessitate a change in copyright laws, the advent of AI does not inherently demand a revision.
The key lies in discerning genuine human creative contributions from purely machine-generated outputs.

Question 20. "Is legal protection for AI-generated material desirable as a policy matter? Is legal protection
for AI-generated material necessary to encourage development of generative AI technologies and
systems?"

From our discussions, it is evident that while legal protection for creative works is essential, extending this
protection to AI-generated material requires careful consideration. The primary concern is reconciling copyright
protection with the broader principle of freedom of expression. While copyright aims to protect original works, it
should not stifle the free flow of ideas-especially in the realm of AI and ML. Existing copyright protection for
computer code does offer some incentives for the development of generative AI technologies.[13] However, the
focus should be on ensuring that these protections do not hinder the broader goals of innovation, education, and
promoting science and art. In essence, AI and ML utilize the "idea" behind a work rather than replicating its unique
"expression," which is what copyright traditionally protects.

Question 20.1. "If you believe protection is desirable, should it be a form of copyright or a separate sui
generis right?"

The current copyright act is sufficiently equipped to handle the challenges posed by AI-generated content.
Introducing a separate sui generis right would only complicate the landscape further. The existing framework of the
Copyright Act-if interpreted and applied judiciously-can address the nuances of AI creations. While it is essential to
protect creators and innovators, it is equally crucial to uphold the broader goals of freedom of expression, education
and innovation. When approached with this balanced perspective, the current copyright act can serve these dual
purposes without additional rights or protections.

Question 21. "Does the Copyright Clause in the U.S. Constitution permit copyright protection for AI-
generated material?"

The Copyright Clause in the U.S. Constitution aims to "promote the progress of science and useful arts." While it
does not explicitly address AI-generated material, the spirit of the clause is to foster creativity and innovation.
Protecting AI-generated content could arguably align with this goal, but only if done judiciously. As emphasized
throughout our comments, while protection is essential, it is equally crucial to ensure that works remain accessible
for future AI and ML endeavors under the Fair Use doctrine. Such accessibility ensures that AI and ML can
continue to evolve without the threat of infringement. By interpreting copyright narrowly, in line with Article 8 of the
Constitution, we can strike a balance that upholds freedom, education and innovation. This approach respects the
essence of the Copyright Clause while ensuring that AI and ML can operate within a framework that recognizes
their unique nature and potential.

Conclusion

How can we navigate the complex and ever-changing intersection of copyright law and AI in a way that protects
creators, encourages innovation and upholds fundamental liberties like freedom of expression? While the current
copyright system can handle many AI-related challenges, it is necessary to approach this issue with a nuanced
perspective to ensure that protections do not hinder the broader objectives of freedom of expression, education and

                                                                                                   Page 6 of 7
       Regulatory Comments Before the U.S. Copyright Office Library of Congress In the Matter of Artificial
                                        Intelligence and Copyright

innovation. We must find a middle ground that safeguards original works while allowing for the exchange of ideas. It
is important to interpret the Copyright Clause in the U.S. Constitution, which aims to promote the progress of
science and arts, in a manner that acknowledges the transformative potential of AI. However, we should always
interpret copyright narrowly to minimize its impact on freedom of expression-a fundamental right that predates any
government and is superior to copyright.

As stated in Article 8 of the U.S. Constitution, copyright exists to serve a specific goal, and expanding its scope
would undermine both freedom of expression and the philosophy behind copyright itself. Expanding the fair use
doctrine can play a significant role in mitigating the damage caused by copyright to freedom of expression-
especially in the context of AI and ML.
Respectfully submitted,

 A group of black letters Description automatically generated
Wayne T. Brough
Policy Director, Technology and Innovation
The R Street Institute
1411 K Street NW, Suite 900
Washington, D.C. 20005
202-525-5717
[email protected]

[1] Jacques Bughin et al., "Skill shift: Automation and the future of the workforce," McKinsey Global Institute, May
23, 2018, pp. 3-84. https://www.mckinsey.com/featured-insights/future-of-work/skill-shift-automation-and-the-future-
of-the-workforce.
[2] Amanda Beshears Cook, "Copyright and Freedom of Expression: Saving Free Speech from Advancing
Legislation," Chicago-Kent Journal of Intellectual Property 12:1 (2013); see also Craig W. Dallon, "The Problem with
Congress and Copyright Law: Forgetting the Past and Ignoring the Public Interest," Santa Clara Law Review 44:2
(2003), pp. 365-455.
[3] Mark A. Lemley and Bryan Casey, "Fair learning," Texas Law Review 99:4 (2020), pp. 743-785.
[4] Embodied in 17 U.S. Code § 102(b) - Subject matter of copyright: In general; see also Edward Samuel, "The
Idea-Expression Dichotomy in Copyright Law," Tennessee Law Review 56 (1988), p. 321.
[5] CFR § 202.1 - Material Not Subject to Copyright; see also Lemley and Casey, supra, note 3.
[6] Lemley and Casey, supra, note 3, p. 749.
[7] Pierre N. Level, "Toward a Fair Use Standard," Harvard Law Review 103:5 (1990), p. 1124.
[8] Lemley and Casey, supra, note 3, p. 776; See also Bill Graham Archives v. Dorling Kindersley Ltd., 448 F.3d
605, 614-15 (2d Cir. 2006).
[9] Id. at p. 770.

[10] Jason S. Rooks, "Constitutionality of Judicially-Imposed Compulsory Licenses in Copyright Infringement
Cases,"        Journal   of    Intellectual   Property      Law 3:1     (October      1995),   pp.      255-276.
https://digitalcommons.law.uga.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1112&context=jipl.

[11] Margot E. Kaminski, "Authorship, Disrupted: AI Authors in Copyright and First Amendment Law," U.C. Davis
Law Review 51 (2017), p. 597. https://scholar.law.colorado.edu/cgi/viewcontent.cgi?article=2193&context=faculty-
articles.
[12] Id. at p. 598.

[13] Megan Svedman, "Artificial Creativity: A Case Against Copyright for AI-Created Visual Artwork," IP Theory 9:1
(2020), p. 13. https://www.repository.law.indiana.edu/cgi/viewcontent.cgi?article=1053&context=ipt.


Load-Date: October 28, 2023

                                                                                                 Page 7 of 7
     Regulatory Comments Before the U.S. Copyright Office Library of Congress In the Matter of Artificial
                                      Intelligence and Copyright


End of Document

                                                                                                       Page 1 of 4
                        'Doing the right thing' Americas International tops Best Places to Work list




 'Doing the right thing'; Americas International tops Best Places to Work list
                                                     Rubber & Plastics News
                                                          November 30, 2020
                                                            Print Version



Copyright 2020 Crain Communications All Rights Reserved




Section: Pg. 1; Vol. 50
Length: 1865 words
Byline: Andrew Schunk
Dateline: AKRON

Body


What better place from which to supply polymers and rubber additives for the global tire and industrial rubber goods
industries than the Rubber Capital of the World? And what better business to do it than this year's Best Places to
Work winner?

Americas International Inc. President Wayne Stair, founder of the company and former Goodyear employee, counts
the location of AI's headquarters as a feather in his cap, growing up around the likes of industry giants Goodyear
and Firestone.

"I always felt it was critical to have the company headquartered in Akron," Stair said. "I was fortunate to have the
opportunity to travel extensively throughout the world. I quickly learned that Akron enjoys a very significant role.
Industry professionals from all over recognize Akron, the companies located here, the history and the University of
Akron-all important aspects of the rubber industry."

Now AI can add another accolade to its portfolio, having been named the top company in Rubber & Plastics News'
Best Places to Work for 2020. The second annual survey was conducted by the Best Companies Group, and nine
rubber industry firms scored high enough to be labeled a rubber industry Best Place to Work.

"Obviously I am very gratified," Stair said. "I've always wanted as my No. 1 goal to have AI as a challenging but
enjoyable work experience for our associates. Most importantly, I really want them to be well-compensated for their
efforts.

"I always try to keep in mind-since I worked for Goodyear for 18 years-that we are all here to do a job. And good
compensation is important because we all have families. This continues to be my No. 1 philosophy."

                                                                                                       Page 2 of 4
                     'Doing the right thing' Americas International tops Best Places to Work list

The distributor of rubber accelerators, additives, synthetic rubber, latex rubber, thermoplastic elastomers and heat
transfer fluids was founded in 1997, and supplies customers with products from some of the top raw material
manufacturers in the industry, including Eastman Chemical Co., Goodyear Chemical, Nocil, Sasol, Taminco Corp.
and Therminol (heat transfer fluid produced by Eastman).

With its 7,500-sq.-ft. headquarters on Embassy Parkway (in an overall 15,000-sq.-ft. building which AI owns,
leasing out the remaining space), AI remains a small company with 17 employees. AI maintains 16 warehouses
throughout the U.S., in Ohio, South Carolina, Tennessee, Illinois, California and Texas.

And while Americas International may not have a large staff, it does have high expectations.

"Everyone is dedicated to the customer-first approach, making the business successful without personal agendas,"
Stair said. "We have excellent communication between departments and collaborative relationships with global
supply partners. Employees are willing to take on a challenge even if it's not within their core competency."

The staff is 70 percent female and 30 percent male, and experienced zero turnover last year in an industry that
averaged 17 people per year for businesses of comparable size.

Stair attributes the low turnover rate to company amenities such as an excellent health plan, through which AI pays
between 75 percent and 99 percent of the premium on medical coverage for employees; and discounted medical,
dental and vision rates for dependents.

The company maintains both a Safe Harbor program and a traditional 401(k), essentially two avenues for in-kind
company donations to employee retirement programs-one through a traditional matching donation in the 401(k)
itself, and the other through Safe Harbor, which is based on overall company profitability.

AI offers generous and flexible PTO and vacation time, crucial during the pandemic to any company. And during the
summer months, office staff can take a half-day every other Friday, a perk that lost some of its luster when work-
from-home efforts began.

The firm also maintains active recruiting programs for minorities, diverse ethnic backgrounds and potential aging
work force employees-all efforts to make the company stronger by way of diversity.

"Americas International is a great place to work because it has the best people in the industry," Stair said. "The
people at the company are not only experts in their field, well-known and respected throughout the rubber industry,
but they are a pleasure for our suppliers and customers to work with. Having only the highest quality staff allows
Americas International to continuously expand the products and suppliers available to our customers and to
continuously expand the customers and market base for our suppliers.

"Americas International understands that people are the heart of the business and treats them accordingly."

Leadership and outreach

"Surround yourself with good people."

Stair said he took this advice from Gen. Joseph Dunford, commander of NATO coalition forces in Afghanistan, who
once was asked about his three keys to success. After stating the first, Dunford reportedly said "he forgot the other
two."

Such is the importance of a good team.

The moment they come through the door, AI employees are issued the company constitution, the tenets and morals
by which they are expected to conduct themselves.

                                                                                                       Page 3 of 4
                     'Doing the right thing' Americas International tops Best Places to Work list

They include such virtues as integrity and honesty-doing the right thing-reliability, communication, respect and
cooperation. Employees are expected to be detail-oriented and efficient with a sense of environmental
responsibility.

And they are urged through various avenues to maintain a work-life balance.

"I'm really proud of this," Stair said. "We start off everyone with company culture, part of our corporate documents.
The No. 1 thing is to do the right thing!"

On the professional side, AI offers continuing education programs and leadership workshops for its employees, and
these offerings are counterbalanced by golf outings, corporate cookouts, holiday celebrations and the popular
Halloween party, complete with a costume contest.

The firm also looks outside its company walls and into the Akron community with programs like SAYM, the South
Akron Youth Mentorship.

"This is one I am real proud of, as it reaches out to inner city youths," Stair said. "It is a mentorship program
whereby these youngsters are mentored as to basically the difference between what's happening in the inner city
and what is happening outside of inner city."

Through SAYM, AI employees are able to mentor youths through high school and secondary education, helping
them to understand that opportunities are available to all cultural backgrounds.

"It is really an ongoing process to try to change patterns," said Stair, a graduate of Penn State University and the
University of Akron's polymer science program. "I know one great young kid who attended UA and works at
Firestone now. It is really a great program."

In general, Stair said the company has been successful in identifying and hiring associates who typically have
extensive backgrounds in the tire and rubber industries, and many of its associates-including the boss-have worked
for well-known companies, including Goodyear, DuPont, Lanxess and Flexsys America L.P.

"We have an outstanding group of experienced and dedicated associates to whom the growth and success of the
company is directly related," Stair said. "And we have had a good history of success, with good relationships with
suppliers and customers. We have a harmonious relationship with people and there is very little confrontation.

"This makes day-to-day operations rewarding."

AI saw its period of greatest growth coming out of the Great Recession, from about 2010-12, when it won the
Cascade Business Award for three consecutive years with the highest sales increase over a five-year period for any
company in Summit County.

"We were well-poised to expand sales coming out of the recession and hope to perform well coming out of the
current pandemic," Stair said.

Taking on the pandemic together

Setting immediate policies early in the pandemic for its Akron offices and numerous warehouses may have been
key to protecting workers and maintaining some semblance of workflow and production, as production "was way off
in June and July," Stair said.

AI did have to furlough two people, though the company is looking to rehire staff in early 2021 as business looks to
be increasing once again, especially in the automotive segment. All other employee salaries have remained at
normal levels throughout the health crisis, according to AI.

Most important has been the safety of AI workers.

                                                                                                             Page 4 of 4
                      'Doing the right thing' Americas International tops Best Places to Work list

"We have had a tremendous success record. I don't think anyone has even had a cold. Most people are working at
home, though key people who are coming into the office are very separated," Stair said.

All employees were given the option of working from home, though once they made their choice of home or office,
they were asked to be consistent. And like the edicts from many companies, all travel was banned for the safety of
employees.

"The no-travel thing-that really changes the lifestyle of the sales force and support groups who would normally be
traveling to meet with vendors and visit warehouses," Stair said. "Every case was different with what they chose.
One young lady was expecting, so the safest thing for her to do was to stay home."

Stair said it remains unclear which policies will become lasting rules, "since we are still in the midst of the
pandemic."

In regards to the spectrum of industries and applications served by AI, industrial products, the adhesives market,
and military and defense (for boots, respirators and gas masks) have remained strong, while automotive has been
hit hard.

Conversely, AI has seen an enormous uptick in sporting goods and outdoor recreation, and more recently
automotive has begun to rebound.

"When I went shopping at Walmart recently I was looking for some sporting goods items-and every shelf was
cleaned off," Stair said. "It was like the toilet paper aisle. There literally was nothing left in sporting goods. This is a
sign of the times, I guess."

AI is considered an essential company, supplying its polymers and additives to the medical segment, "a small
portion of the company, but an important portion."

While the Akron company did not shift gears in its product supply specifically because of the pandemic, it did
continue to keep stock on hand to supply other essential downstream companies with necessary raw materials for
ventilators, gloves and other personal protection equipment.

"I believe what happened is our customers were the ones who switched gears, and we gave them the materials to
make their products," Stair said. "For me the biggest success is we were able to maintain with a majority of our
associates, even with two furloughed, keeping everyone employed and safe.

"If our employees can get through the pandemic and not have to face real hardship, that is what is most important.
There is such a vast group of people who are devastated right now. I can't imagine going through this unemployed,
sitting at home, depressed and wondering what to do. We have tried to keep morale up so our team does not have
to worry about the impact of what is going on."

As evidenced by their top spot on the Best Places to Work list, AI and its employees can consider that attempt as
"mission accomplished" during perhaps the most challenging year they have ever experienced.


Load-Date: December 3, 2020


  End of Document

                                                                                                       Page 1 of 3
    Leidos and Clarify Health Announce Strategic Alliance to Deliver Innovative Analytics Solutions to Healthcare
                                                      Partners




 Leidos and Clarify Health Announce Strategic Alliance to Deliver Innovative
                 Analytics Solutions to Healthcare Partners
                                            The Breeze: James Madison University
                                                      January 13, 2020 Monday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 727 words

Body

RESTON, Va., Jan. 13, 2020 /PRNewswire/ -- Leidos (NYSE:LDOS), a FORTUNE® 500 science and technology
leader, today announced a strategic alliance with Clarify Health Solutions, a leader in advanced healthcare
analytics, that will facilitate improved healthcare operations and impact through world-class and governance-based
digital solutions. Under the agreement, Leidos will enable its customers to deliver Clarify-generated observed and
predictive insights directly into healthcare operations through its careC2 platform.

"Both our companies share a mission to improve health and access to high value healthcare," said Todd Gottula,
co-founder and chief product officer of Clarify Health. "We are excited to collaborate with Leidos to create
innovative and unprecedented offerings in advanced predictive analytics for our partners that ultimately improve
value and increase performance transparency in healthcare."

Clarify Health Solutions has accumulated one of the largest patient-level datasets in healthcare which it uses to
generate observed and predictive insights by a world-class team of data scientists, engineers, clinicians, and
healthcare experts. Clarify Health's products and insights are leveraged by industry leaders across health systems,
health plans, and life sciences companies to improve the value of care delivered as well as therapies offered
patients.

Leidos' careC2 platform enables its customers to improve their clinical, financial and operational results by
providing a single, secure, real-time view of operations across their healthcare ecosystem in order to efficiently
deliver the right services to the right patient at the right point in their health journey. CareC2 provides users with the
tools to design, build and commercialize their own applications to close capability gaps where they may exist and
diversify revenue. Delivering Clarify Health Solutions predictive insights through the Leidos careC2 applications
provides Leidos with a differentiated solution in the market, combining the power of the careC2 data services,
security, compliance, and governance capabilities with Clarify's analytics capabilities.

"We are thrilled to team up with Clarify Health to propel healthcare analytics forward," said Jon Scholl, Leidos
Health Group president."The insights gained through our combined expertise will create new visibility for our
healthcare partners and improve care for millions of patients."

                                                                                                      Page 2 of 3
   Leidos and Clarify Health Announce Strategic Alliance to Deliver Innovative Analytics Solutions to Healthcare
                                                     Partners

With a joint focus on the delivery of better care through technology that can most effectively distill fractured,
disparate health data into actionable insights, Clarify Health and Leidos will co-develop a roadmap to address their
current and new customers' unmet needs.

About Clarify Health Solutions

Clarify Health's enterprise analytics platform empowers stakeholders across the healthcare industry, including
providers, payers, and life sciences companies, to deliver better care to patients through actionable insights. With
industry-leading statistical modeling, machine learning, and AI, Clarify Health harnesses the power of the most
comprehensive longitudinal dataset in the US by linking clinical, claims, prescription, lab, and social determinant of
health data across 250 million+ lives. For more information, visit www.clarifyhealth.com.

Contact:           Nishta Giallorenzo nishta@clarifyhealth.com

About Leidos

Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working
to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets.
The company's 34,000 employees support vital missions for government and commercial customers.
Headquartered in Reston, Va., Leidos reported annual revenues of approximately $10.19 billion for the fiscal year
ended December 28, 2018. For more information, visit www.leidos.com.

Contact:     Melissa Koskovich                                                                            (571) 526-
6011 Koskovichm@Leidos.com

Suzzanna Martinez (303) 299-5343 suzzanna.m.martinez@leidos.com

This article originally ran on curated.tncontentexchange.com.
    •      Facebook
    •      Twitter
    •      WhatsApp
    •      SMS
    •      Email
    •      Print
    •      Save

Tags
    •      Clarify Health Solutions
    •      Commerce
    •      Economics
    •      Insight
    •      Health
    •      Patient
    •      Revenue
    •      Todd Gottula

TownNews.com Content Exchange

                                                                                                      Page 3 of 3
   Leidos and Clarify Health Announce Strategic Alliance to Deliver Innovative Analytics Solutions to Healthcare
                                                     Partners


Load-Date: January 14, 2020


  End of Document

                                                                                                       Page 1 of 3
    Leidos and Clarify Health Announce Strategic Alliance to Deliver Innovative Analytics Solutions to Healthcare
                                                      Partners




 Leidos and Clarify Health Announce Strategic Alliance to Deliver Innovative
                 Analytics Solutions to Healthcare Partners
                                            The Breeze: James Madison University
                                                      January 13, 2020 Monday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 714 words

Body

RESTON, Va., Jan. 13, 2020 /PRNewswire/ -- Leidos (NYSE:LDOS), a FORTUNE® 500 science and technology
leader, today announced a strategic alliance with Clarify Health Solutions, a leader in advanced healthcare
analytics, that will facilitate improved healthcare operations and impact through world-class and governance-based
digital solutions. Under the agreement, Leidos will enable its customers to deliver Clarify-generated observed and
predictive insights directly into healthcare operations through its careC2 platform.

"Both our companies share a mission to improve health and access to high value healthcare," said Todd Gottula,
co-founder and chief product officer of Clarify Health. "We are excited to collaborate with Leidos to create
innovative and unprecedented offerings in advanced predictive analytics for our partners that ultimately improve
value and increase performance transparency in healthcare."

Clarify Health Solutions has accumulated one of the largest patient-level datasets in healthcare which it uses to
generate observed and predictive insights by a world-class team of data scientists, engineers, clinicians, and
healthcare experts. Clarify Health's products and insights are leveraged by industry leaders across health systems,
health plans, and life sciences companies to improve the value of care delivered as well as therapies offered
patients.

Leidos' careC2 platform enables its customers to improve their clinical, financial and operational results by
providing a single, secure, real-time view of operations across their healthcare ecosystem in order to efficiently
deliver the right services to the right patient at the right point in their health journey. CareC2 provides users with the
tools to design, build and commercialize their own applications to close capability gaps where they may exist and
diversify revenue. Delivering Clarify Health Solutions predictive insights through the Leidos careC2 applications
provides Leidos with a differentiated solution in the market, combining the power of the careC2 data services,
security, compliance, and governance capabilities with Clarify's analytics capabilities.

"We are thrilled to team up with Clarify Health to propel healthcare analytics forward," said Jon Scholl, Leidos
Health Group president."The insights gained through our combined expertise will create new visibility for our
healthcare partners and improve care for millions of patients."

                                                                                                      Page 2 of 3
   Leidos and Clarify Health Announce Strategic Alliance to Deliver Innovative Analytics Solutions to Healthcare
                                                     Partners

With a joint focus on the delivery of better care through technology that can most effectively distill fractured,
disparate health data into actionable insights, Clarify Health and Leidos will co-develop a roadmap to address their
current and new customers' unmet needs.

About Clarify Health Solutions

Clarify Health's enterprise analytics platform empowers stakeholders across the healthcare industry, including
providers, payers, and life sciences companies, to deliver better care to patients through actionable insights. With
industry-leading statistical modeling, machine learning, and AI, Clarify Health harnesses the power of the most
comprehensive longitudinal dataset in the US by linking clinical, claims, prescription, lab, and social determinant of
health data across 250 million+ lives. For more information, visit www.clarifyhealth.com.

Contact:           Nishta Giallorenzo nishta@clarifyhealth.com

About Leidos

Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working
to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets.
The company's 34,000 employees support vital missions for government and commercial customers.
Headquartered in Reston, Va., Leidos reported annual revenues of approximately $10.19 billion for the fiscal year
ended December 28, 2018. For more information, visit www.leidos.com.

Contact:     Melissa Koskovich                                                                            (571) 526-
6011 Koskovichm@Leidos.com

Suzzanna Martinez (303) 299-5343 suzzanna.m.martinez@leidos.com
    •      Facebook
    •      Twitter
    •      WhatsApp
    •      SMS
    •      Email
    •      Print
    •      Save

Tags
    •      Prnewswire
    •      Clarify Health Solutions
    •      Commerce
    •      Economics
    •      Insight
    •      Health
    •      Patient
    •      Revenue
    •      Todd Gottula

                                                                                                      Page 3 of 3
   Leidos and Clarify Health Announce Strategic Alliance to Deliver Innovative Analytics Solutions to Healthcare
                                                     Partners


Load-Date: January 14, 2020


  End of Document

                                                                                                       Page 1 of 2
                               School Safety Index Predicts K-12 COVID Policy Effectiveness




             School Safety Index Predicts K-12 COVID Policy Effectiveness
                                                Government TechNology
                                                October 11, 2021 Monday



Copyright 2021 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 620 words
Byline: Brandon Paykamian, Government Technology

Body


Oct. 11—As schools seek to mitigate the risks of in-person learning in the face of the COVID-19 delta variant,
officials are turning to digital resources for advice. To help, the health technology firm HSR.health built an online
data tool to predict the effectiveness of school health policies, down to each building and classroom.

According to a news release, the Maryland-based company recently developed its School Safety Index to inform
administrators about best practices depending on specific school conditions. It also created a COVID-19
Transmission Risk Index to predict future outbreaks, and a Mortality Risk Index to identify geographical areas with
the highest risk of deaths.

HSR.health CEO Ajay Gupta said the aim of the company was to provide schools with online guidance for safety
policies after nearly two years of shifting to and from virtual learning.

"Research has shown that more than half of the student population nationwide have lacked the motivation and
engagement to successfully learn in a remote setting," he said in a statement. "Our goal for the School Safety Index
is to provide administrators with the accurate data insights they need to make well-informed decisions and safely
return both students and teachers to the classroom."

Gupta told Government Technology the platform asks administrators to describe their schools, local conditions, and
the layouts of each building and classroom in order to gauge the risk of spread. The platform is part of a suite of
health risk data tools offered by the company.

"We got our start by analyzing social determinants of health data down to specific locations, as they impact the
health outcomes and the cost for individuals, patients and populations in those locations," he said. "When COVID-
19 broke out, we developed a number of AI models and public health models to track the spread of the disease so
we could identify where the disease is going, how it's spreading and who is at risk of becoming sick from the
disease."

                                                                                                    Page 2 of 2
                          School Safety Index Predicts K-12 COVID Policy Effectiveness

According to Gupta, school and public health officials can use the platform to determine whether a classroom could
use plexiglass barriers or whether a school should shift to remote or hybrid learning, among other mitigation
strategies.

"Based on our understanding of the social determinants of health in that region, the COVID case counts and other
health outcomes of that region, we can assess the risk of disease transmission in the school, but with no COVID
mitigation put in place," he said. "Then we can assess the value of any mitigation, whether they're masks, social
distancing or reducing class sizes, or any changes that may take place."

Even though millions of students were vaccinated before returning to school this year, Gupta said the virus could
remain a threat to K-12 districts in the years to come as an endemic — a regularly occurring disease in the
population. Gupta said it's important for schools to look to data to mitigate the spread of other common school
illnesses such as the flu, to say nothing of future pandemics.

The index is among several similar data platforms available to schools online, including a COVID-19 K-12 School
Testing Impact Estimator developed by the data analytics company Mathematica, which measures the
effectiveness of school COVID-19 testing policies.

"What we need to do is start looking at how, in our everyday lives, we can operate schools," he said. "We have the
opportunity to adjust infrastructure to reduce the risk of disease transmission to not only address the current
pandemic, but maybe on a permanent basis reduce the spread of seasonal flu."

___ (c)2021 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: October 12, 2021


  End of Document

                                                                                                          Page 1 of 2
                  Meet the new vice dean and executive director of the Duke Clinical Research Institute




Meet the new vice dean and executive director of the Duke Clinical Research
                                Institute
                                             The Duke Chronicle: Duke University
                                                      June 3, 2020 Wednesday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 494 words

Body


After a national search, the Duke University School of Medicine named Adrian Hernandez vice dean and executive
director of the Duke Clinical Research Institute last month.

In the new position, Hernandez oversees DCRI's research and teaching agenda, ensuring the Institute sustains a
broad spectrum of clinical research programs and trials. Meanwhile, he continues to serve as vice dean for clinical
research, a role that the cardiologist has held since 2017, according to a news release announcing his selection for
the DCRI role.

"When we reimagine healthcare delivery or research, you need to have the leverage to make it sustainable. It's
really through people, partnerships and platforms that I see DCRI evolving as I go forward," Hernandez said. "We
have an exciting group of these things at Duke that can change the status quo and make it better for everyone."

Even though Hernandez has stepped back from some elements of his role as vice dean, he has continued to direct
the Duke Institute for Health Innovations and will partake in the Medical School's leadership team for data science
and AI Health, the press release states.

In response to COVID-19, Hernandez initiated the Healthcare Worker Exposure Responses and Outcomes
Registry, which invites healthcare workers to answer questions about the impact of coronavirus on their lives and
participate in rapid-cycle research projects. One effort focuses on the effectiveness of hydroxychloroquine in
preventing coronavirus infections in healthcare workers, according to a DCRI news release.

The $50 million study is funded by the Patient-Centered Outcomes Research Institute.

"Healthcare workers treat and protect all of us from COVID-19. With the HERO Registry, we aim to develop better
measures to protect and support them," said Hernandez, who is principal investigator of the program, in the DCRI
press release.

Hernandez first joined DCRI in 2002 as a cardiology fellow. Before serving as vice dean, he was a faculty associate
director of Duke clinical research and director of health services and outcomes research at the DCRI. He became a
Duke assistant professor in 2004.

                                                                                                       Page 2 of 2
               Meet the new vice dean and executive director of the Duke Clinical Research Institute

The new executive director earned his medical degree at the University of Texas-Southwestern and completed his
residency in internal residency at the University of California-San Francisco School of Medicine, according to the
School of Medicine.

"Right now, COVID-19 has really disrupted healthcare and research as we know it, allowing us to reimagine not
only healthcare delivery that people talked about for years but also the importance of data science in understanding
biology," Hernandez said. "There are a number of different ways for undergraduates to get involved with medicine
whether that be understanding the biology, developing diagnostics, studying policy, developing therapeutics, and
learning what's critical."

Get The Chronicle straight to your inbox

Signup for our editorially curated, weekly newsletter. Cancel at any time.


Load-Date: June 3, 2020


  End of Document

                                                                                                       Page 1 of 2
                       PhysIQ Elects Former Vice Admiral Raquel C. Bono, M.D. to Advisory Board




PhysIQ Elects Former Vice Admiral Raquel C. Bono, M.D. to Advisory Board
                                                 Chicago Daily Herald
                                             January 6, 2021 Wednesday
                                              WEB EditioneBlast Edition



Copyright 2021 Paddock Publications, Inc.

Section: SUBMITTED CONTENT; Pg. 0
Length: 675 words
Byline: Staci Rubinstein

Body


physIQ announced that Raquel C. Bono, M.D., a board-certified trauma surgeon and retired Vice Admiral of the
United States Navy Medical Corps, has been selected as a member of the companyâ€™s Advisory Board. Dr.
Bono retired from the Navy in 2019 as Chief Executive Officer and Director for the Health Agency. Most recently,
she led Washington State's medical and healthcare systems response to the COVID-19 pandemic. Throughout her
career, Dr. Bono has led the charge for disruptive change in the delivery of healthcare services. "Dr. Bono brings an
impressive background consisting of distinguished military service, trauma surgery, and health care
administration,â€ said Gary Conkright, physIQâ€™s CEO and co-founder.

"She brings valuable knowledge and perspective for how healthcare delivery can leverage technology to improve
outcomes and best leverage the healthcare assets for efficient deployment, and we are honored that she sees such
promise in the role physIQ is playing to make that happen. We all believe that physIQ was a logical next step in Dr.
Bonoâ€™s pursuit of healthcare excellence and we welcome her to the physIQ TEAM.â€ Commissioned in June
1979, Dr. Bono obtained her bachelorâ€™s degree from the University of Texas at Austin and MD from the School
of Medicine at the Texas Tech University Health Sciences Center. She completed a surgical internship and a
General Surgery residency at Naval Medical Center Portsmouth, and a Trauma and Critical Care fellowship at the
Eastern Virginia Graduate School of Medicine in Norfolk, Virginia. She saw duty in Operations Desert Shield and
Desert Storm and is the first female Navy medical officer to have achieved three-star rank. In addition, she is a
Diplomate of the American Board of Surgery, also a Fellow of the American College of Surgeons and a member of
the Eastern Association for the Surgery of Trauma. Her personal decorations include a Defense Superior Service
Medal, three Legion of Merit Medals, two Meritorious Service Medals, and two Navy and Marine Corps
Commendation Medals. â€œHealthcare is undergoing a needed and dramatic change, accelerated by the COVID-
19 pandemic, which illustrates how digital health and innovative technology, like physIQâ€™s, can improve
outcomes more efficiently,â€ said Dr. Bono. â€œI am impressed with the role physIQ is playing to address the
current pandemic and excited that my experience and skills will help physIQâ€™s mission to transform healthcare
for all.â€ This announcement builds on a big year for physIQ. Kicking off 2020, they announced the publication of
their breakthrough LINK-HF study, which was published in Circulation â€" Heart Failure. This study, conducted with
the U.S. Veteranâ€™s Affairs, predicted Heart Failure hospitalization up to 10 days in advance. Following this,
physIQ announced projects with the Department of Defense and the Henry M. Jackson Foundation for The

                                                                                                        Page 2 of 2
                     PhysIQ Elects Former Vice Admiral Raquel C. Bono, M.D. to Advisory Board

Advancement of Military Medicine, as well as UI Health and the Chicago Medical Society to fight the COVID-19
pandemic. And most recently, physIQ was awarded a grant from the National Institutes of Health to develop an AI-
based COVID-19 digital biomarker to address the rapid decline of high-risk COVID-19 patients. #### About physIQ
PhysIQ is a leading digital medicine company dedicated to generating unprecedented health insight using
continuous wearable biosensor data and advanced analytics. Its enterprise-ready cloud platform continuously
collects and processes data from any wearable biosensor using a deep portfolio of FDA-cleared analytics. The
company has published one of the most rigorous clinical studies to date in digital medicine and are pioneers in
developing, validating, and achieving regulatory approval of Artificial Intelligence-based analytics. With applications
in both healthcare and clinical trial support, physIQ is transforming continuous physiological data into insight for
health systems, payers, and pharmaceutical companies. For more information, please visit www.physIQ.com.
Follow us on Twitter and LinkedIn.



Graphic


Dr. Raquel C. Bono


Load-Date: January 6, 2021


  End of Document

                                                                                                      Page 1 of 2
                                            4 retirement trends for the coming decade




                               4 retirement trends for the coming decade
                                                       Daily News (New York)
                                                      December 5, 2021 Sunday
                                                           1STAR Edition



Copyright 2021 Daily News, L.P. All Rights Reserved

Section: MAIN; CS; Pg. 38
Length: 553 words
Byline: Catherine Siskos Kiplinger's Personal Finance

Body


The era of trading a long career for a pension and afternoons on the golf course ended long ago. In its place,
today's retirees face growing financial pressure from multiple directions.

Here are four forces shaping retirement in the 2020s:

Flexible work. The pandemic set up less traditional work and more remote work, and that's good for seniors, says
Allison Schrager, senior fellow at the Manhattan Institute. Many may prefer to work part time or switch to a less
stressful full-time job. Members of Generation X, who start turning 60 in 2025 and are known for being
entrepreneurial, may be especially well positioned to work as consultants and set their own hours.

Evolving entitlement programs. Social Security is expected to run short of money in 2033 and Medicare as early as
2026. To fix the shortfalls, Congress can raise revenue, cut benefits or both. Politicians, though, are unlikely to
slash benefits.

That doesn't mean the fixes will be painless. One solution, according to the Center for Retirement Research, is to
raise payroll taxes 1.6% for employees and employers alike, which would fund Social Security for the next 75 years.

As for Medicare, the growing popularity of Advantage plans means millions of seniors are choosing private insurers
each year. The trend toward privatization, though, hasn't been as good for beneficiaries or Medicare's bottom line.

Unlike traditional Medicare, which lets patients see any doctor they want, Advantage plans are managed care with
restrictive provider networks and lower premiums. Several studies, however, have shown that sicker enrollees are
far more likely to switch to traditional Medicare, raising questions about the quality of care from Advantage plans.
Medicare Advantage also costs the government more.

Any discussion about fixing Medicare must address those inefficiencies and the quality of care before expanding
the program, says David Lipschutz, associate director of the Center for Medicare Advocacy.

                                                                                                        Page 2 of 2
                                     4 retirement trends for the coming decade

A tech revolution in care. Adding to Medicare's burden is the looming shortage of medical professionals. The
Association of American Medical Colleges projects a shortfall of up to 139,000 doctors in the U.S. by 2033. The
health care industry hopes technology can help fill the void.

Artificial intelligence can potentially improve health care. With AI's data analysis, doctors and hospitals can detect
and diagnose illnesses more accurately, customize treatments and track patient outcomes closely.

Climate disruption. The signs of climate change - wildfires, droughts, hurricanes and floods - are all around us, but
many older Americans contemplating where to retire don't take it into account.

Tom Nowak, a certified financial planner in Langley, Washington, says they should because many retiree locations
in the South and West are in the crosshairs of global warming. If grocery prices soared from recent disruptions to
the food supply, just imagine what prices will be like when water emergencies are declared in the bread and fruit
baskets of America, Nowak says.

The single biggest worry for retirees is the loss of home value, says David Stookey, author of "Climate-Proof Your
Personal Finances." That loss can come suddenly after a drought, flood or fire devastates a community.

Catherine Siskos is managing editor at Kiplinger's Retirement Report.


Load-Date: December 5, 2021


  End of Document

                                                                                                     Page 1 of 4
                                      UC Berkeley community talks artificial intelligence




                       UC Berkeley community talks artificial intelligence
                                     Daily Californian: University of California - Berkeley
                                                      May 20, 2021 Thursday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1669 words

Body


Facial recognition, search engines, social media algorithms, ad recommendations and robots are rooted in a
technology that is present in nearly all aspects of daily life: artificial intelligence.

AI refers to the idea that humans can train computers to be "rational agents" that have preferences and make
informed decisions, according to Sergey Levine, a UC Berkeley assistant professor in the electrical engineering and
computer sciences department. AI systems aim to optimize a particular outcome that they have been instructed to
prefer.

The term artificial intelligence dates back to the 1950s when psychologists studied the human brain and explored
how machines could simulate human intelligence, according to Levine. The basic concepts of AI are much older,
Levine noted, referencing the writings of mathematician Alan Turing, who suggested that computers be
programmed to act like children rather than adults.

"If your preferences about outcomes in the world can be put into an ordering and assigned numerical values, then
you are rational," Levine said. "From that basic idea, we can derive methods and computer algorithms that allow us
to actually construct artificial agents that behave in rational ways."

How do computers learn behavior?

AI systems are designed to optimize a particular utility, according to campus senior Albert Yu, head TA for
Computer Science 188, "Introduction to Artificial Intelligence."

YouTube recommendations, for example, use AI to maximize the amount of time a user spends on the platform,
which in turn increases profits, according to Yu. Other popular applications of AI in society today include search
engines, which optimize for the most relevant web pages based on a given search query; self-driving cars, which
are optimized to reach a destination safely and quickly and advertisements, which aim to maximize revenue.

AI systems are most commonly taught to perform these and other functions through a mechanism known as
supervised learning, Levine said. This technique consists of providing a computer with examples of data that are
classified as a particular category.

                                                                                                        Page 2 of 4
                                 UC Berkeley community talks artificial intelligence

AI is useful because it can perform these tedious computations over a large amount of data and quickly learn to
recognize and classify objects in images, Yu added.

"(AI is) able to process a ton of data in ways and at speeds that humans can't necessarily process," Yu said. "As
long as we have internet access to all of the data and pictures and language in the world, it does have the potential
of being more accurate than humans in some very specific tasks."

Nikita Samarin, a GSI for CS 188, demonstrated the process using an example of an algorithm with the goal is to
distinguish between apples and oranges. Instead of informing a machine about the differences between the fruits,
the machine is shown several images of apples and several images of oranges, Samarin said. Over time, the
system learns to differentiate between the two fruits at a high level of accuracy.

Beyond teaching the systems, AI also entails studying what tools machines require to be capable of learning and
having intelligence, Samarin added.

Levine said his lab - the Robotics AI and Learning Lab - studies another type of AI learning mechanism known as
reinforcement learning. Instead of telling a machine exactly what to do, reinforcement learning involves providing
feedback on whether the machine is doing something good or bad.

This type of learning is particularly helpful when considering applications of robots in the real world where it can be
difficult to provide exact instructions on how a robot should accomplish a task such as navigating a forest, Levine
noted. Reinforcement learning informs the robot on whether it performs well or poorly, and the robot adjusts its
behavior accordingly.

"A very effective way to use AI is to handle those aspects of decision-making that we're not so great at and provide
support for human decision-making," Levine said. "Longer term, there is a lot of promise in AI systems that do
interact with the physical world in meaningful ways."

Fairness and transparency: Ethical considerations of AI

While effective, AI presents pressing ethical concerns that call for regulation and governance of the technology.

According to Samarin, AI machines are trained by the data they are given, which are inherently biased. Oftentimes,
these systems will indirectly reflect the bias present in the data.

There have been "disturbing" instances where AI use has yielded discriminatory outcomes, Samarin noted,
including when it was used in hiring processes and when it was used to determine whether someone should be
released from bail.

Brandie Nonnecke, director of the Center for Information Technology Research in the Interest of Society and the
Banatao Institute, said AI technologies should be developed with principles of fairness, accountability and
transparency. She added that AI-enabled tools should be transparent in terms of the data used, how the model was
built and any assumptions that were made.

Nonnecke is also co-chair of the UC system's Presidential Working Group on Artificial Intelligence, which aims to
develop a set of ethical principles to guide the university in its use of AI. The working group focuses on four main
applications of AI: health, human resources, law enforcement and student experience.

"Over the past few years, it's become apparent that AI-enabled systems can have harmful effects on society -
especially, the revelations we've found that AI models can perpetuate bias and discrimination," Nonnecke said. "In
light of these findings, there has been great effort to develop appropriate governance mechanisms for AI."

Yu described a malicious application of AI known as generative adversarial networks, a form of AI that can not only
generate realistic images of fake people but also be used to make videos of a person saying something very
different from what they actually said.

                                                                                                        Page 3 of 4
                                   UC Berkeley community talks artificial intelligence

This has particularly dangerous implications in the world of politics. The possibility for AI to generate a "deepfake"
of a public figure such as a president saying something they did not actually say is "very concerning," Yu said.

He added that AI also poses a problem when its objectives do not align with those held by the user. An AI that aims
to increase users' watch time on a web page, for example, may not align with a person's objective to balance work
and relaxation.

"Right now, researchers can't explain the decision-making algorithms," Samarin said. "The direction of trying to
understand how to make the systems more transparent, more accountable and fairer is very important, and we
should really think about that as we go forward."

Current and future impacts of AI

AI's impact on society today has both positive and negative consequences for the world tomorrow.

Mesut Yang, a GSI for CS 188, described AI's impact in the vast field of social media. Yang explained that AI
algorithms aim to learn the behavior and opinions of individual users to continue recommending content that they
know the users will enjoy. This often drives individuals down a "rabbit hole" to increase user engagement.

Yang noted that this has dangerous ramifications in regard to extremism. When users go on social media,
algorithms will feed them content that confirms their beliefs; one example is the role Facebook played in supporting
Myanmar's ethnic cleansing campaign.

"One of the issues with a lot of current AI systems is that they are not grounded in the same physical experience as
we are and therefore they understand the world differently than we do," Levine said. "And that's the reason why
these systems behave in a way that is counterintuitive to us."

There are, nonetheless, several positive impacts of AI, and a lot of university research is being done to discover
even more practical applications.

Nonnecke described how California's Employment Development Department, or EDD, had a backlog of
approximately 1.6 million unemployment claims in October 2020, as many people applied for unemployment
benefits during the COVID-19 pandemic.

She said the main reason for this backlog was that the application process required an employee to manually verify
an individual's identity. To increase efficiency, EDD developed an automated process to verify unemployment by
using a branch of AI known as computer vision.

Computer vision bridges AI and the visual world and it allows AI agents to interpret and classify images, Yang said.

Angjoo Kanazawa, a campus assistant professor in electrical engineering and computer sciences, specializes in
computer vision research with a focus on modeling the 3D world. To illustrate computer vision's potential, she said
AI systems can recover 3D features of someone's face simply from an image.

Her research extends to 3D motion capture, which can be useful for medical diagnosis and rehabilitation.

"My goal is to really take a single image or video and understand what's happening in the 3D world," Kanazawa
said. "Ideally, this is getting close to what it means to perceive an image."

Another important aspect of university research is natural language processing, Yu said, which relates to
interpreting human language. Google Translate is an example of natural language processing.

Yang is currently conducting research in the field of robotics, specifically to improve human-robot interactions. His
research aims to identify how to train AI agents to understand human behavior and commands.

                                                                                                        Page 4 of 4
                                 UC Berkeley community talks artificial intelligence

With all its potential for greatness yet possible manipulation, society's knowledge about the impacts of AI remains
limited, according to Yang. He said more work should be done to increase the public's knowledge about AI,
unlocking future opportunities.

"Improving the general public's literacy about artificial intelligence is really important," Yang said. "After most of
society is up to date on what AI is and what its strengths and flaws are when we are all standing on this common
knowledge as a society, we're able to move forward a lot better and a lot faster."


Load-Date: May 20, 2021


  End of Document

                                                                                                    Page 1 of 2
                Great American Smokeout aims to reduce smoking rates, increase lung cancer screenings




     Great American Smokeout aims to reduce smoking rates, increase lung
                            cancer screenings
                                                        The Bakersfield Californian
                                                      November 16, 2023 Thursday



Copyright 2023 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 556 words
Byline: Steven Mayer, The Bakersfield Californian

Body


Nov. 16—There's a lot of encouraging news these days in the study and treatment of lung cancer.

More lung cancer patients, for example, are living longer following their initial diagnosis. And the prevalence of
cigarette smoking in adults in the U.S. declined from 14 percent in 2019 to 12 percent in 2021.

That translates to an estimated 5.7 million fewer adults who smoke, according to an American Cancer Society study
released earlier this year.

But there's bad news, too.

The cancer society joined with Kern County Public Health, Blue Zones Project Bakersfield, and Adventist Health to
hold a joint news conference Thursday morning to kick off the Great American Smoke Out of Kern County — and to
emphasize the importance of early lung cancer screening aimed at reducing cancer deaths.

"Thank you for joining us this morning as we raise awareness around smoking cessation on this day, the Great
American Smokeout," Jasmine Ochoa, health equity officer at the Kern County Department of Public Health, said
at a gathering in front of the AIS Cancer Center.

"According to the 2022 results of the California Health Interview Survey, 33.1 percent of Kern County adult
residents who have ever smoked, reported that they smoke every day," Ochoa said.

That's more than twice the rate in the state as a whole, she said.

Ochoa invited everyone to visit kernpublichealth.com or ask to speak with the agency's Tobacco Prevention
Program by calling 661-321-3000.

Karina Funez, policy advocate at Blue Zones Project Bakersfield, said commercial tobacco companies have a long
history of targeting vulnerable populations.

                                                                                                 Page 2 of 2
             Great American Smokeout aims to reduce smoking rates, increase lung cancer screenings

"Unfortunately, that has created inequity among our communities, which has disproportionately affected the health
of youth and people of color," Funez said. "However, we know that through policy and education, we can create
change that helps us decrease commercial tobacco use and prevent the next generation of tobacco users."

This month, the cancer society released updated screening recommendations, which should allow more people to
receive low-dose CT lung cancer screenings, said Raymond Andreas, lung oncology nurse navigator at the AIS
Cancer Center in Bakersfield.

"Lung cancer, if you can diagnose it in stage 1 or 2, it's curable," Andreas said. "You can get surgery and move on
with life.

"The problem is," he said, "people wait until stage 3 or 4."

Early detection is the key.

"I'm really excited to share with you that Adventist Health and AIS Cancer Center are opening up Kern County's
first lung screening program."

According to Andreas, Medicare and most private insurances cover the screenings, so there's little to no out-of-
pocket expense for those who are between 50 and 80 years of age and are currently smokers or are former
smokers.

"According to the American Lung Association," he said, "close to 237,000 people in the U.S. will be diagnosed with
lung cancer this year.

"The 2022 State of Lung Cancer report shows that only 5.8 percent of eligible Americans have been screened for
lung cancer, and some states have screening rates as low as 1 percent ..." including California, he said.

Reporter Steven Mayer can be reached at 661-395-7353.

___ (c)2023 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: November 19, 2023


  End of Document

                                                                                                    Page 1 of 2
                Great American Smokeout aims to reduce smoking rates, increase lung cancer screenings




     Great American Smokeout aims to reduce smoking rates, increase lung
                            cancer screenings
                                                        The Bakersfield Californian
                                                      November 16, 2023 Thursday



Copyright 2023 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 556 words
Byline: Steven Mayer, The Bakersfield Californian

Body


Nov. 16—There's a lot of encouraging news these days in the study and treatment of lung cancer.

More lung cancer patients, for example, are living longer following their initial diagnosis. And the prevalence of
cigarette smoking in adults in the U.S. declined from 14 percent in 2019 to 12 percent in 2021.

That translates to an estimated 5.7 million fewer adults who smoke, according to an American Cancer Society study
released earlier this year.

But there's bad news, too.

The cancer society joined with Kern County Public Health, Blue Zones Project Bakersfield, and Adventist Health to
hold a joint news conference Thursday morning to kick off the Great American Smoke Out of Kern County — and to
emphasize the importance of early lung cancer screening aimed at reducing cancer deaths.

"Thank you for joining us this morning as we raise awareness around smoking cessation on this day, the Great
American Smokeout," Jasmine Ochoa, health equity officer at the Kern County Department of Public Health, said
at a gathering in front of the AIS Cancer Center.

"According to the 2022 results of the California Health Interview Survey, 33.1 percent of Kern County adult
residents who have ever smoked, reported that they smoke every day," Ochoa said.

That's more than twice the rate in the state as a whole, she said.

Ochoa invited everyone to visit kernpublichealth.com or ask to speak with the agency's Tobacco Prevention
Program by calling 661-321-3000.

Karina Funez, policy advocate at Blue Zones Project Bakersfield, said commercial tobacco companies have a long
history of targeting vulnerable populations.

                                                                                                 Page 2 of 2
             Great American Smokeout aims to reduce smoking rates, increase lung cancer screenings

"Unfortunately, that has created inequity among our communities, which has disproportionately affected the health
of youth and people of color," Funez said. "However, we know that through policy and education, we can create
change that helps us decrease commercial tobacco use and prevent the next generation of tobacco users."

This month, the cancer society released updated screening recommendations, which should allow more people to
receive low-dose CT lung cancer screenings, said Raymond Andreas, lung oncology nurse navigator at the AIS
Cancer Center in Bakersfield.

"Lung cancer, if you can diagnose it in stage 1 or 2, it's curable," Andreas said. "You can get surgery and move on
with life.

"The problem is," he said, "people wait until stage 3 or 4."

Early detection is the key.

"I'm really excited to share with you that Adventist Health and AIS Cancer Center are opening up Kern County's
first lung screening program."

According to Andreas, Medicare and most private insurances cover the screenings, so there's little to no out-of-
pocket expense for those who are between 50 and 80 years of age and are currently smokers or are former
smokers.

"According to the American Lung Association," he said, "close to 237,000 people in the U.S. will be diagnosed with
lung cancer this year.

"The 2022 State of Lung Cancer report shows that only 5.8 percent of eligible Americans have been screened for
lung cancer, and some states have screening rates as low as 1 percent ..." including California, he said.

Reporter Steven Mayer can be reached at 661-395-7353.

___ (c)2023 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: November 21, 2023


  End of Document

                                                                                                    Page 1 of 2
                Great American Smokeout aims to reduce smoking rates, increase lung cancer screenings




     Great American Smokeout aims to reduce smoking rates, increase lung
                            cancer screenings
                                                        The Bakersfield Californian
                                                      November 16, 2023 Thursday



Copyright 2023 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 556 words
Byline: Steven Mayer, The Bakersfield Californian

Body


Nov. 16—There's a lot of encouraging news these days in the study and treatment of lung cancer.

More lung cancer patients, for example, are living longer following their initial diagnosis. And the prevalence of
cigarette smoking in adults in the U.S. declined from 14 percent in 2019 to 12 percent in 2021.

That translates to an estimated 5.7 million fewer adults who smoke, according to an American Cancer Society study
released earlier this year.

But there's bad news, too.

The cancer society joined with Kern County Public Health, Blue Zones Project Bakersfield, and Adventist Health to
hold a joint news conference Thursday morning to kick off the Great American Smoke Out of Kern County — and to
emphasize the importance of early lung cancer screening aimed at reducing cancer deaths.

"Thank you for joining us this morning as we raise awareness around smoking cessation on this day, the Great
American Smokeout," Jasmine Ochoa, health equity officer at the Kern County Department of Public Health, said
at a gathering in front of the AIS Cancer Center.

"According to the 2022 results of the California Health Interview Survey, 33.1 percent of Kern County adult
residents who have ever smoked, reported that they smoke every day," Ochoa said.

That's more than twice the rate in the state as a whole, she said.

Ochoa invited everyone to visit kernpublichealth.com or ask to speak with the agency's Tobacco Prevention
Program by calling 661-321-3000.

Karina Funez, policy advocate at Blue Zones Project Bakersfield, said commercial tobacco companies have a long
history of targeting vulnerable populations.

                                                                                                 Page 2 of 2
             Great American Smokeout aims to reduce smoking rates, increase lung cancer screenings

"Unfortunately, that has created inequity among our communities, which has disproportionately affected the health
of youth and people of color," Funez said. "However, we know that through policy and education, we can create
change that helps us decrease commercial tobacco use and prevent the next generation of tobacco users."

This month, the cancer society released updated screening recommendations, which should allow more people to
receive low-dose CT lung cancer screenings, said Raymond Andreas, lung oncology nurse navigator at the AIS
Cancer Center in Bakersfield.

"Lung cancer, if you can diagnose it in stage 1 or 2, it's curable," Andreas said. "You can get surgery and move on
with life.

"The problem is," he said, "people wait until stage 3 or 4."

Early detection is the key.

"I'm really excited to share with you that Adventist Health and AIS Cancer Center are opening up Kern County's
first lung screening program."

According to Andreas, Medicare and most private insurances cover the screenings, so there's little to no out-of-
pocket expense for those who are between 50 and 80 years of age and are currently smokers or are former
smokers.

"According to the American Lung Association," he said, "close to 237,000 people in the U.S. will be diagnosed with
lung cancer this year.

"The 2022 State of Lung Cancer report shows that only 5.8 percent of eligible Americans have been screened for
lung cancer, and some states have screening rates as low as 1 percent ..." including California, he said.

Reporter Steven Mayer can be reached at 661-395-7353.

___ (c)2023 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: November 18, 2023


  End of Document

                                                                                                        Page 1 of 4
         Artificial Intelligence in Medical Imaging Market to Watch: Spotlight on Firms Like OrCam , Babylon ,
                               Freenome, Clarify Health Solutions, BioXcel Therapeutics -....




Artificial Intelligence in Medical Imaging Market to Watch: Spotlight on Firms
      Like OrCam, Babylon, Freenome, Clarify Health Solutions, BioXcel
                            Therapeutics - The Courier
                                              The Courier: Monmouth University
                                                      January 31, 2021 Sunday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1178 words

Body

The growing aging population, coupled with rising investment in the healthcare ecosystem, is expected to impact
overall market growth over the forecast period positively. Developed nations have been facing this demographic
challenge and have been investing in bringing affordable and advanced healthcare systems to the people, thereby
providing impetus to the market. X-ray imaging is being widely used to detect lung and breast cancer.

Artificial Intelligence in Medical Imaging Market research is an intelligence report with meticulous efforts undertaken
to study the right and valuable information. The data which has been looked upon is done considering both, the
existing top players and the upcoming competitors.

Get        Sample        Copy        Of       This        Report                   With        Global            Industry
Analysis: www.a2zmarketresearch.com/sample?reportId=64867

Key Players Included Are: OrCam, Babylon, Freenome, Clarify Health Solutions, BioXcel Therapeutics, Ada Health
GmbH, GNS Healthcare, Zebra Medical Vision, Qventus Inc, IDx Technologies, K Health, Prognos, Medopad,
Viz.ai, Voxel Technology, Renalytix AI plc, Beijing Pushing Technology Co. Ltd, PAIGE, mPulse Mobile, Suki AI,
BERG LLC, Zealth, OWKIN, Your.MD.

Business strategies of the key players and the new entering market industries are studied in detail. Well explained
SWOT analysis, revenue share and contact information are shared in this report analysis. It also provides market
information in terms of development and its capacities.

"Artificial Intelligence in Medical Imaging Market is growing at a High CAGR during the forecast period 2021-2027.
The increasing interest of the individuals in this industry is that the major reason for the expansion of this market".

Global Artificial Intelligence in Medical Imaging Market research report offers:
     •    Market definition of the global Artificial Intelligence in Medical Imaging market along with the analysis of
          different influencing factors like drivers, restraints, and opportunities.
     •    Extensive research on the competitive landscape of global Artificial Intelligence in Medical Imaging

                                                                                                       Page 2 of 4
        Artificial Intelligence in Medical Imaging Market to Watch: Spotlight on Firms Like OrCam , Babylon ,
                              Freenome, Clarify Health Solutions, BioXcel Therapeutics -....

    •   Identification and analysis of micro and macro factors that are and will effect on the growth of the market.
    •   A comprehensive list of key market players operating in the global Artificial Intelligence in Medical Imaging
        market.
    •   Analysis of the different market segments such as type, size, applications, and end-users.
    •   It offers a descriptive analysis of demand-supply chaining in the global Artificial Intelligence in Medical
        Imaging market.
    •   Statistical analysis of some significant economics facts
    •   Figures, charts, graphs, pictures to describe the market clearly.

Various factors are responsible for the market's growth trajectory, which are studied at length in the report. In
addition, the report lists down the restraints that are posing threat to the global Artificial Intelligence in Medical
Imaging market. It also gauges the bargaining power of suppliers and buyers, threat from new entrants and product
substitute, and the degree of competition prevailing in the market. The influence of the latest government guidelines
is also analyzed in detail in the report. It studies the Artificial Intelligence in Medical Imaging market's trajectory
between forecast periods.

Enquire For Customized Report or Specific Requirements:www.a2zmarketresearch.com/enquiry?reportId=64867

Regions Covered in the Global Artificial Intelligence in Medical Imaging Market Report 2021:

· The Middle East and Africa (GCC Countries and Egypt)

· North America (the United States, Mexico, and Canada)

· South America (Brazil etc.)

· Europe (Turkey, Germany, Russia UK, Italy, France, etc.)

· Asia-Pacific (Vietnam, China, Malaysia, Japan, Philippines, Korea, Thailand, India, Indonesia, and Australia)

The cost analysis of the Global Artificial Intelligence in Medical Imaging Market has been performed while keeping
in view manufacturing expenses, labor cost, and raw materials and their market concentration rate, suppliers, and
price trend. Other factors such as Supply chain, downstream buyers, and sourcing strategy have been assessed to
provide a complete and in-depth view of the market. Buyers of the report will also be exposed to a study on market
positioning with factors such as target client, brand strategy, and price strategy taken into consideration.

Table of Content

Global Artificial Intelligence in Medical Imaging Market Report 2021 - Growth, Trend and Forecast to 2027

Chapter 1 Artificial Intelligence in Medical Imaging Market Overview

Chapter 2 Global Economic Impact on Artificial Intelligence in Medical Imaging Industry

Chapter 3 Global Artificial Intelligence in Medical Imaging Market Competition by Manufacturers

Chapter 4 Global Production, Revenue (Value) by Region (2014-2021)

Chapter 5 Global Supply (Production), Consumption, Export, Import by Regions (2014-2021)

Chapter 6 Global Production, Revenue (Value), Price Trend by Type

Chapter 7 Global Market Analysis by Application

                                                                                                       Page 3 of 4
        Artificial Intelligence in Medical Imaging Market to Watch: Spotlight on Firms Like OrCam , Babylon ,
                              Freenome, Clarify Health Solutions, BioXcel Therapeutics -....

Chapter 8 Manufacturing Cost Analysis

Chapter 9 Industrial Chain, Sourcing Strategy and Downstream Buyers

Chapter 10 Marketing Strategy Analysis, Distributors/Traders

Chapter 11 Market Effect Factors Analysis

Chapter 12 Global Artificial Intelligence in Medical Imaging Market Forecast (2021-2027)

Chapter 13 Appendix

Key questions answered in the report include:
    •   What will be the market size and the growth rate by the end of the forecast period?
    •   What are the key Artificial Intelligence in Medical Imaging Market trends impacting the growth of the
        market?
    •   What are the potential growth opportunities and threats faced by the leading competitors in the market?
    •   What are the key outcomes of Porter's five forces analysis and the SWOT analysis of the key players
        functioning in the global Artificial Intelligence in Medical Imaging Market?
    •   This report gives all the information regarding industry Overview, analysis and revenue of this market.
    •   What are the market opportunities and threats faced by the vendors in the global Artificial Intelligence in
        Medical Imaging market?

Get Great Discount On The First Purchase Of This Report: www.a2zmarketresearch.com/discount?reportId=64867

If you have any special requirements, please let us know and we will offer you the report as you want.

About A2Z Market Research:

The A2Z Market Research library provides syndication reports from market researchers around the world. Ready-
to-buy syndication Market research studies will help you find the most relevant business intelligence.

Our Research Analyst Provides business insights and market research reports for large and small businesses.

The company helps clients build business policies and grow in that market area. A2Z Market Research is not only
interested in industry reports dealing with telecommunications, healthcare, pharmaceuticals, financial services,
energy, technology, real estate, logistics, F & B, media, etc. but also your company data, country profiles, trends,
information and analysis on the sector of your interest.

Contact Us:

Roger Smith

1887 WHITNEY MESA DR HENDERSON, NV 89014

sales@a2zmarketresearch.com

+1 775 237 4147


Load-Date: January 31, 2021

                                                                                                    Page 4 of 4
     Artificial Intelligence in Medical Imaging Market to Watch: Spotlight on Firms Like OrCam , Babylon ,
                           Freenome, Clarify Health Solutions, BioXcel Therapeutics -....


End of Document

                                                                                                     Page 1 of 3
                                             AI Is Learning to Read Mammograms




                                  AI Is Learning to Read Mammograms
                                              Richmond Times Dispatch (Virginia)
                                                   January 13, 2020 Monday
                                                               2 Edition



Copyright 2020 Richmond Newspapers, Inc. All Rights Reserved

Section: NEWS; Pg. 1Z
Length: 914 words
Byline: DENISE GRADY © 2020 The New York Times

Body


Artificial intelligence can help doctors do a better job of finding breast cancer on mammograms, researchers from
Google and medical centers in the United States and Britain are reporting in the journal Nature.

The new system for reading mammograms, which are X-rays of the breast, is still being studied and is not yet
available for widespread use. It is just one of Google's ventures into medicine. Computers can be trained to
recognize patterns and interpret images, and the company has already created algorithms to help detect lung
cancers on CT scans, diagnose eye disease in people with diabetes and find cancer on microscope slides.

"This paper will help move things along quite a bit," said Dr. Constance Lehman, director of breast imaging at the
Massachusetts General Hospital in Boston, who was not involved in the study. "There are challenges to their
methods. But having Google at this level is a very good thing."

 Tested on images where the diagnosis was already known, the new system performed better than radiologists. On
scans from the United States, the system produced a 9.4% reduction in false negatives, in which a mammogram is
mistakenly read as normal and a cancer is missed. It also provided a lowering of 5.7% in false positives, where the
scan is incorrectly judged abnormal but there is no cancer.

 On mammograms performed in Britain, the system also beat the radiologists, reducing false negatives by 2.7% and
false positives by 1.2%.

Google paid for the study, and worked with researchers from Northwestern University in Chicago and two British
medical centers, Cancer Research Imperial Centre and Royal Surrey County Hospital.

Last year, 268,600 new cases of invasive breast cancer and 41,760 deaths were expected among women in the
United States, according to the American Cancer Society. Globally, there are about 2 million new cases a year, and
more than half a million deaths.

                                                                                                        Page 2 of 3
                                        AI Is Learning to Read Mammograms

 About 33 million screening mammograms are performed each year in the United States. The test misses about
20% of breast cancers, according to the American Cancer Society, and false positives are common, resulting in
women being called back for more tests, sometimes even biopsies.

Doctors have long wanted to make mammography more accurate.

 "There are many radiologists who are reading mammograms who make mistakes, some well outside the
acceptable margins of normal human error," Lehman said.

 To apply artificial intelligence to the task, the authors of the Nature report used mammograms from about 76,000
women in Britain and 15,000 in the United States, whose diagnoses were already known, to train computers to
recognize cancer.

 Then, they tested the computers on images from about 25,000 other women in Britain, and 3,000 in the United
States, and compared the system's performance with that of the radiologists who had originally read the X-rays.
The mammograms had been taken in the past, so the women's outcomes were known, and the researchers could
tell whether the initial diagnoses were correct.

 "We took mammograms that already happened, showed them to radiologists and asked, '˜Cancer or no?' and then
showed them to AI, and asked, '˜Cancer, or no?' " said Dr. Mozziyar Etemadi, an author of the study from
Northwestern University.

This was the test that found AI more accurate than the radiologists.

Unlike humans, computers do not get tired, bored or distracted toward the end of a long day of reading
mammograms, Etemadi said.

In another test, the researchers pitted AI against six radiologists in the United States, presenting 500
mammograms to be interpreted. Overall, AI again outperformed the humans.

But in some instances, AI missed a cancer that all six radiologists found ' and vice versa.

 "There's no denying that in some cases our AI tool totally gets it wrong and they totally get it right," Etemadi said.
"Purely from that perspective it opens up an entirely new area of inquiry and study. Why is it that they missed it?
Why is it that we missed it?"

 Lehman, who is also developing AI for mammograms, said the Nature report was strong, but she had some
concerns about the methods, noting that the patients studied might not be a true reflection of the general
population. A higher proportion had cancer, and the racial makeup was not specified. She also said that "reader"
analyses involving a small number of radiologists ' this study used six ' were not always reliable.

 The next step in the research is to have radiologists try using the tool as part of their routine practice in reading
mammograms. New techniques that pass their initial tests with flying colors do not always perform as well out in the
real world.

"We have to see what happens when radiologists have it, see if they do better," Etemadi said.

Lehman said: "We have to be very careful. We want to make sure this is helping patients."

 She and Etemadi said that a potentially good use of AI would be to sort mammograms and flag those most in need
of the radiologist's attention. The system may also be able to identify those that are clearly negative, so they could
be read quickly and patients could promptly be given a clean bill of health.

 Although developers of AI often say it is intended to help radiologists, not replace them, Lehman predicted that
eventually, computers alone will read at least some mammograms, without help from humans.

                                                                                                   Page 3 of 3
                                      AI Is Learning to Read Mammograms

 "We're onto something," she said. "These systems are picking up things a human might not see, and we're right at
the beginning of it."


Load-Date: January 15, 2020


  End of Document

                                                                                                        Page 1 of 2
                              COVID-19 booster shot available for high-risk, elderly individuals




          COVID-19 booster shot available for high-risk, elderly individuals
                                        The Dominion Post (Morgantown, West Virginia)
                                                   October 2, 2021 Saturday



Copyright 2021 The Dominion Post (Morgantown, W.Va.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 517 words
Byline: Gabriella Brown, The Dominion Post, Morgantown, W.Va.

Body


Oct. 2—MORGANTOWN — COVID-19 vaccine booster shots are available to select populations across the United
States, and several locations in the Morgantown and surrounding area are available to distribute it to those eligible.

According to the Centers for Disease Control and Prevention, the booster shot is available to certain groups who
received the first two doses of the Pfizer-BioNTech vaccine at least six months ago. Eligible groups as of Friday
include:

— 65 years and older — Age 18 + who live in long-term care settings — Age 18 + who have underlying medical
conditions — Age 18 + who work in high-risk settings — Age 18 + who live in high-risk settings The CDC defines
those at increased risk for COVID-19 exposure as frontline, essential workers and health care workers, including
first responders, education staff, food and agriculture workers, manufacturing workers, corrections workers, U.S.
Postal Service employees, public transit workers, and grocery store workers.

"For the elderly and for those patients who are immunocompromised who could suffer really bad effects from
COVID, it's important to maintain a high level of immunity, which the booster will produce, " said Todd Karpinski,
WVU Medicine chief pharmacy officer. "For those individuals with a lot of occupational exposures, such as those
individuals that are caring for COVID patients in the hospital setting, it just gives them a further immunity to try to
prevent them from acquiring the COVID virus."

Karpinski said booster shots are available in several locations, including WVU Medicine booster shot clinics and at
pharmacies such as Walgreens, CVS and Rite Aid.

Mary Wade Burnside, Monongalia County Health Department public information officer, said MCHD will distribute
COVID-19 vaccines as well as booster shots to those who are eligible from 1-3 p.m. Friday and Oct. 15 at the WVU
Recreational Center. Sign-ups are available online at novelhealth.ai /practice /monongalia-county-health-
department-clinical-services-383538.

"Filling out their insurance information online in advance will save them time at the appointment, " Burnside said.
"The insurance is for the administration of the vaccine, which is free."

                                                                                                         Page 2 of 2
                          COVID-19 booster shot available for high-risk, elderly individuals

Booster shot appointments can also be made by calling the Monongalia County Health Department at 304-598-
5119.

Those who receive the booster shot may experience similar side effects to those seen during the initial vaccine
doses.

"With any vaccine, the most common side effect that we're seeing with the boosters is the soreness in the arm at
the injection site, " Karpinski said. "The data that's released shows no more side effects of the [Pfizer ] booster dose
compared to the first or second doses."

According to the CDC, data shows protection against the COVID-19 virus may decrease over time after initially
getting vaccinated. As more data becomes available, additional populations may be recommended to receive a
booster shot.

TWEET @DominionPostWV

___ (c)2021 The Dominion Post (Morgantown, W.Va.) Visit The Dominion Post (Morgantown, W.Va.) at
www.dominionpost.com Distributed by Tribune Content Agency, LLC.


Load-Date: October 2, 2021


  End of Document

                                                                                                        Page 1 of 2
                              COVID-19 booster shot available for high-risk, elderly individuals




          COVID-19 booster shot available for high-risk, elderly individuals
                                        The Dominion Post (Morgantown, West Virginia)
                                                   October 3, 2021 Sunday



Copyright 2021 The Dominion Post (Morgantown, W.Va.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 517 words
Byline: Gabriella Brown, The Dominion Post, Morgantown, W.Va.

Body


Oct. 3—MORGANTOWN — COVID-19 vaccine booster shots are available to select populations across the United
States, and several locations in the Morgantown and surrounding area are available to distribute it to those eligible.

According to the Centers for Disease Control and Prevention, the booster shot is available to certain groups who
received the first two doses of the Pfizer-BioNTech vaccine at least six months ago. Eligible groups as of Friday
include:

— 65 years and older — Age 18 + who live in long-term care settings — Age 18 + who have underlying medical
conditions — Age 18 + who work in high-risk settings — Age 18 + who live in high-risk settings The CDC defines
those at increased risk for COVID-19 exposure as frontline, essential workers and health care workers, including
first responders, education staff, food and agriculture workers, manufacturing workers, corrections workers, U.S.
Postal Service employees, public transit workers, and grocery store workers.

"For the elderly and for those patients who are immunocompromised who could suffer really bad effects from
COVID, it's important to maintain a high level of immunity, which the booster will produce, " said Todd Karpinski,
WVU Medicine chief pharmacy officer. "For those individuals with a lot of occupational exposures, such as those
individuals that are caring for COVID patients in the hospital setting, it just gives them a further immunity to try to
prevent them from acquiring the COVID virus."

Karpinski said booster shots are available in several locations, including WVU Medicine booster shot clinics and at
pharmacies such as Walgreens, CVS and Rite Aid.

Mary Wade Burnside, Monongalia County Health Department public information officer, said MCHD will distribute
COVID-19 vaccines as well as booster shots to those who are eligible from 1-3 p.m. Friday and Oct. 15 at the WVU
Recreational Center. Sign-ups are available online at novelhealth.ai /practice /monongalia-county-health-
department-clinical-services-383538.

"Filling out their insurance information online in advance will save them time at the appointment, " Burnside said.
"The insurance is for the administration of the vaccine, which is free."

                                                                                                         Page 2 of 2
                          COVID-19 booster shot available for high-risk, elderly individuals

Booster shot appointments can also be made by calling the Monongalia County Health Department at 304-598-
5119.

Those who receive the booster shot may experience similar side effects to those seen during the initial vaccine
doses.

"With any vaccine, the most common side effect that we're seeing with the boosters is the soreness in the arm at
the injection site, " Karpinski said. "The data that's released shows no more side effects of the [Pfizer ] booster dose
compared to the first or second doses."

According to the CDC, data shows protection against the COVID-19 virus may decrease over time after initially
getting vaccinated. As more data becomes available, additional populations may be recommended to receive a
booster shot.

TWEET @DominionPostWV

___ (c)2021 The Dominion Post (Morgantown, W.Va.) Visit The Dominion Post (Morgantown, W.Va.) at
www.dominionpost.com Distributed by Tribune Content Agency, LLC.


Load-Date: October 4, 2021


  End of Document

                                                                                                        Page 1 of 2
      Big tech startups falling fast Collapsing firms show how venture-backed darlings ran out of time, money,
                                                         support




                       Big tech startups falling fast
Collapsing firms show how venture-backed darlings ran out of time, money,
                                 support
                                                       The Baltimore Sun
                                                  December 9, 2023 Saturday
                                                           First Edition



Copyright 2023 The Baltimore Sun Company All Rights Reserved

Section: MAIN; A; Pg. 8
Length: 554 words
Byline: Erin Griffith The New York Times
Highlight: Antonio Sortino/The New York Times

Body


SAN FRANCISCO - WeWork raised over $11 billion in funding as a private company. Olive AI, a health care
startup, gathered $852 million. Convoy, a freight startup, raised $900 million. Veev, a home construction startup,
amassed $647 million.

In the last six weeks, they all filed for bankruptcy or shut down.

They are the most recent failures in a tech startup collapse that investors say is only just beginning.

After staving off mass failure by cutting costs over the past two years, many once-promising tech companies are
now on the verge of running out of time and money. They face a harsh reality: Investors are no longer interested in
promises. Rather, venture capital firms are deciding which young companies are worth saving and urging others to
shut down or sell.

It has fueled an astonishing cash bonfire. In August, Hopin, a startup that raised more than $1.6 billion and was
once valued at $7.6 billion, sold its main business for just $15 million. Last month, Zeus Living, a real estate startup
that raised $150 million, said it was shutting down. Plastiq, a financial technology startup that raised $226 million,
went bankrupt in May. In September, Bird, a scooter company that raised $776 million, was delisted from the New
York Stock Exchange because of its low stock price. Its $7 million market capitalization is less than the value of the
$22 million Miami mansion that its founder, Travis VanderZanden, bought in 2021.

"As an industry we should all be braced to hear about a lot more failures," said Jenny Lefcourt, an investor at
Freestyle Capital. "The more money people got before the party ended, the longer the hangover."

                                                                                                        Page 2 of 2
      Big tech startups falling fast Collapsing firms show how venture-backed darlings ran out of time, money,
                                                         support

Getting a full picture of the losses is difficult since private tech companies are not required to disclose when they go
under or sell. The industry's gloom has also been masked by a boom in companies focused on artificial intelligence,
which has attracted hype and funding over the last year.

But approximately 3,200 private venture-backed U.S. companies have gone out of business this year, according to
data compiled for The New York Times by PitchBook, which tracks startups. Those companies had raised $27.2
billion in venture funding. PitchBook said the data was not comprehensive and probably undercounts the total
because many companies go out of business quietly. It also excluded many of the largest failures that went public,
such as WeWork, or that found buyers, like Hopin.

Carta, a company that provides financial services for many Silicon Valley startups, said 87 of the startups on its
platform that raised at least $10 million had shut down as of October, twice the number for all of 2022.

But as many companies that have languished for years now show signs of collapse, investors expect the losses to
be more drastic because of how much cash was invested over the last decade.

From 2012 to 2022, investment in private U.S. startups ballooned eightfold to $344 billion. The flood of money was
driven by low interest rates and successes in social media and mobile apps, propelling venture capital to a
formidable global asset class akin to hedge funds or private equity.

But the ad profits gushing from the likes of Facebook and Google proved elusive for the next wave of startups,
which tried untested business models like gig work, the metaverse, micromobility and crypto.


Load-Date: December 11, 2023


  End of Document

                                                                                                         Page 1 of 2
       Big tech startups falling fast Collapsing firms show how venture-backed darlings ran out of time, money,
                                                          support




                       Big tech startups falling fast
Collapsing firms show how venture-backed darlings ran out of time, money,
                                 support
                                                          The Morning Call
                                                    December 9, 2023 Saturday
                                                            FIRST Edition



Copyright 2023 Capital Gazette Communications, Inc. All Rights Reserved

Section: MAIN; A; Pg. 9
Length: 554 words
Byline: Erin Griffith The New York Times
Highlight: Antonio Sortino/The New York Times

Body


SAN FRANCISCO - WeWork raised over $11 billion in funding as a private company. Olive AI, a health care
startup, gathered $852 million. Convoy, a freight startup, raised $900 million. Veev, a home construction startup,
amassed $647 million.

In the last six weeks, they all filed for bankruptcy or shut down.

They are the most recent failures in a tech startup collapse that investors say is only just beginning.

After staving off mass failure by cutting costs over the past two years, many once-promising tech companies are
now on the verge of running out of time and money. They face a harsh reality: Investors are no longer interested in
promises. Rather, venture capital firms are deciding which young companies are worth saving and urging others to
shut down or sell.

It has fueled an astonishing cash bonfire. In August, Hopin, a startup that raised more than $1.6 billion and was
once valued at $7.6 billion, sold its main business for just $15 million. Last month, Zeus Living, a real estate startup
that raised $150 million, said it was shutting down. Plastiq, a financial technology startup that raised $226 million,
went bankrupt in May. In September, Bird, a scooter company that raised $776 million, was delisted from the New
York Stock Exchange because of its low stock price. Its $7 million market capitalization is less than the value of the
$22 million Miami mansion that its founder, Travis VanderZanden, bought in 2021.

"As an industry we should all be braced to hear about a lot more failures," said Jenny Lefcourt, an investor at
Freestyle Capital. "The more money people got before the party ended, the longer the hangover."

                                                                                                        Page 2 of 2
      Big tech startups falling fast Collapsing firms show how venture-backed darlings ran out of time, money,
                                                         support

Getting a full picture of the losses is difficult since private tech companies are not required to disclose when they go
under or sell. The industry's gloom has also been masked by a boom in companies focused on artificial intelligence,
which has attracted hype and funding over the last year.

But approximately 3,200 private venture-backed U.S. companies have gone out of business this year, according to
data compiled for The New York Times by PitchBook, which tracks startups. Those companies had raised $27.2
billion in venture funding. PitchBook said the data was not comprehensive and probably undercounts the total
because many companies go out of business quietly. It also excluded many of the largest failures that went public,
such as WeWork, or that found buyers, like Hopin.

Carta, a company that provides financial services for many Silicon Valley startups, said 87 of the startups on its
platform that raised at least $10 million had shut down as of October, twice the number for all of 2022.

But as many companies that have languished for years now show signs of collapse, investors expect the losses to
be more drastic because of how much cash was invested over the last decade.

From 2012 to 2022, investment in private U.S. startups ballooned eightfold to $344 billion. The flood of money was
driven by low interest rates and successes in social media and mobile apps, propelling venture capital to a
formidable global asset class akin to hedge funds or private equity.

But the ad profits gushing from the likes of Facebook and Google proved elusive for the next wave of startups,
which tried untested business models like gig work, the metaverse, micromobility and crypto.


Load-Date: December 10, 2023


  End of Document

                                                                                                         Page 1 of 2
                             Governments Consider Ethics, Transparency in Cutting-Edge Tech




         Governments Consider Ethics, Transparency in Cutting-Edge Tech
                                                Government TechNology
                                             December 1, 2021 Wednesday



Copyright 2021 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 885 words
Byline: Julia Edinger, Government Technology

Body


Dec. 1—As Stephen Hawking once said, "Our future is a race between the growing power of technology and the
wisdom with which we use it." As the COVID-19 pandemic pushed government to rapidly modernize for the remote
world in 2020, 2021 saw public agencies grapple with making this transition equitable, transparent and secure.
During the past year, emerging technologies have reshaped not only what government is able to do for
constituents, but also people's expectations of government.

While public-sector agencies found their footing in the remote world, private-sector innovation has been reaching
new heights — quite literally, as in the realm of space travel. Elon Musk's SpaceX launched multiple rockets into
space, while Jeff Bezos and Richard Branson launched themselves. And the work of these three billionaires'
extraterrestrial exploration is happening at a time when satellite Internet is becoming a more viable option to
connect currently unserved communities to the Internet.

And as satellite Internet options skyrocketed, the pandemic challenged governments, driving new public-private
partnerships and solutions; for example, private partners are helping government make significant strides toward
universal broadband.

Other tech has followed a similar trajectory. Robots and drones are more commonly delivering food, medicine and
other products. Some government uses though, like the New York City Police Department's robot dog Spot, spurred
feedback from the public and civil liberties groups holding on to surveillance fears.

One notable advance in recent months is the use of virtual and augmented reality in the public sector. While its
specific value is still being studied by organizations like the National Institute of Standards and Technology, it is
reshaping the way many agencies engage, train and retain talent. From workforce development to tourism to
emergency response, it has been found to improve retention and reduce training costs.

The pandemic also gave way to other significant changes in the workforce, highlighting the gaps that exist in certain
sectors, including IT. While some state solutions, like Indiana's Hoosier Talent Network, use artificial intelligence to
help match candidates with job openings, some experts have raised concerns about the technology's potential for
bias — an issue which frequently gets raised during debates on government use. The World Health Organization

                                                                                                              Page 2 of 2
                          Governments Consider Ethics, Transparency in Cutting-Edge Tech

released a report this year offering guidance for ethical use of AI within the health sector, but a comprehensive set
of regulations for AI in government has yet to be established. Meanwhile, government continues to explore its use,
notably to advance cybersecurity defenses and achieve workflow efficiencies using tools like robotic process
automation.

Ethical questions have also been raised about facial recognition as disparities are brought to light about the way
this tech identifies transgender people, people of color and nonbinary individuals. Several cities and states have
implemented regulations banning or restricting the use of facial recognition and other AI-powered tools to calm
fears over their use, suggesting the tech still has some work to do in proving its value.

Federal policymakers set their sights on deepfakes in 2021, videos that feature realistic audio and video of a person
that has been fraudulently manipulated. For example, this technology could make it look like any authority figure is
saying something they never said. These videos are an increasing concern in the misinformation discourse,
prompting discussions on how to curb their proliferation online. Programs like Cyber Florida are offering students
the skills to determine validity of information they find on the Internet and underlining the value of this particular skill.

But while government entities have rapidly made modernization strides in the COVID-19 era, newer does not
always mean better. In their rush to deploy new technology, some are quick to dismiss the value of legacy systems
that can still capably do the important work of government. Take COBOL, for example, a programming language
five decades old that surfaces often in conversations about the shameful state of legacy IT. But COBOL, and other
older tech, is a known quantity with known capabilities. A more targeted problem-solving approach, rather than an
abolish-all-legacy-tech approach, is likely the most prudent course, as new tech might not always add value to the
enterprise.

"And at the end of the day, what you now have is a new program that does exactly the same thing as the old
program, and you sit down and you say, 'Why did I spend my money on that project?'" asked William Malik, vice
president of infrastructure strategies at Trend Micro, in a piece examining COBOL this year on govtech.com.

Ultimately, technology leaders in government must continue to smartly evangelize the benefits new tools can bring
in making public-sector organizations better at their core missions. By advocating for scalable pilots where results
are closely measured and transparently reported, CIOs have a key role to play in maintaining and growing the
public's appetite for innovation using new technology.

___ (c)2021 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: December 2, 2021


  End of Document

                                                                                                         Page 1 of 2
                             Governments Consider Ethics, Transparency in Cutting-Edge Tech




         Governments Consider Ethics, Transparency in Cutting-Edge Tech
                                                Government TechNology
                                             December 1, 2021 Wednesday



Copyright 2021 Government Technology

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 885 words
Byline: Julia Edinger, Government Technology

Body


Dec. 1—As Stephen Hawking once said, "Our future is a race between the growing power of technology and the
wisdom with which we use it." As the COVID-19 pandemic pushed government to rapidly modernize for the remote
world in 2020, 2021 saw public agencies grapple with making this transition equitable, transparent and secure.
During the past year, emerging technologies have reshaped not only what government is able to do for
constituents, but also people's expectations of government.

While public-sector agencies found their footing in the remote world, private-sector innovation has been reaching
new heights — quite literally, as in the realm of space travel. Elon Musk's SpaceX launched multiple rockets into
space, while Jeff Bezos and Richard Branson launched themselves. And the work of these three billionaires'
extraterrestrial exploration is happening at a time when satellite Internet is becoming a more viable option to
connect currently unserved communities to the Internet.

And as satellite Internet options skyrocketed, the pandemic challenged governments, driving new public-private
partnerships and solutions; for example, private partners are helping government make significant strides toward
universal broadband.

Other tech has followed a similar trajectory. Robots and drones are more commonly delivering food, medicine and
other products. Some government uses though, like the New York City Police Department's robot dog Spot, spurred
feedback from the public and civil liberties groups holding on to surveillance fears.

One notable advance in recent months is the use of virtual and augmented reality in the public sector. While its
specific value is still being studied by organizations like the National Institute of Standards and Technology, it is
reshaping the way many agencies engage, train and retain talent. From workforce development to tourism to
emergency response, it has been found to improve retention and reduce training costs.

The pandemic also gave way to other significant changes in the workforce, highlighting the gaps that exist in certain
sectors, including IT. While some state solutions, like Indiana's Hoosier Talent Network, use artificial intelligence to
help match candidates with job openings, some experts have raised concerns about the technology's potential for
bias — an issue which frequently gets raised during debates on government use. The World Health Organization

                                                                                                              Page 2 of 2
                          Governments Consider Ethics, Transparency in Cutting-Edge Tech

released a report this year offering guidance for ethical use of AI within the health sector, but a comprehensive set
of regulations for AI in government has yet to be established. Meanwhile, government continues to explore its use,
notably to advance cybersecurity defenses and achieve workflow efficiencies using tools like robotic process
automation.

Ethical questions have also been raised about facial recognition as disparities are brought to light about the way
this tech identifies transgender people, people of color and nonbinary individuals. Several cities and states have
implemented regulations banning or restricting the use of facial recognition and other AI-powered tools to calm
fears over their use, suggesting the tech still has some work to do in proving its value.

Federal policymakers set their sights on deepfakes in 2021, videos that feature realistic audio and video of a person
that has been fraudulently manipulated. For example, this technology could make it look like any authority figure is
saying something they never said. These videos are an increasing concern in the misinformation discourse,
prompting discussions on how to curb their proliferation online. Programs like Cyber Florida are offering students
the skills to determine validity of information they find on the Internet and underlining the value of this particular skill.

But while government entities have rapidly made modernization strides in the COVID-19 era, newer does not
always mean better. In their rush to deploy new technology, some are quick to dismiss the value of legacy systems
that can still capably do the important work of government. Take COBOL, for example, a programming language
five decades old that surfaces often in conversations about the shameful state of legacy IT. But COBOL, and other
older tech, is a known quantity with known capabilities. A more targeted problem-solving approach, rather than an
abolish-all-legacy-tech approach, is likely the most prudent course, as new tech might not always add value to the
enterprise.

"And at the end of the day, what you now have is a new program that does exactly the same thing as the old
program, and you sit down and you say, 'Why did I spend my money on that project?'" asked William Malik, vice
president of infrastructure strategies at Trend Micro, in a piece examining COBOL this year on govtech.com.

Ultimately, technology leaders in government must continue to smartly evangelize the benefits new tools can bring
in making public-sector organizations better at their core missions. By advocating for scalable pilots where results
are closely measured and transparently reported, CIOs have a key role to play in maintaining and growing the
public's appetite for innovation using new technology.

___ (c)2021 Government Technology Visit Government Technology at www.govtech.com Distributed by Tribune
Content Agency, LLC.


Load-Date: December 2, 2021


  End of Document

                                                                                                        Page 1 of 3
                        The 'PodoSighter' uses AI to identify a key indicator of early kidney disease




 The 'PodoSighter' uses AI to identify a key indicator of early kidney disease
                                     Niagara-Wheatfield Tribune (Niagara Falls, New York)
                                                      October 29, 2021



Copyright 2021 Niagara Frontier Publications
Distributed by Newsbank, Inc. All Rights Reserved

Section: CURRENT NEWS
Length: 959 words

Body


Journal is highlighting this artificial intelligence advance on the cover of the November issue

By the University at Buffalo

 In the early stages of kidney disease, a specialized type of kidney cell called the podocyte undergoes damaging
changes in both its structure and function. Those changes are key indicators of the ultimately devastating damage
that end-stage renal disease can cause, but these specialized cells are difficult to detect.

 Now, University at Buffalo researchers have leveraged the power of digital pathology and computational modeling
to develop a new approach to detecting and quantifying podocytes.

The cloud-based tool, called the "PodoSighter," is described in a paper in the Journal of the American Society of
Nephrology; the research is being highlighted on the cover of the journal's November issue.

 The project is an example of how advanced computational capabilities are allowing scientists to glean new
information from complex images of anatomical structures.

Understanding Human Systems

 "In the medical domain, understanding human systems depends on analyzing huge amounts of very different types
of data," said Pinaki Sarder, Ph.D., senior author on the paper and associate professor of pathology and anatomical
sciences in the Jacobs School of Medicine and Biomedical Sciences. "The question is, how do we combine all
these data to try and understand fundamental human systems and disease?"

 Working in the emerging area of computational nephropathology, Sarder and his colleagues are focused on
developing a better understanding of the information found in images of kidney biopsy samples.

 "It's been known for decades that the quantity and density of podocytes are important both for diagnosis and
prognosis of end-stage kidney disease," said Darshana Govind, Ph.D., first author, who did her doctoral work in
Sarder's lab. She is now a data scientist at Janssen Pharmaceuticals.

                                                                                                           Page 2 of 3
                    The 'PodoSighter' uses AI to identify a key indicator of early kidney disease

 In the early stages of kidney disease, podocytes begin to change shape and, as the disease progresses, the
number of them will fall.

 "A healthy person has more podocytes than a sick person," Sarder explained. "If one day we can track the loss of
podocytes, then we can determine the stage of the disease."

Right now, that's not possible, but it's one of the goals of the UB research.

 One of the biggest challenges in dealing with images of biopsied tissue is that they contain huge amounts of data.
The additional challenge with podocytes is that they are found deep within the glomeruli, the sac-like bundles of
capillaries that handle first-line filtration of blood in the kidneys.

 "It's very challenging to identify podocytes in an image," Govind explained, noting there are so many cells in the
glomerulus that it's hard even for trained pathologists to figure out which nuclei belong to podocytes. Different types
of staining can be used to highlight the podocytes, but sometimes the staining causes other important image
information to be lost.

Convolutional Neural Networks

 The solution they developed is to use a machine learning technique called convolutional neural networks, a
learning algorithm that can distinguish specific objects in an image. It was developed based, to a certain degree, on
the ways that the visual cortex in the human brain processes visual information.

The technique involves essentially "training" the computer to detect podocytes.

 "The tissue is prepared in the clinic and the AI-based method detects it for you," Govind said. "You click a button,
and the podocytes are identified."

Density information is also provided.

 "The PodoSighter not only detects podocytes, but it spits out a report on how many of these cells are identified in
each glomerulus and what the density is, a key indicator for disease progression," Sarder said. He explained that,
as kidney disease progresses, the glomerulus grows in size while the number of podocytes goes down.

 Currently primarily a research tool, the PodoSighter can work on samples from both animals and humans. The goal
is to eventually get this into routine use in clinics for human use, which the researchers say may be possible in just
a few years.

The researchers conducted some of their work at the Center for Computational Research at UB.

Sarder added there is tremendous potential for this kind of research that utilizes artificial intelligence in medicine.

 "One of my goals at UB is not only to do research but also to develop a workforce, and that's very important," he
said. "Dr. Govind has done excellent, very difficult work for her Ph.D. and has been published in a top journal."

He noted that, while it's improving, there still aren't many women working in artificial intelligence right now.

 "It's challenging," Govind said, "because you don't see a lot of women in the field. I'd like to see more women join
STEM and data science. It's a great field to be in. It's hard to be one female in a room full of men, so I encourage
more women to join AI teams. There's a lot of cutting-edge research and you're literally changing lives, using AI
applied to health care."

 This project was supported by several grants from the National Institute of Diabetes and Digestive and Kidney
Diseases of the National Institutes of Health, including a Kidney Precision Medicine Project grant and a grant from
the Human BioMolecular Atlas Program.

                                                                                                    Page 3 of 3
                    The 'PodoSighter' uses AI to identify a key indicator of early kidney disease

 In addition to Sarder and Govind, other UB co-authors are Jeffrey Miecznikowski, Rabi Yacoub, Brendan Lutnick,
Amber Worral, Imtiaz Mohammad and John Tomaszewski. Other co-authors are from University Hospital Cologne;
Johns Hopkins University; Université de Paris; Kitware Inc.; University Hospital Hamburg Eppendorf; University
Hospital Essen; University of California San Francisco; and University of California Davis.


Load-Date: November 4, 2021


  End of Document

                                                                                                        Page 1 of 3
                        The 'PodoSighter' uses AI to identify a key indicator of early kidney disease




 The 'PodoSighter' uses AI to identify a key indicator of early kidney disease
                                          Lewiston-Porter Sentinel (Lewiston, New York)
                                                        October 29, 2021



Copyright 2021 Niagara Frontier Publications
Distributed by Newsbank, Inc. All Rights Reserved

Section: CURRENT NEWS
Length: 959 words

Body


Journal is highlighting this artificial intelligence advance on the cover of the November issue

By the University at Buffalo

 In the early stages of kidney disease, a specialized type of kidney cell called the podocyte undergoes damaging
changes in both its structure and function. Those changes are key indicators of the ultimately devastating damage
that end-stage renal disease can cause, but these specialized cells are difficult to detect.

 Now, University at Buffalo researchers have leveraged the power of digital pathology and computational modeling
to develop a new approach to detecting and quantifying podocytes.

The cloud-based tool, called the "PodoSighter," is described in a paper in the Journal of the American Society of
Nephrology; the research is being highlighted on the cover of the journal's November issue.

 The project is an example of how advanced computational capabilities are allowing scientists to glean new
information from complex images of anatomical structures.

Understanding Human Systems

 "In the medical domain, understanding human systems depends on analyzing huge amounts of very different types
of data," said Pinaki Sarder, Ph.D., senior author on the paper and associate professor of pathology and anatomical
sciences in the Jacobs School of Medicine and Biomedical Sciences. "The question is, how do we combine all
these data to try and understand fundamental human systems and disease?"

 Working in the emerging area of computational nephropathology, Sarder and his colleagues are focused on
developing a better understanding of the information found in images of kidney biopsy samples.

 "It's been known for decades that the quantity and density of podocytes are important both for diagnosis and
prognosis of end-stage kidney disease," said Darshana Govind, Ph.D., first author, who did her doctoral work in
Sarder's lab. She is now a data scientist at Janssen Pharmaceuticals.

                                                                                                           Page 2 of 3
                    The 'PodoSighter' uses AI to identify a key indicator of early kidney disease

 In the early stages of kidney disease, podocytes begin to change shape and, as the disease progresses, the
number of them will fall.

 "A healthy person has more podocytes than a sick person," Sarder explained. "If one day we can track the loss of
podocytes, then we can determine the stage of the disease."

Right now, that's not possible, but it's one of the goals of the UB research.

 One of the biggest challenges in dealing with images of biopsied tissue is that they contain huge amounts of data.
The additional challenge with podocytes is that they are found deep within the glomeruli, the sac-like bundles of
capillaries that handle first-line filtration of blood in the kidneys.

 "It's very challenging to identify podocytes in an image," Govind explained, noting there are so many cells in the
glomerulus that it's hard even for trained pathologists to figure out which nuclei belong to podocytes. Different types
of staining can be used to highlight the podocytes, but sometimes the staining causes other important image
information to be lost.

Convolutional Neural Networks

 The solution they developed is to use a machine learning technique called convolutional neural networks, a
learning algorithm that can distinguish specific objects in an image. It was developed based, to a certain degree, on
the ways that the visual cortex in the human brain processes visual information.

The technique involves essentially "training" the computer to detect podocytes.

 "The tissue is prepared in the clinic and the AI-based method detects it for you," Govind said. "You click a button,
and the podocytes are identified."

Density information is also provided.

 "The PodoSighter not only detects podocytes, but it spits out a report on how many of these cells are identified in
each glomerulus and what the density is, a key indicator for disease progression," Sarder said. He explained that,
as kidney disease progresses, the glomerulus grows in size while the number of podocytes goes down.

 Currently primarily a research tool, the PodoSighter can work on samples from both animals and humans. The goal
is to eventually get this into routine use in clinics for human use, which the researchers say may be possible in just
a few years.

The researchers conducted some of their work at the Center for Computational Research at UB.

Sarder added there is tremendous potential for this kind of research that utilizes artificial intelligence in medicine.

 "One of my goals at UB is not only to do research but also to develop a workforce, and that's very important," he
said. "Dr. Govind has done excellent, very difficult work for her Ph.D. and has been published in a top journal."

He noted that, while it's improving, there still aren't many women working in artificial intelligence right now.

 "It's challenging," Govind said, "because you don't see a lot of women in the field. I'd like to see more women join
STEM and data science. It's a great field to be in. It's hard to be one female in a room full of men, so I encourage
more women to join AI teams. There's a lot of cutting-edge research and you're literally changing lives, using AI
applied to health care."

 This project was supported by several grants from the National Institute of Diabetes and Digestive and Kidney
Diseases of the National Institutes of Health, including a Kidney Precision Medicine Project grant and a grant from
the Human BioMolecular Atlas Program.

                                                                                                    Page 3 of 3
                    The 'PodoSighter' uses AI to identify a key indicator of early kidney disease

 In addition to Sarder and Govind, other UB co-authors are Jeffrey Miecznikowski, Rabi Yacoub, Brendan Lutnick,
Amber Worral, Imtiaz Mohammad and John Tomaszewski. Other co-authors are from University Hospital Cologne;
Johns Hopkins University; Université de Paris; Kitware Inc.; University Hospital Hamburg Eppendorf; University
Hospital Essen; University of California San Francisco; and University of California Davis.


Load-Date: November 4, 2021


  End of Document

                                                                                                        Page 1 of 3
                        The 'PodoSighter' uses AI to identify a key indicator of early kidney disease




 The 'PodoSighter' uses AI to identify a key indicator of early kidney disease
                                               Island Dispatch (Grand Island, New York)
                                                          October 29, 2021



Copyright 2021 Niagara Frontier Publications
Distributed by Newsbank, Inc. All Rights Reserved

Section: SCHOOL
Length: 959 words

Body


Journal is highlighting this artificial intelligence advance on the cover of the November issue

By the University at Buffalo

 In the early stages of kidney disease, a specialized type of kidney cell called the podocyte undergoes damaging
changes in both its structure and function. Those changes are key indicators of the ultimately devastating damage
that end-stage renal disease can cause, but these specialized cells are difficult to detect.

 Now, University at Buffalo researchers have leveraged the power of digital pathology and computational modeling
to develop a new approach to detecting and quantifying podocytes.

The cloud-based tool, called the "PodoSighter," is described in a paper in the Journal of the American Society of
Nephrology; the research is being highlighted on the cover of the journal's November issue.

 The project is an example of how advanced computational capabilities are allowing scientists to glean new
information from complex images of anatomical structures.

Understanding Human Systems

 "In the medical domain, understanding human systems depends on analyzing huge amounts of very different types
of data," said Pinaki Sarder, Ph.D., senior author on the paper and associate professor of pathology and anatomical
sciences in the Jacobs School of Medicine and Biomedical Sciences. "The question is, how do we combine all
these data to try and understand fundamental human systems and disease?"

 Working in the emerging area of computational nephropathology, Sarder and his colleagues are focused on
developing a better understanding of the information found in images of kidney biopsy samples.

 "It's been known for decades that the quantity and density of podocytes are important both for diagnosis and
prognosis of end-stage kidney disease," said Darshana Govind, Ph.D., first author, who did her doctoral work in
Sarder's lab. She is now a data scientist at Janssen Pharmaceuticals.

                                                                                                           Page 2 of 3
                    The 'PodoSighter' uses AI to identify a key indicator of early kidney disease

 In the early stages of kidney disease, podocytes begin to change shape and, as the disease progresses, the
number of them will fall.

 "A healthy person has more podocytes than a sick person," Sarder explained. "If one day we can track the loss of
podocytes, then we can determine the stage of the disease."

Right now, that's not possible, but it's one of the goals of the UB research.

 One of the biggest challenges in dealing with images of biopsied tissue is that they contain huge amounts of data.
The additional challenge with podocytes is that they are found deep within the glomeruli, the sac-like bundles of
capillaries that handle first-line filtration of blood in the kidneys.

 "It's very challenging to identify podocytes in an image," Govind explained, noting there are so many cells in the
glomerulus that it's hard even for trained pathologists to figure out which nuclei belong to podocytes. Different types
of staining can be used to highlight the podocytes, but sometimes the staining causes other important image
information to be lost.

Convolutional Neural Networks

 The solution they developed is to use a machine learning technique called convolutional neural networks, a
learning algorithm that can distinguish specific objects in an image. It was developed based, to a certain degree, on
the ways that the visual cortex in the human brain processes visual information.

The technique involves essentially "training" the computer to detect podocytes.

 "The tissue is prepared in the clinic and the AI-based method detects it for you," Govind said. "You click a button,
and the podocytes are identified."

Density information is also provided.

 "The PodoSighter not only detects podocytes, but it spits out a report on how many of these cells are identified in
each glomerulus and what the density is, a key indicator for disease progression," Sarder said. He explained that,
as kidney disease progresses, the glomerulus grows in size while the number of podocytes goes down.

 Currently primarily a research tool, the PodoSighter can work on samples from both animals and humans. The goal
is to eventually get this into routine use in clinics for human use, which the researchers say may be possible in just
a few years.

The researchers conducted some of their work at the Center for Computational Research at UB.

Sarder added there is tremendous potential for this kind of research that utilizes artificial intelligence in medicine.

 "One of my goals at UB is not only to do research but also to develop a workforce, and that's very important," he
said. "Dr. Govind has done excellent, very difficult work for her Ph.D. and has been published in a top journal."

He noted that, while it's improving, there still aren't many women working in artificial intelligence right now.

 "It's challenging," Govind said, "because you don't see a lot of women in the field. I'd like to see more women join
STEM and data science. It's a great field to be in. It's hard to be one female in a room full of men, so I encourage
more women to join AI teams. There's a lot of cutting-edge research and you're literally changing lives, using AI
applied to health care."

 This project was supported by several grants from the National Institute of Diabetes and Digestive and Kidney
Diseases of the National Institutes of Health, including a Kidney Precision Medicine Project grant and a grant from
the Human BioMolecular Atlas Program.

                                                                                                    Page 3 of 3
                    The 'PodoSighter' uses AI to identify a key indicator of early kidney disease

 In addition to Sarder and Govind, other UB co-authors are Jeffrey Miecznikowski, Rabi Yacoub, Brendan Lutnick,
Amber Worral, Imtiaz Mohammad and John Tomaszewski. Other co-authors are from University Hospital Cologne;
Johns Hopkins University; Université de Paris; Kitware Inc.; University Hospital Hamburg Eppendorf; University
Hospital Essen; University of California San Francisco; and University of California Davis.


Load-Date: November 4, 2021


  End of Document

                                                                                                       Page 1 of 3
                                            Big Tech swallows most of the hot AI startups




                            Big Tech swallows most of the hot AI startups
                                                        Chicago Daily Herald
                                                      March 22, 2020 Sunday
WEB EditionNC1 EditionNC2 EditionMF12 EditionNC3 EditionNM1 EditionNC EditionNC14 EditionMC1 EditionMC3
       EditionMD1 EditionML2 EditionNL1 EditionNC14C EditionNC4 EditionCLFM EditioneBlast Edition



Copyright 2020 Paddock Publications, Inc.

Section: BUSINESS; Pg. 0
Length: 1260 words
Byline: Dina Bass and Joshua Brustein Bloomberg

Body


In 2016, Seattle-based startup Turi was helping almost 100 customers create and manage software that uses
machine learning, a powerful type of artificial intelligence. Its technology was so promising that Apple Inc. snapped
it up for $200 million. The deal was a triumph for investors and founders, but one backer thought Turi — and the
broader tech industry — might be better off if the startup had spurned Apple's advances. Matt McIlwain, managing
director at Madrona Venture Group, said it's important that at least some emerging tech businesses remain
independent, rather than falling into the arms of Apple, Amazon.com Inc., Facebook Inc., Google or Microsoft Corp.

"It is economically beneficial to society to have more stand-alone, independent companies. We generally think that's
better than just having these companies consolidated into larger ones," McIlwain said. "There have to be some in
each era that are willing to take the risk and stand the test of time as independent companies so we have the next
generation of leading platforms." Regulators and lawmakers are investigating whether the largest U.S. technology
companies have become too powerful. Acquisitions are a major part of the probes, with the Federal Trade
Commission re-examining hundreds of small deals from the previous decade made by Apple, Amazon, Facebook,
Google and Microsoft. Artificial intelligence is a prime example of an important technology field where the majority
of promising startups have been gobbled up, frequently ending public availability of any products they created. Last
year saw a record 231 acquisitions of AI startups, up from 42 in 2014, according to data from CB Insights. Apple
has been the top acquirer since 2010, followed by Google, Microsoft, Facebook, Intel Corp. and Amazon. "If big
tech companies buy them all up, they eliminate these future competitors, and have a chance of actually owning the
winners," said Sean Gourley, chief executive officer of machine-learning startup Primer AI. "It's a real shame. We
lost something. There may have been different approaches in this field, but now we only have what these larger
companies decide." Bloomberg Beta, the venture capital arm of Bloomberg LP, is an investor in Primer AI. It's
particularly important to have a broad, diverse community developing AI because the technology is informing more
decisions and has been susceptible to bias, according to researchers. Representatives for Turi and Apple declined
to comment, as did Amazon, Facebook, Google and Microsoft. Apart from consolidating promising technology,
many of the acquisitions were done to amass talent. There's a shortage of workers with experience in deep learning
and machine learning, and many companies, not just in tech, are competing for these specialists. Google's 2013
purchase of DNNResearch brought deep-learning godfather Geoffrey Hinton to the internet giant. In 2014, Google

                                                                                                          Page 2 of 3
                                    Big Tech swallows most of the hot AI startups

also snapped up DeepMind, a London research outfit led by Demis Hassabis that used software to beat the best
players at the strategy game Go and is working on health applications for AI. The industry's deal spree has raised
concern that the biggest technology companies have a lock on brain power in a field that's considered critical to the
future of computing, global competitiveness and even military supremacy. "It's the most important technology we
will see in our lifetime," said Diego Oppenheimer, CEO of Seattle-based Algorthimia, which provides a marketplace
for machine-learning algorithms. "When you look at it that way, if it is concentrated on the few, it's going to be really
hard to compete with those few." At least some of the motivation behind the acquisition of smaller AI firms has to be
more than talent hoarding, according to Frederic Laurin, partnership director at Mila, a prominent Montreal-based
deep learning research lab. "The other potential explanation is they see those firms as competitors," he said. For
startups, selling can be the best option when promising technology is failing to become a real business. Joining a
larger company can provide a bigger audience for a startup's ideas, along with more resources to develop products
quicker. Giants such as Google and Facebook have massive data sets that are crucial for training AI models, for
instance. "It's easy to get funding for an AI startup, or at least it was. Easier than translating an idea into revenue,
so the exit often becomes an acquisition," said Babak Hodjat, who invented some of the technology that became
Apple's Siri digital assistant and sold parts of his AI company Sentient Technologies to outsourcing giant Cognizant
Technology Solutions Corp. last year. Before Apple bought Turi, venture capital firm Opus Capital backed the
startup because it had an "awesome product and a very technically sharp team," said Preeti Rathi, who was at
Opus at the time. But the market wasn't ready for the technology, she said. "When a good team meets a not-ready
market, it takes a lot of capital," said Rathi, who is now a general partner at Icon Ventures. "Startups don't typically
have that much cash," so the Apple sale was a good outcome for Turi, she added. One new reason AI startups look
to be acquired by a big patron is the cost of computing power. As AI models get more complex, startups are paying
a lot for cloud computing services to train and run those models. And they often pay their rivals, Amazon, Microsoft
and Google, which are the dominant cloud providers. This is pricing smaller firms out of the space, said Laurin of
Mila, the Montreal-based deep-learning lab. Even Mila, with 450 researchers and support from several universities,
can't keep up sometimes, Laurin said. Yoshua Bengio, a deep-learning pioneer and scientific director at Mila, has
told Laurin that there are research papers from Google and Facebook that Mila can't replicate because it doesn't
have access to the same computing power. In 2015, Elon Musk, Sam Altman and other technologists helped start
nonprofit research group OpenAI with a $1 billion commitment because they were concerned about big tech
companies dominating such an important technology. Now OpenAI has started a for-profit arm and taken a $1
billion investment from Microsoft partially to fund the intensive computing needs its work requires. Still, some
promising AI startups have stayed independent, and new ones are being formed all the time. There were 2,235
venture capital AI funding deals last year worth a total of $26.6 billion, according to CB Insights, which also counted
24 AI unicorns — companies valued at $1 billion or more. "New startups are emerging every day, some of which
are building large businesses and will emerge as leaders," said Rathi. "This is despite the current generation of
incumbent competitors — Google, Amazon, etc. — that are quite formidable." Madrona's McIlwain casts an envious
eye at data and machine-learning software firm Databricks which is now valued at more than $6 billion and has a
customer list that includes Cisco Systems Inc., HP and ViacomCBS. Turi may have become more valuable if it too
had stayed independent, he said, but it also could have gone worse. It's been a hard road for other AI
independents. Employees at Clarifai, founded in 2013, were initially confident they had found a defensible niche.
Instead, the company struggled to maintain momentum. Last year, the startup cut about 20% of its staff, according
to two people familiar with the situation. Clarifai Founder and CEO, Matt Zeiler, didn't respond to requests for
comment.



Graphic


Regulators and lawmakers are investigating whether the largest U.S. technology companies have become too
powerful. Acquisitions are a major part of the probes, with the Federal Trade Commission re-examining hundreds of
small deals from the previous decade made by Apple, Amazon, Facebook, Google and Microsoft. (AP Photo/Kathy
Willens, File)

                                                                            Page 3 of 3
                            Big Tech swallows most of the hot AI startups


Load-Date: March 23, 2020


  End of Document

                                                                                                        Page 1 of 2
                                              Adventist nurses receive a gift of gratitude




                                Adventist nurses receive a gift of gratitude
                                                        The Bakersfield Californian
                                                        November 8, 2021 Monday



Copyright 2021 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 390 words
Byline: John Cox, The Bakersfield Californian

Body


Nov. 8—It's not just the thought that counts. The caffeine scores points, too.

A local medical specialist who worries people are beginning to forget the invaluable contributions of health-care
workers on Monday delivered a special gift to the nursing staff of Adventist Health Bakersfield on Chester Avenue.

With close to a dozen masked nurses lined up behind him near the main entrance of the hospital, Stockdale
Podiatry owner Dr. Brandon Hawkins presented a gift of 900 Starbucks gift cards, each good for $5.

That's $4,500 worth of java for a hard-working group of people he says have helped the community through the
pandemic, largely without much fanfare as public recognition of the crisis seems to be fading.

"We have appreciated our nurses and we feel like they have not been appreciated in our community," said
Hawkins, who also works at the hospital.

He added that his gift carries a message for the rest of the community: Don't forget about the health-care workers
on whom the pandemic has been especially hard.

About two years ago Hawkins and his wife donated a quarter of a million dollars to help pay for the Estella
Espericueta Memorial Garden at the nearby Adventist Health AIS Cancer Center. Hawkins said Monday it felt like
time to do something more especially for nurses.

"They have long hours (and a) hard job," he said. "Just thinking about others instead of ourselves is definitely a
gesture we wanted to do."

The hospital's nurse leader, Heather Von Housen, said the gift cards will provide literal fuel to people working long
hours to keep others alive and healthy day in, day out.

But more than that, she said it serves as recognition that, with more than 60 COVID-19 patients still being treated at
the Adventist Health Bakersfield campus Monday, the pandemic isn't over.

                                                                                                         Page 2 of 2
                                      Adventist nurses receive a gift of gratitude

"It's really hard work and I'm not sure that the general public knows," she said, adding that members of the general
public have shown waves of support for health-care workers but that the gratitude seems to have waned despite
the continuing need for committed nurses.

"I'm just so proud of them," Von Housen said. "They are hard-working, humble and doing sacred work."

___ (c)2021 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: November 9, 2021


  End of Document

                                                                                                           Page 1 of 18
                        Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference




    Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference
                                                        New York Observer
                                                    January 13, 2020 Monday



Copyright 2020 The New York Observer, L.P. All Rights Reserved

Length: 12487 words
Byline: Arick Wierson and Beau Draghiciu

Body


On Monday, January 13, like a swarm of honey bees, thousands of health tech entrepreneurs, health care execs,
venture capitalists, bankers, regulators and business media will descend upon downtown San Francisco as the 38th
Annual J.P. Morgan Healthcare Conference gets under way. And, as is the case with any multi-day industry
gathering worth its salt, an entire ecosystem of satellite events has popped up around the main attraction, which
has created a seemingly endless circuit of networking events, summits and other health care-related shindigs-all
offering ample excuses to down lattes during the day and throw back a shot or two at night.

Even though only a select few are invited to attend the official main stage, marking one's presence at J.P. Morgan
is paramount, as the four-day confab has positioned itself as not only the first, but perhaps the most important event
of the global health care conference calendar year.

SEE ALSO: Revel Is Rewriting the Playbook on How Health Plans Talk to You

Ahead of last year's J.P. Morgan gathering, Observer was among the first to point out a trend that was beginning to
emerge across the health industry-the rise in interest from both large health care players, as well as hungry
venture capitalists, for health tech plays originating in cities not typically associated with startup culture, places like
Minneapolis, Nashville and Chicago. Observer even coined a new term for these disruptors from Middle America:
Flyover Tech.

And, judging by the pre-conference buzz, by all accounts, last year was not a fluke; many of the entries from the
2019 list have emerged as some of the biggest and most important players in their respective sectors over the past
12 months. Some of them have even carved out completely new niches within the vast health care ecosystem that
didn't exist a year ago.

As some informed observers of the high-flying health tech space quipped, "Flannel is the New Black," when it
comes to innovation in health care and big bets in health tech.

Take for example Bind, a Minneapolis-based startup health plan that has already raised a jaw-dropping $82 million.
After occupying last year's top position on the list for its ability to use data science and artificial intelligence (AI) to
analyze existing claims data, Bind had a banner year. The company has been expanding its services across
multiple new areas of coverage, while empowering customers to understand what they are really paying for with
their health plans, which makes it easy to compare treatment options, prices and quality. Bind, along with fellow

                                                                                                      Page 2 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

Minnesota wunderkind health insurance startup              Bright Health-which just announced the closing of
$635 million in Series D financing in December, on top of over $400 million of funding in previous rounds (putting its
total raise now over the billion dollar mark)-have chiseled out completely new offerings in the health insurance
space, a sector that, less than a decade ago, was considered nearly impenetrable due to the vast resources
needed to scale a business of that nature.

"It still amazes me the number of investors that haven't taken full advantage of the 'flyover tech' ecosystem,"
observed Jodi Hubler, managing director of Lemhi Ventures, a venture capital firm that invests primarily in early- to
mid-stage health companies in the Midwest and Rocky Mountain regions. "Many places in Middle America are
actually centers of innovation and deep domain knowledge not only in health care, but in medtech device and
services as well," added Hubler, referring to the largest players in health care and medtech, like UnitedHealth
Group, Medtronic, Cardinal Health, Humana and Anthem-all of which have main bases of operations in between
the coasts.

"It's common sense economics-every dollar of capital goes further in these locations, and the access to talent from
developers to board members comes with differentiated experience and knowledge," Hubler told Observer. "In
places like the Midwest, people don't play in health care, they've lived it... that experience and intuition is
invaluable."

Another big winner from last year's list was Nashville-based SmileDirectClub, a tele-dentistry startup that produces
direct-to-consumer 3D-printed clear aligners. In September, the teeth-straightening startup went public,
raising more than $1.3 billion at an initial market cap of roughly $10 billion, more than three times its most recent
private valuation. And although the stock price has since clawed back some of those ebullient IPO gains, it's yet
another shining example of a flyover tech success story.

Flyover Tech Is Now a 'Badge of Honor' in Health Tech

For serial health care entrepreneur and founder of San Francisco-based Roam Analytics Alex Turkeltaub, there is
gold to be mined in Middle America. "Hubs like Raleigh, Columbus and Nashville, just to name a few, are quickly
becoming known as exciting centers of innovation in health care. With strong legacy technology and health care
systems, it's only natural that these local ecosystems will fuel the next generation of disruptors in digital health,"
observed Turkeltaub, who recently stepped down as CEO of Roam and is setting up a venture fund that focuses on
the         intersection of AI and health care. The fund will look to make strategic investments in major health tech
hubs across the country, as well as in emerging overseas markets like Brazil.

"The term 'flyover' used to be somewhat derogatory, but now it's a badge of honor in health tech. Entrepreneurs in
the middle of the country know that technology can't exist for its own sake; it has to be combined with functional
business models to deliver real value to patients and investors alike," added Turkeltaub. "Any serious health care
VC who isn't making monthly visits to places like Minneapolis or Chicago is completely missing the boat."

Chicago, Nashville and Minneapolis Are Emerging as the New 'Silicon Valleys' of Health Tech

Although there are entries on this year's list from a wide swath of cities across the country, experts and insiders
repeatedly point to the surfeit of companies emerging from three major hubs of innovation in health care from
Middle America: Nashville, Chicago and the Twin Cities of Minneapolis and St. Paul.

"With a diverse set of headquartered legacy companies spanning the entire spectrum of health care, regional hubs
such as Nashville, Chicago and Minneapolis will continue to produce industry-leading innovation and transformation
in the sector. These are the new hotbeds in health care," noted Sara Ratner, a veteran health care industry insider
who is one of the nation's foremost experts on government-run Medicare and Medicaid programs.

Observer spoke with health care experts from across the U.S. to offer their thoughts about the biggest emerging
trends at the 2020 J.P. Morgan Healthcare Conference and the sector's continued interest in flyover tech. They
were also asked to highlight some of the hottest companies in between the two coasts that will be feted in San
Francisco this week. Like last year, the current list is not a ranking in the traditional sense-the companies singled

                                                                                                       Page 3 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

out are in different stages of development and growth and, for the most part, are positioned in non-competing
verticals; rather, the list is a snapshot of 20 early- to mid-stage startups that have caught the attention of health
care insiders from around the globe and have one thing in common: they all hail from what many a New Yorker
might describe as 'flyover country.'

And now, here is Observer's 20 Hottest Companies in 'Flyover Tech' at the 2020 J.P. Morgan Healthcare
Conference.

1. HistoSonics (Ann Arbor, Michigan); Capital Raised: $87 Million

Non-invasive cancer treatment. Let those words sink in. By using technology similar to an ultrasound, this new
interventional therapy will transform nearly all forms of cancer detection and eradication. In some respects, the
company's flagship product is not unlike the "healing machine"-the technology central to the plot to the 2013 Matt
Damon thriller Elysium set 134 years in the future.

Led by veteran health care executive Mike Blue, the company's non-invasive robotics platform and novel sonic
beam therapy is awaiting full FDA clearance, but the company has already announced reams of promising new
clinical and preclinical data, including successful human trials in Spain. In April of last year, HistoSonics closed a
$54 million C-Round led by Varian Medical Systems, Inc., the global leader in radiation therapy and oncology
solutions, and included          Johnson & Johnson Innovation and the          State of Wisconsin Investment Board,
among others. Initially targeting liver and pancreatic cancer, HistoSonics' Robotically Assisted Sonic Therapy
(RASTSM) combines advanced robotics and imaging with a proprietary sensing technology to deliver personalized
treatments with unparalleled precision and control. In layman's terms, the tech uses sound energy to generate
pressures strong enough to liquify and completely destroy targeted tissues at sub-cellular levels.

Meanwhile, HistoSonics is busy building a new HQ in a Minneapolis suburb. "Our tech was born in the labs of the
University of Michigan, but we quickly realized we needed to be at the epicenter of health care innovation, which is
why we decided to move our base to Minnesota," explained Blue. "This is where all the action is right now in health
tech."

2. Olive AI (Columbus, Ohio); Capital Raised: $72.8 Million

Over one trillion dollars are spent every year in the U.S. on health care administration. Not on doctors, needles,
meds or IVs, but on pens, paper, IT and something called 'system integration.' It's a huge outlay-and the fact that
much of that spend could be better directed toward treating patients and saving lives is what constitutes the driving
force behind Ohio-based startup Olive AI.

CEO Sean Lane and the team at Olive understand that hospital employee time is money, which is why in the last
year, their AI-powered workforce has become the utility player for over 500 individual hospitals around the U.S.,
handling high-volume, administrative workloads. Olive's automated workforce takes on the minutia of the often
repetitive paperwork that plagues nearly all sectors of health care-from human resources and IT to supply chain
management and revenue cycle tracking-allowing employees to focus on the important, big picture aspects of their
work. Convenient, efficient, fast and accurate, Olive AI is an overworked employee's dream assistant, and the
venture world, which has plowed over $70 million into the company thus far, seems to agree.

3. NightWare (Minneapolis, Minnesota); Capital Raised: Undisclosed

The highly secretive NightWare was on last year's hot list, and while it is still not disclosing its fundraising totals
(one of the advantages of not raising with institutional investors), the company continues to make big strides in the
treatment of PTSD and nightmare disorder, a condition affecting over five million Americans and hundreds of
thousands of U.S. vets. Over the past 12 months, NightWare received official "Breakthrough Status" designation by
the FDA, which is only given to treatments that, according to the FDA, "demonstrate substantial improvement on a
clinically significant endpoint over available therapies." In plain English, NightWare might very well become the first
prescribable digital therapeutic for a key symptom of PTSD. It's a big deal coming to an Apple Watch near you.

                                                                                                      Page 4 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

4. Eyesafe (Eden Prairie, Minnesota); Capital Raised: $9 Million

Projecting Apple's resurgence and ultimate market dominance in consumer tech, years before the iPhone, made
tech-watcher Gene Munster something of an oracle on Wall Street. Now a founding partner at tech-focused VC
Loup Ventures, Munster has become a regular fixture on the business news circuit as he shares his hot takes on
Tesla, Apple, Amazon and the tech industry at large. Munster believes            Eyesafe, a privately held company
that is advancing consumer electronics with its blue light protection technology, has become an influential player,
building standards for safeguarding users' eyes from the intense, albeit invisible, blue light that Harvard Medical
School says "       has a dark side."

"I don't have a financial stake directly or indirectly in Eyesafe," cautioned Munster. "But brands like Dell, HP and
Lenovo are becoming increasingly aware of the health dangers posed by blue light. Eyesafe sits atop a very short
list of solutions that large tech companies are turning to for help in designing and implementing safer displays that
maintain color performance. While nascent today, Eyesafe's long-term addressable market is significant, given that
over time, some form of blue light protections will likely be mandated in all displays."

In fact, Eyesafe has already cut impressive deals with Dell and aftermarket screen-protector leader ZAGG,
distributed in Verizon, AT&T and T-Mobile stores across the nation, as well the major component suppliers in the
electronics industry. And with the passage of the State of California's recent "Blue Light Resolution," it seems
Munster's prediction of regulation is happening fast, putting Eyesafe in pole position to own the low blue light
market and, in the process, seize the mantle as the "          Intel Inside" of health and safety across consumer
electronics.

5. MyMeds (Minneapolis, Minnesota); Capital Raised: $8 Million

Your doctor prescribes some medication and tells you to pick it up at the local pharmacy. Once you show up at the
Duane Reade or CVS, an officious-looking individual in a white lab coat gives you a brief glimpse of an amber
colored pill container, mumbles a word or two of advice and then places your prescription in a white bag, along with
an intimidating piece of paper full of fine print, sending you on your way. Now, you are on your own; it's just you, a
dozen or so pills, and a piece of paper written by a lawyer who went to medical school, or maybe the other way
around.

Sound familiar? Today's medication experience is broken, and with the phenomenon of medication non-adherence
emerging as the biggest issue driving up health care costs across the entire sector, MyMeds is bringing to market a
suite of solutions unlike any other in the digital health space.

"We are redefining the medication experience so people are never alone and always have access to their own
data," said MyMeds founder and CEO Dr. Rajiv Shah, whose company was recently selected to join SAP's
prestigious accelerator program in New York City. "Our patented Digital + Human ACE Medication Experience is an
ecosystem that connects patients, caregivers, providers and payors in real-time." In more plain speak, Shah's
MyMeds is laying pipe that connects doctor, pharmacist, you and your health insurance in ways that have never
been possible before, savings costs and ensuring better health outcomes.

The experts Observer spoke to believe that 2020 will be a breakout year for MyMeds, as it rolls out its integration
with SAP, launches a new real-time Medicare Stars product and unfurls the much-anticipated MyMeds
Connect(TM), a secure real-time prescription data connectivity engine-a real game changer in light of Washington's
focus on medication history data rights. According to Fox Business Network analyst Ethan Bearman, who follows
the booming medication non-adherence space, MyMeds has the potential to become a billion-dollar company in the
coming years.

"Some health companies are really smart with their tech or business model, while others are just plain lucky in that
the regulatory environment sways in their direction at just the right time," Bearman told Observer. "MyMeds is both
smart and lucky, which is why it wouldn't surprise me if Dr. Raj is able to launch his own version of Tres Comas
Tequila sometime in the next few years."

                                                                                                       Page 5 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

6. Regroup + InSight (Chicago, Illinois); Capital Raised: $19 Million + Undisclosed Private Equity Backing

While it may be unorthodox for two companies to be named in one spot, a recent merger between Regroup
Telehealth and InSight Telepsychiatry deserves the spotlight. The two companies merged in late 2019, and the
combined company is now packing a lot of heat, making it one of the largest and most comprehensive
telepsychiatry service providers in the U.S. The new entity is tackling mental health care disparities head on with
their unique suite of individualized telehealth services.

Many times, being geographically, economically or socially isolated means that patients with mental health issues
don't have access to the specialized psychiatric care that they require. Regroup + Insight is connecting patients
from one end of the country to the doctors and specialists they need to see, irrespective of their physical location.
With a high-capacity data pipe from the physicians' location to the clinical setting, the Regroup + Insight tie-up
enables doctors to treat, consult and prescribe medication from afar and coordinate remotely with the patient's local
health care support team.

Like several other companies on both this year's and last year's lists, Regroup was born inside of Chicago's Health
Incubator, Matter, which has emerged as a breeding ground for some of the most innovative and fast-growing
companies in digital health. Now all their C-Suite needs to do is come up with a name for the new combined entity.

7. Revel Health (Minneapolis, Minnesota); Capital Raised: $17 Million

Revel Health is rewriting the playbook for how health plans talk to their members. Gone are the days of the
robocall with a voice that sounds entirely too enthusiastic reminding you that it's time for another prostate exam or a
mailed form letter that looks like an audit notice from the IRS reminding you that it is flu-shot season.

After initially catching Observer's eye late last year, the experts we spoke to were impressed with not only the
company's tech, but also its savvy application into real-world, actionable results. Revel uses lessons that consumer
marketers and Big Retail pioneered and is applying them across the health care marketplace. Revel helps
members stay healthier by connecting them with their health care support system through sophisticated AI, which
culls and analyzes mind-boggling Big Data sets and translates them into personable and highly personalized health
action communication. Under the leadership of veteran health care CEO Jeff Fritz, Revel is leading a revolution in
preventive health care and is quickly becoming a secret weapon for major health plans.

8. Owlet (Lehi, Utah); Capital Raised: $48 Million

Perhaps it isn't a coincidence that Utah-based Owlet Baby Care was started in the same state that has the largest
average household size in the U.S. Or maybe the team at Owlet just knows how hard it is raising a child, much less
two or three, which is why they are betting big that over-protective parents want more than a simple nanny cam to
keep an eye on their brood.

Owlet is gaining traction with a product set that provides parents with real-time, non-invasive video and audio
monitoring, allowing for the child's blood oxygen level, heart rate, temperature and sleeping patterns to be
monitored and tracked by an app easily accessible on any worried parent's smartphone. Founded by a team of
passionate parents in 2013, this Silicon Slopes company is taking the baby monitoring game to an entirely new
level and investors love it.

The company's newest innovation, the Owlet Band Pregnancy Monitor, is on track to be the hottest product in baby-
care tech this year, having already won two distinctive awards at the Consumer Electronics Show for Best
Wearable and Tech to Change the World.

9. PhysIQ (Chicago, Illinois); Capital Raised: $25 Million

PhysIQ can detect the smallest, most subtle changes in an individual's biosensory data and can alert care teams to
potential problems far before they would surface during a regular check-up. The technology enables doctors to see
around corners by applying sophisticated, FDA-cleared physiological analytics to extract personalized health

                                                                                                         Page 6 of 18
                      Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

insights. This Windy City startup uses software that was originally designed for data-tracking on jet engines and
nuclear power plants, where the smallest performance deviations can pose immensely profound dangers. Now,
PhysIQ is taking that same approach to performance calibration and applying it to the human body; it tracks data
around the clock to capture a patient's standard bodily rhythms and tempos and packages the data into neat,
digestible bundles for clinical teams all around the country. Like several other entries on this year's list, PhysIQ is a
product of downtown Chicago's Matter health incubator.

10. Pops! Diabetes (Oak Park Heights, Minnesota); Capital Raised: $8 Million

Siri and Alexa: Meet Mina-every diabetics' new best friend and one of the latest products from Minnesota-based
Pops! Diabetes, a company which is upending the consumer side of the nearly $200 billion global diabetes market.
CEO Lonny Stormo believes that while self-care should take precedence, life oftentimes gets in the way, which is
why his consumer-first approach to diabetes management has focused on platforms such as Mina that can step in
and do important monitoring on a patient's behalf. "Mina sent an alert to my wife when my blood-sugar read 60. She
was able to get in touch with me and my doctor immediately and make sure we addressed the situation promptly,"
Stormo recounted to Observer. "Mina really helps me own my diabetes, and not let the diabetes own me."

Mina is a state-of-the-art chronic care management platform that tracks health management for diabetics and its
always on; cloud-based accessibility means that an individual's care support team, from loved ones to doctors, can
be instantly alerted about a potential crisis by receiving an alert from Mina.

Simplifying the diabetes management business is a huge area of focus for both medtech and health care.

Stormo, a Medtronic alum, will be kicking off a new round of capital raising at this year's J.P. Morgan Healthcare
Conference, and his dance card is filling up quickly. "We have been fortunate to be coming to market just as the
interest in virtual care and diabetes management is near or at the top of the shopping list of many digital health
VCs," offered Stormo.

11. DispatchHealth (Denver, Colorado); Capital Raised: $68 Million

They seem like genius ideas: Need a ride? Hail an Uber. Hungry? Ping GrubHub. But what about if you need a
doctor? Colorado-based DispatchHealth is proving that with technology, on-demand health care at your doorstep is
not only possible, but also a viable business model. In a few taps, via the Disptach app, a board-certified medical
team will come to your home, office or wherever you need them to be, equipped with all the tools necessary to
tackle whatever specialized care you might need.

As access to medical care becomes increasingly consumer-focused, it seems that many health tech investors
believe that visits to traditional brick-and-mortar health care facilities will be reserved only for the most serious of
situations.

12. Learn to Live (Minneapolis,Minnesota); Capital Raised: $9 Million

There is no shortage of well-funded startups looking to stake out their own territory in the red-hot digital mental
health therapy space. Health plans, large employers and universities, governments and branches of the military, as
well as the VA, among many others, are keen to offer online CBT (cognitive behavioral therapy) to their members,
students and employees.

In a recent Observer profile of the digital mental health space, Learn to Live was highlighted as one of the
innovators in the sector, pushing the industry to adopt more serious, evidenced-based approaches to digital mental
health treatment in contrast to many of its competitors, which, despite having raised significant amounts of capital,
seem to be dabbling in what can best be described as different flavors of "pop psychology." 2019 was a banner
year for Minneapolis-based Learn to Live, inking scores of key new accounts, including a collaboration with
Blue Cross Blue Shield of Massachusetts, as well as landing a coveted billing in Express Scripts'             Digital
Health Formulary.

                                                                                                       Page 7 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

Learn to Live's co-founder and CEO Dale Cook grew up in Bogotá, Colombia, the son of missionaries, and the first-
time entrepreneur has certainly infused Learn to Live with a sense of mission and purpose. The company recently
announced the launch a new product tackling substance use, which makes it among the first to market to address
this clinical need.

13. Lifesprk (St. Louis Park, Minnesota); Capital Raised: $36 Million

Senior or geriatric care is among the fastest growing segments in health care. The nearly $740 billion elderly-care
market is ripe for disruption, and Minnesota-based Lifesprk has adroitly carved out a commanding position to
capitalize on this burgeoning segment of the health care landscape. At its core, Lifesprk is all about bringing a
comprehensive suite of support services to elderly patients, empowering them and their families to stay in control
and enabling them to live the life they want and to retire on their own terms. But behind the scenes-and this is why
founder and CEO Joel Theisen has become something of a superstar within the national senior care marketplace-is
the data.

Lifesprk is collecting and integrating data that has either been siloed, or not even captured at all, to develop a
personalized Electronic Life Record, or ELR, an innovative platform that is as revolutionary to senior care as the
Bloomberg Terminal was to global financial markets. By aggregating huge data sets focused on the individual,
Lifesprk can quickly identify and even suggest personalized services at the appropriate price point to meet the
needs any life scenario a senior might encounter. The result is longer, fuller lives, lower costs and a booming
company.

14. IDx (Iowa City, Iowa); Capital Raised: $55 Million

The eyes are all-important gateway into our mind, body and, some might say, soul. IDx's flagship product, the IDx-
DR, is the first FDA-approved autonomous artificial intelligence (AI) platform that uses software to analyze images
from a high powered camera for evidence of retinal lesions typically associated with the early onset of blindness
from diabetes. Founded by an ophthalmologist originally from the Netherlands who moved to the Midwest to
practice medicine at the University of Iowa, this startup is revolutionizing the early detection of blindness, a common
affliction associated with diabetes, which afflicts roughly 8.5% of the global population.

The company's secret sauce is its ability to scale by sidestepping the need for a clinician to interpret the results of
its retinal scans, making the data more widely available by health care providers who are not normally involved in
eye care.

15. Sera Prognostics (Salt Lake City, Utah); Capital Raised: $151 million

Mothers-to-be and physicians are increasingly turning to Utah-based Sera Prognostics for early prediction of a
woman's individualized risk of premature birth and other pregnancy-related complications. The company is a real
game changer, having developed a suite of diagnostic tests designed to give women and their physicians the time
needed to make individualized treatment and care plans. The company's flagship product, the PreTRM blood test,
is the only clinically recognized bio-marker available to the public at large.

Dr. Garrett Lam, Sera's chief medical officer, commented, "I've shared in the heartbreak and tragedy caused by
complications of pregnancy throughout my career. Our work at Sera, to identify risks early in pregnancy, will assist
doctors, positively impact mothers and benefit the health of newborns to make a significant difference in our
world."

The health care investment community is betting big on Sera becoming the gold-standard for early-risk detection in
expectant mothers and a global leader in high-value women's health diagnostics. Like many other entries on this
year's list, Sera is solving a specific set of issues-in this case, by delivering pivotal information to patients and
physicians-that will play a broader role in improving the economics of the entire health care ecosystem.

16. Aunt Bertha (Austin, Texas); Capital Raised: $22 Million

                                                                                                        Page 8 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

In the U.S., there are thousands of nonprofits and social care providers set up to serve those in need, but the reality
is that navigating the complex maze of which organization does what is nothing short of daunting for the average
person in need. For many, what should be a simple and straightforward process, becomes time consuming, leaving
many frustrated to the point of giving up. Bottomline: too many Americans are needlessly suffering despite a surfeit
of accessible resources from charities, NGOs and nonprofits. Enter Aunt Bertha, an Austin-based platform that
connects people seeking help and the verified social care providers that serve them. Aunt Bertha is the "favorite
Aunt you can trust," powering the country's most comprehensive online directory of social service organizations.

But Aunt Bertha is more than just a 'Yellow Pages' for social services; the reason the company has become a
favorite among VCs is its ability to tap into a largely overlooked, but critically important, aspect of the health care
ecosystem, offering big brand health care customers solutions with advanced features like EHR (Electronic
Hospital Record) integrations and giving caregiver teams a more complete view of a patient's global support
environment.

17. AxialHealthcare (Nashville, Tennessee); Capital Raised: $26 Million

Presidential candidates on the campaign trail often talk about the nation's runaway opioid epidemic. According to
the 2018 National Survey on Drug Use and Health, over 10 million Americans aged 12 and older misused opioids
in 2018, and the impact on communities across the country has been devastating. Nashville-based AxialHealthcare
is teaming up with hospitals and caretakers around the country to combat opioid abuse by leveraging state-of-the
art analytics to identify patients at risk, prevent escalation of their conditions and support appropriate treatment
enrollment and adherence. Axial is on the frontline of a deadly diseases (nearly 130 Americans die each day from
opioid-related abuse) and an immense marketplace; last year, over $200 billion was spent combating the opioid
epidemic in the U.S.

Axial's approach is predicated on a high-touch, community-based approach that delivers clinical metrics and
financial outcomes by managing the cost of care while supporting sustained recovery efforts for patients diagnosed
with opioid use disorder. Newly-minted CEO Carter Paine-the former president and COO of value-based care
manager naviHealth, who brings a career's worth of insight from his time working with companies in the IT and
health services world-will look to expand the Axial platform's reach, which now covers nearly three million people.

18. Benovate (Minneapolis, Minnesota); Capital Raised: $6 Million

Although no one can find the original tape recording, the quote, "Let food be thy medicine, and let medicine be thy
food" is famously attributed to the ancient Greek physician Hippocrates-often regarded as the father of all medicine.
Whether Hippocrates actually said it or not, it's increasingly clear that our less than ideal 21st century diets are the
root cause behind a host of modern health issues, and Benovate is one of the leading disruptors in the "food as
medicine" movement, mixing up an elixir of tech, AI, nutrition and health care industry knowledge to market their
trademarked Gx product (a riff off the pharmaceutical 'Rx' with 'G' for grocery).

Benovate is wellbeing 2.0. Its Gx app is breaking new ground in enabling the entire health ecosystem, from doctor
to insurance provider, to prescribe and reimburse everyday foods, like a cucumber, which is packed with valuable
nutrients. Under the seasoned guidance of company CEO Mark Walinske, a 30-year veteran of the health care
space, Benovate's Gx product aims to transform your local grocery into the neighborhood pharmacist.

19. Abilitech Medical (St. Paul, Minnesota); Capital Raised: $9 Million

Fresh off a $7.4 Million Series A financing round, Minnesota's Abilitech Medical has a gust of arctic wind at its back.
CEO Angie Conley has collected so many business awards in the last year that she is probably running out of room
atop her fireplace mantle. And that's a good thing because Abilitech is a company with a lot of heart in addition to
solving a very serious health challenge-enabling those with upper-limb neuromuscular conditions to function
independently.

                                                                                                      Page 9 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

The company's first product, the Abilitech Assist, is a powered orthotic device providing functional assistance and
support to both the elbow and the shoulder, improving the lives of those affected by muscular dystrophy, multiple
sclerosis, spinal cord injury and, in some cases, those who have suffered a stroke.

In 2020, the company is poised to earn FDA registration, undergo clinical studies and begin widespread
commercialization of the Abilitech(TM) Assist, which has made many VCs at this year's confab in San Francisco
eager to get some quality time with Conley. Observer isn't the only publication to have realized the potential of this
game-changing company; they've already received recognition as a Top 10 Medical Device Startup in the country
by Medical Tech Outlook magazine, a Top 10 Promising Company by the Rice Alliance, and was touted as a Top
20 Medical Device Startup by MassDevice.

20. Omcare (Bloomington, Minnesota); Capital Raised: $9 Million

What's the size of breadbox, looks like a coffee-maker designed by Apple and dispenses pills? No idea? It's the
Omcare home medicine dispenser, equipped with a pair of Wi-Fi-enabled interactive cameras that will enable
caregivers to watch grandma in real-time not only handle the packet of pre-loaded pills (at the right time), but also
swallow them as well (ergo the second camera!) to ensure there is none of that "hide the pill under the tongue
trickery." The Omcare technology, which was adapted from founder and CEO Lisa Lavin's previous intelligent treat
dispenser for pets startup, has a deadly serious mission: reduce errors in medication and maximize adherence in
the elderly community.

Omcare was recently given a big boost by the addition of long-time health care veteran Jeannine Rivet to its board.
Rivet, the former executive vice president of UnitedHealth Group, one of the world's largest publicly-traded health
care corporations, believes that remote care is the way of the future and that companies like Omcare, which enable
elderly patients to stay independent longer, make sense not only in terms of the economics, but also by meeting the
needs of seniors who desire to age in place.

"I began my career in health care as a nurse, and so I know first-hand the challenges and constraints placed upon
caregivers," Rivet explained. "Although in its early stages, Omcare has the potential to revolutionize medication
non-adherence among elderly and others struggling to manage chronic or complex health conditions."

Omcare's Home Health Hub utilizes audio and visual messages, which lets caregivers and care teams monitor
medication adherence, and its multi-dose packaging is specially designed in collaboration with pharmacies so that
correct dosage consumption is no longer an issue.

Finding Diamonds in the Rough

The annual J.P. Morgan Healthcare Conference sets the tone for the rest of the year when it comes to the biggest
trends crisscrossing the global health care industry. Last year, the surfeit of bold health care innovators emerging
from places like St Louis, Missouri and Columbus, Ohio, for example, wasn't a surprise to industry insiders, but it
did appear to catch some of the coastal business media who only breathe in that rarified air of Silicon Valley
somewhat by surprise. But this year, VCs, Big Pharma, big health care and the business media are well aware that
some of the biggest stars at this year's conference will hail from 'flyover country.'

Aly Lovett, a partner at New York City-based Radian Capital, a growth equity firm with a strong presence in the
health care software space, openly embraces looking for investment opportunities in cities typically overlooked by
most traditional health care VCs. "The knowledge base required to build a leading technology company is no
longer concentrated in just a few cities, and capital is starting to follow that trend. Lower costs, higher quality of
living and more diffused access to great talent make these smaller cities highly desirable places to start
businesses," commented Lovett. "There are many amazing angels and seed funds in these regions that can help
get companies started, and we think there is an opportunity for Radian to provide growth equity to support these
businesses in their next phase of growth."

                                                                                                          Page 10 of 18
                      Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

But if Lovett has been holding on to something of a secret, it would seem that her secret is now out in the open;
capital far and wide is searching for the new, new thing in health tech from flyover country, and many will be using
the J.P. Morgan confab as an opportunity to get to know them.

No matter where they call home.

On Monday, January 13, like a swarm of honey bees, thousands of health tech entrepreneurs, health care execs,
venture capitalists, bankers, regulators and business media will descend upon downtown San Francisco as the 38th
Annual J.P. Morgan Healthcare Conference gets under way. And, as is the case with any multi-day industry
gathering worth its salt, an entire ecosystem of satellite events has popped up around the main attraction, which
has created a seemingly endless circuit of networking events, summits and other health care-related shindigs-all
offering ample excuses to down lattes during the day and throw back a shot or two at night.

Even though only a select few are invited to attend the official main stage, marking one's presence at J.P. Morgan
is paramount, as the four-day confab has positioned itself as not only the first, but perhaps the most important event
of the global health care conference calendar year.

SEE ALSO: Revel Is Rewriting the Playbook on How Health Plans Talk to You

Ahead of last year's J.P. Morgan gathering, Observer was among the first to point out a trend that was beginning to
emerge across the health industry-the rise in interest from both large health care players, as well as hungry
venture capitalists, for health tech plays originating in cities not typically associated with startup culture, places like
Minneapolis, Nashville and Chicago. Observer even coined a new term for these disruptors from Middle America:
Flyover Tech.

And, judging by the pre-conference buzz, by all accounts, last year was not a fluke; many of the entries from the
2019 list have emerged as some of the biggest and most important players in their respective sectors over the past
12 months. Some of them have even carved out completely new niches within the vast health care ecosystem that
didn't exist a year ago.

As some informed observers of the high-flying health tech space quipped, "Flannel is the New Black," when it
comes to innovation in health care and big bets in health tech.

Take for example Bind, a Minneapolis-based startup health plan that has already raised a jaw-dropping $82 million.
After occupying last year's top position on the list for its ability to use data science and artificial intelligence (AI) to
analyze existing claims data, Bind had a banner year. The company has been expanding its services across
multiple new areas of coverage, while empowering customers to understand what they are really paying for with
their health plans, which makes it easy to compare treatment options, prices and quality. Bind, along with fellow
Minnesota wunderkind health insurance startup                 Bright Health-which just announced the closing of
$635 million in Series D financing in December, on top of over $400 million of funding in previous rounds (putting its
total raise now over the billion dollar mark)-have chiseled out completely new offerings in the health insurance
space, a sector that, less than a decade ago, was considered nearly impenetrable due to the vast resources
needed to scale a business of that nature.

"It still amazes me the number of investors that haven't taken full advantage of the 'flyover tech' ecosystem,"
observed Jodi Hubler, managing director of Lemhi Ventures, a venture capital firm that invests primarily in early- to
mid-stage health companies in the Midwest and Rocky Mountain regions. "Many places in Middle America are
actually centers of innovation and deep domain knowledge not only in health care, but in medtech device and
services as well," added Hubler, referring to the largest players in health care and medtech, like UnitedHealth
Group, Medtronic, Cardinal Health, Humana and Anthem-all of which have main bases of operations in between
the coasts.

"It's common sense economics-every dollar of capital goes further in these locations, and the access to talent from
developers to board members comes with differentiated experience and knowledge," Hubler told Observer. "In

                                                                                                     Page 11 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

places like the Midwest, people don't play in health care, they've lived it... that experience and intuition is
invaluable."

Another big winner from last year's list was Nashville-based SmileDirectClub, a tele-dentistry startup that produces
direct-to-consumer 3D-printed clear aligners. In September, the teeth-straightening startup went public,
raising more than $1.3 billion at an initial market cap of roughly $10 billion, more than three times its most recent
private valuation. And although the stock price has since clawed back some of those ebullient IPO gains, it's yet
another shining example of a flyover tech success story.

Flyover Tech Is Now a 'Badge of Honor' in Health Tech

For serial health care entrepreneur and founder of San Francisco-based Roam Analytics Alex Turkeltaub, there is
gold to be mined in Middle America. "Hubs like Raleigh, Columbus and Nashville, just to name a few, are quickly
becoming known as exciting centers of innovation in health care. With strong legacy technology and health care
systems, it's only natural that these local ecosystems will fuel the next generation of disruptors in digital health,"
observed Turkeltaub, who recently stepped down as CEO of Roam and is setting up a venture fund that focuses on
the         intersection of AI and health care. The fund will look to make strategic investments in major health tech
hubs across the country, as well as in emerging overseas markets like Brazil.

"The term 'flyover' used to be somewhat derogatory, but now it's a badge of honor in health tech. Entrepreneurs in
the middle of the country know that technology can't exist for its own sake; it has to be combined with functional
business models to deliver real value to patients and investors alike," added Turkeltaub. "Any serious health care
VC who isn't making monthly visits to places like Minneapolis or Chicago is completely missing the boat."

Chicago, Nashville and Minneapolis Are Emerging as the New 'Silicon Valleys' of Health Tech

Although there are entries on this year's list from a wide swath of cities across the country, experts and insiders
repeatedly point to the surfeit of companies emerging from three major hubs of innovation in health care from
Middle America: Nashville, Chicago and the Twin Cities of Minneapolis and St. Paul.

"With a diverse set of headquartered legacy companies spanning the entire spectrum of health care, regional hubs
such as Nashville, Chicago and Minneapolis will continue to produce industry-leading innovation and transformation
in the sector. These are the new hotbeds in health care," noted Sara Ratner, a veteran health care industry insider
who is one of the nation's foremost experts on government-run Medicare and Medicaid programs.

Observer spoke with health care experts from across the U.S. to offer their thoughts about the biggest emerging
trends at the 2020 J.P. Morgan Healthcare Conference and the sector's continued interest in flyover tech. They
were also asked to highlight some of the hottest companies in between the two coasts that will be feted in San
Francisco this week. Like last year, the current list is not a ranking in the traditional sense-the companies singled
out are in different stages of development and growth and, for the most part, are positioned in non-competing
verticals; rather, the list is a snapshot of 20 early- to mid-stage startups that have caught the attention of health
care insiders from around the globe and have one thing in common: they all hail from what many a New Yorker
might describe as 'flyover country.'

And now, here is Observer's 20 Hottest Companies in 'Flyover Tech' at the 2020 J.P. Morgan Healthcare
Conference.

1. HistoSonics (Ann Arbor, Michigan); Capital Raised: $87 Million

Non-invasive cancer treatment. Let those words sink in. By using technology similar to an ultrasound, this new
interventional therapy will transform nearly all forms of cancer detection and eradication. In some respects, the
company's flagship product is not unlike the "healing machine"-the technology central to the plot to the 2013 Matt
Damon thriller Elysium set 134 years in the future.

                                                                                                      Page 12 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

Led by veteran health care executive Mike Blue, the company's non-invasive robotics platform and novel sonic
beam therapy is awaiting full FDA clearance, but the company has already announced reams of promising new
clinical and preclinical data, including successful human trials in Spain. In April of last year, HistoSonics closed a
$54 million C-Round led by Varian Medical Systems, Inc., the global leader in radiation therapy and oncology
solutions, and included          Johnson & Johnson Innovation and the          State of Wisconsin Investment Board,
among others. Initially targeting liver and pancreatic cancer, HistoSonics' Robotically Assisted Sonic Therapy
(RASTSM) combines advanced robotics and imaging with a proprietary sensing technology to deliver personalized
treatments with unparalleled precision and control. In layman's terms, the tech uses sound energy to generate
pressures strong enough to liquify and completely destroy targeted tissues at sub-cellular levels.

Meanwhile, HistoSonics is busy building a new HQ in a Minneapolis suburb. "Our tech was born in the labs of the
University of Michigan, but we quickly realized we needed to be at the epicenter of health care innovation, which is
why we decided to move our base to Minnesota," explained Blue. "This is where all the action is right now in health
tech."

2. Olive AI (Columbus, Ohio); Capital Raised: $72.8 Million

Over one trillion dollars are spent every year in the U.S. on health care administration. Not on doctors, needles,
meds or IVs, but on pens, paper, IT and something called 'system integration.' It's a huge outlay-and the fact that
much of that spend could be better directed toward treating patients and saving lives is what constitutes the driving
force behind Ohio-based startup Olive AI.

CEO Sean Lane and the team at Olive understand that hospital employee time is money, which is why in the last
year, their AI-powered workforce has become the utility player for over 500 individual hospitals around the U.S.,
handling high-volume, administrative workloads. Olive's automated workforce takes on the minutia of the often
repetitive paperwork that plagues nearly all sectors of health care-from human resources and IT to supply chain
management and revenue cycle tracking-allowing employees to focus on the important, big picture aspects of their
work. Convenient, efficient, fast and accurate, Olive AI is an overworked employee's dream assistant, and the
venture world, which has plowed over $70 million into the company thus far, seems to agree.

3. NightWare (Minneapolis, Minnesota); Capital Raised: Undisclosed

The highly secretive NightWare was on last year's hot list, and while it is still not disclosing its fundraising totals
(one of the advantages of not raising with institutional investors), the company continues to make big strides in the
treatment of PTSD and nightmare disorder, a condition affecting over five million Americans and hundreds of
thousands of U.S. vets. Over the past 12 months, NightWare received official "Breakthrough Status" designation by
the FDA, which is only given to treatments that, according to the FDA, "demonstrate substantial improvement on a
clinically significant endpoint over available therapies." In plain English, NightWare might very well become the first
prescribable digital therapeutic for a key symptom of PTSD. It's a big deal coming to an Apple Watch near you.

4. Eyesafe (Eden Prairie, Minnesota); Capital Raised: $9 Million

Projecting Apple's resurgence and ultimate market dominance in consumer tech, years before the iPhone, made
tech-watcher Gene Munster something of an oracle on Wall Street. Now a founding partner at tech-focused VC
Loup Ventures, Munster has become a regular fixture on the business news circuit as he shares his hot takes on
Tesla, Apple, Amazon and the tech industry at large. Munster believes            Eyesafe, a privately held company
that is advancing consumer electronics with its blue light protection technology, has become an influential player,
building standards for safeguarding users' eyes from the intense, albeit invisible, blue light that Harvard Medical
School says "       has a dark side."

"I don't have a financial stake directly or indirectly in Eyesafe," cautioned Munster. "But brands like Dell, HP and
Lenovo are becoming increasingly aware of the health dangers posed by blue light. Eyesafe sits atop a very short
list of solutions that large tech companies are turning to for help in designing and implementing safer displays that

                                                                                                     Page 13 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

maintain color performance. While nascent today, Eyesafe's long-term addressable market is significant, given that
over time, some form of blue light protections will likely be mandated in all displays."

In fact, Eyesafe has already cut impressive deals with Dell and aftermarket screen-protector leader ZAGG,
distributed in Verizon, AT&T and T-Mobile stores across the nation, as well the major component suppliers in the
electronics industry. And with the passage of the State of California's recent "Blue Light Resolution," it seems
Munster's prediction of regulation is happening fast, putting Eyesafe in pole position to own the low blue light
market and, in the process, seize the mantle as the "          Intel Inside" of health and safety across consumer
electronics.

5. MyMeds (Minneapolis, Minnesota); Capital Raised: $8 Million

Your doctor prescribes some medication and tells you to pick it up at the local pharmacy. Once you show up at the
Duane Reade or CVS, an officious-looking individual in a white lab coat gives you a brief glimpse of an amber
colored pill container, mumbles a word or two of advice and then places your prescription in a white bag, along with
an intimidating piece of paper full of fine print, sending you on your way. Now, you are on your own; it's just you, a
dozen or so pills, and a piece of paper written by a lawyer who went to medical school, or maybe the other way
around.

Sound familiar? Today's medication experience is broken, and with the phenomenon of medication non-adherence
emerging as the biggest issue driving up health care costs across the entire sector, MyMeds is bringing to market a
suite of solutions unlike any other in the digital health space.

"We are redefining the medication experience so people are never alone and always have access to their own
data," said MyMeds founder and CEO Dr. Rajiv Shah, whose company was recently selected to join SAP's
prestigious accelerator program in New York City. "Our patented Digital + Human ACE Medication Experience is an
ecosystem that connects patients, caregivers, providers and payors in real-time." In more plain speak, Shah's
MyMeds is laying pipe that connects doctor, pharmacist, you and your health insurance in ways that have never
been possible before, savings costs and ensuring better health outcomes.

The experts Observer spoke to believe that 2020 will be a breakout year for MyMeds, as it rolls out its integration
with SAP, launches a new real-time Medicare Stars product and unfurls the much-anticipated MyMeds Connect, a
secure real-time prescription data connectivity engine-a real game changer in light of Washington's focus on
medication history data rights. According to Fox Business Network analyst Ethan Bearman, who follows the
booming medication non-adherence space, MyMeds has the potential to become a billion-dollar company in the
coming years.

"Some health companies are really smart with their tech or business model, while others are just plain lucky in that
the regulatory environment sways in their direction at just the right time," Bearman told Observer. "MyMeds is both
smart and lucky, which is why it wouldn't surprise me if Dr. Raj is able to launch his own version of Tres Comas
Tequila sometime in the next few years."

6. Regroup + InSight (Chicago, Illinois); Capital Raised: $19 Million + Undisclosed Private Equity Backing

While it may be unorthodox for two companies to be named in one spot, a recent merger between Regroup
Telehealth and InSight Telepsychiatry deserves the spotlight. The two companies merged in late 2019, and the
combined company is now packing a lot of heat, making it one of the largest and most comprehensive
telepsychiatry service providers in the U.S. The new entity is tackling mental health care disparities head on with
their unique suite of individualized telehealth services.

Many times, being geographically, economically or socially isolated means that patients with mental health issues
don't have access to the specialized psychiatric care that they require. Regroup + Insight is connecting patients
from one end of the country to the doctors and specialists they need to see, irrespective of their physical location.
With a high-capacity data pipe from the physicians' location to the clinical setting, the Regroup + Insight tie-up

                                                                                                        Page 14 of 18
                      Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

enables doctors to treat, consult and prescribe medication from afar and coordinate remotely with the patient's local
health care support team.

Like several other companies on both this year's and last year's lists, Regroup was born inside of Chicago's Health
Incubator, Matter, which has emerged as a breeding ground for some of the most innovative and fast-growing
companies in digital health. Now all their C-Suite needs to do is come up with a name for the new combined entity.

7. Revel Health (Minneapolis, Minnesota); Capital Raised: $17 Million

Revel Health is rewriting the playbook for how health plans talk to their members. Gone are the days of the
robocall with a voice that sounds entirely too enthusiastic reminding you that it's time for another prostate exam or a
mailed form letter that looks like an audit notice from the IRS reminding you that it is flu-shot season.

After initially catching Observer's eye late last year, the experts we spoke to were impressed with not only the
company's tech, but also its savvy application into real-world, actionable results. Revel uses lessons that consumer
marketers and Big Retail pioneered and is applying them across the health care marketplace. Revel helps
members stay healthier by connecting them with their health care support system through sophisticated AI, which
culls and analyzes mind-boggling Big Data sets and translates them into personable and highly personalized health
action communication. Under the leadership of veteran health care CEO Jeff Fritz, Revel is leading a revolution in
preventive health care and is quickly becoming a secret weapon for major health plans.

8. Owlet (Lehi, Utah); Capital Raised: $48 Million

Perhaps it isn't a coincidence that Utah-based Owlet Baby Care was started in the same state that has the largest
average household size in the U.S. Or maybe the team at Owlet just knows how hard it is raising a child, much less
two or three, which is why they are betting big that over-protective parents want more than a simple nanny cam to
keep an eye on their brood.

Owlet is gaining traction with a product set that provides parents with real-time, non-invasive video and audio
monitoring, allowing for the child's blood oxygen level, heart rate, temperature and sleeping patterns to be
monitored and tracked by an app easily accessible on any worried parent's smartphone. Founded by a team of
passionate parents in 2013, this Silicon Slopes company is taking the baby monitoring game to an entirely new
level and investors love it.

The company's newest innovation, the Owlet Band Pregnancy Monitor, is on track to be the hottest product in baby-
care tech this year, having already won two distinctive awards at the Consumer Electronics Show for Best
Wearable and Tech to Change the World.

9. PhysIQ (Chicago, Illinois); Capital Raised: $25 Million

PhysIQ can detect the smallest, most subtle changes in an individual's biosensory data and can alert care teams to
potential problems far before they would surface during a regular check-up. The technology enables doctors to see
around corners by applying sophisticated, FDA-cleared physiological analytics to extract personalized health
insights. This Windy City startup uses software that was originally designed for data-tracking on jet engines and
nuclear power plants, where the smallest performance deviations can pose immensely profound dangers. Now,
PhysIQ is taking that same approach to performance calibration and applying it to the human body; it tracks data
around the clock to capture a patient's standard bodily rhythms and tempos and packages the data into neat,
digestible bundles for clinical teams all around the country. Like several other entries on this year's list, PhysIQ is a
product of downtown Chicago's Matter health incubator.

10. Pops! Diabetes (Oak Park Heights, Minnesota); Capital Raised: $8 Million

Siri and Alexa: Meet Mina-every diabetics' new best friend and one of the latest products from Minnesota-based
Pops! Diabetes, a company which is upending the consumer side of the nearly $200 billion global diabetes market.
CEO Lonny Stormo believes that while self-care should take precedence, life oftentimes gets in the way, which is

                                                                                                       Page 15 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

why his consumer-first approach to diabetes management has focused on platforms such as Mina that can step in
and do important monitoring on a patient's behalf. "Mina sent an alert to my wife when my blood-sugar read 60. She
was able to get in touch with me and my doctor immediately and make sure we addressed the situation promptly,"
Stormo recounted to Observer. "Mina really helps me own my diabetes, and not let the diabetes own me."

Mina is a state-of-the-art chronic care management platform that tracks health management for diabetics and its
always on; cloud-based accessibility means that an individual's care support team, from loved ones to doctors, can
be instantly alerted about a potential crisis by receiving an alert from Mina.

Simplifying the diabetes management business is a huge area of focus for both medtech and health care.

Stormo, a Medtronic alum, will be kicking off a new round of capital raising at this year's J.P. Morgan Healthcare
Conference, and his dance card is filling up quickly. "We have been fortunate to be coming to market just as the
interest in virtual care and diabetes management is near or at the top of the shopping list of many digital health
VCs," offered Stormo.

11. DispatchHealth (Denver, Colorado); Capital Raised: $68 Million

They seem like genius ideas: Need a ride? Hail an Uber. Hungry? Ping GrubHub. But what about if you need a
doctor? Colorado-based DispatchHealth is proving that with technology, on-demand health care at your doorstep is
not only possible, but also a viable business model. In a few taps, via the Disptach app, a board-certified medical
team will come to your home, office or wherever you need them to be, equipped with all the tools necessary to
tackle whatever specialized care you might need.

As access to medical care becomes increasingly consumer-focused, it seems that many health tech investors
believe that visits to traditional brick-and-mortar health care facilities will be reserved only for the most serious of
situations.

12. Learn to Live (Minneapolis,Minnesota); Capital Raised: $9 Million

There is no shortage of well-funded startups looking to stake out their own territory in the red-hot digital mental
health therapy space. Health plans, large employers and universities, governments and branches of the military, as
well as the VA, among many others, are keen to offer online CBT (cognitive behavioral therapy) to their members,
students and employees.

In a recent Observer profile of the digital mental health space, Learn to Live was highlighted as one of the
innovators in the sector, pushing the industry to adopt more serious, evidenced-based approaches to digital mental
health treatment in contrast to many of its competitors, which, despite having raised significant amounts of capital,
seem to be dabbling in what can best be described as different flavors of "pop psychology." 2019 was a banner
year for Minneapolis-based Learn to Live, inking scores of key new accounts, including a collaboration with
Blue Cross Blue Shield of Massachusetts, as well as landing a coveted billing in Express Scripts'             Digital
Health Formulary.

Learn to Live's co-founder and CEO Dale Cook grew up in Bogotá, Colombia, the son of missionaries, and the first-
time entrepreneur has certainly infused Learn to Live with a sense of mission and purpose. The company recently
announced the launch a new product tackling substance use, which makes it among the first to market to address
this clinical need.

13. Lifesprk (St. Louis Park, Minnesota); Capital Raised: $36 Million

Senior or geriatric care is among the fastest growing segments in health care. The nearly $740 billion elderly-care
market is ripe for disruption, and Minnesota-based Lifesprk has adroitly carved out a commanding position to
capitalize on this burgeoning segment of the health care landscape. At its core, Lifesprk is all about bringing a
comprehensive suite of support services to elderly patients, empowering them and their families to stay in control
and enabling them to live the life they want and to retire on their own terms. But behind the scenes-and this is why

                                                                                                      Page 16 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

founder and CEO Joel Theisen has become something of a superstar within the national senior care marketplace-is
the data.

Lifesprk is collecting and integrating data that has either been siloed, or not even captured at all, to develop a
personalized Electronic Life Record, or ELR, an innovative platform that is as revolutionary to senior care as the
Bloomberg Terminal was to global financial markets. By aggregating huge data sets focused on the individual,
Lifesprk can quickly identify and even suggest personalized services at the appropriate price point to meet the
needs any life scenario a senior might encounter. The result is longer, fuller lives, lower costs and a booming
company.

14. IDx (Iowa City, Iowa); Capital Raised: $55 Million

The eyes are all-important gateway into our mind, body and, some might say, soul. IDx's flagship product, the IDx-
DR, is the first FDA-approved autonomous artificial intelligence (AI) platform that uses software to analyze images
from a high powered camera for evidence of retinal lesions typically associated with the early onset of blindness
from diabetes. Founded by an ophthalmologist originally from the Netherlands who moved to the Midwest to
practice medicine at the University of Iowa, this startup is revolutionizing the early detection of blindness, a common
affliction associated with diabetes, which afflicts roughly 8.5% of the global population.

The company's secret sauce is its ability to scale by sidestepping the need for a clinician to interpret the results of
its retinal scans, making the data more widely available by health care providers who are not normally involved in
eye care.

15. Sera Prognostics (Salt Lake City, Utah); Capital Raised: $151 million

Mothers-to-be and physicians are increasingly turning to Utah-based Sera Prognostics for early prediction of a
woman's individualized risk of premature birth and other pregnancy-related complications. The company is a real
game changer, having developed a suite of diagnostic tests designed to give women and their physicians the time
needed to make individualized treatment and care plans. The company's flagship product, the PreTRM blood test,
is the only clinically recognized bio-marker available to the public at large.

Dr. Garrett Lam, Sera's chief medical officer, commented, "I've shared in the heartbreak and tragedy caused by
complications of pregnancy throughout my career. Our work at Sera, to identify risks early in pregnancy, will assist
doctors, positively impact mothers and benefit the health of newborns to make a significant difference in our
world."

The health care investment community is betting big on Sera becoming the gold-standard for early-risk detection in
expectant mothers and a global leader in high-value women's health diagnostics. Like many other entries on this
year's list, Sera is solving a specific set of issues-in this case, by delivering pivotal information to patients and
physicians-that will play a broader role in improving the economics of the entire health care ecosystem.

16. Aunt Bertha (Austin, Texas); Capital Raised: $22 Million

In the U.S., there are thousands of nonprofits and social care providers set up to serve those in need, but the reality
is that navigating the complex maze of which organization does what is nothing short of daunting for the average
person in need. For many, what should be a simple and straightforward process, becomes time consuming, leaving
many frustrated to the point of giving up. Bottomline: too many Americans are needlessly suffering despite a surfeit
of accessible resources from charities, NGOs and nonprofits. Enter Aunt Bertha, an Austin-based platform that
connects people seeking help and the verified social care providers that serve them. Aunt Bertha is the "favorite
Aunt you can trust," powering the country's most comprehensive online directory of social service organizations.

But Aunt Bertha is more than just a 'Yellow Pages' for social services; the reason the company has become a
favorite among VCs is its ability to tap into a largely overlooked, but critically important, aspect of the health care
ecosystem, offering big brand health care customers solutions with advanced features like EHR (Electronic

                                                                                                       Page 17 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

Hospital Record) integrations and giving caregiver teams a more complete view of a patient's global support
environment.

17. AxialHealthcare (Nashville, Tennessee); Capital Raised: $26 Million

Presidential candidates on the campaign trail often talk about the nation's runaway opioid epidemic. According to
the 2018 National Survey on Drug Use and Health, over 10 million Americans aged 12 and older misused opioids
in 2018, and the impact on communities across the country has been devastating. Nashville-based AxialHealthcare
is teaming up with hospitals and caretakers around the country to combat opioid abuse by leveraging state-of-the
art analytics to identify patients at risk, prevent escalation of their conditions and support appropriate treatment
enrollment and adherence. Axial is on the frontline of a deadly diseases (nearly 130 Americans die each day from
opioid-related abuse) and an immense marketplace; last year, over $200 billion was spent combating the opioid
epidemic in the U.S.

Axial's approach is predicated on a high-touch, community-based approach that delivers clinical metrics and
financial outcomes by managing the cost of care while supporting sustained recovery efforts for patients diagnosed
with opioid use disorder. Newly-minted CEO Carter Paine-the former president and COO of value-based care
manager naviHealth, who brings a career's worth of insight from his time working with companies in the IT and
health services world-will look to expand the Axial platform's reach, which now covers nearly three million people.

18. Benovate (Minneapolis, Minnesota); Capital Raised: $6 Million

Although no one can find the original tape recording, the quote, "Let food be thy medicine, and let medicine be thy
food" is famously attributed to the ancient Greek physician Hippocrates-often regarded as the father of all medicine.
Whether Hippocrates actually said it or not, it's increasingly clear that our less than ideal 21st century diets are the
root cause behind a host of modern health issues, and Benovate is one of the leading disruptors in the "food as
medicine" movement, mixing up an elixir of tech, AI, nutrition and health care industry knowledge to market their
trademarked Gx product (a riff off the pharmaceutical 'Rx' with 'G' for grocery).

Benovate is wellbeing 2.0. Its Gx app is breaking new ground in enabling the entire health ecosystem, from doctor
to insurance provider, to prescribe and reimburse everyday foods, like a cucumber, which is packed with valuable
nutrients. Under the seasoned guidance of company CEO Mark Walinske, a 30-year veteran of the health care
space, Benovate's Gx product aims to transform your local grocery into the neighborhood pharmacist.

19. Abilitech Medical (St. Paul, Minnesota); Capital Raised: $9 Million

Fresh off a $7.4 Million Series A financing round, Minnesota's Abilitech Medical has a gust of arctic wind at its back.
CEO Angie Conley has collected so many business awards in the last year that she is probably running out of room
atop her fireplace mantle. And that's a good thing because Abilitech is a company with a lot of heart in addition to
solving a very serious health challenge-enabling those with upper-limb neuromuscular conditions to function
independently.

The company's first product, the Abilitech Assist, is a powered orthotic device providing functional assistance and
support to both the elbow and the shoulder, improving the lives of those affected by muscular dystrophy, multiple
sclerosis, spinal cord injury and, in some cases, those who have suffered a stroke.

In 2020, the company is poised to earn FDA registration, undergo clinical studies and begin widespread
commercialization of the Abilitech Assist, which has made many VCs at this year's confab in San Francisco eager
to get some quality time with Conley. Observer isn't the only publication to have realized the potential of this game-
changing company; they've already received recognition as a Top 10 Medical Device Startup in the country by
Medical Tech Outlook magazine, a Top 10 Promising Company by the Rice Alliance, and was touted as a Top 20
Medical Device Startup by MassDevice.

20. Omcare (Bloomington, Minnesota); Capital Raised: $9 Million

                                                                                                     Page 18 of 18
                     Flannel Is the New Black at the 2020 J.P. Morgan Healthcare Conference

What's the size of breadbox, looks like a coffee-maker designed by Apple and dispenses pills? No idea? It's the
Omcare home medicine dispenser, equipped with a pair of Wi-Fi-enabled interactive cameras that will enable
caregivers to watch grandma in real-time not only handle the packet of pre-loaded pills (at the right time), but also
swallow them as well (ergo the second camera!) to ensure there is none of that "hide the pill under the tongue
trickery." The Omcare technology, which was adapted from founder and CEO Lisa Lavin's previous intelligent treat
dispenser for pets startup, has a deadly serious mission: reduce errors in medication and maximize adherence in
the elderly community.

Omcare was recently given a big boost by the addition of long-time health care veteran Jeannine Rivet to its board.
Rivet, the former executive vice president of UnitedHealth Group, one of the world's largest publicly-traded health
care corporations, believes that remote care is the way of the future and that companies like Omcare, which enable
elderly patients to stay independent longer, make sense not only in terms of the economics, but also by meeting the
needs of seniors who desire to age in place.

"I began my career in health care as a nurse, and so I know first-hand the challenges and constraints placed upon
caregivers," Rivet explained. "Although in its early stages, Omcare has the potential to revolutionize medication
non-adherence among elderly and others struggling to manage chronic or complex health conditions."

Omcare's Home Health Hub utilizes audio and visual messages, which lets caregivers and care teams monitor
medication adherence, and its multi-dose packaging is specially designed in collaboration with pharmacies so that
correct dosage consumption is no longer an issue.

Finding Diamonds in the Rough

The annual J.P. Morgan Healthcare Conference sets the tone for the rest of the year when it comes to the biggest
trends crisscrossing the global health care industry. Last year, the surfeit of bold health care innovators emerging
from places like St Louis, Missouri and Columbus, Ohio, for example, wasn't a surprise to industry insiders, but it
did appear to catch some of the coastal business media who only breathe in that rarified air of Silicon Valley
somewhat by surprise. But this year, VCs, Big Pharma, big health care and the business media are well aware that
some of the biggest stars at this year's conference will hail from 'flyover country.'

Aly Lovett, a partner at New York City-based Radian Capital, a growth equity firm with a strong presence in the
health care software space, openly embraces looking for investment opportunities in cities typically overlooked by
most traditional health care VCs. "The knowledge base required to build a leading technology company is no
longer concentrated in just a few cities, and capital is starting to follow that trend. Lower costs, higher quality of
living and more diffused access to great talent make these smaller cities highly desirable places to start
businesses," commented Lovett. "There are many amazing angels and seed funds in these regions that can help
get companies started, and we think there is an opportunity for Radian to provide growth equity to support these
businesses in their next phase of growth."

But if Lovett has been holding on to something of a secret, it would seem that her secret is now out in the open;
capital far and wide is searching for the new, new thing in health tech from flyover country, and many will be using
the J.P. Morgan confab as an opportunity to get to know them.

No matter where they call home.


Load-Date: January 13, 2020


  End of Document

                                                                                                            Page 1 of 2
                                       USC to open new campus in Washington, D.C.




                          USC to open new campus in Washington, D.C.
                                        Daily Trojan: University of Southern California
                                                  March 15, 2023 Wednesday



University Wire
Copyright 2023 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 497 words
Byline: NOAH DANESH

Body


The purchase of the property, located in the Dupont Circle neighborhood, cost $49.4 million, The Washington Post
reported. The tower had previously been the home of the National Association of Broadcasters and recently
underwent extensive remodeling to modernize the property. (Courtesy Alan Karchmer)

USC will broaden its nationwide footprint by opening a new campus next month in Washington, D.C., the University
announced Wednesday.

The 60,000-square-foot Capital Campus will provide a home for USC initiatives in policy and connect community
members with global leaders. The location will also serve as a gathering space for alumni and prospective students,
the University wrote in a news release. The campus, a roughly five-minute drive from the White House and less
than three miles from the Capitol, will increase opportunities for members of the USC community to collaborate with
policymakers and prominent research institutions.

"In such fields as sustainability, media, culture, AI and health care, our scholars can bring to bear the full strength
of our diverse disciplines to Washington, D.C.," said Ishwar K. Puri, senior vice president of Research and
Innovation, in the news release.

Comprising the seven stories of the Capital Campus are classrooms, event venues and office spaces, with further
plans to develop a bookstore and a theater.

The purchase of the property, located in the Dupont Circle neighborhood, cost $49.4 million, The Washington Post
reported. The tower had previously been the home of the National Association of Broadcasters and recently
underwent extensive remodeling to modernize the property.

President Carol Folt said in the news release that Washington is a prime location to develop an East Coast center
for the University.

"Washington, D.C., is the natural place for us to establish a thriving hub," Folt said. "It is a nexus for the arts, public
policy organizations, research agencies and foundations."

                                                                                                     Page 2 of 2
                                  USC to open new campus in Washington, D.C.

The Capital Campus, which will have its official grand opening next month, will enable new multidisciplinary
undergraduate and graduate programs, the news release read. USC already has operations in Washington,
including the Dornsife College of Letters, Arts and Sciences' semester-long program providing internships and
courses for students in the nation's capital.

USC's Office of Research Advancement, which works to secure federal funding opportunities for research, has also
been operating in the capital and will move to the new campus. The ORA has contributed to the submission of 320
successful project proposals, receiving a total of $848 million in funding, according to the office's website.

"Washington, D.C., offers unparalleled opportunities for our experts, researchers and students to learn and listen,
connect and share views on the national stage," Folt said in the news release. "USC is known for its service to the
Los Angeles community, and we look forward to being an active participant in the civic life of Washington, D.C."


Load-Date: March 16, 2023


  End of Document

                                                                                                          Page 1 of 3
                                        A Robot Wrote This Book Review Nonfiction




                           A Robot Wrote This Book Review; Nonfiction
                                                     The New York Times
                                          November 21, 2021 Sunday 11:08 EST



Copyright 2021 The New York Times Company All Rights Reserved

Section: BOOKS; review
Length: 1416 words
Byline: Kevin Roose
Highlight: In “The Age of AI,” Henry Kissinger, Eric Schmidt and Daniel Huttenlocher explore how far artificial
intelligence has come.

Body


THE AGE OF AI
And Our Human Future
By Henry A. Kissinger, Eric Schmidt and Daniel Huttenlocher

One of the great promises of technology is that it can do the work that humans find too boring or arduous.

In the 19th and 20th centuries, factory machines relieved us of repetitive manual labor and backbreaking farm work.
In this century, artificial intelligence has taken care of a few more tasks — curating Spotify playlists, selecting the
next YouTube video, vacuuming the floor and so on — but many more mind-numbing activities remain ripe for the
picking. The experts promise us that someday, all of our least favorite chores — including complex cognitive ones,
like interviewing job candidates or managing global supply chains — will be outsourced to machines.

But that day has not yet arrived. Or has it?

After finishing “The Age of AI,” a new book about artificial intelligence by Henry A. Kissinger, Eric Schmidt and
Daniel Huttenlocher, I found myself unmoved by the prospect of reviewing it. I’ve read dozens of books about A.I.,
and while the conceit of this one was intriguing — bringing together a 98-year-old diplomat, a former Google chief
executive and an M.I.T. professor — the book itself was a fairly forgettable entry in the genre.

Then I got a bright idea. What if I could have an A.I. finish this review, and save myself the trouble?

So I fired up Sudowrite, an A.I. writing program I’ve been experimenting with recently. The app uses GPT-3, the
cutting-edge A.I. system developed by the San Francisco-based OpenAI, which acts as a kind of turbocharged
version of Gmail’s autocomplete feature. Provide a snippet of text, and GPT-3 will try to complete it, using
everything it has learned from ingesting billions of examples of other people’s writing. It does this with the help of a
supercomputer containing some 285,000 processors, and a multilayered neural network that ranks among the
world’s most powerful A.I. engines. The authors of “The Age of AI” call GPT-3 one of several promising
technologies that are producing a “revolution in human affairs.”

                                                                                                            Page 2 of 3
                                      A Robot Wrote This Book Review Nonfiction

I pasted the first several paragraphs of this review into Sudowrite, and asked the A.I. to finish. Here’s what it wrote:

Henry Kissinger, Eric Schmidt and Daniel Huttenlocher’s “The Age of AI” is a bold new book on artificial intelligence
that will become the go-to guide for anyone who wants to understand this transformative technology.

The authors have examined the full range of AI technologies — from computer vision systems to natural language
processing — and written about them in a way that will appeal to both experts and laypeople.

One of the most inspiring aspects of this book is its scope. The authors delve deeply into the potential of AI in all
areas of human enterprise. They describe the impact of AI on health care, economics, geopolitics, law, urban
development, governance, journalism, the military and even the life sciences.

Kissinger, Schmidt and Huttenlocher are not afraid to explore the darkest side of AI, either. They are clear-eyed
about the ways that AI could enable dictators to monitor their citizens and manipulate information to incite people to
commit violence.

Although AI is already making our lives better in many ways, Kissinger, Schmidt and Huttenlocher caution that it will
take us as a species many years to create a system as powerful as we deserve. They wisely suggest that we not
lose sight of the values we want to instill in this new machine intelligence.

Thank you, GPT-3! Now, a few notes:

First, the A.I. wasn’t an unqualified success. It took Sudowrite a few tries. On the first attempt, it spit out a series of
run-on sentences that hinted that GPT-3 had gotten stuck in some kind of odd, recursive loop. (It began: “The book
which you are reading at the moment is a book on a nook, which is a book on a book, which is a book on a subject,
which is a subject on a subject, which is a subject on a subject.”) A few tries later, it seemed to give up on the task
of book reviewing altogether, and started merely listing the names of tech companies. (“Google, Facebook, Apple,
Amazon, IBM, Microsoft, Baidu, Tencent, Tesla, Uber, Airbnb, Twitter, Snap, Alibaba, WeChat, Slack.”)

But it warmed up quickly, and within a few minutes, the A.I. was coming up with impressively cogent paragraphs of
analysis — some, frankly, better than what I could have generated on my own.

This speaks to one of the recurring themes of “The Age of AI,” which is that although today’s A.I. systems can be
clunky and erratic at times, they are getting better fast, and will soon match or surpass human proficiency in a
number of important tasks, solving problems in ways no human would have thought to solve them. At that point, the
authors write, A.I. will “transform all realms of human experience.”

Second, while GPT-3 was correct about the scope of “The Age of AI” — with chapters on everything from social
media algorithms to autonomous weapons — it failed to note that all of that broadness comes at a cost. The book
feels cursory and shallow in places, and many of its recommendations are puzzlingly vague.

In a chapter on the geopolitical risks posed by A.I., the authors conclude that “the nations of the world must make
urgent decisions regarding what is compatible with concepts of inherent human dignity and moral agency.” (OK,
we’ll get right on that!) A brief section about TikTok — an app used by more than a billion people worldwide, whose
ownership by a Chinese company raises legitimately fascinating questions about national sovereignty and free
speech — ends with the throwaway observation that “more complex geopolitical and regulatory riddles await us in
the near future.” And when the authors do make specific recommendations — such as a proposal to restrict the use
of A.I. in developing biological weapons — they fail to elaborate on how such an outcome might be achieved, or
who might stand in its way.

Finally, GPT-3 didn’t address the biggest question about the book, which is why it exists at all. Kissinger, who was
66 years old when the World Wide Web was invented, is not a full-time A.I. practitioner, nor a particularly savvy
parser of tech hype. (His last newsworthy foray into the tech world was when he sat on the board of Theranos, the
doomed blood-testing start-up.) Schmidt, who spent a decade running Google, is these days preoccupied with
trying to scare up military contracts for big tech companies. And while Huttenlocher, the dean of M.I.T.’s

                                                                                                         Page 3 of 3
                                         A Robot Wrote This Book Review Nonfiction

Schwarzman College of Computing, may be a bona fide subject matter expert, it’s not clear how much of the book
he actually wrote.

That said, the book does get some things right. The authors do a commendable job of avoiding what I call “A.I.
fatalism” — the belief, sadly common in tech circles, that A.I. is part of an inevitable future whose course we are
powerless to change. Instead, they write that “humans still control” A.I., and have the opportunity to “shape it with
our values.” They also point out, correctly, that while many people worry about killer robots who achieve human-
level sentience and mow us all down with Uzis, a much bigger near-term danger lurks in the innocuous-seeming
A.I.s we all use every day, from the feed-ranking algorithms of social media apps to the automated dispatch
systems that power Uber and Lyft.

“Without significant fanfare — or even visibility — we are integrating nonhuman intelligence into the basic fabric of
human activity,” they write.

Still, while it could be a useful summary of A.I. for those just starting to learn about the topic, “The Age of AI” does
not advance the ball much. It’s a shame, given how much access the authors presumably had to a who’s who of the
A.I. elite. And it makes me wish that…

Actually, you know what? It’s sunny outside, my dogs need a walk, and I don’t really feel like finishing this review.
Take it away, GPT-3.

…It makes me wish that someone out there would crank out a comprehensive survey text on AI, one that’s laser-
focused on the technical issues, written by industry mavens who are actually doing this stuff day in and day out, and
is written in an engaging, clear, plain-spoken style.

I couldn’t have said it better myself.

Kevin Roose is a technology columnist for The Times and the author of “Futureproof: 9 Rules for Humans in the
Age of Automation.” THE AGE OF AI And Our Human Future By Henry A. Kissinger, Eric Schmidt and Daniel
Huttenlocher 254 pp. Little, Brown & Company. $30.

PHOTO: (PHOTOGRAPH BY Elliot Ulm FOR THE NEW YORK TIMES)


Load-Date: March 1, 2022


  End of Document

                                                                                                      Page 1 of 3
         NYSOFA brings ElliQ Proactive care companion to older adults, reducing social isolation, supporting
                                    independence, connection & engagement




   NYSOFA brings ElliQ Proactive care companion to older adults, reducing
    social isolation, supporting independence, connection & engagement
                                          Lewiston-Porter Sentinel (Lewiston, New York)
                                                         May 25, 2022



Copyright 2022 Niagara Frontier Publications
Distributed by Newsbank, Inc. All Rights Reserved

Section: CURRENT NEWS
Length: 1044 words

Body


NYSOFA-ElliQ partnership joins lineup of NYSOFA initiatives to help older adults age in place with innovative
supports and program offerings to combat loneliness and social isolation

Submitted by the New York State Office for the Aging

Building on its comprehensive effort to battle social isolation and support aging-in-place, the New York State Office
for the Aging is delivering voice-operated smart technology into the homes of over 800 older adults.

Under the program, NYSOFA will work with local offices for the aging and partners to identify older adults who
would most benefit from the technology – ElliQ by Intuition Robotics – which is the first-ever proactive and
empathetic care companion.

ElliQ is designed to foster independence and provide support for older adults through daily check-ins, assistance
with wellness goals and physical activities, connection to family and friends, and more using voice commands
and/or on-screen instructions. The technology, which recently launched commercially after years of pilots and early
production deployments, has shown unprecedented engagement levels with older adults. Users have an average of
20 daily interactions.

Distinct from other smart technologies, ElliQ is made specifically for older adults to support independence at home.
While other technologies are reactive to commands, ElliQ proactively suggests activities and initiates conversations,
building context through artificial intelligence (AI) to inform follow-up conversations that create a sense of
relationship with the AI. To support health and wellness, ElliQ offers sleep relaxation exercises, physical activity
exercises, in-depth nutrition-related conversations, and medication reminders for each user's unique condition(s).

In 2017, the U.S. surgeon general declared social isolation to be a "global epidemic" – one that has only worsened
in the COVID-19 health emergency. According to the AARP Public Policy Institute, social isolation drives $6.7
billion in additional associated Medicare spending per year. The health consequences of loneliness and isolation
are equivalent to smoking almost a pack of cigarettes daily. At a time when older adults are at increased risk for

                                                                                                     Page 2 of 3
        NYSOFA brings ElliQ Proactive care companion to older adults, reducing social isolation, supporting
                                   independence, connection & engagement

loneliness and social isolation, ElliQ offers another form of companionship, supplementing traditional, in-person
support.

NYSOFA Director Greg Olsen said, "We are so pleased to partner with Intuition Robotics and make ElliQ available
to older adults in New York. This product does so many things to improve health, combat isolation, and improve
overall well-being and independence. Designed with input from older adults, the future of supporting and serving
older adults includes technology. The future is here."

He added, "Despite misconceptions and generalizations, older adults embrace new technology, especially when
they see it is designed by older adults to meet their needs. For those who experience some form of isolation and
wish to age in place, ElliQ is a powerful complement to traditional forms of social interaction and support from
professional or family caregivers."

Intuition Robotics CEO and co-founder Dor Skuler said, "We've long believed that connecting older adults with local
communities via ElliQ will add an important element in providing holistic support to older adults aging in place. This
partnership with NYSOFA helps us further that mission through an innovative initiative that we are incredibly proud
to be part of."

He added, "We're thrilled to be working with New York state as our first state government partner and believe ElliQ
will be able to effectively engage and encourage older adults in New York to be more independent, healthy and
happy."

Association on Aging in New York (AgingNY) Executive Director Becky Preve said, "The Association on Aging in
New York is thrilled to offer additional technology services to combat social isolation and loneliness. We are so
thankful for NYSOFA's continued commitment to older New Yorkers and the opportunity to partner on innovative
solutions that support aging in place."

The newly enacted fiscal year 2023 state budget includes $2.9 million in funding for pioneering NYSOFA initiatives
to combat social isolation and offer new or expanded innovations in aging service provision at multiple levels. In
addition to ElliQ, this includes: NYSOFA's animatronic pet initiative, which provides lifelike companion pets for older
adults and is proven to reduce self-reported loneliness by 70%; statewide access to Trualta's family caregiver
support platform offering expert-led training across critical care competencies; ride-sharing services designed
exclusively for older adults; and online communities that provide facilitator-led classes and services.

The New York State Office for the Aging continuously works to help the state's 4.6 million older adults be as
independent as possible for as long as possible through advocacy, development and delivery of person-centered,
consumer-oriented, and cost-effective policies, programs, and services that support and empower older adults and
their families, in partnership with the network of public and private organizations that serve them. Stay connected:
Visit the NYSOFA Facebook page; follow @NYSAGING on Twitter and NYSAging on Instagram; or visit
aging.ny.gov.

Intuition Robotics, a startup company based in Israel, is on a mission to empower older adults to live happier,
healthier and more independent lives at home. The company's award-winning product, ElliQ, is a proactive care
companion for older adults. ElliQ helps keep users healthy, engaged and informed, while alleviating the effects of
loneliness and social isolation. Intuition Robotics has won several awards for its work with ElliQ, including Fast
Company's Most Innovative Companies and the CES Best of Innovation award. To learn more, visit www.elliq.com
OR follow on Facebook.

The Association on Aging in New York supports and advocates for New York's mostly county-based Area Agencies
on Aging (AAAs), and works collaboratively with a network of organizations that exist to promote independence,
preserve dignity, and provide support for residents of New York as they age. For more information, follow on
Facebook, visit www.agingny.org, or call 518-449-7080.

                                                                                                   Page 3 of 3
      NYSOFA brings ElliQ Proactive care companion to older adults, reducing social isolation, supporting
                                 independence, connection & engagement


Load-Date: May 26, 2022


 End of Document

                                                                                                     Page 1 of 4
                            Teachers Need More Than Just Pay Raises, Secretary Cardona Says




        Teachers Need More Than Just Pay Raises, Secretary Cardona Says
                                                              Education Week
                                                                May 2, 2023



Copyright 2023 Editorial Projects in Education, Inc All Rights Reserved




Section: Pg. 8; Vol. 42; No. 33
Length: 1579 words

Byline: Libby Stanford, lstanford@educationweek.org
Highlight: Education Secretary Miguel Cardona sat down with Education Week to talk about the teaching
profession, AI, and students' mental health.

Body


Education Secretary Miguel Cardona doesnâ€™t think itâ€™s enough to pay teachers more. Teachers' working
conditions must improve, too.

The secretary said as much during a one-on-one conversation with Education Week following the conclusion of the
International Summit of the Teaching Profession last week. The three-day event brought together education
ministers and teachers' union leaders from 22 countries to discuss strategies and actions each country can take to
improve education.

Cardona made a point to highlight his agency's collaboration with the nation's two largest teachers' unions at the
summit, which the Education Department co-hosted. Randi Weingarten, president of the American Federation of
Teachers; Becky Pringle, president of the National Education Association; and Carissa Moffat Miller, executive
director of the Council of Chief State School Officers, joined Cardona to represent the U.S. throughout the summit.

Cardona called their partnership â€œintentional collaboration,â€ and said he believes their voices will help the
Education Department improve conditions for teachers.

The summit, meanwhile, happened the same week Republican lawmakers brought Weingarten before a U.S.
House subcommittee to answer to their accusations that her union improperly influenced the U.S. CDC's pandemic
reopening guidance for schools.

The U.S. delegates at the summit identified four commitments over the next year, including collaborating with
unions to ensure student well-being and academic success, promoting schools as full-service community centers,
strengthening support for educators, and modernizing education.

                                                                                                      Page 2 of 4
                       Teachers Need More Than Just Pay Raises, Secretary Cardona Says

This interview has been edited for length and clarity.

What would you like teachers to understand about what the Education Department does?

Teacher voice is alive and well at the Department of Education. That wasnâ€™t always the case. That is the case
while Iâ€™m secretary. Their perspective helps drive what our commitments are: to not only work on teacher salary
but working conditions, making sure teachers have appropriate professional development on AI, making sure
weâ€™re supporting schools as the hub. These are all things that were influenced by AFT and NEA.

What we output is also informed. When weâ€™re putting out grant applications for different things, for additional
reading teachers, for additional mental health support, for additional support for schools as they develop pathways
to careers for students, itâ€™s all informed by our interactions with teachers and the voice of teachers. Like them,
weâ€™re fighting for equity. Like them, weâ€™re trying to remove the nonsense and the politics out of education
policy and focus on students. Weâ€™re keeping the needs of the students at the center of the conversation.

How do you define leading the world, and how far are we from achieving that?

Right now our country is in the middle when it comes to reading and math compared to other developed
countriesâ€”thatâ€™s unacceptable. Weâ€™re not leading the world there. We have major teacher shortages.
Weâ€™re not like other countries in terms of showing respect for the profession, making sure itâ€™s a competitive
salary, providing pathways into the profession. Weâ€™re not leading the world there. Weâ€™re going to lead the
world there.

When it comes to mental health, I want to make sure that our schools are looking at the holistic needs of our
students. We have work to do there. Weâ€™re better than many other countries in that aspect.

The majority of the people in that room were multilingual, so we have work to do there. In terms of pathways,
making sure our high schools are connected to industry partners or two-year colleges or four-year colleges,
weâ€™re making headway. Iâ€™m really excited about that work, but there are some countries where theyâ€™ve
been doing this for years. I want to lead the world on all those indicators.

What is a quality community school, and why should schools be working to replicate this model?

The schools that reopened safely the best were the ones that were more closely aligned to the principles of full-
service community schools. There was trust. There were resources available for parents in whatever language they
needed. There were mental health supports available to students. There was food where food insecurities existed
in the community. There were liaisons whose job it was to connect to community partners to make sure the
students in that school have what they need.

We know that model works. We saw it work during the pandemic. But we know when there is no pandemic that
when the schools become the hub of the community, students are more likely to thrive, and families are more likely
to be connected to the schools. Authentic parent engagement is more possible. It feels like a sense of community.

Iâ€™ll tell you, when the pandemic hit and kids were separated from schools, kids werenâ€™t upset because they
missed their math class. They mightâ€™ve missed their math teacher. They missed the sense of community that
schools provide. Full-service community schools do just that, they build a family and a sense of community.
Thatâ€™s where children thrive.

You said itâ€™s not enough to just give teachers a raise; working conditions have to improve, too. What are some
concrete actions the Education Department can take to improve teacher working conditions?Youâ€™ve got to start
with pay. Teachers make on average 20 to 30 percent less than other professions with similar degrees. Thatâ€™s
unacceptable. Weâ€™ve got to not normalize teachers driving Uber on the weekends. We canâ€™t have that.
Theyâ€™re professionals. Treat them like professionals.

Teachers, once they get into the parking lot, theyâ€™re on. They have students in front of them the whole day.
Maybe theyâ€™ll get half an hour for lunch where they have to make calls and hit the copy machine because it was

                                                                                                       Page 3 of 4
                       Teachers Need More Than Just Pay Raises, Secretary Cardona Says

too busy in the beginning. They have long days. So how do we build into the teacher day time for professional
learning, time for reflection, and time to observe another teacher? Thatâ€™s one thing.

Do we provide enough support and mentorship for teachers, teacher-to-teacher mentorship where they have time
during their workdayâ€”not on their personal timeâ€”to grow, to reflect, to observe another teacher? Do they have
an opportunity to ask questions if theyâ€™re struggling with something?

And then a third thing, do they have access to professional learning around topics that are important to them?

Four, do the classroom teachers have enough student support staff around them? Are there paraeducators to
support the students that need extra support? Do they have the right technology to make sure that they can keep
up with the needs of the students? Are there enough social workers, psychologists, and school counselors available
so that when students are struggling they have adequate support? Are there school nurses? Do they have
administrative support and leaders that are well trained and well supported so they could provide support for
educators? Do they have managers or instructional leaders? I would rather work in a school with an instructional
leader.

What role do you see ChatGPT and other AI platforms playing in the classroom, and what can the Education
Department do to regulate it?

My mentality is we have to get ahead of it to make sure weâ€™re providing guidance on how we could enhance
learning and create opportunities for critical thinking. Also, create what I call guardrails to make sure weâ€™re
protecting our students.

When the internet came out there were very few guardrails. There was too much exposure, and it was harder to
unlearn some of the things that were happening. Similarly, on social media, there were too few guardrails. As a
result, we believe social media has contributed to the youth mental health crisis. So letâ€™s take lessons from that
and say, technology is here. We need to embrace it. It could be amazing, but letâ€™s make sure that weâ€™re
staying ahead of it.

What Iâ€™m proposing is to have a national group that we convene with perspectives of teachers, students,
parents, educators, and some of our tech partners to collectively act upon our shared intent to protect children, but
also provide tools and professional learning for teachers that is appropriate and adequateâ€”so that a 3rd-grade
teacher knows how to use it to enhance learning, so that a high school teacher knows how to use it to develop
critical thinking skills.

How do you think Congress and the Education Department should approach social media's impact on student
mental health?

I do think regulatory safeguards are necessary. When the cars cameâ€”tremendous advancementâ€”we soon put
on seatbelts and airbags. It evolved over time. But we didnâ€™t say, weâ€™ve got to stop cars.

We can also work with our stakeholders and our companies to talk about reasonable uses of social media or
guidance on how it could be used for good. We need to take lessons from what weâ€™ve done in the past and the
impact on kids.

As a dad, I want to make sure that, if my child is on one of these apps, I know [how] theyâ€™re being targeted.
Social media is a good thing. I think it allows students to engage with one another, but I think itâ€™s the Joe
Camel, [the decades-old cigarette mascot that appealed to children], of this generation if left unchecked.

A version of this article appeared in theMay 17, 2023edition ofEducation WeekasTeachers Need More Than Just
Pay Raises, Education Secretary Argues


Load-Date: May 16, 2023

                                                                                    Page 4 of 4
                  Teachers Need More Than Just Pay Raises, Secretary Cardona Says



End of Document

                                                                                                      Page 1 of 3
         NYSOFA brings ElliQ Proactive care companion to older adults, reducing social isolation, supporting
                                    independence, connection & engagement




   NYSOFA brings ElliQ Proactive care companion to older adults, reducing
    social isolation, supporting independence, connection & engagement
                                     Niagara-Wheatfield Tribune (Niagara Falls, New York)
                                                        May 25, 2022



Copyright 2022 Niagara Frontier Publications
Distributed by Newsbank, Inc. All Rights Reserved

Section: CURRENT NEWS
Length: 1044 words

Body


NYSOFA-ElliQ partnership joins lineup of NYSOFA initiatives to help older adults age in place with innovative
supports and program offerings to combat loneliness and social isolation

Submitted by the New York State Office for the Aging

Building on its comprehensive effort to battle social isolation and support aging-in-place, the New York State Office
for the Aging is delivering voice-operated smart technology into the homes of over 800 older adults.

Under the program, NYSOFA will work with local offices for the aging and partners to identify older adults who
would most benefit from the technology – ElliQ by Intuition Robotics – which is the first-ever proactive and
empathetic care companion.

ElliQ is designed to foster independence and provide support for older adults through daily check-ins, assistance
with wellness goals and physical activities, connection to family and friends, and more using voice commands
and/or on-screen instructions. The technology, which recently launched commercially after years of pilots and early
production deployments, has shown unprecedented engagement levels with older adults. Users have an average of
20 daily interactions.

Distinct from other smart technologies, ElliQ is made specifically for older adults to support independence at home.
While other technologies are reactive to commands, ElliQ proactively suggests activities and initiates conversations,
building context through artificial intelligence (AI) to inform follow-up conversations that create a sense of
relationship with the AI. To support health and wellness, ElliQ offers sleep relaxation exercises, physical activity
exercises, in-depth nutrition-related conversations, and medication reminders for each user's unique condition(s).

In 2017, the U.S. surgeon general declared social isolation to be a "global epidemic" – one that has only worsened
in the COVID-19 health emergency. According to the AARP Public Policy Institute, social isolation drives $6.7
billion in additional associated Medicare spending per year. The health consequences of loneliness and isolation
are equivalent to smoking almost a pack of cigarettes daily. At a time when older adults are at increased risk for

                                                                                                     Page 2 of 3
        NYSOFA brings ElliQ Proactive care companion to older adults, reducing social isolation, supporting
                                   independence, connection & engagement

loneliness and social isolation, ElliQ offers another form of companionship, supplementing traditional, in-person
support.

NYSOFA Director Greg Olsen said, "We are so pleased to partner with Intuition Robotics and make ElliQ available
to older adults in New York. This product does so many things to improve health, combat isolation, and improve
overall well-being and independence. Designed with input from older adults, the future of supporting and serving
older adults includes technology. The future is here."

He added, "Despite misconceptions and generalizations, older adults embrace new technology, especially when
they see it is designed by older adults to meet their needs. For those who experience some form of isolation and
wish to age in place, ElliQ is a powerful complement to traditional forms of social interaction and support from
professional or family caregivers."

Intuition Robotics CEO and co-founder Dor Skuler said, "We've long believed that connecting older adults with local
communities via ElliQ will add an important element in providing holistic support to older adults aging in place. This
partnership with NYSOFA helps us further that mission through an innovative initiative that we are incredibly proud
to be part of."

He added, "We're thrilled to be working with New York state as our first state government partner and believe ElliQ
will be able to effectively engage and encourage older adults in New York to be more independent, healthy and
happy."

Association on Aging in New York (AgingNY) Executive Director Becky Preve said, "The Association on Aging in
New York is thrilled to offer additional technology services to combat social isolation and loneliness. We are so
thankful for NYSOFA's continued commitment to older New Yorkers and the opportunity to partner on innovative
solutions that support aging in place."

The newly enacted fiscal year 2023 state budget includes $2.9 million in funding for pioneering NYSOFA initiatives
to combat social isolation and offer new or expanded innovations in aging service provision at multiple levels. In
addition to ElliQ, this includes: NYSOFA's animatronic pet initiative, which provides lifelike companion pets for older
adults and is proven to reduce self-reported loneliness by 70%; statewide access to Trualta's family caregiver
support platform offering expert-led training across critical care competencies; ride-sharing services designed
exclusively for older adults; and online communities that provide facilitator-led classes and services.

The New York State Office for the Aging continuously works to help the state's 4.6 million older adults be as
independent as possible for as long as possible through advocacy, development and delivery of person-centered,
consumer-oriented, and cost-effective policies, programs, and services that support and empower older adults and
their families, in partnership with the network of public and private organizations that serve them. Stay connected:
Visit the NYSOFA Facebook page; follow @NYSAGING on Twitter and NYSAging on Instagram; or visit
aging.ny.gov.

Intuition Robotics, a startup company based in Israel, is on a mission to empower older adults to live happier,
healthier and more independent lives at home. The company's award-winning product, ElliQ, is a proactive care
companion for older adults. ElliQ helps keep users healthy, engaged and informed, while alleviating the effects of
loneliness and social isolation. Intuition Robotics has won several awards for its work with ElliQ, including Fast
Company's Most Innovative Companies and the CES Best of Innovation award. To learn more, visit www.elliq.com
OR follow on Facebook.

The Association on Aging in New York supports and advocates for New York's mostly county-based Area Agencies
on Aging (AAAs), and works collaboratively with a network of organizations that exist to promote independence,
preserve dignity, and provide support for residents of New York as they age. For more information, follow on
Facebook, visit www.agingny.org, or call 518-449-7080.

                                                                                                   Page 3 of 3
      NYSOFA brings ElliQ Proactive care companion to older adults, reducing social isolation, supporting
                                 independence, connection & engagement


Load-Date: May 26, 2022


 End of Document

                                                                                                      Page 1 of 3
         NYSOFA brings ElliQ Proactive care companion to older adults, reducing social isolation, supporting
                                    independence, connection & engagement




   NYSOFA brings ElliQ Proactive care companion to older adults, reducing
    social isolation, supporting independence, connection & engagement
                                               Island Dispatch (Grand Island, New York)
                                                            May 25, 2022



Copyright 2022 Niagara Frontier Publications
Distributed by Newsbank, Inc. All Rights Reserved

Section: STATE NEWS
Length: 1044 words

Body


NYSOFA-ElliQ partnership joins lineup of NYSOFA initiatives to help older adults age in place with innovative
supports and program offerings to combat loneliness and social isolation

Submitted by the New York State Office for the Aging

Building on its comprehensive effort to battle social isolation and support aging-in-place, the New York State Office
for the Aging is delivering voice-operated smart technology into the homes of over 800 older adults.

Under the program, NYSOFA will work with local offices for the aging and partners to identify older adults who
would most benefit from the technology – ElliQ by Intuition Robotics – which is the first-ever proactive and
empathetic care companion.

ElliQ is designed to foster independence and provide support for older adults through daily check-ins, assistance
with wellness goals and physical activities, connection to family and friends, and more using voice commands
and/or on-screen instructions. The technology, which recently launched commercially after years of pilots and early
production deployments, has shown unprecedented engagement levels with older adults. Users have an average of
20 daily interactions.

Distinct from other smart technologies, ElliQ is made specifically for older adults to support independence at home.
While other technologies are reactive to commands, ElliQ proactively suggests activities and initiates conversations,
building context through artificial intelligence (AI) to inform follow-up conversations that create a sense of
relationship with the AI. To support health and wellness, ElliQ offers sleep relaxation exercises, physical activity
exercises, in-depth nutrition-related conversations, and medication reminders for each user's unique condition(s).

In 2017, the U.S. surgeon general declared social isolation to be a "global epidemic" – one that has only worsened
in the COVID-19 health emergency. According to the AARP Public Policy Institute, social isolation drives $6.7
billion in additional associated Medicare spending per year. The health consequences of loneliness and isolation
are equivalent to smoking almost a pack of cigarettes daily. At a time when older adults are at increased risk for

                                                                                                     Page 2 of 3
        NYSOFA brings ElliQ Proactive care companion to older adults, reducing social isolation, supporting
                                   independence, connection & engagement

loneliness and social isolation, ElliQ offers another form of companionship, supplementing traditional, in-person
support.

NYSOFA Director Greg Olsen said, "We are so pleased to partner with Intuition Robotics and make ElliQ available
to older adults in New York. This product does so many things to improve health, combat isolation, and improve
overall well-being and independence. Designed with input from older adults, the future of supporting and serving
older adults includes technology. The future is here."

He added, "Despite misconceptions and generalizations, older adults embrace new technology, especially when
they see it is designed by older adults to meet their needs. For those who experience some form of isolation and
wish to age in place, ElliQ is a powerful complement to traditional forms of social interaction and support from
professional or family caregivers."

Intuition Robotics CEO and co-founder Dor Skuler said, "We've long believed that connecting older adults with local
communities via ElliQ will add an important element in providing holistic support to older adults aging in place. This
partnership with NYSOFA helps us further that mission through an innovative initiative that we are incredibly proud
to be part of."

He added, "We're thrilled to be working with New York state as our first state government partner and believe ElliQ
will be able to effectively engage and encourage older adults in New York to be more independent, healthy and
happy."

Association on Aging in New York (AgingNY) Executive Director Becky Preve said, "The Association on Aging in
New York is thrilled to offer additional technology services to combat social isolation and loneliness. We are so
thankful for NYSOFA's continued commitment to older New Yorkers and the opportunity to partner on innovative
solutions that support aging in place."

The newly enacted fiscal year 2023 state budget includes $2.9 million in funding for pioneering NYSOFA initiatives
to combat social isolation and offer new or expanded innovations in aging service provision at multiple levels. In
addition to ElliQ, this includes: NYSOFA's animatronic pet initiative, which provides lifelike companion pets for older
adults and is proven to reduce self-reported loneliness by 70%; statewide access to Trualta's family caregiver
support platform offering expert-led training across critical care competencies; ride-sharing services designed
exclusively for older adults; and online communities that provide facilitator-led classes and services.

The New York State Office for the Aging continuously works to help the state's 4.6 million older adults be as
independent as possible for as long as possible through advocacy, development and delivery of person-centered,
consumer-oriented, and cost-effective policies, programs, and services that support and empower older adults and
their families, in partnership with the network of public and private organizations that serve them. Stay connected:
Visit the NYSOFA Facebook page; follow @NYSAGING on Twitter and NYSAging on Instagram; or visit
aging.ny.gov.

Intuition Robotics, a startup company based in Israel, is on a mission to empower older adults to live happier,
healthier and more independent lives at home. The company's award-winning product, ElliQ, is a proactive care
companion for older adults. ElliQ helps keep users healthy, engaged and informed, while alleviating the effects of
loneliness and social isolation. Intuition Robotics has won several awards for its work with ElliQ, including Fast
Company's Most Innovative Companies and the CES Best of Innovation award. To learn more, visit www.elliq.com
OR follow on Facebook.

The Association on Aging in New York supports and advocates for New York's mostly county-based Area Agencies
on Aging (AAAs), and works collaboratively with a network of organizations that exist to promote independence,
preserve dignity, and provide support for residents of New York as they age. For more information, follow on
Facebook, visit www.agingny.org, or call 518-449-7080.

                                                                                                   Page 3 of 3
      NYSOFA brings ElliQ Proactive care companion to older adults, reducing social isolation, supporting
                                 independence, connection & engagement


Load-Date: May 26, 2022


 End of Document

                                                                                                          Page 1 of 4
                         Artificial intelligence may influence whether you can get pain medication




   Artificial intelligence may influence whether you can get pain medication
                                                  The Philadelphia Daily News
                                                  September 5, 2023 Tuesday



Copyright 2023 Philadelphia Newspapers, LLC All Rights Reserved

Section: MAIN NEWS; Pg. A1
Length: 1587 words
Byline: Andy Miller and Sam Whitehead (KFF Health News)

Body


Elizabeth Amirault had never heard of a Narx Score. But she said she learned last year the tool had been used to
track her medication use.

During an August 2022 visit to a hospital in Fort Wayne, Ind., Amirault told a nurse practitioner she was in severe
pain, she said. She received a puzzling response.

"Your Narx Score is so high, I can't give you any narcotics," she recalled the man saying, as she waited for an MRI
before a hip replacement.

Tools such as Narx Scores are used to help medical providers review controlled substance prescriptions. They
influence, and can limit, the prescribing of painkillers, similar to a credit score influencing the terms of a loan. Narx
Scores and an algorithm-generated overdose risk rating are produced by health care technology company Bamboo
Health (formerly Appriss Health) in its NarxCare platform.

Such systems are designed to fight the nation's opioid epidemic, which has led to an alarming number of overdose
deaths. The platforms draw on data about prescriptions for controlled substances that states collect to identify
patterns of potential problems involving patients and physicians. State and federal health agencies, law
enforcement officials, and health care providers have enlisted these tools, but the mechanics behind the formulas
used are generally not shared with the public.

Artificial intelligence is working its way into more parts of American life. As AI spreads within the health care
landscape, it brings familiar concerns of bias and accuracy and whether government regulation can keep up with
rapidly advancing technology.

The use of systems to analyze opioid-prescribing data has sparked questions over whether they have undergone
enough independent testing outside of the companies that developed them, making it hard to know how they work.

Lacking the ability to see inside these systems leaves only clues to their potential impact. Some patients say they
have been cut off from needed care. Some doctors say their ability to practice medicine has been unfairly
threatened. Researchers warn that such technology - despite its benefits - can have unforeseen consequences if it
improperly flags patients or doctors.

                                                                                                       Page 2 of 4
                       Artificial intelligence may influence whether you can get pain medication

"We need to see what's going on to make sure we're not doing more harm than good," said Jason Gibbons, a
health economist at the Colorado School of Public Health at the University of Colorado's Anschutz Medical
Campus. "We're concerned that it's not working as intended, and it's harming patients."

Amirault, 34, said she has dealt for years with chronic pain from health conditions such as sciatica, degenerative
disc disease, and avascular necrosis, which results from restricted blood supply to the bones.

The opioid Percocet offers her some relief. She'd been denied the medication before, but never had been told
anything about a Narx Score, she said.

In a chronic pain support group on Facebook, she found others posting about NarxCare, which scores patients
based on their supposed risk of prescription drug misuse. She's convinced her ratings negatively influenced her
care.

"Apparently being sick and having a bunch of surgeries and different doctors, all of that goes against me," Amirault
said.

Database-driven tracking has been linked to a decline in opioid prescriptions, but evidence is mixed on its impact on
curbing the epidemic. Overdose deaths continue to plague the country, and patients such as Amirault have said the
monitoring systems leave them feeling stigmatized as well as cut off from pain relief.

The Centers for Disease Control and Prevention estimated that in 2021 about 52 million American adults suffered
from chronic pain, and about 17 million people lived with pain so severe that it limited their daily activities. To
manage the pain, many use prescription opioids, which are tracked in nearly every state through electronic
databases known as prescription drug monitoring programs (PDMPs).

The last state to adopt a program, Missouri, is still getting it up and running.

More than 40 states and territories use the technology from Bamboo Health to run PDMPs. That data can be fed
into NarxCare, a separate suite of tools to help medical professionals make decisions. Hundreds of health care
facilities and five of the top six major pharmacy retailers also use NarxCare, the company said.

The platform generates three Narx Scores based on a patient's prescription activity involving narcotics, sedatives,
and stimulants. A peer-reviewed study showed the "Narx Score metric could serve as a useful initial universal
prescription opioid-risk screener."

NarxCare's algorithm-generated "Overdose Risk Score" draws on a patient's medication information from PDMPs -
such as the number of doctors writing prescriptions, the number of pharmacies used, and drug dosage - to help
medical providers assess a patient's risk of opioid overdose.

Bamboo Health did not share the specific formula behind the algorithm or address questions about the accuracy of
its Overdose Risk Score but said it continues to review and validate the algorithm behind it, based on current
overdose trends.

       Guidance from the CDC advised clinicians to consult PDMP data before prescribing pain medications. But
the agency warned that "special attention should be paid to ensure that PDMP information is not used in a way that
is harmful to patients."

This prescription-drug data has led patients to be dismissed from clinician practices, the CDC said, which could
leave patients at risk of being untreated or undertreated for pain. The agency further warned that risk scores may
be generated by "proprietary algorithms that are not publicly available" and could lead to biased results.

Bamboo Health said that NarxCare can show providers all of a patient's scores on one screen, but that these tools
should never replace decisions made by physicians.

Some patients say the tools have had an outsized impact on their treatment.

                                                                                                        Page 3 of 4
                      Artificial intelligence may influence whether you can get pain medication

Bev Schechtman, 47, who lives in North Carolina, said she has occasionally used opioids to manage pain flare-ups
from Crohn's disease. As vice president of the Doctor Patient Forum, a chronic pain patient advocacy group, she
said she has heard from others reporting medication access problems, many of which she worries are caused by
red flags from databases.

"There's a lot of patients cut off without medication," according to Schechtman, who said some have turned to illicit
sources when they can't get their prescriptions. "Some patients say to us, 'It's either suicide or the streets.'"

The stakes are high for pain patients. Research shows rapid dose changes can increase the risk of withdrawal,
depression, anxiety, and even suicide.

Some doctors who treat chronic pain patients say they, too, have been flagged by data systems and then lost their
license to practice and were prosecuted.

Lesly Pompy, a pain medicine and addiction specialist in Monroe, Mich., believes such systems were involved in a
legal case against him.

His medical office was raided by a mix of local and federal law enforcement agencies in 2016 because of his
patterns in prescribing pain medicine. A year after the raid, Pompy's medical license was suspended. In 2018, he
was indicted on charges of illegally distributing opioid pain medication and health care fraud.

"I knew I was taking care of patients in good faith," he said. A federal jury in January acquitted him of all charges.
He said he's working to have his license restored.

One firm, Qlarant, a Maryland-based technology company, said it has developed algorithms "to identify
questionable behavior patterns and interactions for controlled substances, and for opioids, in particular," involving
medical providers.

The company, in an online brochure, said its "extensive government work" includes partnerships with state and
federal enforcement entities such as the Department of Health and Human Services' Office of Inspector General,
the FBI, and the Drug Enforcement Administration.

In a promotional video, the company said its algorithms can "analyze a wide variety of data sources," including
court records, insurance claims, drug monitoring data, property records, and incarceration data to flag providers.

William Mapp, the company's chief technology officer, stressed the final decision about what to do with that
information is left up to people - not the algorithms.

Mapp said that "Qlarant's algorithms are considered proprietary and our intellectual property" and that they have not
been independently peer-reviewed.

"We do know that there's going to be some percentage of error, and we try to let our customers know," Mapp said.
"It sucks when we get it wrong. But we're constantly trying to get to that point where there are fewer things that are
wrong."

Prosecutions against doctors through the use of prescribing data have attracted the attention of the American
Medical Association.

"These unknown and unreviewed algorithms have resulted in physicians having their prescribing privileges
immediately suspended without due process or review by a state licensing board - often harming patients in pain
because of delays and denials of care," said Bobby Mukkamala, chair of the AMA's Substance Use and Pain Care
Task Force.

Even critics of drug-tracking systems and algorithms say there is a place for data and artificial intelligence systems
in reducing the harms of the opioid crisis.

                                                                                                       Page 4 of 4
                      Artificial intelligence may influence whether you can get pain medication

"It's just a matter of making sure that the technology is working as intended," said health economist Gibbons.

      KFF Health News is a national newsroom that covers health issues.


Load-Date: September 5, 2023


  End of Document

                                                                                                        Page 1 of 2
                    Adventist Health Bakersfield celebrates new designation for its AIS Cancer Center




 Adventist Health Bakersfield celebrates new designation for its AIS Cancer
                                   Center
                                               The Bakersfield Californian
                                              February 22, 2020 Saturday



Copyright 2020 The Bakersfield Californian

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 564 words
Byline: Steven Mayer, The Bakersfield Californian

Body


Feb. 22--     Feb. 22--When Dale Lamason was diagnosed with prostate cancer in 2019, he suddenly was faced
with decisions he never expected to have to make.

One of them was where to seek treatment -- out of town at some big-name university hospital or at a cancer center
near where he lives.

Lamason, 62, chose Adventist Health's AIS Cancer Center in downtown Bakersfield, a cancer treatment facility that
on Friday announced it has been designated a Comprehensive Community Cancer Program by the American
College of Surgeons Commission on Cancer.

"This designation means that when you come to the Adventist Health AIS Cancer Center, you're receiving care
from a team of board-certified experts who adhere to national, evidence-based treatment guidelines," said Dr. Luis
Mariscal, the center's medical director.

To earn the designation, cancer centers must provide coordinated care, meaning all services for patients, from
diagnosis through treatment and recovery are provided in-house, from imaging services to radiation treatments.

And through the center's wellness programs, patients receive continuing support.

"The journey doesn't end when the treatment ends," Mariscal said.

At a press conference held Friday in front of the cancer center, Mariscal was joined by several members of the
community and the center's executive staff, including Dr. Francesca Hoehne, director of the facility's Breast Center,
Dr. James Cusator, medical director at Adventist Health Quest Imaging, and others.

The value, Cusator said, of being able to remain in Bakersfield and receive world-class cancer treatment is
significant. He referred to it as the "home field advantage."

                                                                                                         Page 2 of 2
                  Adventist Health Bakersfield celebrates new designation for its AIS Cancer Center

"We all understand that concept," he said, "the importance of facing your adversary in your own backyard."

The center has cared for more than 15,000 patients since it opened in 2013, said Cusator. And rather than spend
hours on the road and money in hotels, those patients have been able to rely on their "home field" support system,
their families, friends and their community.

"It all comes down to the patient-first principle," he said.

For Lamason, having the confidence to stay "home" for his cancer treatment was a "big thing."

"I've known people who drive hours for their treatment," he said. "They stay in hotels or in trailers.

"When dealing with a life-shortening issue ... being at home is like comfort food."

According to data provided by Adventist, rates for colorectal, lung, breast and prostate cancer have all dropped
significantly in Kern County over the past decade -- progress that can be attributed to greater public awareness,
earlier screening and diagnosis, and better treatment.

Who knows what the next 10 years will hold.

For Mariscal, the designation from the American College of Surgeons is about more than just the boxes that had to
be checked to earn the title, as important as those requirements are.

"This designation is a promise to our community that we will always hold ourselves to the highest standards," he
said, "constantly innovate and strive to do better each day as we stand alongside you in your fight against cancer."

Steven Mayer can be reached at 661-395-7353. Follow him on Facebook and on Twitter: @semayerTBC.

___ (c)2020 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: February 22, 2020


  End of Document

                                                                                            Page 1 of 2
    Case Study: Saving Employers $6M Annually Through Machine Learning + Value-Based Care Management




  Case Study: Saving Employers $6M Annually Through Machine Learning +
                      Value-Based Care Management
                                    College Heights Herald: Western Kentucky University
                                                      July 7, 2020 Tuesday



University Wire
Copyright 2020 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 761 words

Body

LOUISVILLE, Ky., July 7, 2020 /PRNewswire/ -- Working with national insurers and PBMs, Certilytics deploys its
sophisticated predictive analytics in support of value-based care management programs at dozens of large, self-
funded employers.



A recent analysis of those programs showed they save participating employers an average of over $200 per
member, per year , relative to previous care-management strategies. For a typical employer-with about 30,000
participating beneficiaries-this translates toannual savings of more than $6 million.

To achieve these savings, we help our customers move from retrospective reporting to prospective predictive
analytics-identifying members for outreach before they've incurred significant costs.

This includes identifying members at risk for high-cost events, such as an emergency room visits, along with
members at risk for developing chronic disease, such as diabetes. In the case of emerging clinical risk, we group
members into risk buckets based on their likelihood of developing chronic diseases, enabling our clients to track
progress in using care management strategies to move members from high risk to medium risk, or medium risk to
low risk. We also predict a member's likelihood of engagement, maximizing the chances that clinical interventions
will be effective.

Our advanced, predictive approach is not intended to replace an employer's existing health benefit and care
management programs. Instead, we seek to optimize those programs by acting as a centralized hub-the Nucleus
Data Warehouse-that can be deployed with ease and integrates with existing resources. We help employers
maximize the potential of their care management investments by analyzing utilization and engagement data to
predict which beneficiaries will take advantage when directed to the services that will have the greatest impact on
their health.

The data from our analysis shows our sophisticated approach to value-based care management is having the
intended effect, with cost savings that correspond with a positive shift in utilization patterns, including increased
medication adherence.

                                                                                           Page 2 of 2
   Case Study: Saving Employers $6M Annually Through Machine Learning + Value-Based Care Management

"As the predictive analytics space becomes more crowded, modelers must move beyond quoting validation
accuracies and show real-world results," said Certilytics Chief Data Scientist Robert Dwyer, PhD. "In this analysis
we used best-practice causal modeling approaches to show that our analytics-driven programs actually achieve
real-world savings on the order of hundreds of dollars PMPY."

The problem with traditional approaches to care management

Traditional approaches to value-based care management typically include identifying members for intervention
based on retrospective factors such as:
    •   Open Gaps in Care
    •   Historic Utilization / Costs
    •   Financial Risk

Unfortunately, these factors fail to provide care managers with a complete picture of their members' emerging
clinical risk profile. By the time care managers react based on open gaps in care or avoidable utilization, members
have oftentimes already incurred a significant (and avoidable) spike in their healthcare costs.

The Certilytics Approach

Certilytics enhances the member identification process with prospective analytics that account for a member's
likelihood of modifying behavior if targeted by a care manager.

Rather than focusing on members already diagnosed with chronic conditions, Certilytics' predictive models identify
members at high risk of developing chronic conditions, enabling earlier interventions to prevent high-cost events.
These models are aggregated into the Certilytics Health Index , an AI-powered proprietary algorithm that stratifies
members based on the optimal combination of three factors:
    •   Emerging Clinical Risk: the prospective likelihood of a member developing chronic diseases or utilizing
        high-cost services, such as the Emergency Room
    •   Prospective Financial Risk: a member's predicted financial risk over the next twelve months based on
        medical history, utilization patterns, gaps in care, demographic data, and other non-traditional data sources
    •   Propensity for Engagement: the likelihood a member will adjust behaviors because of outreach from a
        nurse or care manager

Because Certilytics' models account for a member's propensity for engagement, Certilytics has a substantial edge
over traditional approaches to value-based care management.

Contact us to hear more about our recent analysis and how we can save your organizations millions of dollars per
year through value-based care management.

Contact: Austin Wright Austin.wright@certilytics.com 804-698-9461


Load-Date: July 7, 2020


  End of Document

                                                                                                           Page 1 of 3
                                                A Robot Wrote This Review




                                        A Robot Wrote This Review
                                                   The New York Times
                                                December 12, 2021 Sunday
                                                    Late Edition - Final



Copyright 2021 The New York Times Company

Section: Section BR; Column 0; Book Review Desk; Pg. 17; NONFICTION
Length: 1423 words
Byline: By Kevin Roose

Body


THE AGE OF AIAnd Our Human FutureBy Henry A. Kissinger, Eric Schmidt and Daniel Huttenlocher

One of the great promises of technology is that it can do the work that humans find too boring or arduous.

  In the 19th and 20th centuries, factory machines relieved us of repetitive manual labor and backbreaking farm
work. In this century, artificial intelligence has taken care of a few more tasks -- curating Spotify playlists, selecting
the next YouTube video, vacuuming the floor and so on -- but many more mind-numbing activities remain ripe for
the picking. The experts promise us that someday, all of our least favorite chores -- including complex cognitive
ones, like interviewing job candidates or managing global supply chains -- will be outsourced to machines.

 But that day has not yet arrived. Or has it?

 After finishing ''The Age of AI,'' a new book about artificial intelligence by Henry A. Kissinger, Eric Schmidt and
Daniel Huttenlocher, I found myself unmoved by the prospect of reviewing it. I've read dozens of books about A.I.,
and while the conceit of this one was intriguing -- bringing together a 98-year-old diplomat, a former Google chief
executive and an M.I.T. professor -- the book itself was a fairly forgettable entry in the genre.

 Then I got a bright idea. What if I could have an A.I. finish this review, and save myself the trouble?

  So I fired up Sudowrite, an A.I. writing program I've been experimenting with recently. The app uses GPT-3, the
cutting-edge A.I. system developed by the San Francisco-based OpenAI, which acts as a kind of turbocharged
version of Gmail's autocomplete feature. Provide a snippet of text, and GPT-3 will try to complete it, using
everything it has learned from ingesting billions of examples of other people's writing. It does this with the help of a
supercomputer containing some 285,000 processors, and a multilayered neural network that ranks among the
world's most powerful A.I. engines. The authors of ''The Age of AI'' call GPT-3 one of several promising
technologies that are producing a ''revolution in human affairs.''

 I pasted the first several paragraphs of this review into Sudowrite, and asked the A.I. to finish. Here's what it wrote:

                                                                                                             Page 2 of 3
                                               A Robot Wrote This Review

  Henry Kissinger, Eric Schmidt and Daniel Huttenlocher's ''The Age of AI'' is a bold new book on artificial
intelligence that will become the go-to guide for anyone who wants to understand this transformative technology.

 The authors have examined the full range of AI technologies -- from computer vision systems to natural language
processing -- and written about them in a way that will appeal to both experts and laypeople.

 One of the most inspiring aspects of this book is its scope. The authors delve deeply into the potential of AI in all
areas of human enterprise. They describe the impact of AI on health care, economics, geopolitics, law, urban
development, governance, journalism, the military and even the life sciences.

 Kissinger, Schmidt and Huttenlocher are not afraid to explore the darkest side of AI, either. They are clear-eyed
about the ways that AI could enable dictators to monitor their citizens and manipulate information to incite people to
commit violence.

 Although AI is already making our lives better in many ways, Kissinger, Schmidt and Huttenlocher caution that it
will take us as a species many years to create a system as powerful as we deserve. They wisely suggest that we
not lose sight of the values we want to instill in this new machine intelligence.

 Thank you, GPT-3! Now, a few notes:

 First, the A.I. wasn't an unqualified success. It took Sudowrite a few tries. On the first attempt, it spit out a series of
run-on sentences that hinted that GPT-3 had gotten stuck in some kind of odd, recursive loop. (It began: ''The book
which you are reading at the moment is a book on a nook, which is a book on a book, which is a book on a subject,
which is a subject on a subject, which is a subject on a subject.'') A few tries later, it seemed to give up on the task
of book reviewing altogether, and started merely listing the names of tech companies. (''Google, Facebook, Apple,
Amazon, IBM, Microsoft, Baidu, Tencent, Tesla, Uber, Airbnb, Twitter, Snap, Alibaba, WeChat, Slack.'')

 But it warmed up quickly, and within a few minutes, the A.I. was coming up with impressively cogent paragraphs of
analysis -- some, frankly, better than what I could have generated on my own.

 This speaks to one of the recurring themes of ''The Age of AI,'' which is that although today's A.I. systems can be
clunky and erratic at times, they are getting better fast, and will soon match or surpass human proficiency in a
number of important tasks, solving problems in ways no human would have thought to solve them. At that point, the
authors write, A.I. will ''transform all realms of human experience.''

  Second, while GPT-3 was correct about the scope of ''The Age of AI'' -- with chapters on everything from social
media algorithms to autonomous weapons -- it failed to note that all of that broadness comes at a cost. The book
feels cursory and shallow in places, and many of its recommendations are puzzlingly vague.

  In a chapter on the geopolitical risks posed by A.I., the authors conclude that ''the nations of the world must make
urgent decisions regarding what is compatible with concepts of inherent human dignity and moral agency.'' (OK,
we'll get right on that!) A brief section about TikTok -- an app used by more than a billion people worldwide, whose
ownership by a Chinese company raises legitimately fascinating questions about national sovereignty and free
speech -- ends with the throwaway observation that ''more complex geopolitical and regulatory riddles await us in
the near future.'' And when the authors do make specific recommendations -- such as a proposal to restrict the use
of A.I. in developing biological weapons -- they fail to elaborate on how such an outcome might be achieved, or who
might stand in its way.

  Finally, GPT-3 didn't address the biggest question about the book, which is why it exists at all. Kissinger, who was
66 years old when the World Wide Web was invented, is not a full-time A.I. practitioner, nor a particularly savvy
parser of tech hype. (His last newsworthy foray into the tech world was when he sat on the board of Theranos, the
doomed blood-testing start-up.) Schmidt, who spent a decade running Google, is these days preoccupied with
trying to scare up military contracts for big tech companies. And while Huttenlocher, the dean of M.I.T.'s
Schwarzman College of Computing, may be a bona fide subject matter expert, it's not clear how much of the book
he actually wrote.

                                                                                                            Page 3 of 3
                                              A Robot Wrote This Review

  That said, the book does get some things right. The authors do a commendable job of avoiding what I call ''A.I.
fatalism'' -- the belief, sadly common in tech circles, that A.I. is part of an inevitable future whose course we are
powerless to change. Instead, they write that ''humans still control'' A.I., and have the opportunity to ''shape it with
our values.'' They also point out, correctly, that while many people worry about killer robots who achieve human-
level sentience and mow us all down with Uzis, a much bigger near-term danger lurks in the innocuous-seeming
A.I.s we all use every day, from the feed-ranking algorithms of social media apps to the automated dispatch
systems that power Uber and Lyft.

 ''Without significant fanfare -- or even visibility -- we are integrating nonhuman intelligence into the basic fabric of
human activity,'' they write.

 Still, while it could be a useful summary of A.I. for those just starting to learn about the topic, ''The Age of AI'' does
not advance the ball much. It's a shame, given how much access the authors presumably had to a who's who of the
A.I. elite. And it makes me wish that...

 Actually, you know what? It's sunny outside, my dogs need a walk, and I don't really feel like finishing this review.
Take it away, GPT-3.

  ...It makes me wish that someone out there would crank out a comprehensive survey text on AI, one that's laser-
focused on the technical issues, written by industry mavens who are actually doing this stuff day in and day out, and
is written in an engaging, clear, plain-spoken style.

  I couldn't have said it better myself.Kevin Roose is a technology columnist for The Times and the author of
''Futureproof: 9 Rules for Humans in the Age of Automation.''THE AGE OF AIAnd Our Human FutureBy Henry A.
Kissinger, Eric Schmidt and Daniel Huttenlocher254 pp. Little, Brown & Company. $30.


https://www.nytimes.com/2021/11/21/books/review/the-age-of-ai-henry-kissinger-eric-schmidt-daniel-
huttenlocher.html



Graphic


PHOTO: (PHOTOGRAPH BY Elliot Ulm FOR THE NEW YORK TIMES)


Load-Date: December 12, 2021


  End of Document

                                                                                                         Page 1 of 2
                     Review: A Fierce Clarity of Vision in ‘J’ai Pleuré Avec les Chiens’ Critic’s Pick




   Review: A Fierce Clarity of Vision in ‘J’ai Pleuré Avec les Chiens’; Critic’s
                                       Pick
                                                     The New York Times
                                            January 15, 2023 Sunday 22:57 EST



Copyright 2023 The New York Times Company All Rights Reserved

Section: ARTS; dance
Length: 676 words
Byline: Siobhan Burke
Highlight: The Indigenous artist Daina Ashbee’s first group piece, at the Gibney, simmers with tension and offers
an approach to healing.

Body


The Indigenous artist Daina Ashbee’s first group piece, at the Gibney, simmers with tension and offers an approach
to healing.

At the beginning of Daina Ashbee’s “J’ai Pleuré Avec les Chiens (Time, Creation, Destruction),” we hear the placid
voice of the New Age author Louise Hay, who published the popular self-help book “You Can Heal Your Life” in
1984. “This tape is about healing,” Hay says. “How healthy are you?”

In the low light of a studio-theater at Gibney’s Agnes Varis Performing Arts Center, where the audacious “J’ai
Pleuré” had its New York premiere over the weekend, five dancers were crawling, naked, across the floor. Isolated
for a while, they eventually made contact as one climbed atop another: two bodies stacked on all fours, a
precarious arrangement that would reconfigure itself many times over the work’s volatile, often gripping 80 minutes.

Ashbee, an Indigenous artist from British Columbia (of Cree, Métis and Dutch heritage), has garnered much
attention internationally for dances that often push the body to unsettling extremes. In her early 30s, she has
already presented a retrospective of works created in her 20s. “J’ai Pleuré,” her first group piece — solos and duets
have been her focus — demonstrates both the uncertainty of moving in a new choreographic direction and a fierce
clarity of vision.

In the work’s opening moments, tension simmers. Initially, Hay’s accompanying musings sound reasonable, even
wise: “The body is always talking to us, if we will only take the time to listen.” But they become increasingly
questionable, as she posits that “all illness is self-created” and “we choose our parents; we choose our sex, our
color, our country.” The piercing whimper of a dog — an alarming interruption — drowns out her voice. (The title
translates to “I cried with the dogs.”)

This cry of distress ushers in what could be a different approach to healing: one created on the artists’ own terms,
taking seriously the interconnection of the self with social structures (and with other species). Channeling canine
behavior, the dancers — with formidable conviction — bark, moan, grunt, howl and pant. Alone and in pairs, they

                                                                                                        Page 2 of 2
                    Review: A Fierce Clarity of Vision in ‘J’ai Pleuré Avec les Chiens’ Critic’s Pick

wrest themselves into severe contortions and painful-looking balances, sometimes coming right up close to the
audience, which surrounds them on three sides.

At first this all resembles a form of self-torture, intensified by ominous drones and squawks in the intermittent score
(by Sean MacPherson, Ashbee and Gabriel Nieto, who is also one of the dancers). Yet intriguingly, it evolves into
something more like play, one dancer tagging another as an invitation to perilously partner. Nieto lies on his back,
legs up, supporting Greys Vecchionacce in a suspended handstand. In a similar fashion, Audrey Sides teeters
horizontally on the soles of Elise Vanderborght’s feet. Irene Martínez does a headstand on her own, legs arching
back in a physics-defying curve. They all appear to take great pleasure in these feats.

At times, the provocations of “J’ai Pleuré” seem unmoored from a deeper foundation, seeking to shock for shock’s
sake. But by the end, the piece unmistakably finds its sense of purpose, most potently in a duet for Nieto and
Vecchionacce, which feels like a mourning and a reclamation. While the poetic lighting dims, as if to signal an end,
the two conjure a new beginning in a transporting call-and-response, a sound between a growl and a wail flowing
from their bodies. As Nieto traverses the perimeter of the space, Vecchionacce punches, stamps and spins in the
center, a breathtaking force. When all five dancers reunite in the end, lights up on their exposed bodies, something
has been healed.

J’ai Pleuré Avec les Chiens (Time, Creation, Destruction)

Jan. 13-14 at Gibney Dance; gibneydance.org.

J’ai Pleuré Avec les Chiens (Time, Creation, Destruction) Performed Friday and Saturday at Gibney Dance

PHOTO: From top, Greys Vecchionacce and Gabriel Nieto in “J’ai Pleuré Avec Les Chiens.” (PHOTOGRAPH BY
ANDREA MOHIN/THE NEW YORK TIMES) This article appeared in print on page C2.


Load-Date: January 15, 2023


  End of Document

                                                                                                         Page 1 of 4
                                 Indonesia striving to solve shortage of specialists doctors




                Indonesia striving to solve shortage of specialists doctors


                                                       ASEAN Tribune
                                                   February 26, 2023 Sunday



Copyright 2023 ASEAN Tribune All Rights Reserved




Length: 1502 words

Body


26 Feb 2023 (Antara News Agency) Indonesia'sHouse of Representatives (DPR RI)'s plenary meeting, held on
Tuesday, February 14, had approved the draft of theHealthcareOmnibus Bill to be then finalized by the House's
Commission IX overseeing the health and labor issues along with the government.

The draft of the bill, initiated by the House, thathad been approved by eight factions, except the Prosperous Justice
Party (PKS), isrelated to factual issues in today's society, especially in the health sector.

In a public discussion agenda entitled "The Urgency of the Health Bill" that the National Awakening Party (PKB)
held on February 18, the Health Ministry's Secretary GeneralKunta Wibawa Dasanugrahahad highlighted the
importance of havingregulations that are able to answer challenges in the health transformation system in
Indonesia.

Of the six pillars of the Health Ministry'shealth transformation,Dasanugraha highlighted several important issues
that required strengthening of the legal framework, including increasing the quality and distribution of doctors in
Indonesia.

The shortage of specialist doctors in Indonesia is related to distribution which is too concentrated in Java Island,
especially in Jakarta. Apart from thedistribution issue, the shortage of specialist doctors in Indonesia is also related
to inadequate educational institutions.

ccording to the Indonesian Medical Council's (KKI's) data, as of December 6, 2022, the number of specialist doctors
in Java hadreached 34,763 people. It means,there are approximately 22 medical specialists for every 100,000
residents in Java.

Meanwhile, there are only 615 specialist doctors in Maluku and Papua or around seven specialist doctors for every
100,000 residents in eastern Indonesia.

The digital footprint also records dozens of tuberculosis (TB) patients lining up at the Sidikalang Hospital in North
Sumatra. One obstetrician specialist was also dismissed from the Sidikalang Hospital for negligence in a baby that
caused to the baby's death.

                                                                                                         Page 2 of 4
                              Indonesia striving to solve shortage of specialists doctors

The management of the Sidikalang Hospital admits that they only have two obstetricians. The hospital often refuses
patients with complaints of ear, nose, and throat pain because they do not have an otorhinolaryngologist.

The Karangasem General Hospital in Bali also experiencesthe same situation. It has been facinga shortage of
cardiologists, radiologists, general practitioners, and internists over the past few years.

Head of the KarangasemPublic Hospital'sService Department I Komang Wiryasaid there is only one cardiologist
available who shouldserve around 10-15 patients per day.

In Aceh, RahmatAulia, a sixth-grader from Pidie Jaya, musttake his father by a motorized pedicabonce in every 10
days to a hospital in North Aceh District, about 160 kilometers away from his home, due to the lack of health
facilities.

Shortage of specialist doctors

The Health Ministry reports that Indonesia still lacks around 3,941 Obstetrics and Gynecology doctors.
Unfortunately, around 300 pregnant women die from 100,000 live births in the country.In addition, neonatal infants
aged 0-28 days, are reported to die for every 1,000 births. This figure is far above other countries,including
Singapore, Malaysia, Thailand, and Vietnam.

The current system of Medical Specialist Education Program (PPDS) in Indonesia still requires an average of 36
years to produce the needs of obstetricians in Indonesia.

Specialist doctors seem to be a rare item in Indonesia. The biggest shortage of specialist doctors was experienced
by obstetricians with 3,941 doctors, 3,662 pediatricians, and 2,581 internists.

With the current number of lecturers and student quotas per lecturer, medical schools in Indonesia are estimated to
need 1.36 years to meet the needs of obstetricians, 2.26 years for pediatricians, and 3.23 years for internists.

The PPDS entrance fees as well as expensive college tuition fees (for 10 semesters) and "illegal levies" or locally
called "biaya siluman" that prospective students need to pay may have contributed to the limited number of
specialist doctors in Indonesia.

The medical students are also facing other challenges, such as paying costs for participating in workshops and
training outside the city, daily living expenses for themselves and families, as well as "unofficial costs" when
meeting with seniors who want them to buy food, office needs, and medicines.

part from the limited PPDS quota and the "bullying system", the "biaya siluman" may become the reason why
Indonesia is still lacking specialist doctors. There has been a lack of transparency at universities regarding the costs
that are suspected to be illegal.

On the other hand, doctors who are pursuing specialist or residency do not receive a salary reward, even though
they work for 48 hours per week without taking a rest.

However, the salary system for resident doctors is mandated in Law Number 20/2013 concerning Medical
Education. Article 31, paragraph b, stipulates that every student has the right to receive incentives at Teaching
Hospitals and Medical Education Facilities.

This provision applies to students of primary care doctor programs, specialist and sub-specialist doctors, as well as
specialists and sub-specialist dentists.

What is regulated in these provisions is also applied in other countries. The average salary for resident doctors in
the United States, for example, can be up to Rp900 million per year or around US$58 thousand. In Australia, the
salary could reach Rp1.2 billion or US$78 thousand per year, and Rp121 million or US$8 thousand per year in
India.

                                                                                                          Page 3 of 4
                              Indonesia striving to solve shortage of specialists doctors

cceleration

Health Minister Budi Gunadi Sadikin stated that the concept of hospital-based specialist education is a new system
to increase the number and distribution of specialist doctors in all districts/cities in Indonesia.

The addition of the capacity of the medical faculty according to the government's plan is estimated to cut the time
needed to meet the need for specialist doctors to six to eight years.

The concept is carried out through the assistance of senior doctors at the hospital and a salary system for general
practitioners who participate in the specialist program.

However, Dean of the University of Indonesia's Faculty of Medicine Professor Ari Fahrial said the program has the
potential to reduce the quality of specialist medical graduates due to the absence of a curriculum and role of
professors in fulfilling competencies.

ccording to him, medical education and medical practice cannot be combined through the provisions of the
Healthcare Omnibus Bill owing to the fact that both of them are still dealing by problems that have not been
completely resolved.

The rapid development of medical science in Indonesia has not been equipped with equal infrastructure and
educational resources in Indonesia. For example, many medical schools do not have biomedical science lecturers.
Therefore, scholarships are needed for prospective teaching staff.

Meanwhile, some of the problems in medical practice are included in the challenges of using telemedicine and
artificial intelligence (AI) innovations in the health sector, bringing foreign doctors to Indonesia, and accelerate
doctors' graduation.

Based on Fahrial's experience in formulating the Health Law 10 years ago, the issue of the current bill being
deliberated is not much different. The current crisis of specialist doctors is actually the result of stakeholders'
collective failure to comply with the mandate of Law Number 20/2013.

Meanwhile, Chairperson of the Executive Board of the Indonesian Medical Association (PB-IDI) Adib Khumaidi has
pushed for data alignment on the number of medical professions in Indonesia.

ccording to the IDI version, the number of doctors and specialists is recorded at around 204,492 people, while the
KKI version shows a different figure, namely 214,878 people. This number also differs from the figure the Health
Ministry's report reveals: 145,913 people.

He said he is worried about a possibility that the acceleration of the production of doctors in Indonesia will trigger an
increase in the number of the unemployed professionals in Indonesia.

Referring to the IDI and KKI data in which the number of specialist doctors is recorded at around 44,753 people,
there will be a need for additional specialists doctors of around 67 thousand people to meet the WHO ratio of
1:1,000 in Indonesia.

part from the pros and cons related to the Healthcare Omnibus Bill currently being deliberated by the lawmakers
and government, the availability of specialist doctors is a goodwill from the state to meet its citizens' rights to get
access to equitable health services.

In this regard, those involving in deliberating the bill need to prioritize the principles of collaboration of all
stakeholders to enable all members of communities throughout Indonesia to receive improved quality of healthcare
services.

baca-jugaRelated news: Indonesia needs thousands of specialist doctors: Health MinisterRelated news: More
specialist doctors proof of healthcare transformation

                                                                                        Page 4 of 4
                          Indonesia striving to solve shortage of specialists doctors


Load-Date: February 28, 2023


  End of Document

                                                                                                         Page 1 of 2
                                    Pushing the Extremes Toward a Kind of Healing




                       Pushing the Extremes Toward a Kind of Healing
                                                 The New York Times
                                              January 16, 2023 Monday
                                                  Late Edition - Final



Copyright 2023 The New York Times Company

Section: Section C; Column 0; The Arts/Cultural Desk; Pg. 2; CRITIC'S PICK
Length: 654 words
Byline: By Siobhan Burke

Body


The Indigenous artist Daina Ashbee's first group piece, at the Gibney, simmers with tension and offers an approach
to healing.

At the beginning of Daina Ashbee's ''J'ai Pleuré Avec les Chiens (Time, Creation, Destruction),'' we hear the placid
voice of the New Age author Louise Hay, who published the popular self-help book ''You Can Heal Your Life'' in
1984. ''This tape is about healing,'' Hay says. ''How healthy are you?''

  In the low light of a studio-theater at Gibney's Agnes Varis Performing Arts Center, where the audacious ''J'ai
Pleuré'' had its New York premiere over the weekend, five dancers were crawling, naked, across the floor. Isolated
for a while, they eventually made contact as one climbed atop another: two bodies stacked on all fours, a
precarious arrangement that would reconfigure itself many times over the work's volatile, often gripping 80 minutes.

 Ashbee, an Indigenous artist from British Columbia (of Cree, Métis and Dutch heritage), has garnered much
attention internationally for dances that often push the body to unsettling extremes. In her early 30s, she has
already presented a retrospective of works created in her 20s. ''J'ai Pleuré,'' her first group piece -- solos and duets
have been her focus -- demonstrates both the uncertainty of moving in a new choreographic direction and a fierce
clarity of vision.

  In the work's opening moments, tension simmers. Initially, Hay's accompanying musings sound reasonable, even
wise: ''The body is always talking to us, if we will only take the time to listen.'' But they become increasingly
questionable, as she posits that ''all illness is self-created'' and ''we choose our parents; we choose our sex, our
color, our country.'' The piercing whimper of a dog -- an alarming interruption -- drowns out her voice. (The title
translates to ''I cried with the dogs.'')

  This cry of distress ushers in what could be a different approach to healing: one created on the artists' own terms,
taking seriously the interconnection of the self with social structures (and with other species). Channeling canine
behavior, the dancers -- with formidable conviction -- bark, moan, grunt, howl and pant. Alone and in pairs, they
wrest themselves into severe contortions and painful-looking balances, sometimes coming right up close to the
audience, which surrounds them on three sides.

                                                                                                      Page 2 of 2
                                 Pushing the Extremes Toward a Kind of Healing

  At first this all resembles a form of self-torture, intensified by ominous drones and squawks in the intermittent
score (by Sean MacPherson, Ashbee and Gabriel Nieto, who is also one of the dancers). Yet intriguingly, it evolves
into something more like play, one dancer tagging another as an invitation to perilously partner. Nieto lies on his
back, legs up, supporting Greys Vecchionacce in a suspended handstand. In a similar fashion, Audrey Sides
teeters horizontally on the soles of Elise Vanderborght's feet. Irene Martínez does a headstand on her own, legs
arching back in a physics-defying curve. They all appear to take great pleasure in these feats.

  At times, the provocations of ''J'ai Pleuré'' seem unmoored from a deeper foundation, seeking to shock for shock's
sake. But by the end, the piece unmistakably finds its sense of purpose, most potently in a duet for Nieto and
Vecchionacce, which feels like a mourning and a reclamation. While the poetic lighting dims, as if to signal an end,
the two conjure a new beginning in a transporting call-and-response, a sound between a growl and a wail flowing
from their bodies. As Nieto traverses the perimeter of the space, Vecchionacce punches, stamps and spins in the
center, a breathtaking force. When all five dancers reunite in the end, lights up on their exposed bodies, something
has been healed.

 J'ai Pleuré Avec les Chiens (Time, Creation, Destruction)

 Jan. 13-14 at Gibney Dance; gibneydance.org. J'ai                Pleuré   Avec   les   Chiens   (Time,   Creation,
Destruction)Performed Friday and Saturday at Gibney Dance


https://www.nytimes.com/2023/01/15/arts/dance/daina-ashbee-jai-pleure-avec-les-chiens.html



Graphic


PHOTO: From top, Greys Vecchionacce and Gabriel Nieto in ''J'ai Pleuré Avec Les Chiens.'' (PHOTOGRAPH BY
ANDREA MOHIN/THE NEW YORK TIMES) This article appeared in print on page C2.


Load-Date: January 16, 2023


  End of Document

                                                                                                     Page 1 of 4
    Blockchain for Healthcare Market Future Outlook | IBM Corporation , Microsoft , Guardtime, PokitDok, Gem,
                                Hashed Health, Chronicled, iSolve - The Courier




     Blockchain for Healthcare Market Future Outlook | IBM Corporation,
  Microsoft, Guardtime, PokitDok, Gem, Hashed Health, Chronicled, iSolve -
                                The Courier
                                              The Courier: Monmouth University
                                                      January 16, 2021 Saturday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1357 words

Body

A new versatile research report on "Global Blockchain for Healthcare Market Size, Share, Growth and Forecast
2020-2027" is aimed at promising a unique approach towards provides highly efficient and accurate market
research services at extremely reasonable rates. Blockchain for Healthcare is the wide-ranging, top-line market
research document which combines breadth and depth of knowledge. Blockchain for Healthcare Market 2021
research report presents an analysis of statistical and comprehensive data of the global market. The market Study
is segmented by key regions that is accelerating the marketization. At present, the market is sharping its presence
and some of the key players in the study areIBM Corporation, Microsoft, Guardtime, PokitDok, Inc., Gem, Hashed
Health, Chronicled, iSolve, LLC

Get the PDF Sample Copy (Including FULL TOC, Graphs and Tables)                                  of   this   report
@: https://www.databridgemarketresearch.com/reports/global-blockchain-for-healthcare-market

Detailed Market Analysis and Insights:

Blockchain for healthcare market is expected to gain market growth in the forecast period of 2020 to 2027. Data
Bridge Market Research analyses the market to account to USD 8362.01 million by 2027 growing at a CAGR of
72.0% in the above-mentioned forecast period.

Rising adoption of blockchain technology, increasing demand of cost-effective and secured data interoperability
with the help of blockchain, introduction of transparency and immutability of the distributed ledger technology and
growing threats of counterfeit drugs are some of the factors that will accelerate the growth of the blockchain for
healthcare market in the forecast period f 2020-2027. On the other hand, increasing initiatives of the government
and surging investment for the development of advanced solutions will further create new and ample opportunities
for the growth of growth of blockchain for healthcare market in the above mentioned forecast period.

Blockchain for Healthcare Market Segment Analysis:

Analysis byEnd-User:

                                                                                                     Page 2 of 4
    Blockchain for Healthcare Market Future Outlook | IBM Corporation , Microsoft , Guardtime, PokitDok, Gem,
                                Hashed Health, Chronicled, iSolve - The Courier

    •   Pharmaceutical Companies
    •   Healthcare Providers
    •   Healthcare Payers

Analysis by Application:
    •   Clinical Data Exchange and Interoperability
    •   Claims Adjudication and Billing Management
    •   Drug Supply Chain Management
    •   Drug Discovery and Clinical Trials
    •   Prescription Drug Abuse

The cost analysis of the Global Blockchain for Healthcare Market has been performed while keeping in view
manufacturing expenses, labor cost, and raw materials and their market concentration rate, suppliers, and price
trend. The research carried out after the launch of a new product can help to find loopholes and devise plans to
counter that loss and increase the profits. With the reliable Blockchain for Healthcare market research report, the
chances of loss can be reduced to a large extent.

The research study evaluates the overall size of the market, by making use of a bottom-up approach, wherein data
for different industry verticals, and end-user industries and its applications across various product types have been
recorded and predicted during the forecast period. The report helps to recognize new areas for expansion, and
increase customer base. After discovering potential customers and their needs via the winning Blockchain for
Healthcarereport the same can be incorporated into the client's services.

Read complete report along with TOC @ https://www.databridgemarketresearch.com/toc/?dbmr=global-blockchain-
for-healthcare-market

Table of Contents

Global Blockchain for Healthcare Market Outlook-by Major Company, Regions, Type, Application and Segment
Forecast, 2021 -2027

Chapter 1: Market Scope Blockchain for Healthcare

Chapter 2: Global Blockchain for Healthcare Industry Analysis

Chapter 3: Blockchain for Healthcare Market Estimates & Forecasts

Chapter 4: Value Chain (Impact of COVID-19)

Chapter 5: Competitive Analysis

Chapter 6: Industry Consumption by Regions

Chapter 7: Marketing Strategy Analysis, Distributors/Traders

Chapter 8: Manufacturing Cost Analysis

Chapter 9: Industrial Chain, Sourcing Strategy and Downstream Buyers

Chapter 10: Research Findings and Conclusion

Competitive Landscape and Blockchain for Healthcare Market Share Analysis:

                                                                                                     Page 3 of 4
    Blockchain for Healthcare Market Future Outlook | IBM Corporation , Microsoft , Guardtime, PokitDok, Gem,
                                Hashed Health, Chronicled, iSolve - The Courier

Blockchain for healthcare market competitive landscape provides details by competitor. Details included are
company overview, company financials, revenue generated, market potential, investment in research and
development, new market initiatives, global presence, production sites and facilities, production capacities,
company strengths and weaknesses, product launch, product width and breadth, application dominance. The above
data points provided are only related to the companies' focus related to blockchain for healthcare market.

The major players covered in the blockchain for healthcare market report are IBM Corporation, Microsoft,
Guardtime, PokitDok, Inc., Gem, Hashed Health, Chronicled, iSolve, LLC, Patientory., Factom., Medicalchain SA.,
Proof.Works, SimplyVital Health, Inc, Blockchain AI Solutions Ltd, Change Healthcare, Doc.ai, Inc, among other
domestic and global players. Market share data is available for Global, North America, Europe, Asia-Pacific , Middle
East and Africa and South America separately. DBMR analysts understand competitive strengths and provide
competitive analysis for each competitor separately.

Global Blockchain for Healthcare Market Scope and Market Size:

Based on application, blockchain for healthcare market is segmented into clinical data exchange and
interoperability, claims adjudication and billing management, drug supply chain management, drug discovery and
clinical trials, prescription drug abuse and others.

Blockchain for healthcare market has also been segmented based on the end user into pharmaceutical companies,
healthcare providers, healthcare payers and others.

Do     You      Have    Any    Query      Or    Specific     Requirement?     Ask      to   Our            Industry
Expert@ https://www.databridgemarketresearch.com/inquire-before-buying/?dbmr=global-blockchain-for-
healthcare-market

By Geographical Regions:-

Asia Pacific: China, Japan, India, and Rest of Asia Pacific

Europe: Germany, the UK, France, and Rest of Europe

North America: The US, Mexico, and Canada

Latin America: Brazil and Rest of Latin America

Middle East & Africa: GCC Countries and Rest of Middle East & Africa

If you have any special requirements, please let us know and we will offer you the report as you want.

This Report Answers the Following Questions:
    •   What are the Global Blockchain for Healthcare Market trends and growth analysis?
    •   How many segments does the market contain?
    •   What are the Blockchain for Healthcare market opportunities, market risk and market overview that the
        market may face?
    •   How are the key factors driving keeping up with the changing consumer behavior?
    •   What are the latest industry developments for the Blockchain for Healthcare market size?
    •   What are sales, revenue, and price analysis by types and applications of Blockchain for Healthcare
        market?

About Data Bridge Market Research:

An absolute way to forecast what future holds is to comprehend the trend today!

                                                                                                    Page 4 of 4
   Blockchain for Healthcare Market Future Outlook | IBM Corporation , Microsoft , Guardtime, PokitDok, Gem,
                               Hashed Health, Chronicled, iSolve - The Courier

Data Bridge Market Research set forth itself as an unconventional and neoteric Market research and consulting firm
with unparalleled level of resilience and integrated approaches. We are determined to unearth the best market
opportunities and foster efficient information for your business to thrive in the market. Data Bridge endeavours to
provide appropriate solutions to the complex business challenges and initiates an effortless decision-making
process. Data bridge is an aftermath of sheer wisdom and experience which was formulated and framed in the year
2015 in Pune.

Data Bridge Market Research has over 500 analysts working in different industries. We have catered more than
40% of the fortune 500 companies globally and have a network of more than 5000+ clientele around the globe.
Data Bridge adepts in creating satisfied clients who reckon upon our services and rely on our hard work with
certitude. We are content with our glorious 99.9 % client satisfying rate.

Contact Us:-

Data Bridge Market Research

US: +1 888 387 2818

UK: +44 208 089 1725

Hong Kong: +852 8192 7475

Email:-corporatesales@databridgemarketresearch.com


Load-Date: January 17, 2021


  End of Document

                                                                              Page 1 of 2
     AI TO DETECT HEART ATTACKS? PITT AND UPMC DEVELOP A TOOL TO BETTER ANALYZE EKGS




  AI TO DETECT HEART ATTACKS? PITT AND UPMC DEVELOP A TOOL TO
                      BETTER ANALYZE EKGS
                                              Pittsburgh Post-Gazette
                                               July 23, 2023 Sunday
                                               TWO STAR EDITION



Copyright 2023 P.G. Publishing Co.

Section: HEALTH; Pg. H-1
Length: 590 words
Byline: Anya Sostek Pittsburgh Post-Gazette

Body


Every year, more than 805,000 people in America have heart attacks. But only about a third of those heart attacks
are immediately obvious using an electrocardiogram, or EKG - often the first test used in diagnosis. The remaining
two-thirds take hours or even days to identify through clinician analysis, blood tests or presenting symptoms.

A new tool in development by the University of Pittsburgh and UPMC uses artificial intelligence to analyze EKG
data, identifying heart attacks more quickly and more accurately than current methods. Researchers published their
results of the tool's performance in late June in the journal Nature Medicine.

"The classic adage for heart attacks is that time is muscle," said Christian Martin-Gill, chief of the Emergency
Medical Services division at UPMC and a co-author of the study. "If we can identify these partial blockages or heart
attacks that we might otherwise miss for hours or days, then we have an opportunity to intervene more
aggressively."

Researchers from Pitt and UPMC have been working to develop this tool for more than a decade, and published
their research after testing it on real-world patients in Pittsburgh and North Carolina. Study co-author Ervin Sejdic
developed the model at Pitt and has since moved to a position at the University of Toronto.

A standard EKG takes data from multiple electrodes placed on the chest and synthesizes that data into a set of
wavy lines on graph paper that clinicians are trained to read. The new tool from Pitt is more accurate in part
because it can look at far more data - all the readings from each electrode - than the synthesized version provides.

Using machine learning, researchers developed the model by feeding it all of that data, along with outcomes, and
allowing it to figure out its own system of analysis.

"With machine learning, you do not give rules to the computer, you give the data," said Salah Al-Zaiti, lead author of
the study and associate professor in the Pitt School of Nursing. "Eventually, the machine learning model learns the
rules and how to reach from EKG to a certain conclusion. It may start learning rules that we do not know about and
start identifying new insights."

                                                                              Page 2 of 2
     AI TO DETECT HEART ATTACKS? PITT AND UPMC DEVELOP A TOOL TO BETTER ANALYZE EKGS

Researchers were surprised to find, through real-world tests, that the model had not just matched current science in
accuracy of identifying heart attacks, but was actually more accurate.

Before beginning treatments or further diagnostics, doctors want to know they are treating a heart attack and not a
condition such as reflux or pneumonia that may have similar symptoms.

"Part of the challenge is that we haven't had a way to identify these early enough to know what we should do to
prevent some of that heart damage," said Martin-Gill.

Widespread use of the tool is still years away, but the research team is currently developing a user interface for the
model, which it plans to deploy in partnership with the city of Pittsburgh's Bureau of Emergency Medical Services.

The cloud-based model under development will be able to integrate with hospital command centers, said Al-Zaiti,
providing real-time guidance on medical decisions.

"This information can help guide EMS medical decisions such as initiating certain treatments in the field or alerting
hospitals that a high-risk patient is incoming," Martin-Gill said. "On the flip side, it's also exciting that it can help
identify low-risk patients who don't need to go to a hospital with a specialized cardiac facility, which could improve
prehospital triage."

Anya Sostek: asostek@post-gazette.com



Graphic


PHOTO: UPMC: Chief of the Emergency Medical Services division at UPMC Christian Martin-Gill is a co-author of
the study.

PHOTO: University of Pittsburgh: The study's lead author Salah Al-Zaiti is an associate professor in the Pitt School
of Nursing.

PHOTO: Shutterstock: Heart illustration for HEARTAI0723


Load-Date: July 23, 2023


  End of Document

                                                                              Page 1 of 2
     AI TO DETECT HEART ATTACKS? PITT AND UPMC DEVELOP A TOOL TO BETTER ANALYZE EKGS




  AI TO DETECT HEART ATTACKS? PITT AND UPMC DEVELOP A TOOL TO
                      BETTER ANALYZE EKGS
                                              Pittsburgh Post-Gazette
                                               July 23, 2023 Sunday
                                               TWO STAR EDITION



Copyright 2023 P.G. Publishing Co.

Section: HEALTH; Pg. H-1
Length: 590 words
Byline: Anya Sostek Pittsburgh Post-Gazette

Body


Every year, more than 805,000 people in America have heart attacks. But only about a third of those heart attacks
are immediately obvious using an electrocardiogram, or EKG - often the first test used in diagnosis. The remaining
two-thirds take hours or even days to identify through clinician analysis, blood tests or presenting symptoms.

A new tool in development by the University of Pittsburgh and UPMC uses artificial intelligence to analyze EKG
data, identifying heart attacks more quickly and more accurately than current methods. Researchers published their
results of the tool's performance in late June in the journal Nature Medicine.

"The classic adage for heart attacks is that time is muscle," said Christian Martin-Gill, chief of the Emergency
Medical Services division at UPMC and a co-author of the study. "If we can identify these partial blockages or heart
attacks that we might otherwise miss for hours or days, then we have an opportunity to intervene more
aggressively."

Researchers from Pitt and UPMC have been working to develop this tool for more than a decade, and published
their research after testing it on real-world patients in Pittsburgh and North Carolina. Study co-author Ervin Sejdic
developed the model at Pitt and has since moved to a position at the University of Toronto.

A standard EKG takes data from multiple electrodes placed on the chest and synthesizes that data into a set of
wavy lines on graph paper that clinicians are trained to read. The new tool from Pitt is more accurate in part
because it can look at far more data - all the readings from each electrode - than the synthesized version provides.

Using machine learning, researchers developed the model by feeding it all of that data, along with outcomes, and
allowing it to figure out its own system of analysis.

"With machine learning, you do not give rules to the computer, you give the data," said Salah Al-Zaiti, lead author of
the study and associate professor in the Pitt School of Nursing. "Eventually, the machine learning model learns the
rules and how to reach from EKG to a certain conclusion. It may start learning rules that we do not know about and
start identifying new insights."

                                                                              Page 2 of 2
     AI TO DETECT HEART ATTACKS? PITT AND UPMC DEVELOP A TOOL TO BETTER ANALYZE EKGS

Researchers were surprised to find, through real-world tests, that the model had not just matched current science in
accuracy of identifying heart attacks, but was actually more accurate.

Before beginning treatments or further diagnostics, doctors want to know they are treating a heart attack and not a
condition such as reflux or pneumonia that may have similar symptoms.

"Part of the challenge is that we haven't had a way to identify these early enough to know what we should do to
prevent some of that heart damage," said Martin-Gill.

Widespread use of the tool is still years away, but the research team is currently developing a user interface for the
model, which it plans to deploy in partnership with the city of Pittsburgh's Bureau of Emergency Medical Services.

The cloud-based model under development will be able to integrate with hospital command centers, said Al-Zaiti,
providing real-time guidance on medical decisions.

"This information can help guide EMS medical decisions such as initiating certain treatments in the field or alerting
hospitals that a high-risk patient is incoming," Martin-Gill said. "On the flip side, it's also exciting that it can help
identify low-risk patients who don't need to go to a hospital with a specialized cardiac facility, which could improve
prehospital triage."

Anya Sostek: asostek@post-gazette.com



Graphic


PHOTO: UPMC: Chief of the Emergency Medical Services division at UPMC Christian Martin-Gill is a co-author of
the study.

PHOTO: University of Pittsburgh: The study's lead author Salah Al-Zaiti is an associate professor in the Pitt School
of Nursing.

PHOTO: Shutterstock: Heart illustration for HEARTAI0723

PHOTO: University of Pittsburgh: The study's lead author Salah Al-Zaiti is an associate professor in the Pitt School
of Nursing.


Load-Date: July 24, 2023


  End of Document

                                                                                                Page 1 of 1
                                    IN SCHOOLS, AI IS TRACKING MENTAL HEALTH




                        IN SCHOOLS, AI IS TRACKING MENTAL HEALTH
                                                 Wall Street Journal Abstracts
                                               September 22, 2021 Wednesday



Copyright 2021 The New York Times Company: Abstracts All Rights Reserved

Section: A; Pg. 14
Length: 32 words
Byline: JULIE JARGON

Body


ABSTRACT

Julie Jargon Family #$1# Tech column notes many educators and administrators are depending on AI bots to alert
them of students who are at risk of harming themselves or others; drawing (M)



Graphic


Diagrams and Drawings


Load-Date: September 23, 2021


  End of Document

                                                                                                  Page 1 of 11
         Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                             Opportunities for Canada




 Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices
           in South Korea and Strategic Opportunities for Canada
                                                   Canadian Global Affairs Institute
                                                     26 September 2023 Tuesday



Copyright 2023 Content Engine, LLC.
All Rights Reserved
Copyright 2023 Canadian Global Affairs Institute All Rights Reserved

Length: 6430 words
Byline: cgai

Body

by Daniel Jacinto
September 2023

A joint publication with:

Triple_Helix_Top_Logo.JPG


Introduction

Information technology is fundamental to national security in the 21st century. Advances in remote technology,
sensors, communication networks and artificial intelligence (AI) have pushed the boundaries for defence innovation
from anti-satellite (ASAT) weapons1 to hypersonic glide vehicles,2 to the drones famously deployed in the ongoing
war in Ukraine.3 Increasing dependence on computer networking has also opened a new domain in cyberspace,
with the past two decades alone witnessing high-profile cyberattacks on nation states or critical infrastructure.
These include:
            •      Distributed denial-of-service (DDoS) attacks against the Estonian government in 20074 and
            Georgian government in 20085;
     •      The Stuxnet worm used to sabotage Iranian uranium enrichment centrifuges in 2011;6
     •      Data breaches of U.S. federal agencies during the 2020 SolarWinds hack;7 and
     •    The ransomware attack that shut down the American Colonial Pipeline in 2021.8
South Korea has grappled first-hand with the threat of advanced warfare. Neighboured by a North Korea intent on
flexing its advanced missile and cyber-capabilities, and a China in the midst of a military modernization program,
South Korea is situated in a threat environment that necessitates keeping up with the bleeding edge of
contemporary high-tech war. As a fellow player in the Pacific arena, and sharing a mutual ally in the United States,
this also makes South Korea a prospective partner for Canada's own ambitions in technological defence innovation.

                                                                                              Page 2 of 11
     Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                         Opportunities for Canada

This paper examines defence technology practices in South Korea to identify strategic opportunities for Canada.
The first section provides a brief overview of the relationship between technology and defence in the 21st century.
The second and third sections assess defence technology practices in South Korea and Canada respectively,
noting particular differences in each country's threat environment. Taking stock of these comparisons, the article
concludes by highlighting potential strategic opportunities for Canada in pursuing closer defence technology ties
with South Korea.

 Technology and Defence in the 21st Century: The Nature of the Threat
For observers of the information revolution, the primary challenge has been to comprehend the threat posed by
these emerging technologies. Epitomized in then-U.S. Defense secretary Leon Panetta's 2012 warning of a "cyber-
Pearl Harbor,"9 a substantial focus has historically been cyberwar - the coercive use of offensive information
technologies against other states - as the primary threat. For the most part, this notion stems from the idea that with
a few lines of code or key presses, a nefarious agent can subvert one's weapons or defence systems or else cripple
a nation's critical infrastructure, a fear exacerbated by the experience of the 2011 Stuxnet worm which the U.S. and
Israel reportedly launched against Iran's nuclear program. In a related line of thinking, the cyberwar threat also
manifests in the capacity for cyber-tools to disrupt military, civilian or governance structures in a manner that states
could perceive as an armed attack.10 For others, the escalatory potential rests in the fact that increased
dependence on computing systems turns them into a key resource that states may seek to defend by a pre-emptive
strike.11
However, not all observers agree that cyberwar is the primary threat from emerging technologies. Running counter
to the cyber-alarmists are the (seemingly more numerous) cyber-skeptics, those who view the cyberwar threat as
overstated. Pointing to the empirical paucity of cyberattacks that possess any existential threat, the difficulty of
relying on anonymous attacks to elicit political objectives and the inability of cyber-tools to supplant broader
strategic paradigms like deterrence or conventional force, such experts have gone so far as to claim outright that
"cyber war will not take place."12

Thus, the zeitgeist of cyberwar has diminished somewhat;13 the scholarly consensus now appears to have settled
on a more nuanced approach centred on two areas: offensive cyber-capabilities below the threshold of war, and
correspondingly, a more subdued understanding of the threat posed by cyber-power. In the first area, scholars have
pointed to the use of cyber-tools for the purposes of political subversion or social movements;14 cumulative
campaigns of sabotage or espionage aimed at long-term shifts in balance of power rather than immediate attack;15
or the deployment of cyber-tools not as a standalone, but to complement or support offensive capabilities.16 In the
second area, one development has focused on how technological advances primarily enhance military capabilities
through defence innovation; for example, in AI for autonomous weapons systems, or AI-guided command and
control.17 Another development is that a broader understanding of cyber-threat appears to be emerging, with
greater recognition of economic, social and psychological threats alongside purely those of national security,18 and
a corresponding need for general cybersecurity.19

Technology and Defence in South Korea

Ranked 11th in internet access according to 2021 data from the International Telegraph Union,20 South Korea is
often regarded as one of the most technologically advanced societies worldwide. In the defence realm, much of the
impetus for South Korea's technological integration stems from the Northeast Asian regional threat environment.
Defence analysts have frequently commented on China's military modernization towards informatized war that
relies increasingly on advanced technology, support systems and information operations, and joint operations
across domains (including the cyber-domain).21 The clearest advancement has been in the establishment of the
People's Liberation Army Strategic Support Force, formed explicitly to harness electronic warfare capabilities.22
More recent developments include China's move to incorporate AI technology into strategic planning and decision-
making, as well as human-machine integration, shifting from purely informatized warfare to "intelligentized"
combat.23 On the cyber-operations front, the U.S. government's Cybersecurity and Infrastructure Security Agency
recognizes China as an advanced persistent threat, i.e., an adversary with the resources and expertise to conduct
sophisticated malicious cyberattacks geared towards espionage, data theft or network disruption.24 South Korea
has occasionally been on the receiving end of these capabilities. In March 2017, Chinese hacking groups launched

                                                                                                 Page 3 of 11
        Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                            Opportunities for Canada

DDoS and malware attacks against the Ministry of Foreign Affairs and the Lotte Group, presumably in retaliation for
the deployment of U.S. Terminal High Altitude Area Defense systems.25 In January 2023, Chinese hacking groups
targeted a number of Korean universities, disrupting access to some of their websites.26
North Korea is known to possess significant offensive cyber-capabilities. As noted in a 2023 report by a UN panel of
experts tasked with investigating North Korean sanctions evasion, North Korea possesses an organized network of
cyber-threat actors operating largely under the Technical Surveillance Bureau of North Korea's Reconnaissance
General Bureau,27 with U.S. government estimates of up to 6,000-7,000 active personnel, some of whom are
active abroad.28 These cyber-actors have launched numerous attacks on South Korea, with DDoS attacks on
South Korean government and banking systems in 200929 and again in 2011,30 and a suspected virus against
banks and TV broadcasters in 2013.31 Between 2016 and 2023, a number of incidents linked to North Korean
hacking groups such as Thallium and Kimsuky have involved various actors in South Korea's defence structure.
Notable among these are a data breach of an unnamed defence firm which stole information on submarine-
launched ballistic missiles; a malware attack that compromised 3,200 Ministry of Defense computers (including that
of then-minister Han Min-goo); and attacks against a battle simulation centre affiliated with U.S.-South Korean joint
operations.32 Though not directed at the South, other major attacks reportedly attributed to North Korea occurred in
2014 against Sony Pictures Entertainment in retaliation for the satirical film The Interview (about a fictional
assassination attempt on Kim Jong-un).33 There was also a planned raid of up to $1 billion on Bangladesh Bank in
2016 that ultimately netted $81 million34 and the 2017 WannaCry ransomware attack that infected computer
systems in as many as 99 countries.35
A more recent trend has been North Korea's targeting of crypto markets, such as the attack on South Korean
cryptocurrency exchanges Bithumb in 201736 and UPbit in 2019,37 and against Vietnam-based Sky Mavis' crypto-
incorporating digital pets game Axie Infinity in 2023 which stole $625 million in cryptocurrency.38 In its most recent
crypto-crime report, blockchain firm Chainalysis estimates that the value of crypto assets North Korea stole totalled
$1.65 billion in 2022, compared to roughly $429 million in 2021 and $300 million in 2020.39 Testifying before the
U.S. Senate Committee on Homeland Security and Governmental Affairs in November 2022, Secretary of
Homeland Security Alejandro N. Mayorkas noted that North Korea's cyber-heists have been used to fund the
country's weapons-of-mass-destruction programs.40
As a final observation, it is crucial to note that beyond China and North Korea, other actors in the region such as
Japan41 and Taiwan42 have also experienced shifts in their cyber-securitization discourses, representing a broader
regional salience of technological security.

In light of this threat environment, integration of technology and defence in South Korea can be observed in two
areas: defence innovation and general cybersecurity practices. Under the Moon administration (2017-2022),
technological integration for defence innovation was covered under the policy of Defense Reform 2.0. Featured in
both the country's 2018 and 2020 defence white papers,43 one of the policy's core tenets is to incorporate fourth
industrial revolution technologies (data analysis, artificial intelligence, sophisticated networking technology) to
enhance the country's operational capacity in response to resource constraints, such as demographic shifts
affecting the country's military conscription program,44 and the character of future warfare. Examples of the
weapons technologies include manned and unmanned systems and smart surveillance and strike systems. On the
support systems front, these include virtual simulation and training facilities, and AI-supported barracks, personnel,
health and materiel management systems. More recently, the Yoon administration's policy direction since 2022 has
followed the Defense Innovation 4.0 policy line.45 As commentators have pointed out,46 this new policy places a
greater emphasis on implementation tasks: strengthening research and development through private and military
links; acquisition of AI-based forces and corresponding education and training; and broader strategic
reconceptualization of AI technology. The policy notes technology applications including the transition from remote-
controlled to semi-autonomous and autonomous weapons systems as well as robotics and drone technology.
South Korea's cybersecurity approach is largely driven by its National Cybersecurity Strategy.47 Released under
the Moon administration in 2019, the policy identifies six core tasks:
    •      Increasing the safety of national core infrastructure;
    •      Enhancing cyberattack response capabilities;
    •      Establishing cybersecurity governance based on trust and co-operation;

                                                                                                 Page 4 of 11
        Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                            Opportunities for Canada

    •      Fostering cybersecurity industry growth;
    •      Fostering a cybersecurity culture; and
   •      Leading international co-operation in cybersecurity.
Though much of the policy's subtasks appear rather generic or aspirational, it does refer to several specific
capabilities:
    •      AI-based cyberattack detection and response;
    •      The use of public-private-military readiness exercises;
    •      Strengthening of legal frameworks and prosecutorial capacity against perpetrators of cybercrimes; and
    •      Public education programs for cyber-ethics and security practices.

Cybersecurity has also been picked up on the military front: the 2020 Defense white paper echoes the National
Cybersecurity Strategy's efforts to engage with AI-based cyberattack detection systems and cyber-simulation
training. It further mentions among its achievements the restructuring and reinforcement of its joint Cyber
Operations Command, the creation of dedicated cyber-positions for its officers, noncommissioned officers and
civilian military employees and the creation of dedicated courses in cyber-operations for military personnel.

On a broader scale, the Yoon administration announced in September 2022 a new Digital Strategy of Korea.48
Among other objectives, the strategy stipulates greater investments in AI and cybersecurity as two of six major
innovative digital technology focuses, expanding cybersecurity talent by 100,000 individuals and increasing
educational programing offerings in computer education, including graduate training. Korea's cybersecurity
practices, however, are not without criticism. Observers have noted that the National Cybersecurity Strategy
notwithstanding, the institutional backbone of cybersecurity governance is fragmentary, reliant on a patchwork of
laws and response systems, and governance strategies separated among the military, government and public and
private sectors.49
Ultimately, however, what we observe of defence innovation and general cybersecurity is a high degree of
technological integration tailored to the country's specific threat environment.

Technology and Defence in Canada

Canada faces a drastically different threat environment than South Korea. Though ongoing geopolitical
uncertainties such as the war in Ukraine and global competition between the U.S. and China are likely to have long-
term strategic implications, Canada appears to have fewer immediate threats. Among the core security trends
identified in Canada's 2017 defence policy, Strong, Secure, Engaged (SSE),50 those with the greatest potential to
necessitate defence innovation likely pertain to shifts in the nature of 21st century conflict and rapid technological
change. On the cybersecurity front, whereas the cyber-threats Korea faces largely stem from state actors, the
Canadian Centre for Cyber Security's National Cyber Threat Assessment reports for 2018,51 202052 and 2023-
202453 have consistently identified cybercrime as the primary online threat to Canadians. A quick survey of
reported cyberattacks over the past three years supports this conclusion. Although governments have been
affected on occasion, for instance, the Newfoundland provincial health system in October 2021,54 Global Affairs
Canada in January 202255 and Nova Scotia in June 2023,56 the remaining incidents have often been ransomware
attacks aimed at municipal branches, private businesses or educational facilities. It should be stressed that these
figures do not include the likely more numerous unreported cybercrimes targeted at individuals. State-sponsored
cyber-operations, particularly in the realm of cyber-espionage against government and commercial actors, still
remain a liability, evidenced in Canada's decision to ban Huawei from its 5G network infrastructure57 as well as the
social media app TikTok from government devices.58
Regarding technological integration for defence innovation, SSE identifies three critical categories of technological
development: space, cyber and remotely piloted systems. For space, SSE points to space situational awareness,
space-based Earth observation and maritime domain awareness, and satellite communications as the core
applications for space technology with explicit reference to the Arctic region. In terms of cyber-capabilities, SSE is
vague, mentioning only its intention to develop active cyber-operations capabilities, alongside requisite occupational

                                                                                                 Page 5 of 11
        Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                            Opportunities for Canada

and training changes. For remotely piloted systems, SSE points to varying land, air and naval applications, again
explicitly focused on their potential for northern surveillance. Puzzlingly, SSE makes little mention of applications for
artificial intelligence, though this may be a function of timing.
A 2021 report59 by the Canadian Army Land Warfare Centre identifies a variety of potential applications currently
being considered:
    •      AI assistance in command and control, communication flow (including translation), legal research and
           other operational decision-making;
    •      Optimizing of sensor technology;
    •      Data mining, simulations and training;
    •      Use in combination with unmanned vehicles or robotics;
    •      Network protection;
    •      Supervised autonomous weapons systems; and
    •    Various logistical support functions such as predictive maintenance, supply chain management and
         medical treatment.
Canada is governed by its own National Cyber Security Strategy released in 2018.60 Among the policy tasks listed
in the document are:
    •      Enhancement of law enforcement capacities to respond to cybercrime;
    •      Implementation support for cybersecurity measures for small and medium-sized organizations;
    •      Investing in cyber-technology research and skills building; and
    •      Intergovernmental and public-private partnership in developing cybersecurity capacities.

Two gaps are worth noting: the first is that consistent with the National Cyber Threat Assessments, the policy's
thrust appears directed towards the threat of cybercrime. As previous CGAI research has shown, the establishment
of active cyber-defence capabilities continues to be a weak point in Canadian cybersecurity practice.61 A second
concern, here echoing SSE, is the stark absence of reference to AI technology. While Canada has adopted several
AI governance measures such as the Directive on Automated Decision-Making62 and the Pan-Canadian Artificial
Intelligence Strategy,63 neither reflects the known cybersecurity threats posed by AI-enhanced cyberattacks or
attacks capable of exploiting AI-based systems.64

 Conclusion: Overlaps and Opportunities for Canada
A clear takeaway from the above analysis is that South Korea and Canada experience vastly different threat
environments. These environments in turn appear to be reflected in varied practices pertaining to the use of
technology for defence innovation, as well as in general cybersecurity approaches. Such differences
notwithstanding, there are a number of intersecting points that can facilitate productive bilateral co-operation and
furthering of Canada's defence interests.

In defence innovation, overlapping objectives pertaining to several core technologies such as unmanned or remote-
operated systems and sensors and surveillance technology may be fruitful for public and private partnerships aimed
at defence technology research or acquisition. These innovation partnerships would be especially beneficial for
Canada in cases where South Korea already possesses the requisite technology, as with AI smart training facilities
or logistical support systems. However, it remains to be seen what role AI will play in Canada's defence innovation
as we await the results of the defence policy update announced in 2022.65 A creative take on these partnerships
might, for instance, include jointly sponsored competitive projects, innovation contests and sandboxes or test drives
akin to those deployed by the Department of National Defence's Innovation for Defence Excellence and Security
(IDEaS) funding program.66
Given the mutual threats posed in the cyber-domain, exchanges could also be pursued in cybersecurity. Efforts
should be made with a view to exchanging best practices at all levels (government, military, private, individual), and,
given the main threats Canada faces, may involve practices to raise general public awareness of cyber-threats, or

                                                                                              Page 6 of 11
     Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                         Opportunities for Canada

pertain to joint readiness exercises such as those highlighted in Korea's cybersecurity strategy. These partnerships
may also help to offset Canada's relative backwardness when it comes to cyber-defence, given Korea's experience
with state-based cyber-threats.
As a foundation for both defence innovation and cybersecurity, a final opportunity could perhaps be found in
education. Academic exchanges or joint programming at the graduate or early research career levels would be an
essential component in fostering future talent for technological integration for defence and further bilateral co-
operation. This approach would be especially effective if it encourages disciplinary cross-pollination between STEM
fields and strategic studies to satisfy both the technical and operational needs of contemporary defence. A
dedicated funding stream for such exchanges, perhaps akin to DND's Mobilizing Insights in Defence and Security
(MINDS) funding opportunities,67 could be leveraged for these purposes.
Ultimately, despite facing its own unique threat environment and strategic priorities, Canada has much to gain in
defence innovation and cybersecurity and would do well to foster deeper co-operation with South Korea on these
fronts.

End Notes

1 Mark Smith, "Anti-satellite Weapons: History, Types and Purpose," space.com., August 10, 2022,
https://www.space.com/anti-satellite-weapons-asats.

2 Jeff Seldin, "What Are Hypersonic Weapons and Who Has Them?" Voice of America News, March 19, 2022,
https://www.voanews.com/a/what-are-hypersonic-weapons-and-who-has-them-/6492459.html.

3 Staff, "The War in Ukraine Shows How Technology Is Changing the Battlefield," The Economist, July 3, 2023,
https://www.economist.com/special-report/2023/07/03/the-war-in-ukraine-shows-how-technology-is-changing-the-
battlefield.

4      Staff,   "The     Cyber      Raiders    Hitting     Estonia,"     BBC        News,     May      17,    2007,
http://news.bbc.co.uk/2/hi/europe/6665195.stm.

5 John Markoff, "Before the Gunfire, Cyberattacks,"                    New   York    Times,   August    12,   2008,
https://www.nytimes.com/2008/08/13/technology/13cyber.html.

6 Jonathan Fildes, "Stuxnet Worm 'Targeted High-value Iranian Assets,'" BBC News, September 23, 2010,
https://www.bbc.com/news/technology-11388018.

7 Rishi Iyengar, "Massive SolarWinds Hack Has Big Business on High Alert," CNN, December 19, 2020,
https://www.cnn.com/2020/12/19/tech/solarwinds-hack-companies/index.html.

8 Veronica Stracqualursi, Geneva Sands and Arlette Saenz, "Cyberattack Forces Major US Fuel Pipeline to Shut
Down,"     CNN,    May     8,   2021,   https://www.cnn.com/2021/05/08/politics/colonial-pipeline-cybersecurity-
attack/index.html.

9 Elisabeth Bumiller and Thom Shanker, "Panetta Warns of Dire Threat of Cyberattack on U.S.," New York Times,
October 11, 2012, https://www.nytimes.com/2012/10/12/world/panetta-warns-of-dire-threat-of-cyberattack.html.
10 Mark R. Jacobson, "War in the Information Age: International Law, Self-Defense, and the Problem of 'Non-
Armed Attacks," Journal of Strategic Studies 21, no. 3, (September 1998): 1-23; John Stone, "Cyber War Will Take
Place!" Journal of Strategic Studies 36, no. 1, (2013): 101-108.
11 Jacquelyn Schneider, "The Capability/Vulnerability Paradox and Military Revolutions: Implications for
Computing, Cyber, and the Onset of War," Journal of Strategic Studies 42, no. 6, (2019): 841-863.
12 Thomas Rid, "Cyber War Will Not Take Place," Journal of Strategic Studies 35, no. 1, (February 2012): 5-32. For
other examples of these viewpoints, see: Bradley A. Thayer, "The Political Effects of Information Warfare: Why New
Military Capabilities Cause Old Political Dangers," Security Studies 10, no. 1, (Autumn 2000): 43-85; Martin C.
Libicki, "Cyberwar as a Confidence Game," Strategic Studies Quarterly 5, no. 1, (Spring 2011): 132-147; Adam P.

                                                                                              Page 7 of 11
     Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                         Opportunities for Canada

Liff, "Cyberwar: A New 'Absolute Weapon'? The Proliferation of Cyberwarfare Capabilities and Interstate War,"
Journal of Strategic Studies 35, no. 3, (June 2012): 401-428; Erik Gartzke, "The Myth of Cyberwar: Bringing War in
Cyberspace Back Down to Earth," International Security 38, no. 2, (Fall 2013): 41-73; Jon R. Lindsay, "Stuxnet and
the Limits of Cyber Warfare," Security Studies 22, no. 3, (2013): 365-404; Erik Gartzke and Jon R. Lindsay,
"Weaving Tangled Webs: Offense, Defense, and Deception in Cyberspace," Security Studies 24, no. 2, (2015):
316- 348; Ian Bowers and Sarah Kirchberger, "Not So Disruptive After All: The 4IR, Navies and the Search for Sea
Control," Journal of Strategic Studies 44, no. 4, (2021): 613-636.
13 Samuel Zilincik and Isabelle Duyvesteyn, "Strategic Studies and Cyber Warfare," Journal of Strategic Studies,
(2023): 1-22.
14 David Betz, "Cyberpower in Strategic Affairs: Neither Unthinkable nor Blessed," Journal of Strategic Studies 35,
no. 5, (October 2012): 689-711; Lennart Maschmeyer, "A New and Better Quiet Option? Strategies of Subversion
and Cyber Conflict," Journal of Strategic Studies 46, no. 3, (2023): 570-594.
15 Christopher Whyte, "Power and Predation in Cyberspace," Strategic Studies Quarterly 9, no. 1, (Spring 2015):
100-118; Martin C. Libicki, "The Convergence of Information Warfare," Strategic Studies Quarterly 11, no. 1,
(Spring 2017): 49-65; Benjamin Jensen, Brandon Valeriano and Ryan Maness, "Fancy Bears and Digital Trolls:
Cyber Strategy With a Russian Twist," Journal of Strategic Studies 42, no. 2 (2019): 212-234; Richard J. Harknett
and Max Smeets, "Cyber Campaigns and Strategic Outcomes," Journal of Strategic Studies 45, no. 4 (2022): 534-
567.
16 Jacquelyn Schneider, Benjamin Schechter and Rachael Shaffer, "A Lot of Cyber Fizzle But Not A Lot of Bang:
Evidence about the Use of Cyber Operations from Wargames," Journal of Global Security Studies 7, no. 2 (2022): 1
-19; Harknett and Smeets, 534-567.

17 Michael C. Horowitz, "When Speed Kills: Lethal Autonomous Weapon Systems, Deterrence and Stability,"
Journal of Strategic Studies 42, no. 6 (2019): 764-788; James S. Johnson, "Artificial Intelligence: A Threat to
Strategic Stability," Strategic Studies Quarterly 14, no. 1 (2020): 16-39; James Johnson, "Delegating Strategic
Decision-making to Machines: Dr. Strangelove Redux?" Journal of Strategic Studies 45, no. 3 (2022): 439-477;
Christopher Whyte, "Poison, Persistence, and Cascade Effects: AI and Cyber Conflict," Strategic Studies Quarterly
14, no. 4 (Winter 2020): 18-46; James Johnson, "'Catalytic Nuclear War' in the Age of Artificial Intelligence &
Autonomy: Emerging Military Technology and Escalation Risk Between Nuclear-armed States," Journal of Strategic
Studies (2021): 1-41; Michael Raska, "The Sixth RMA Wave: Disruption in Military Affairs?" Journal of Strategic
Studies 44, no. 4 (2021): 456-479.
18 John B. Sheldon, "Deciphering Cyberpower: Strategic Purpose in Peace and War," Strategic Studies Quarterly
5, no. 2 (Summer 2011): 95-112; Lucas Kello, "The Meaning of the Cyber Revolution: Perils to Theory and
Statecraft," International Security 38, no. 2, (Fall 2013): 7-40; Nadiya Kostyuk and Carly Wayne, "The
Microfoundations of State Cybersecurity: Cyber Risk Perceptions and the Mass Public," Journal of Global Security
Studies 6, no. 2 (2021): 1-25; Ryan Shandler, Michael L. Gross and Daphna Canetti, "Cyberattacks, Psychological
Distress, and Military Escalation: An Internal Meta-Analysis," Journal of Global Security Studies 8, no. 1 (2023): 1 -
19.
19 Gary McGraw, "Cyber War Is Inevitable (Unless We Build Security In)," Journal of Strategic Studies 36, no. 1
(2013): 109-119.

20 Internet usage statistics available from International Telegraph Union, https://www.itu.int/en/ITU-
D/Statistics/Pages/stat/default.aspx.
21 Jacqueline Newmyer, "The Revolution in Military Affairs with Chinese Characteristics," Journal of Strategic
Studies 33, no. 4 (August 2010): 483-504; Dennis J. Blasko, "Integrating the Services and Harnessing the Military
Area Commands," Journal of Strategic Studies 39, nos. 5-6 (2016): 685-708.
22 Elsa B. Kania and John Costello, "Seizing the Commanding Heights: The PLA Strategic Support Force in
Chinese Military Power," Journal of Strategic Studies 44, no. 2 (2021): 218-264; Nam Tae Park, Changhyung Lee
and Soyeon Kim, "Analysis of Electronic Warfare Capability of the People's Liberation Army Strategic Support
Force (PLASSF): Its Impacts and Implications on Korean Security," The Korean Journal of Defense Analysis 33, no.
1 (March 2021): 119-140.

                                                                                              Page 8 of 11
     Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                         Opportunities for Canada

23 Elsa B. Kania, "Artificial Intelligence in China's Revolution in Military Affairs," Journal of Strategic Studies 44, no.
4 (2021): 515-542.

24 Cybersecurity & Infrastructure Security Agency, "China Cyber Threat Overview and Advisories,"
https://www.cisa.gov/topics/cyber-threats-and-advisories/advanced-persistent-threats/china.

25 Staff, "S. Korean Foreign Ministry Gets Several DDoS Attacks from China," Yonhap News Agency, March 28,
2017, https://en.yna.co.kr/view/AEN20170328012651315; Ibid., "Lotte's Chinese Website Hacked in Protest of U.S.
Missile Defense System," March 1, 2017, https://en.yna.co.kr/view/AEN20170301005600320.

26 Kim Seung-yeon, "Chinese Hackers Attack 12 S. Korean Academic Institutions: KISA," Yonhap News Agency,
January 25, 2023, https://en.yna.co.kr/view/AEN20230125002553320.

27 United Nations Security Council, Final Report of the Panel of Experts Submitted Pursuant to Resolution 2627
(2022),    S/2023/171.     Other     reports   from   the    Panel     of  Experts    can    be   found     at:
https://www.un.org/securitycouncil/sanctions/1718/panel_experts/reports.

28 Congressional Research Service, "North Korean Cyber Capabilities: In Brief," August 3, 2017,
https://crsreports.congress.gov/product/pdf/R/R44912; "North Korean Cyber Activity," Presentation by the U.S.
Department       of   Health    and      Human      Services   Cybersecurity Program,   March     25,   2021,
https://www.hhs.gov/sites/default/files/dprk-cyber-espionage.pdf.

29 Matthew Weaver, "Cyber Attackers Target South Korea and US," The Guardian, July 8, 2009,
https://www.theguardian.com/world/2009/jul/08/south-korea-cyber-attack.

30 Staff, "South Korea Hit by Cyber Attacks," BBC News, March 4, 2011, https://www.bbc.com/news/technology-
12646052.

31 Choe Sang-Hun, "Computer Networks in South Korea Are Paralyzed in Cyberattacks," New York Times, March
20, 2013, https://www.nytimes.com/2013/03/21/world/asia/south-korea-computer-network-crashes.html.

32 Staff, "S. Korean Defense Firms Vigilant Against Hacking: Ministry," Yonhap News Agency, September 26,
2017, https://en.yna.co.kr/view/AEN20170926007400315; Ibid., "Military Investigators Raid Cyber Command in
Hacking Probe," December 13, 2016, https://en.yna.co.kr/view/AEN20161213006500315; Shin Ji-hye, "NK
Hacking Group Targets Korea-US Combined Exercise," The Korea Herald, August 20, 2023,
https://m.koreaherald.com/view.php?ud=20230820000014. For other examples, see: Kwan-Seok Jang, "Hacking
Attempts Made on 30 Computers of Defense Acquisition Agency," Dong-A Ilbo, January 15, 2019,
https://www.donga.com/en/Home/article/all/20190115/1610238/1; Kim Boram, "N. Korea-linked Hackers Attempt to
Break Into Emails of Seoul's Defense Panel Members," Yonhap News Agency, September 12, 2021,
https://en.yna.co.kr/view/AEN20210912001000315.

33 Staff, "The Interview: A Guide to the Cyber Attack on Hollywood," BBC News, December 29, 2014,
https://www.bbc.com/news/entertainment-arts-30512032.

34 Ibid., "The Lazarus Heist: How North Korea Almost Pulled Off a Billion-dollar Hack," June 20, 2021,
https://www.bbc.com/news/stories-57520169.

35 Ibid., "Massive Ransomware Infection                Hits   Computers      in        99   Countries,"   May   13,   2017,
https://www.bbc.com/news/technology-39901382.

36 Ibid., "North Korea 'Hacked Crypto-currency                   Exchange         in    South,'"   December     16,   2017,
https://www.bbc.com/news/world-asia-42378638.

                                                                                              Page 9 of 11
     Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                         Opportunities for Canada

37 Jon Biggs, "North Korean Hackers Target Crypto Exchange UPbit's South Korean Users," CoinDesk, May 30,
2019,   https://www.coindesk.com/markets/2019/05/31/north-korean-hackers-target-crypto-exchange-upbits-south-
korean-users/.

38 Robert McMillan and Dustin Volz, "How North Korea's Hacker Army Stole $3 Billion in Crypto, Funding Nuclear
Program," Wall Street Journal, June 11, 2023, https://www.wsj.com/articles/how-north-koreas-hacker-army-stole-3-
billion-in-crypto-funding-nuclear-program-d6fe8782.

39 Chainalysis, "2023 Crypto Crime Report," https://go.chainalysis.com/2023-crypto-crime-report.html.

40 Alejandro N. Mayorkas, "Threats to the Homeland," Testimony before the U.S. Senate Committee of Homeland
Security     and      Governmental       Affairs,   November       17,     2022,    https://www.hsgac.senate.gov/wp-
content/uploads/imo/media/doc/Testimony-Mayorkas-2022-11-17.pdf.
41 Paul Kallender and Christopher W. Hughes, "Japan's Emerging Trajectory as a 'Cyber Power': From
Securitization to Militarization of Cyberspace," Journal of Strategic Studies 40, nos. 1-2 (2017): 118-145.
42 Hon-min Yau, "Framing Cyber Security in Taiwan: A Perspective of Discursive Knowledge Production," The
Korean Journal of Defense Analysis 32, no. 3 (September 2020): 457-474.

43      Republic    of   Korea     Ministry   of    National    Defense,    2018      Defense    White    Paper,
https://www.mnd.go.kr/cop/pblictn/selectPublicationUser.do?siteId=mndEN&componentId=51&categoryId=0&public
ationSeq=846&pageIndex=1&id=mndEN_031300000000;               Ibid.,   2020       Defense      White      Paper,
https://www.mnd.go.kr/cop/pblictn/selectPublicationUser.do?siteId=mndEN&componentId=51&categoryId=0&public
ationSeq=1036&pageIndex=1&id=mndEN_031300000000.
44 Byung-ook Choi, "The Future of the Korean Military Service System: Direction and Challenge for New Korean
Military Service System Innovation," The Korean Journal of Defense Analysis 33, no. 3 (September 2021): 481-505.

45      Republic   of    Korea      Ministry    of    National    Defense,      "Defense     Innovation   4.0,"
https://www.mnd.go.kr/mbshome/mbs/mndEN/subview.jsp?id=mndEN_031406000000.
46 Kihyun Yoo and Donghwan Yun, "The Conceptual Framework of Korean Defense Innovation 4.0: Transition to
High-Tech Army in the Era of 4IR," The Korean Journal of Defense Analysis 35, no. 2 (June 2023): 165-188.

47       Republic   of     Korea,      National    Cybersecurity     Strategy,    https://www.itu.int/en/ITU-
D/Cybersecurity/Documents/National_Strategies_Repository/National%20Cybersecurity%20Strategy_South%20Ko
rea.pdf.

48 Republic of Korea Ministry of Science and ICT, "Korea to Come Up With the Roadmap of Digital ROK, Realizing
the             New               York            Initiative,"        September              28,           2022,
https://www.msit.go.kr/eng/bbs/view.do?sCode=eng&mId=4&mPid=2&bbsSeqNo=42&nttSeqNo=742.
49 Do-Kyung Kim and Soon-Yang Kim, "Reframing South Korea's National Cybersecurity Governance System in
Critical Information Infrastructure," The Korean Journal of Defense Analysis 33, no. 4 (December 2021): 689-713;
So Jeong Kim and Sunha Bae, "Korean Politics of Cybersecurity and Data Resilience," in The Korean Way With
Data, Evan A. Feigenbaum and Michael R. Nelson, eds. (Washington, DC: Carnegie Endowment for International
Peace, 2021), 39-60.

50 Canada Department of National Defence, Strong, Secure, Engaged: Canada's Defence Policy, 2017,
https://www.canada.ca/en/department-national-defence/corporate/policies-standards/canada-defence-policy.html.

51      Canadian   Centre     for   Cyber      Security,   National   Cyber        Threat    Assessment       2018,
https://www.cyber.gc.ca/en/guidance/national-cyber-threat-assessment-2018.

52 Ibid., 2020, https://www.cyber.gc.ca/en/guidance/national-cyber-threat-assessment-2020.

53 Ibid., 2023-2024, https://www.cyber.gc.ca/en/guidance/national-cyber-threat-assessment-2023-2024.

                                                                                             Page 10 of 11
     Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                         Opportunities for Canada

54 Rob Antle, "N.L. Says Hive Ransomware Group Was Behind 2021 Cyberattack on Health Systems," CBC,
March 14, 2023, https://www.cbc.ca/news/canada/newfoundland-labrador/nl-cyberattack-hive-ransomware-group-
1.6778579.

55 Peter Zimonjic, "Federal Government Investigating After Cyberattack Hits Global Affairs," CBC, January 24,
2022, https://www.cbc.ca/news/politics/cyber-attack-federal-agencies-respond-1.6325792.

56 Jean Laroche, "Members of the Public Among Those Affected By Massive N.S. Cyberattack," CBC, June 9,
2023, https://www.cbc.ca/news/canada/nova-scotia/ns-government-cyberattack-data-personal-information-criminal-
1.6871682.

57 Catharine Tunney and Richard Raycraft, "Canada Bans Chinese Tech Giant Huawei From 5G Network," CBC,
May 19, 2022, https://www.cbc.ca/news/politics/huawei-5g-decision-1.6310839.

58 Richard Raycraft, "Federal Government Banning Social Media Platform TikTok From Government Phones,"
CBC, February 27, 2023, https://www.cbc.ca/news/politics/government-tiktok-phones-ban-1.6761737.

59 Geoffrey Priems and Peter Gizewski, "Leveraging Artificial Intelligence for Canada's Army: Current Possibilities
and      Future    Challenges,"     Canadian        Army      Journal      19,      no.       2     (2021):     40-51,
https://www.canada.ca/en/army/services/line-sight/articles/2022/05/leveraging-artificial-intelligence-for-canadas-
army.html.

60 Public Safety Canada, National Cyber Security Strategy: Canada's Vision for Security and Prosperity in the
Digital Age, 2018, https://www.publicsafety.gc.ca/cnt/rsrcs/pblctns/ntnl-cbr-scrt-strtg/index-en.aspx.

61 Alexander Rudolph, "Canada's Active Cyber-Defence Is Anything But Active," Canadian Global Affairs Institute,
July 2021, https://www.cgai.ca/canadas_active_cyber_defence_is_anything_but_active; Ibid., "When Empty
Promises     are    Literally Empty:   Canadian     Cyber-Defence    Policy    by   Ad-Hoc,"    July     2022,
https://www.cgai.ca/when_empty_promises_are_literally_empty_canadian_cyber_defence_policy_by_ad_hoc.

62 Government of Canada, Directive on Automated Decision-Making, https://www.tbs-sct.canada.ca/pol/doc-
eng.aspx?id=32592.

63 Ibid., Pan-Canadian Artificial Intelligence Strategy, https://ised-isde.canada.ca/site/ai-strategy/en.

64 For a discussion of AI-enhanced and AI-exploiting cyberattacks, see Whyte (2020).

65 Canada Department of National Defence, "We Want to Hear From You," https://www.canada.ca/en/department-
national-defence/corporate/policies-standards/canada-defence-policy/we-want-to-hear-from-you.html.

66 Ibid., "Innovation for Defence Excellence and Security," https://www.canada.ca/en/department-national-
defence/programs/defence-ideas.html.

67 Ibid., "Mobilizing Insights       in   Defence   and    Security,"   https://www.canada.ca/en/department-national-
defence/programs/minds.html.

About the Author

Daniel Jacinto is a Ph.D. student in the Department of Political Science at McGill University. Daniel's research
interests broadly span the areas of international security and global governance, with a regional interest in East
Asia (and the Korean Peninsula, in particular). His doctoral research project looks at so-called 'rogue states'-such
as North Korea-and their relationship to international society.
Daniel holds a B.A. (Hons. Korean Language and Culture, International Relations) and an M.A. (Political Science)
from the University of British Columbia.

                                                                                            Page 11 of 11
    Linking the Mugunghwa and the Maple Leaf: Defence Technology Practices in South Korea and Strategic
                                        Opportunities for Canada


Load-Date: September 27, 2023


 End of Document

                                                                                                    Page 1 of 3
              Hard to track virus impact on Indigenous Inconsistent data masks Native American deaths




  Hard to track virus impact on Indigenous; Inconsistent data masks Native
                              American deaths
                                                     USA Today
                                               August 19, 2021 Thursday
                                                       2 Edition



Copyright 2021 USA Today All Rights Reserved

Section: NEWS; Pg. A5
Length: 1207 words
Byline: By, Nada Hassanein, USA TODAY

Body


Abigail Echo-Hawk, a member of the Pawnee Nation of Oklahoma, has lost six fellow Native loved ones to COVID-
19.

She is not alone. Throughout the pandemic, Indigenous people were the most likely group to be hospitalized and
die of the virus, according to the Centers for Disease Control and Prevention, followed by Hispanic and Black
people.

But data from states, tribal health centers and federal sources are often inconsistent. American Indian and Alaska
Native people have long been misclassified in death records, marked white or Hispanic. A 2016 CDC report found
incorrect death certificate classification among American Indian and Alaska Native deaths was as high as 40%.

And a new study shows just how elusive the numbers can be, finding many states inconsistently or don't report
specific tribal data in death records.

It's why experts fear COVID-19 death rates among the Indigenous are likely even higher than the current estimates.

"I wish I didn't know that it's actually much, much higher," said Echo-Hawk, director of the Urban Indian Health
Institute, a tribal epidemiology center.

Despite national death certificate standards recommending funeral directors collect tribal information, there's no
requirement for states to follow the standard, found authors of the study released late last month in the American
Journal of Public Health.

That, coupled with the lack of accurate classification of American Indians, masks true death rates, as well as tribes'
specific public health concerns that make Indigenous and other people of color vulnerable to COVID-19 disparities.

"People don't think of themselves as American Indian or Alaska Native. They think of themselves as Cheyenne, as
Navajo, as Cherokee. That's our identity," said study author Desi Small-Rodriguez, professor at the University of

                                                                                                   Page 2 of 3
             Hard to track virus impact on Indigenous Inconsistent data masks Native American deaths

California, Los Angeles, Department of Sociology and American Indian Studies Program, who is Northern
Cheyenne and Chicana.

She wrote that along with complete race data, tribal nations need accurate information specific to their populations
to address concerns and "effectively govern" their nations.

The analysis, by Small-Rodriguez and Randall Akee, a professor with the Department of Public Policy and
American Indian Studies Program, who is Native Hawaiian, used 2017 and 2018 death certificate data, and found
that five states allowed reporting more than one tribal affiliation, associated with ethnicity, but not official enrollment
status, which is associated with the rights and responsibilities of a tribal member. Only two states collected Indian
reservation or tribal homeland residency data.

Nine states didn't collect any tribal data on their death certificates, according to the analysis. That includes
California, which has more than 100 tribes. It's also one of the top three states with the most Native Americans,
according to the latest estimates, along with Arizona and Oklahoma.

"This is not just a melting pot. There's a base foundation of people that are so rarely recognized or acknowledged
as the original keepers of this land," said Virginia Hedrick, a Yurok Tribe member of Karuk descent and director of
the California Consortium for Urban Indian Health. "We can't really do targeted efforts - we don't really know if a
certain tribe is experiencing higher COVID rates. And it could also be that there are tribes that have experienced
little to no COVID rates. And what are they doing right?"

It's hard to know, experts say.

"Without data disaggregated by tribal affiliation and tribal enrollment status, we are missing an important
demarcation of difference in health outcomes in the AI/AN population," Small-Rodriguez and Akee wrote.

Within her Northern Cheyenne tribe in Montana, Small-Rodriguez has lost several spiritual mentors in her tribe, and
three relatives, including a cousin. He left behind a 7-year-old daughter.

"I don't think there's been any family here on the reservation who hasn't been impacted," she said. At least 48
people have died of the virus in the tight-knit tribe of about 1,500 people. Many were the last fluent speakers of the
Northern Cheyenne language, she said.

"Every single one of us counts so much because there are so few of us," she said.

Echo-Hawk, who also is executive vice president of the Seattle Indian Health Board, calls the inconsistencies an
erasure that equates "data genocide." Her team also rated each state on how often American Indians were
misclassified in state COVID-19 data.

More than half of states, including California, scored a 'C' or below on the board's report card. New Mexico, with a
population of more than 10% American Indian, received a D+.

"We have these communities and counties across the nation who don't even know they have Native people in their
communities, because of the gross undercounting," she said. "They are effectively eliminating us in the data ...
eliminating our elders' last chance to tell a story that could benefit their community. They've even taken that last
chance from us."

She remembers rushing her son to a Seattle hospital after a severe leg injury. Intake staff classified her son as
white. She informed staff that American Indian and Alaska Native were options on intake forms, and argued her
son's race should be recorded correctly.

"I think about families who don't know what I know," Echo-Hawk said. "They probably would have just left it because
they're in the midst of incredible trauma. And in COVID-19 right now, it couldn't be more traumatizing."

                                                                                                   Page 3 of 3
             Hard to track virus impact on Indigenous Inconsistent data masks Native American deaths

When Echo-Hawk and her team reached out to federal and state partners for masks and other personal protective
equipment early on in the pandemic, the center instead received body bags. Echo-Hawk was stunned. The clinic
isn't an inpatient hospital.

She went home in tears that day. Over the following months, she spent hours turning one of the body bags into a
traditional ribbon dress, processing her grief and trauma and honoring those she'd lost. It's adorned with her
handprints, and the phrase "I am a tangible manifestation of my ancestors resiliency."

Crystal Echo Hawk, also is a Pawnee Nation member and founder of IllumiNative, a nonprofit that aims to improve
American Indian data and representation in educational materials and pop culture.

"Invisibility can be a matter of life or death, and I think we really learned that during COVID," she said. "Data leads
to resources. It leads to policy change. It leads to interventions that keep people safe and healthy."

She called the lack of reporting tragic.

"We'll just never know how many people we truly lost and the depth of the crisis in different places in this country,"
the IllumiNative CEO said. Because of lack of tribal data, she added, "a lot of tribes will never know completely how
many of their citizens they've lost."

Hedrick, a sociologist and public health specialist with a focus on maternal and child health, said her staff at the
consortium have been making sure to ask their grieving Native American community members whether their loved
ones' race, ethnicity and tribal affiliation were on their death certificates.

"It makes it very difficult for California tribes to really assess the deep impacts of COVID when we don't have tribal
affiliation listed," she said. "We're born Indian, and die white."



Graphic


Leticia Aguilar sit in her home in Elk Grove, Calif. , next to photos of her grandmother and aunt who passed away
from COVID-19 last year.

Salgu Wissmath for USA TODAY

Echo-Hawk


Load-Date: August 19, 2021


  End of Document

                                                                                                          Page 1 of 2
                           Jabi Concert: FG Suspends Airline For Flying Naira Marley To Abuja




       Jabi Concert: FG Suspends Airline For Flying Naira Marley To Abuja
                                                          The Will (Nigeria)
                                                        June 16, 2020 Tuesday



Copyright 2020 The Will Newspaper All Rights Reserved

Length: 517 words

Body


Naira Marley The Federal Government has suspended the operations of a private jet charter and aircraft
maintenance firm, Executive Jet Services, for flouting COVID-19 regulations by flying Musician, Azeez Fashola aka
Naira Marley, to Abuja to attend a concert. This was disclosed on Monday by Hadi Sirika, the Minister of Aviation,
during the Presidential Task Force (PTF) briefing in Abuja, where he also revealed that the pilot of the jet would
also be sanctioned for giving wrong information to the control tower.

 Sirika, said approval for the flight was for an essential service, as opposed to what it was eventually used for. Sirika
stated, "So, Executive Jet Services' operations are hereby suspended indefinitely and we will also fine the firm
maximally according to the law.

 "The captain of the flight will also be sanctioned for giving wrong information to the control tower in accordance
with the law. "We approved a flight, but certainly not for any musician.

 The flight, from the application, was to convey Justice Adefope-Okojie from Lagos to Abuja and back to Lagos for
an official assignment. "And in this terrible time, in our wisdom, we considered the judiciary to be part of essential
services to be delivered and to move the justice from Lagos to Abuja was in order.

 "The approval was given for June 14, 2020. However, we do give them a leeway of 24 hours. Sometimes due to
operational reasons, they can either operate the flight slightly earlier or slightly forward within the 24-hour window.

 "In this case, the operator chose to fly on June 13 around 6pm. So, that in itself is not a violation, because we gave
them the leeway.

The operator is Executive Jet Services." Sirika added that the document that was given to the control tower also
made it clear that the operation must be strictly under the COVID-19 protocols.

 "Now, the operation was a clear violation of our approval to which we take very seriously and it seems that this is
becoming a norm, perhaps this is the second time," the minister stated. "Now, it seems also that people are not
tired of trying our resolve and I want them to know that we are also not tired of living and rising up to the challenge
and our responsibility of keeping our people safe.

"We will now escalate the mechanisms that we have in place to deter people from doing so and it also means that
we will be stricter in our approvals. Anyone, who dares us, will face the consequences.

                                                                                                      Page 2 of 2
                       Jabi Concert: FG Suspends Airline For Flying Naira Marley To Abuja

" The Coordinator of the Presidential Task Force on COVID-19, Sani Aliyu, said the FCT authorities would also take
a decision on the matter. "With regards to the fate of Naira Marley, I believe that the FCT authorities have already
taken action with regards to the key organisers of the show.

 "The decision in terms of whether or not he (Naira Marley) will face penalties is actually a decision for the FCT
authorities. "The PTF will certainly support any measures taken against people, who continue to violate the
implementation of the guidelines that we have clearly enumerated, particularly if they continue to put public health
at risk.

" !-- AI CONTENT END 1 --


Load-Date: June 17, 2020


  End of Document

                                                                                                      Page 1 of 3
                             Recruiting Through Computers - Upcoming Virtual Career Events




          Recruiting Through Computers - Upcoming Virtual Career Events
                                              The Aquinas: University of Scranton
                                                  February 16, 2021 Tuesday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: CAMPUS-LIFE; Pg. 1
Length: 837 words
Byline: Kelsey Wynn

Body


by Kelsey Wynn | Editor in Chief

SCRANTON - The University of Scranton's Center for Career Development is encouraging students across various
majors to attend its industry-specific virtual recruiting events, offered throughout the spring semester.

Upcoming Virtual Events:

- WVSOM at University of Scranton Info Session

Thursday, February 18 - noon to 2 p.m.

This event will feature a discussion of the West Virginia School of Osteopathic Medicine unique program, setting
and history.

With questions or for additional information, contact Admissions Counselor Amber Sayre at (304) 647-6251. Visit
Handshake to register.

- Mayo Clinic Virtual Career Fair

Thursday, February 18 - 4 to 8 p.m.

"What if your career could change your life? Whether you are starting your professional life or well vested in your
career journey, you may wonder if you are aligning with the work you were meant to do. Mayo Clinic invites you to
register for the Mayo Clinic Virtual Career Fair!"

This is a free event open to all. Areas of interest include Finance, Coding, Supply Chain, Billing; Human Resources;
Research; Laboratory Medicine and Pathology; Surgical Techs; Facilities & Security; · Patient Appointment
Scheduling and Administrative Services; Environmental Services, Linen Central Services, General Services;
Nursing - RN Students/Graduates, RN Experienced; Nursing Support - LPN, PCA, HUC, NA, MA; Certified
Registered Nurse Anesthetists; Nurse Practitioners and Physician Assistant; Pharmacy; Cardiac Monitoring;

                                                                                                         Page 2 of 3
                          Recruiting Through Computers - Upcoming Virtual Career Events

Information Technology, Information Security, Healthcare Technology Management; Management Engineering and
Consulting; Charter House (Senior Living); and Center for Digital Health (Data science and AI in healthcare).

Interested students may register at careerfair.mayoclinic.org. Once registered, participants will receive a link to the
event page. No downloads or software required. Contact diversityrecruitment@mayo.edu with questions.

- Discover AlphaSights - Leadership Program 2021 Informational Webinar

Thursday, February 18 - 6 to 7 p.m.

"Discover AlphaSights 2021 is our first annual leadership program designed to provide students with an opportunity
to learn about our firm, culture, and people. This multi-day conference invites high performing students from across
the country to explore career possibilities at AlphaSights through attending interactive learning activities and events,
while also building a network with your peers and AlphaSights professionals. Qualified students will have the
opportunity to receive a summer 2022 internship offer."

This opportunity is open to "underrepresented minority students (those who self-identify as Black, Latinx, Native
American, Asian or two or more races)" who must be two years out from their intended graduation date. Interested
students should be looking for a summer 2022 internship AlphaSights' New York or San Fransisco office.

Visit the event page on Handshake to register.

- Hack the Technical Interview Workshop

Thursday, February 18 - 7 to 8 p.m.

"Join a team of seasoned industry experts and professionals at Visa as they demystify the technical interview."

Visit this event's listing on Handshake for access to external registration.

- PwC New York Metro Spring Info Session

Friday, February 19 - 5:30 to 6:30 p.m.

This session will feature New York Metro Recruiters from PricewaterhouseCoopers (PwC), who will discuss the
spring recruiting process, leadership programs and Lines of Service (LoS) and answer questions during breakout
sessions following the presentation.

Interested students may register at this link: https://tinyurl.com/y4fuhqsw

- Washington Internship Institute Information Session

Monday, February 22 - noon to 12:45 p.m.

Learn more about the Washington Internship Institute's program, where students can receive assistance finding
internships with nonprofits, federal agencies, and Congressional offices in Washington, D.C. University of Scranton
credit is available for these internship opportunities.

To register, visit the event's page on Handshake.

- PT, OT, & Nursing Virtual Fair

Thursday, February 25 - 5 to 7 p.m.

Chrome or Firefox are the recommended browsers for this event. Contact Kristi Klien at careers@scranton.edu with
questions.

                                                                                                Page 3 of 3
                         Recruiting Through Computers - Upcoming Virtual Career Events

Visit Handshake to register.

- Human Resources & Health Administration Virtual Fair

Thursday, March 4 - 11 a.m. to 3 p.m.

Please note that Chrome or Firefox are also the recommended browsers for anyone attending this fair. Questions
may be directed toward Kristi Klien at the address above.

Visit Handshake to register.

The Center for Career Development recommends all students attending virtual recruiting events dress to impress
and have resumes ready to distribute to prospective schools and/or employers.

To view a comprehensive list of virtual spring recruiting and career events or to register for an event, visit
Handshake.

Tags: campus campusrecruiting career careerfair education entry events handshake job jobsearch level link
newyork recruiters recruiting resume school scranton study virtual virtualevent zoom


Load-Date: February 17, 2021


  End of Document

                                                                                                       Page 1 of 3
                            Computer Science Department expands as student interest grows




          Computer Science Department expands as student interest grows
                                              Inside Vandy: Vanderbilt University
                                                  September 6, 2021 Monday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: CAMPUS; Pg. 1
Length: 882 words
Byline: Stephanie Ting Shunnar Virani

Body

The Computer Science Department is witnessing growth in its number of student majors, faculty numbers, research
opportunities and courses offerings. The department split from the Electrical Engineering Department in Fall 2021 to
better accommodate growing interest.

Per Julie Johnson, associate chair of the Computer Science Department and director of undergraduate studies in
computer science, this is largely an administrative change and will be seen by students through growth in faculty.

Fall 2021 will mark the start of the second year of Destination Vanderbilt, a three-year $100 million program that
aims to kindle a growing interest in the field. The program's goal is to hire around 20 new computer science faculty
members, adding to the previous 20 faculty members. The Computer Science Department has already hired seven
people this past year and hopes to hire another seven to eight new faculty members in the upcoming year,
according to Johnson.

"We're doubling the size of our faculty, which is very exciting," Johnson stated. "In the meantime, the number of our
students has practically doubled as well."

Since 2019, there has been an approximately 29 percent increase in computer science majors. In 2019, 451
students from the School of Engineering majored in computer science, 103 students outside of the School of
Engineering majored in computer science and 130 students minored in computer science, according to Johnson. As
of Fall 2021, 569 students from the School of Engineering are majoring in computer science, 145 students outside
of the School of Engineering are majoring in computer science and 140 students are minoring in computer science.

"The minors numbers aren't jumping in any big leaps and bounds," Johnson said. "It's the major that obviously has
just exploded."

According to Johnson, the rapid growth in computer science is due to the subject having many "flavors" and being
"ubiquitous" in a diverse range of careers, spanning from data science and software engineering to
entrepreneurship. Karolina Groszewska, a sophomore majoring in computer science, also stated that more majors
are starting to use computer science classes as requirements, inspiring more interest in the field.

                                                                                                        Page 2 of 3
                         Computer Science Department expands as student interest grows

"We're encouraged to take different classes, but once you take the CS intro class, it kind of encourages people to
switch or take on a double major [in computer science]," Zakariyya Al-Quran, a junior majoring in computer
engineering, added.

Al-Qurran expressed excitement about the diverse research interests that Destination Vanderbilt hopes to curate
with its new faculty hires.

"[These professors] have been doing [research] their whole life, so it would be cool to have those professors, who
are teaching us, be the pioneers of their expansion project," Al-Qurran said.

When hiring new faculty, Destination Vanderbilt leaders-who are part of the Office of the Provost-target four aspects
of computer science. These areas include autonomous and intelligent human-AI-machine systems and urban
environments, cybersecurity and resilience, computing and AI for health, medicine and surgery and design of next-
generation systems, structures, materials and manufacturing.

Johnson said hiring new faculty members will also enhance the reach and depth of computer science research at
Vanderbilt.

"Providing opportunities to all students to get research is a good opportunity to keep expanding skillsets,"
Groszewska said. "CS professors foster extracurricular involvement or having more CS professors able to help with
external projects or willing and able to take on young undergraduates helps a lot in diversifying students' interests
and helping a variety of students explore different fields and the like."

With the new hires entering, class offerings for students have also increased. In Fall 2020, the Computer Science
Department offered 22 courses which increased to 29 courses offered in Spring 2021. In Fall 2021, it will offer 29
courses.

Johnson also mentioned the increase of depth courses, which are advanced, specific computer science classes
such as Cyber Security and Artificial Intelligence. The department offered 11 of these courses in Fall 2020 and will
offer 18 in Fall 2021.

"Once [the seven new professors] have kind of integrated into the system, they'll start teaching undergrad courses
next spring and the following fall," Johnson said. "So, that's probably seven more depth courses coming up."

Johnson emphasized the importance of computer science and encouraged students to take a computer science
course, even if it doesn't meet a degree requirement.

"We work on being good teachers and we have an army of teaching assistants to help you," Johnson said. "
Nothing should stop you from taking that first intro class."

Share on FacebookShare on TwitterShare via EmailPrint
    •   computer science
    •   destination vanderbilt
    •   electrical engineering
    •   Julie Johnson
    •   VUSE
    •   Zakariyya Al-Quran
About the Contributor

Anjali Chanda

Anjali Chanda ('23) is from Beverly, MA. She is majoring in sociology and English with a focus in creative writing. In
the past, she wrote for the Arts and Society Section of the Greyhound Newspaper at Loyola University Maryland. In

                                                                                                 Page 3 of 3
                       Computer Science Department expands as student interest grows

her free time, she can be found painting, writing stories, or rewatching New Girl. She can be reached at [email
protected]


Load-Date: September 7, 2021


  End of Document

                                                                                                           Page 1 of 5
                 Medical errors kill thousands of people each year. But are hospitals getting any safer?




 Medical errors kill thousands of people each year. But are hospitals getting
                                  any safer?
                                                        USA Today Online
                                                          May 3, 2023



Copyright 2023 Gannett Media Corp All Rights Reserved

Section: US NEWS
Length: 2319 words
Byline: Karen Weintraub, USA TODAY

Body


Two years ago, administrators and caregivers at St. Bernard Hospital in Chicago were stunned when they flunked a
basic standard for patient safety.

"It was a real jolt," said Charles Holland, the hospital's president and CEO. "We thought we were doing patient
safety and we thought we were doing it well."

But the Leapfrog Group, a nonprofit health care watchdog organization, found the hospital fell short on
documenting and having comprehensive approaches to hand-washing, medication safety systems and fall and
infection prevention.

The wake-up call led Holland to hire a Patient Safety and Quality Officer and to use Leapfrog's criteria as a
roadmap for improving patient safety.

It worked. In its latest annual review of hospital safety, released Wednesday, Leapfrog awarded the century-old
charity hospital an A.

Government watchdog: 1 in 4 older Americans on Medicare harmed during hospital stays

The fact that St. Bernard could turn around so quickly and so effectively without spending a fortune in the process
shows that patient safety is an attainable goal, said Leah Binder, Leapfrog's president and CEO.

Link to Image

"I'm incredibly inspired by St. Bernard's," Binder said. "This is a story of a hospital that has every reason to give
excuses and instead gave us extraordinary performance."

For decades, hospitals have paid lip service to patient safety, but the numbers tell a different story. In 1999, an
Institute of Medicine report called "To Err is Human" found medical errors cause as many as 100,000 deaths per
year.

                                                                                                          Page 2 of 5
               Medical errors kill thousands of people each year. But are hospitals getting any safer?

A 2017 study put the figure at over 250,000 a year, making medical errors the nation's third leading cause of death
at the time. There are no more recent figures.

But the pandemic clearly worsened patient safety, with Leapfrog's new assessment showing increases in hospital-
acquired infections, including urinary tract and drug-resistant staph infections as well as infections in central lines ‒
tubes inserted into the neck, chest, groin, or arm to rapidly provide fluids, blood or medications. These infections
spiked to a 5-year high during the pandemic and remain high.

"Those are really terrible declines in performance," Binder said.

Patient safety: 'I've never ever, ever seen that'

Not all patient safety news is bad. In one study published last year, researchers examined records from 190,000
patients discharged from hospitals nationwide after being treated for a heart attack, heart failure, pneumonia or
major surgery. Patients saw far fewer bad events following treatment for those four conditions, as well as for
adverse events caused by medications, hospital-acquired infections, and other factors.

It was the first study of patient safety that left Binder optimistic. "This was improvement and I've never ever, ever
seen that," she said.

HEALTH NEWS: Loneliness epidemic facing America in 2023, U.S. Surgeon General Vivek Murthy warns

The healing power of a good beat: Neurologic music therapy helps kids with brain injuries

Binder attributes the advances to federal reporting requirements that forced hospitals to reveal patient safety
metrics, such as how many people were catching infections in hospitals and how many patients were falling out of
bed or not being turned enough to avoid pressure sores. Those metrics allowed Leapfrog and others to grade
hospitals on their performance.

As a result, hospital board members started asking their leadership teams, "why are we are getting a C or a D or an
F? How could you not tell us what was happening?" Binder said. "That moved patient safety up on the CEO's
priority list. Fast."

Unfortunately, the pandemic un-did a lot of that progress.

With the increased demands on staff during the pandemic, compounded by burnout, staffing and supply shortages
and high turnover patient safety slipped as a priority, Binder said.

"Hospitals are supposed to be caring for patients and keeping them safe no matter what, even in an emergency,"
she said. "That is why we have hospitals, because emergencies happen. We expect them to be able to handle
them."

According to Leapfrog's latest ranking, over 800 hospitals ‒ nearly 30% ‒ received an A, a slight drop since before
the pandemic. More than 700 ‒ or 26% ‒ received a B; 1,100 ‒ or just under 40% ‒ received a C, a small uptick;
170 or 6% were given a D; and 12 hospitals, or less than 1%, flunked.

The state with the most A hospitals is New Jersey, which jumped from No. 6 to No. 1 since the Leapfrog's last
review. Delaware, North Dakota and Washington, D.C., are tied at the bottom of the ranking, entirely lacking A-
rated hospitals.

On any given day now, 1 of every 31 hospitalized patients acquires an infection while hospitalized, according to a
recent study from the Centers for Disease Control and Prevention. This costs health care systems at least $28.4
billion each year and accounts for an additional $12.4 billion from lost productivity and premature deaths.

                                                                                                              Page 3 of 5
                Medical errors kill thousands of people each year. But are hospitals getting any safer?

"That blew me away," said Shaunte Walton, system director of Clinical Epidemiology & Infection Prevention at
UCLA Health. Electronic tools can help, but even with them, "there's work to do to try to operationalize them," she
said.

The patient experience also slipped during the pandemic. According to Leapfrog's latest survey, patients reported
declines in nurse communication, doctor communication, staff responsiveness, communication about medicine and
discharge information.

Boards and leadership teams are "highly distracted" right now with workforce shortages, new payment systems,
concerns about equity and decarbonization, said Dr. Donald Berwick, president emeritus and senior fellow at the
Institute for Healthcare Improvement and former administrator of the Centers for Medicare & Medicaid Services.

"There a long list of things now on the agenda," Berwick said. "Safety, if it hasn't fallen off the list, it's certainly lost
rank."

Why these problems keep happening

To some extent, hospital safety is a no-brainer.

It's been clear for almost 200 years that dirty hands and medical equipment can transmit infections. Technological
advances and training on basic habits can make a difference.

"We have really good evidence about things that work," Binder said. "What we haven't had is that shove to hospitals
to say 'now go do it.'"

SUMMER SAFETY: As summer approaches, a wake-up call on child drowning deaths. Here's what you should
know

HEALTH AND AI: Chatbots are accurate, show more empathy than doctors in answering questions, study finds

Patient care has also become increasingly complex over the past two decades and if nothing had been done about
patient safety, "the number of errors and deaths from errors would be far higher," said Dr. Robert Wachter,
chairman of the department of medicine at the University of California, San Francisco.

But he admits that the field has stagnated over the past decade as other priorities, such as patient satisfaction,
caregiver burnout and equity, have competed with patient safety for attention and scarce dollars. "The agenda has
grown and grown."

Hospitals did the easy stuff first, the "incredibly, almost flabbergasting errors where we'd do surgery on the wrong
patient," Wachter said. "We don't do as many of the really, really bad, 'how could that possibly happen?' things. The
errors today are more subtle, but they're actually more difficult to eradicate."

Changing a hospital's culture is the hardest part of addressing patient safety, said Dr. Elizabeth Mort, senior vice
president for quality and safety at Massachusetts General Hospital, one of the researchers who led a recent study
on patient safety at Harvard-affiliated hospitals. Workers have to be encouraged to do the right thing and supported
for it.

Serious mistakes are usually the product of systems or basic habits that don't support appropriate behavior.

"Sometimes it's the simple things that are the best things," Mort said.

She pulled up a sign that was posted next to patients getting infusions, reinforcing the "5 rights." "Is it the right
person, is it the right drug, is it the right dose, is it the right time, is it the right route?"

Surgical teams should also be pausing for a "pre-operative timeout" before they begin, to make sure they have the
right patient and right body part identified.

                                                                                                          Page 4 of 5
                Medical errors kill thousands of people each year. But are hospitals getting any safer?

"Each and every time. There's no excuse not to," Mort said.

A culture of openness, awareness and inclusion, where employees feel empowered to raise questions is "a big part
of the solution to safety," Berwick added.

Having electronic systems in place, like bar codes on both patient wristbands and medications, can also help avoid
mistakes.

Electronic medical records have made it easier to avoid mistakes like giving a patient a medication they are known
to be allergic to ‒ but caregivers are subject to so many alerts they can get "pop-up fatigue" and miss important
messages, Mort said.

Technical solutions aren't enough, said Stephanie Mercado, chief executive officer and executive director of the
National Association for Healthcare Quality. Health care executives have to invest in training their workforce to
move the needle on patient safety.

"It's the single biggest lever they have to affect change," she said.

Today's safety training is highly variable and often absent from workforce development plans, said Mercado, whose
organization offers a standardized and specific framework for improving patient safety and quality. About half the
14,000 professionals involved in safety and health care quality don't have funding from their employers for training
and have to scramble to self-fund their training programs, she said.

Too many hospital leaders "view quality as compliance," she said, responding to mistakes that are made instead of
proactively making improvements to insure safer care.

Caregiver burnout is closely tied to patient safety, Mercado said. "Burnout occurs in part because the workforce
sees the same challenges in health care quality and safety playing out over and over and over again."

The health care payment system doesn't help. Short of a truly egregious error, a hospital gets paid for a procedure
whether the "care was perfect or not," Wachter said.

"No one has figured out yet a system that provides appropriate incentives on either quality or safety," he said. "Most
health care organizations want to do the right thing but the kind of investment that has to go into people and
processes to really address this adequately is pretty high."

Patients can help themselves by coming to the hospital with a list of medications they're taking and any allergies.

It's also "fair game" to ask a caregiver to wash their hands when entering a patient's room, Mort said, and to make
sure they are being given the correct medication and that they understand it's effects and possible side effects. "If
something doesn't seem right, speak up," she said.

And it makes sense for patients to bring someone with them, "another set of eyes and ears," Mort said, because it's
hard to pay attention to such things when you're feeling lousy.

But the burden shouldn't be on the patient to keep themselves safe in a hospital, Mort said. "It's really our
responsibility to implement these systems and do the right training."

Hospitals can turnaround

Link to Image

When Michael Richardson was first hired at St. Bernard as Patient Safety and Quality Officer, he said his focus was
to make changes that would show progress quickly.

                                                                                                         Page 5 of 5
               Medical errors kill thousands of people each year. But are hospitals getting any safer?

He helped establish a committee on safe medication administration, corrected systems issues with digital systems,
replaced damaged equipment and began to use existing resources to provide more data on patient safety
measures.

"Straight away we could see a difference," Richardson said.

He also purchased a system from the company BioVigil, providing badges that flash yellow during the first minute a
caregiver is in a patient room and then red if they haven't washed their hands. Both Richardson and Holland
pointed to their shoulders on a recent Zoom call, displaying their green-lit badges.

Compliance with handwashing is now around 90%. "It sends a good message to the patients," Richardson said,
plus it enables the administration to track which staff members and physicians are keeping their hands clean.

Rather than punishing people for making mistakes, the administration now recognizes employees' good work and
tries to encourage workers to speak up if they see a problem. "If they don't tell us, we can't fix it," Richardson said.
"We're still trying to change that culture."

HEALTH NEWS: When should breast cancer screenings start? Black women aren't given a good answer.

Holland said he's also changed his language when he speaks with physicians and his own leadership team.

"I talk about patient safety more," he said. "I address an issue as it relates to patient safety. Before I may have said
that's part of the standard or a quality issue, but now I relate it more directly to keeping a patient safe."

Safety-net hospitals like his, where nearly 80% of patients are covered by Medicaid, need additional resources to
focus more fully on patient safety. His patients deserve the same standards of safety as people and communities
with more economic advantages.

The A grade is a major accomplishment and the hospital is hosting a cupcake celebration Wednesday.

"They saved many lives and I have nothing but congratulations for their entire workforce and their volunteers,"
Binder said. "This had to be an all-out effort."

But Holland said he and his staff aren't stopping now. "We've done some great work, but we have to keep going."

Contact Karen Weintraub at kweintraub@usatoday.com .

Health and patient safety coverage at USA TODAY is made possible in part by a grant from the Masimo
Foundation for Ethics, Innovation and Competition in Healthcare. The Masimo Foundation does not provide editorial
input.

This article originally appeared on USA TODAY: Medical errors kill thousands of people each year. But are
hospitals getting any safer?


Load-Date: May 5, 2023


  End of Document

                                                                                                    Page 1 of 2
         Stanford Medicine [email protected] Concert segment celebrates Asian grandmothers, youth activism




     Stanford Medicine [email protected] Concert segment celebrates Asian
                         grandmothers, youth activism
                                            The Stanford Daily: Stanford University
                                                      May 23, 2021 Sunday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 840 words
Byline: Tom Quach

Body


Stanford Medicine's Center for Asian Health Research and Education hosted the third installment of its [email
protected] Concert series on May 20 to celebrate Asian grandmothers. The two-hour virtual ceremony featured
video performances by over a dozen Bay Area community members and Stanford affiliates, followed by a panel of
six women who discussed the experiences of Asian-American women across generations.

The upbeat event centered on the "power and grace of Asian grandmothers" comes during a time of increased
violent anti-Asian crimes nationwide and President Joe Biden's signing of a bipartisan anti-Asian hate crime bill into
law.

The panelists took turns discussing their own grandmothers' bravery, personal instances of racism and prejudice in
educational and workplace environments and the inspirational nature of energized youth advocacy nationwide.

"Grandmas are conduits to our past," said Kiet Do, a local KPIX 5 reporter who led the panel. "They connect us to
our culture or language, and they make sure that we never go hungry."

"I feel so lucky to have great women come before us and take a stand," said Julia Hu '06, founder of healthcare AI
startup LARK Health. "I'm blessed with the voices and fight of people before me."

While Hu shared her experiences as an Asian woman working within a mainly white, male-dominated Silicon Valley
startup ecosystem, Manjula Waldron M.S. '68 Ph.D. '71 discussed what it was like as the first Asian woman to
receive a Stanford electrical engineering Ph.D. studying in a predominantly white student community.

Hu and Waldron, who at times felt invisible to their peers and professors as they prioritized other students before
her, agreed that it was crucial to find a community of like-minded, empathic people to be themselves with and grow
as a leader of color. For Waldron, this took shape when she founded the Stanford India Association on campus as a
way to inspire community members of color and "empower the disempowered."

The guest speakers also highlighted the inspiring nature of recent youth protests and advocacy that have sprouted
up nationwide in the wake of the Atlanta mass shooting that killed six Asian women. Bryant Lin, associate professor

                                                                                                  Page 2 of 2
       Stanford Medicine [email protected] Concert segment celebrates Asian grandmothers, youth activism

of medicine and co-host of the [email protected] Concert, directly referenced a March attack in San Francisco
involving Xiao Zhen Xie, a 75-year-old Asian grandmother who defended herself after being assaulted. With strong
community support, Xiao collected over $1 million on GoFundMe, which she and her family pledged to charities
fighting Asian-American hate.

Rona Hu, the School of Medicine associate dean, offered a twist on the "fight or flight" expression. Quoting Stop
AAPI Hate's co-founder Russell Jeung, Hu noted that another option is to "flock" and stand together as a group to
face injustices and hate.

Northern California's first Asian-American female judge Lillian Sing agreed, noting that while the stark rise in anti-
Asian hate crimes is appalling, Asian American youth have taken over the stage with their resounding advocacy,
replacing former stereotypes of silence.

"Look at the demonstrations," Sing said. "Young people are rising up, not tolerating all this. This is why I am
hopeful."

Prior to the panel, various vocal and instrumental presentations dedicated to the rich history of Asian communities
and heritage were spotlighted.

Traditional music and song performers ranged from Stephen Murphy-Shigematsu, a lecturer in the Center for
Comparative Studies in Race and Ethnicity, to Stanford's East Asian a capella group O-Tone to seniors Jacob
Bedia '21 and Eunice Jung '21, who performed a piano and vocal rendition of "The Gift of Love" dedicated to
Bedia's grandmother. Several additional individuals including Stanford Magazine writer Andrew Tan '22 recorded
short videos dedicated to their grandmothers living both close by and overseas.

School of Medicine Dean Lloyd Minor stressed the importance of uplifting the Asian and Pacific Islander community
and described their extraordinary talent within the Stanford Medicine network during his introduction. He noted that
while the COVID pandemic has accentuated negative and hurtful actions, society is still fundamentally filled with
love, tolerance and concern for one another - qualities that must be maintained, he said.

For Stanford Medicine leadership, the opportunity to facilitate discussion and pioneer healthcare revolving around
Asian American Pacific Islander communities must continue.

Alongside CARE, Stanford Medicine has dedicated several programs which spearhead research and clinical care
for Asian American and Pacific Islander communities. These include Stanford's Asian Liver Center and South Asian
Translational Heart Initiative. The Pacific Free Clinic offers free health care for uninsured adults living in East San
Jose.

"It is our responsibility to raise awareness and create spaces where our Asian American and Pacific Islander
community members can share their experiences to inform and define the conversation," Minor said.


Load-Date: May 24, 2021


  End of Document

                                                                                                       Page 1 of 2
                               AIS Cancer Center gets $10 million shot in the arm in state funding




         AIS Cancer Center gets $10 million shot in the arm in state funding
                                                        The Bakersfield Californian
                                                    September 28, 2022 Wednesday



Copyright 2022 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 661 words
Byline: Steven Mayer, The Bakersfield Californian

Body


Sep. 28—It started as a dream that, 10 years ago, became a reality.

But Tuesday morning, as a crowd of doctors, patients and dozens of members of the community gathered outside
Adventist Health's AIS Cancer Center in downtown Bakersfield, the dream was clearly not finished.

In a significant state investment in local cancer treatment, Assemblyman Rudy Salas, D-Bakersfield, presented
Adventist Health with a ceremonial check for $10 million to expand the cancer center. The funding, earmarked in
the 2022-23 state budget, includes direct financial support for breast, colorectal, cardiothoracic and specialty care
cancer treatment at the center.

"I am thrilled to bring $10 million to help Adventist Health reach more people in our community and save more
lives," Salas said.

Few go through life untouched by cancer, he noted. His own family, he told the gathering, has been afflicted by the
disease.

"Cancer affects so many of us and our loved ones," he said, "and now we can serve more families closer to home
with specialized care, and better help those fighting back against cancer."

Daniel Wolcott, president of Adventist Health's Kern County network, said the money will help fund "the next
chapter in the growth of the AIS Cancer Center."

Bakersfield, he said, has grown to become the ninth-largest city in California, and Kern's population is headed
toward the 1 million mark.

"We're home to more oil, more renewable energy, more agricultural production than almost anyplace else in the
world, and we have so much abundance and so much to be thankful for," Wolcott said.

"However, this also is a community that suffers from some scarcity," he said. "We struggle with having enough
medical professionals to serve the people of this community."

                                                                                                             Page 2 of 2
                          AIS Cancer Center gets $10 million shot in the arm in state funding

And cancer death rates in Kern are "significantly greater" than across the state as a whole.

"There is work to be done to improve care in this community," Wolcott said, "and that's what the AIS Cancer Center
and Adventist Health is all about."

Cancer survivor Jessica Guevara is only 40, but the Tehachapi resident was diagnosed with breast cancer Dec. 6
and began treatment at AIS on Jan. 10.

"I really had so many questions, and I had so many emotions, and the uncertainty of how this journey was going to
go was extremely overwhelming for me — not just me, my family," she said of her husband, three children and
granddaughter.

But her family seemed to grow when she began treatment.

"Every step that I've taken, we've fought it together," she told the gathering. "It's not just about me, it's not just about
my family, it's about your team that you have here, and how important they are to you to get you through this
journey."

A major guide along that path has been Jacqueline Engstrand, ASI's navigation nurse who is affectionately known
as Nurse Jacqui.

"Every aspect of my life has changed in this past year with cancer treatment, but having an available all-hands-on-
deck team from the center has made that possible for me."

Guevara lauded the entire team, from her oncologist to her radiologist, her surgeon to the infusion nurses.

"They're smart and they're on it every day," she said.

The $10 million will make it possible to begin the process of expanding into the top two floors of Quest Imaging's
north building at the Chester Avenue complex, said AIS Cancer Center Director Jenny Lavers.

"When the Quest Imaging building was designed, which was a decade ago, they knew we would need space and
that we would want to have future growth," Lavers said.

"And as you can see, we intend to fill these two floors — which is 40,000 square feet of available space — with an
unparalleled coordinated care model for patients across Kern County."

Reporter Steven Mayer can be reached at 661-395-7353. Follow him on Facebook and on Twitter: @semayerTBC.

___ (c)2022 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: September 28, 2022


  End of Document

                                                                                                           Page 1 of 2
                                    Boeing gives $3M for Franklin Institute SPACE exhibit




                    Boeing gives $3M for Franklin Institute SPACE exhibit
                                                    The Philadelphia Inquirer
                                                       June 17, 2022 Friday



Copyright 2022 Philadelphia Newspapers, LLC All Rights Reserved

Section: LIFE; Pg. C1
Length: 540 words
Byline: Stephan Salisbury STAFF WRITER

Body


The Franklin Institute, engaged in astronomical presentations and study for most of its two-century existence, will
use a $3 million donation from the Boeing Co. to create a new two-story space exhibit - the first expansion and
reconfiguration of its space exhibit in 20 years.

Opening in the fall of 2023, the new SPACE center will usher in "a new age of space science" at the institute, in
time for celebration of its 200th anniversary in 2024, said Larry Dubinski, institute president and chief executive.

The current exhibit, he said, is on the first floor. The SPACE exhibit will clock in at about twice the size of the
current one, about 7,000 square feet sprawling over two floors.

"Going forward we're just really, really excited about it," said Dubinski. "On the first floor, we'll have the planetarium
that's been here since the building opened [in 1934]. On the top floor, we have the observatory, and now on the
second and third floor, the second floor being the main floor right next to the [Benjamin Franklin] memorial, we'll
have the first part of the space exhibit on that floor and then on the third floor right above. It'll surround the
pendulum staircase."

Boeing has been a consistent supporter of the Franklin Institute over many years and the company sees its current
capital donation as part of its "space legacy," said Ziad Ojakli, Boeing's executive vice president of government
operations.

"We know that space can be an indispensable tool for inspiring and engaging students around science, technology,
engineering, and math," he said.

"Boeing's investment will be transformative for both the Franklin Institute and the hundreds of thousands of students
who will visit the reimagined SPACE exhibit each year."

The SPACE exhibit will represent one of six "topic areas" the institute expects to present in a series of new
exhibition galleries developed and rolled out over the next five years.

                                                                                                           Page 2 of 2
                                Boeing gives $3M for Franklin Institute SPACE exhibit

The first of these, announced three years ago, is "Treasures of the Franklin Institute," scheduled for completion in
2024, which will feature the institute's monster Baldwin 60000 steam locomotive suspended in the air amid a
changing array of "treasures" culled from the collection.

Other thematic exhibitions the institute is looking at, said Dubinski, involve the biosciences, AI and biological
augmentation, health science, earth systems, engineering, advanced machines, and computer science.

"We will go from almost 11 different exhibit topics to six, making larger exhibits going a little bit deeper," he said.
"And obviously, not only will we have exhibit components here in the museum, but, there will also be programmatic
elements, digital elements, and things along those lines."

On a practical level, the institute is looking at building "workforce development and careers," Dubinski said.

"It's very important for people to see different races, different genders in these jobs," he said. "Obviously, the history
and ethics are always going to be important when we talk about science. And then threads like innovation and
sustainability in decision-making, in entrepreneurship and collaboration as well. So t h e s e t h e m e s a n d
threads run through all of these exhibitions." ssalisbury@inquirer.com

215-854-5594 spsalisbury


Load-Date: June 17, 2022


  End of Document

                                                                                                Page 1 of 2
           THAT'S OUT OF THIS WORLD! Boeing gives $3 million for new Franklin Institute Space Center




    THAT'S OUT OF THIS WORLD!; Boeing gives $3 million for new Franklin
                         Institute Space Center
                                                  The Philadelphia Daily News
                                                       June 17, 2022 Friday



Copyright 2022 Philadelphia Newspapers, LLC All Rights Reserved

Section: FEATURES; Pg. 21
Length: 551 words
Byline: Stephan Salisbury STAFF WRITER

Body


ABSTRACT

Boeing gives $3 million for new Franklin Institute Space Center

The Franklin Institute, engaged in astronomical presentations and study for most of its two-century existence, will
use a $3 million donation from the Boeing Co. to create a new two-story space exhibit - the first expansion and
reconfiguration of its space exhibit in 20 years.

Opening in the fall of 2023, the new SPACE center will usher in "a new age of space science" at the institute, in
time for celebration of its 200th anniversary in 2024, said Larry Dubinski, institute president and chief executive.

The current exhibit, he said, is on the first floor. The SPACE exhibit will clock in at about twice the size of the
current one, about 7,000 square feet sprawling over two floors.

"Going forward we're just really, really excited about it," said Dubinski. "On the first floor, we'll have the planetarium
that's been here since the building opened [in 1934]. On the top floor, we have the observatory, and now on the
second and third floor, the second floor being the main floor right next to the [Benjamin Franklin] memorial, we'll
have the first part of the space exhibit on that floor and then on the third floor right above. It'll surround the
pendulum staircase."

Boeing has been a consistent supporter of the Franklin Institute over many years and the company sees its current
capital donation as part of its "space legacy," said Ziad Ojakli, Boeing's executive vice president of government
operations.

"We know that space can be an indispensable tool for inspiring and engaging students around science, technology,
engineering, and math," he said. "Boeing's investment will be transformative for both the Franklin Institute and the
hundreds of thousands of students who will visit the reimagined SPACE exhibit each year."

The SPACE exhibit will represent one of six "topic areas" the institute expects to present in a series of new
exhibition galleries developed and rolled out over the next five years.

                                                                                               Page 2 of 2
          THAT'S OUT OF THIS WORLD! Boeing gives $3 million for new Franklin Institute Space Center

The first of these, announced three years ago, is "Treasures of the Franklin Institute," scheduled for completion in
2024, which will feature the institute's monster Baldwin 60000 steam locomotive suspended in the air amid a
changing array of "treasures" culled from the collection.

Other thematic exhibitions the institute is looking at, said Dubinski, involve the biosciences, AI and biological
augmentation, health science, earth systems, engineering, advanced machines, and computer science.

"We will go from almost 11 different exhibit topics to six, making larger exhibits going a little bit deeper," he said.
"And obviously, not only will we have exhibit components here in the museum, but, there will also be programmatic
elements, digital elements, and things along those lines."

On a practical level, the institute is looking at building "workforce development and careers," Dubinski said.

"It's very important for people to see different races, different genders in these jobs," he said. "Obviously, the history
and ethics are always going to be important when we talk about science. And then threads like innovation and
sustainability in decision-making, in entrepreneurship and collaboration as well. So these themes and threads run
through all of these exhibitions."

+ssalisbury@inquirer.com

^215-854-5594

"spsalisbury


Load-Date: June 17, 2022


  End of Document

                                                                                                           Page 1 of 3
                             Stressed about the election? You're not alone. How to stay calm.




          Stressed about the election? You're not alone. How to stay calm.
                                                        USA Today Online
                                                        November 4, 2022



Copyright 2022 Gannett Media Corp All Rights Reserved

Length: 1154 words
Byline: Josh Peter and David Oliver, USA TODAY

Body


With the midterm election less than a week away, scores of Americans divided by their support for Republicans or
Democrats also are united – by stress.

And it makes sense why they are. "The midterms determine the balance of power in the Senate and Congress. This
has, arguably, significant consequences," says Mona Eshaiker, licensed therapist. "With the ever-increasing
political polarization in the U.S., every election can feel like an 'us vs. them' battle, where our beliefs and values are
potentially on the chopping block."

It seems to have only gotten worse, too. "Research suggests that election anxiety increased between 2016 and
2020," says Marsha Brown, a licensed psychologist. "With growing fear for the future of human rights, health care,
the economy and other life issues, it seems election anxiety may have risen again since the previous election
cycle."

Stress triggers the release of cortisol, the so-called stress hormone, William Heckman, executive director of the the
American Institute of Stress, has told USA TODAY. This affects mood, motivation and fear.

Link to Image

“It works with parts of your brain and the physiology of your body,’’ he says. “You need some of that (cortisol) to be
motivated. But too much of that, you live in a state of ongoing anxiety, which is very bad for you.’’

Still, the Nov. 8 elections will affect everyone differently. "Different people have had different experiences in the
past," says Smriti Joshi, chief psychologist at Wysa, an AI mental health platform. "And there have been genuine
triggers, which can be leading people to feel worried and stressed about the upcoming elections."

Keep these tips in mind for combating stress before, during and after Election Day.

What is burnout? It starts with work and while self-care can help, it isn't just your problem to solve

'Master your morning'

                                                                                                         Page 2 of 3
                          Stressed about the election? You're not alone. How to stay calm.

Nefertiti Nowell, a licensed clinical professional counselor in the Chicago metropolitan area, subscribes to this
motto: “If you can master your morning, you can master your day.’’

She recommends brief stretching exercises and writing down something you’re grateful for – preferably a new
source of gratitude every day. Yoga, deep breathing and meditation can be added to the morning ritual, but it’s not
necessary, according to Nowell.

"I’ve learned that if it’s anything over five minutes, people are less likely to do it,’’ she says. “Everybody has three
minutes to get their blood flowing. And so if we take those three minutes to do that, then it really gets us centered
for that day.

“It’s more about mental health than it is just physical health. It’s the getting the blood flowing for the body but even
for you to say: ‘I have control over something. I’ve got control over three minutes of my morning.’ ”

Brown adds: "Be sure to engage in activities that replenish your mental, physical and emotional stores. Identify the
activities that fill you with energy and make time to complete them. Not sure what you find restorative? Think of
activities you’ve always wanted to try or those you enjoyed as a child. Finding activities that work for you is a
process that usually involves trial and error."

Interesting: Conservative men dominate the politics of abortion access. Where are the progressive men?

Turn off your news alerts

Yes, it's OK if you need to. "Ensuring the hour before you go to bed is free from electronics is helpful to wind down
and keep the nervous system regulated," Eshaiker says. "Similarly, you can limit yourself to media blocks
throughout the day. For example, only checking the news for 30 minutes twice a day. This way you are less likely to
(doom) scroll or go into an anxious spiral."

Also remember that you don't need to talk about the election. "It may also help to set boundaries with family, friends
and co-workers who try to pull you into political conversations," Brown says.

Listen to your body: Your body is trying to tell you something

Channel your stress

Instead of pacing your home afraid, if you have the bandwidth, go forth and galvanize voters in your community.
"Many individuals get a sense of purpose and strength by channeling their anxiety into action," Eshaiker says. "This
can look like attending a town hall, volunteering at the polls, canvassing, protesting, information sharing, attending
workshops and seminars. Being part of a group can also provide a sense of support and community."

And of course, vote. Eshaiker adds: "This can help alleviate feelings of stress and gain a sense of control. Although
we cannot control the outcome of the elections, every vote truly matters. After voting, many people express feeling
empowered and accomplished."

Heads up: Amid midterm voting, Biden warns of 'chaos,' fears of political violence ahead of Nov. 8 election

What to do after the election is over

Chloe Carmichael, a licensed clinical psychologist in New York, recommends making plans for after you vote – for
anything from having lunch with a friend or exercising.

She also suggested writing a one-page journal entry recording your thoughts and feelings about the election.

                                                                                                           Page 3 of 3
                          Stressed about the election? You're not alone. How to stay calm.

“Sometimes writing it all own can relieve our brain of the burden of feeling like you have to keep all of those points
active,’’ Carmichael says. “And thinking about the idea of potentially that page being passed on down to our
children or our children’s children can also help to put the whole event into a little bit of perspective.’’

Remember too that politicians are people and contain multitudes. "Black-and-white thinking can fuel the flames of
anxiety," Eshaiker says. "No one is 'all good' or 'all bad,' and no situation is 'all good' or 'all bad.' Finding the gray
area in any political election can be a helpful way to embody a balanced perspective."

Important: Culture war issues like abortion and trans rights are shaping midterm elections

Once the day is done, Eshaiker suggests a media cleanse: "This can be as little as one day without looking at the
news or social media. Or a week depending on what you think you may need. The point here is to help regulate
your nervous system after election season to get your mind and body back to homeostasis."

Consider professional help if stress persists. "Explore what exactly about the election is causing you stress. Is there
one issue or one politician in particular you are preoccupied by? Oftentimes, when we find ourselves fixated over an
issue, it can mean there’s something deeper going on," Eshaiker says.

We have about 40,000 thoughts a day, Joshi says, and our thoughts are not facts.

"It's very much possible that we can work through these opinions, through these thoughts, with the help of a
professional or self-help techniques that you may pick up from various applications or from books."

In case you missed then: A majority of Americans say 2020 election is 'significant source of stress'

This article originally appeared on USA TODAY: Stressed about the election? You're not alone. How to stay calm.


Load-Date: November 8, 2022


  End of Document

                                                                                                   Page 1 of 3
    Global Blockchain for Healthcare Market by : Complete Analysis of Key Players, Growth Rate, Opportunities,
                                            Challenges - The Courier




     Global Blockchain for Healthcare Market by : Complete Analysis of Key
         Players, Growth Rate, Opportunities, Challenges - The Courier
                                              The Courier: Monmouth University
                                                      January 5, 2021 Tuesday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1447 words

Body


Databridgemarketresearch.com added a new study onGlobal Blockchain for Healthcare Market Research Review
2020 that has been just made available providing an extensive knowledge and perceptions of the industry. This
research report assists the consumer to figure out the actual outcomes of significant market players. It is a
thorough study of new advances and expectancy in the market. TheGlobal Blockchain for Healthcare Market report
aims to discover the technological advancements and investment opportunities in the market. It has an intellectual
glare that offers authentic details regarding developing trends, economical and industrial policies, region wise
industry formation, profitability and downside of company product. This research report aid investors and
organization to comprehend a scene of commercial progress and attributes of the market.

Furthermore, thisGlobal Blockchain for Healthcare Market report throws light on the cavity between supply and
consumption of the market. Apart from that data regarding the growth rate of the market in 2026, is also interpreted
in this report. It also consists of the information on consumption grounded on type and applications of the market.
Identification of the key companies that can influence this market on a global and regional scale are also mentioned
in thisGlobal Blockchain for Healthcare Market research report.

Blockchain for healthcare market is expected to gain market growth in the forecast period of 2020 to 2027. Data
Bridge Market Research analyses the market to account to USD 8362.01 million by 2027 growing at a CAGR of
72.0% in the above-mentioned forecast period. The growing occurrences of healthcare data breaches have been
directly impacting the growth of blockchain for healthcare market.

Get    Sample    Report    +    All   Related   Graphs     &   Charts    (with   COVID       19    Analysis)
@https://www.databridgemarketresearch.com/request-a-sample/?dbmr=global-blockchain-for-healthcare-
market&pm

Competitive Landscape and Blockchain for Healthcare Market Share Analysis

Blockchain for healthcare market competitive landscape provides details by competitor. Details included are
company overview, company financials, revenue generated, market potential, investment in research and
development, new market initiatives, global presence, production sites and facilities, production capacities,

                                                                                                  Page 2 of 3
   Global Blockchain for Healthcare Market by : Complete Analysis of Key Players, Growth Rate, Opportunities,
                                           Challenges - The Courier

company strengths and weaknesses, product launch, product width and breadth, application dominance. The above
data points provided are only related to the companies' focus related to blockchain for healthcare market.

The major players covered in the blockchain for healthcare market report are IBM Corporation, Microsoft,
Guardtime, PokitDok, Inc., Gem, Hashed Health, Chronicled, iSolve, LLC, Patientory., Factom., Medicalchain SA.,
Proof.Works, SimplyVital Health, Inc, Blockchain AI Solutions Ltd, Change Healthcare, Doc.ai, Inc, among other
domestic and global players. Market share data is available for Global, North America, Europe, Asia-Pacific , Middle
East and Africa and South America separately. DBMR analysts understand competitive strengths and provide
competitive analysis for each competitor separately.

Rising adoption of blockchain technology, increasing demand of cost-effective and secured data interoperability
with the help of blockchain, introduction of transparency and immutability of the distributed ledger technology and
growing threats of counterfeit drugs are some of the factors that will accelerate the growth of the blockchain for
healthcare market in the forecast period f 2020-2027. On the other hand, increasing initiatives of the government
and surging investment for the development of advanced solutions will further create new and ample opportunities
for the growth of growth of blockchain for healthcare market in the above mentioned forecast period.

Lack of data safety and standard set will acts as a market restraint for the blockchain for healthcare in the above
mentioned forecast period.

This blockchain for healthcare market report provides details of new recent developments, trade regulations, import
export analysis, production analysis, value chain optimization, market share, impact of domestic and localised
market players, analyses opportunities in terms of emerging revenue pockets, changes in market regulations,
strategic market growth analysis, market size, category market growths, application niches and dominance, product
approvals, product launches, geographic expansions, technological innovations in the market. To gain more info on
blockchain for healthcare market contact Data Bridge Market Research for an Analyst Brief, our team will help you
take an informed market decision to achieve market growth.

Global Blockchain for Healthcare Market Scope and Market Size

Blockchain for healthcare market is segmented on the basis of application and end user. The growth amongst these
segments will help you analyse meagre growth segments in the industries, and provide the users with valuable
market overview and market insights to help them in making strategic decisions for identification of core market
applications.

Based on application, blockchain for healthcare market is segmented into clinical data exchange and
interoperability, claims adjudication and billing management, drug supply chain management, drug discovery and
clinical trials, prescription drug abuse and others.

Blockchain for healthcare market has also been segmented based on the end user into pharmaceutical companies,
healthcare providers, healthcare payers and others.

Blockchain for Healthcare Market Country Level Analysis

Blockchain for healthcare market is analysed and market size insights and trends are provided by country, product
and end use as referenced above.

The countries covered in the blockchain for healthcare market report are U.S., Canada and Mexico in North
America, Germany, France, U.K., Netherlands, Switzerland, Belgium, Russia, Italy, Spain, Turkey, Rest of Europe
in Europe, China, Japan, India, South Korea, Singapore, Malaysia, Australia, Thailand, Indonesia, Philippines, Rest
of Asia-Pacific in the Asia-Pacific , Saudi Arabia, U.A.E, South Africa, Egypt, Israel, Rest of Middle East and Africa
as a part of Middle East and Africa , Brazil, Argentina and Rest of South America as part of South America.

                                                                                                  Page 3 of 3
   Global Blockchain for Healthcare Market by : Complete Analysis of Key Players, Growth Rate, Opportunities,
                                           Challenges - The Courier

North America dominates the blockchain for healthcare market due to the growing occurrences of healthcare data
breaches, strict regulations to improve pharmaceutical supply chain and increasing fraudulent billings will uplift the
growth of the market.

The country section of the blockchain for healthcare market report also provides individual market impacting factors
and changes in regulation in the market domestically that impacts the current and future trends of the market. Data
points such as consumption volumes, production sites and volumes, import export analysis, price trend analysis,
cost of raw materials, down-stream and upstream value chain analysis are some of the major pointers used to
forecast the market scenario for individual countries. Also, presence and availability of global brands and their
challenges faced due to large or scarce competition from local and domestic brands, impact of domestic tariffs and
trade routes are considered while providing forecast analysis of the country data.

For More Insights Get FREE Detailed TOC @https://www.databridgemarketresearch.com/toc/?dbmr=global-
blockchain-for-healthcare-market&pm

Healthcare Infrastructure growth Installed base and New Technology Penetration

Blockchain for healthcare market also provides you with detailed market analysis for every country growth in
healthcare expenditure for capital equipment's, installed base of different kind of products for blockchain for
healthcare market, impact of technology using life line curves and changes in healthcare regulatory scenarios and
their impact on the blockchain for healthcare market. The data is available for historic period 2010 to 2018.

About Data Bridge Market Research:

An absolute way to forecast what future holds is to comprehend the trend today!

Data Bridge set forth itself as an unconventional and neoteric Market research and consulting firm with unparalleled
level of resilience and integrated approaches. We are determined to unearth the best market opportunities and
foster efficient information for your business to thrive in the market. Data Bridge endeavors to provide appropriate
solutions to the complex business challenges and initiates an effortless decision-making process.

Contact:

Data Bridge Market Research

US: +1 888 387 2818

UK: +44 208 089 1725

Hong Kong: +852 8192 7475

Email @ Corporatesales@databridgemarketresearch.com


Load-Date: January 5, 2021


  End of Document

                                                                                                       Page 1 of 4
         Pharma Clinical Trial Digitization Market 2027 Overview, Scope, Growth Trends, Manufacturers- Antidote
                                        Technologies , Aparito, Clinerion - The Courier




     Pharma Clinical Trial Digitization Market 2027 Overview, Scope, Growth
     Trends, Manufacturers- Antidote Technologies, Aparito, Clinerion - The
                                      Courier
                                              The Courier: Monmouth University
                                                      January 18, 2021 Monday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1627 words

Body

DBMR has uploaded a latest report onPharma Clinical Trial Digitization Market from its research database. All the
key market aspects that influence the Pharma Clinical Trial Digitization Market currently and will have an impact on
it have been assessed and propounded in the Pharma Clinical Trial Digitization Market research status and
development trends reviewed in the new report. The report gives key insights available status of the Pharma
Clinical Trial Digitization producers and is an important wellspring of direction and course for organizations and
people keen on the business. worldwide Pharma Clinical Trial Digitization Market covering extremely significant
parameters.Similarly, this market report is useful to learn more about the target market and understand the various
factors involved in the buying decisions. .Pharma Clinical Trial Digitization Market is segmented by
Regions/Countries.

The new tactics of Pharma Clinical Trial Digitization Industry report offers a comprehensive market breakdown on
the basis of value, volume, CAGR, and growth. For business robust expansion, the report suggests new tools and
technology development will drive to boom in the near future by 2027. The Pharma Clinical Trial Digitization Market
report provides a comprehensive outline of Invention, Industry Requirement, technology and production analysis
considering major factors such as revenue, investments and business growth.

Download Free Exclusive Sample (350 Pages PDF) Report: To Know the Impact of COVID-19 on this Industry
@ https://www.databridgemarketresearch.com/request-a-sample/?dbmr=global-pharma-clinical-trial-digitization-
market

The Major Key Players in the Market:
     •      Antidote Technologies, Inc.
     •      Aparito
     •      Clinerion Ltd.
     •      CliniOps, Inc.
     •      Consilx

                                                                                                      Page 2 of 4
        Pharma Clinical Trial Digitization Market 2027 Overview, Scope, Growth Trends, Manufacturers- Antidote
                                       Technologies , Aparito, Clinerion - The Courier

    •      Deep 6 AI
    •      Koneksa Health Inc.
    •      Medidata Solutions
    •      Oracle
    •      PatientsLikeMe
    •      Trialbee
    •      TriNetX, Inc

Pharma clinical trial digitization market is expected to gain market growth in the forecast period of 2020 to 2027.
Data Bridge Market Research analyses the market to grow at a CAGR of 5.7% in the above-mentioned forecast
period. Growing demand for personalized medicine is expected to create new opportunity for the pharma clinical
trial digitization market.

The data presented in the global Pharma Clinical Trial Digitization market offers budding opportunities, which help
users to make strategic moves and prosper their business.The report highlights the impact of numerous factors that
might result in obstructing or propelling the Pharma Clinical Trial Digitization market at global as well as local level.
The global Pharma Clinical Trial Digitization market research report offers the summary of key players dominating
the market including several aspects such as their financial summary, business strategy, and most recent
developments in these firms.

Pharma Clinical Trial Digitization Market Segmentation:

By Services (Drug Dose Adjustment, Drug Impact Monitoring, Medical Prescription System, Bioprinting, Preventive
Therapy, Individualized Drug Printing)

By Application (Clinical Data Management, Trial Monitoring, Patient Recruitment and Enrollment)

Key Points Covered in the Table of Content:

Chapter 1: Introduction, market review, market risk and opportunities, market driving force, product scope of
Pharma Clinical Trial Digitization Market;

Chapter 2: Leading manufacturers (Cost Structure, Raw Material) with sales Analysis, revenue Analysis, and price
Analysis of Pharma Clinical Trial Digitization Market;

Chapter 3: Focused circumstance among the best producers, with deals, income, and Pharma Clinical Trial
Digitization market share 2027

Chapter 4: Display the regional analysis ofGlobal Pharma Clinical Trial Digitization Market with revenue and sales
of an industry, from 2020 to 2027

Chapter 5: key countries (United States, China, Europe, Japan, Korea & Taiwan), with sales, revenue and market
share in key regions;

Chapter 6: International and Regional Marketing Type Analysis, Supply Chain Analysis, Trade Type Analysis;

Chapter 7: Company Profiles Includes Company Overview, Product & Services Offerings, Financials (only for listed
companies), New Developments and Innovation)

Chapter 8: Pharma Clinical Trial Digitization Market forecast by regions, forecast by type and forecast by
application with revenue and sales, from 2020 to 2027

                                                                                                      Page 3 of 4
        Pharma Clinical Trial Digitization Market 2027 Overview, Scope, Growth Trends, Manufacturers- Antidote
                                       Technologies , Aparito, Clinerion - The Courier

Chapter 9: Research Findings and Conclusion, Appendix, methodology and data source of Pharma Clinical Trial
Digitization market buyers, merchants, dealers, sales channel.

Chapter 10: Presenting the Pharma Clinical Trial Digitization Market Factor Analysis Porters Five Forces,
Supply/Value Chain, PESTEL analysis, Market Entropy, Patent/Trademark Analysis.

Continued............

Read complete report along with TOC @ https://www.databridgemarketresearch.com/toc/?dbmr=global-pharma-
clinical-trial-digitization-market

Competitive Landscape and Pharma Clinical Trial Digitization Market Share Analysis

Pharma clinical trial digitization market competitive landscape provides details by competitor. Details included are
company overview, company financials, revenue generated, market potential, investment in research and
development, new market initiatives, global presence, production sites and facilities, production capacities,
company strengths and weaknesses, product launch, product width and breadth, application dominance. The above
data points provided are only related to the companies' focus related to pharma clinical trial digitization market.

The major players covered in the pharma clinical trial digitization market report are Antidote Technologies, Inc.,
Aparito, Clinerion Ltd., CliniOps, Inc., Consilx, Deep 6 AI, Koneksa Health Inc. Medidata Solutions, Oracle,
PatientsLikeMe, Trialbee, TriNetX, Inc., Veeva Systems among other domestic and global players. Market share
and data is available for Global, North America, Europe, Asia-Pacific , Middle East and Africa and South America
separately. DBMR analysts understand competitive strengths and provide competitive analysis for each competitor
separately.

Significant Highlights of the Report:
    •      A detailed look at the Industry
    •      Changing business trends in the global Drugs for Pharma Clinical Trial Digitization market
    •      A concurrent evaluation of multiple parameters is necessary in diagnosing the occurrence of Pharma
           Clinical Trial Digitization Market.
    •      Detailed market bifurcation analysis at different level such as type, application, end-user, regions/countries
    •      Historical and forecast size of the market in terms of revenue (USD Million)
    •      It helps in understanding the key product segments and their future
    •      Competitive landscape and player positioning analysis for the market

Global Pharma Clinical Trial Digitization Market Scope and Market Size

Pharma clinical trial digitization market is segmented of the basis of services, application and themes. The growth
amongst these segments will help you analyse meagre growth segments in the industries, and provide the users
with valuable market overview and market insights to help them in making strategic decisions for identification of
core market applications.
    •      On the basis of services, the pharma clinical trial digitization market is segmented into drug dose
           adjustment, drug impact monitoring, medical prescription system, bioprinting, preventive therapy, and
           individualized drug printing.
    •      Based on application, the market is segmented into clinical data management, trial monitoring, patient
           recruitment and enrollment.

                                                                                                      Page 4 of 4
        Pharma Clinical Trial Digitization Market 2027 Overview, Scope, Growth Trends, Manufacturers- Antidote
                                       Technologies , Aparito, Clinerion - The Courier

    •      The pharma clinical trial digitization market on the basis of theme is segmented into digital continuity
           across clinical trial it systems, patient-centric remote and virtual trial design and direct-to-patient home
           services.

Enquire   for   customization     in      Report       @: https://www.databridgemarketresearch.com/inquire-before-
buying/?dbmr=global-pharma-clinical-trial-digitization-market

Pharma Clinical Trial Digitization Market Country Level Analysis
    •      North America (United States, Canada and Mexico)
    •      Europe (Germany, UK, France, Italy, Russia and Turkey etc.)
    •      Asia-Pacific (China, Japan, Korea, India, Australia, Indonesia, Thailand, Philippines, Malaysia and
           Vietnam)
    •      South America (Brazil etc.)
    •      Middle East and Africa (Egypt and GCC Countries)

About Data Bridge Market Research Private Ltd:

Data Bridge Market Research Pvt Ltd is a multinational management consulting firm with offices in India and
Canada. As an innovative and neoteric market analysis and advisory company with unmatched durability level and
advanced approaches. We are committed to uncover the best consumer prospects and to foster useful knowledge
for your company to succeed in the market.

Data Bridge Market Research is a result of sheer wisdom and practice that was conceived and built-in Pune in the
year 2015. The company came into existence from the healthcare department with far fewer employees intending to
cover the whole market while providing the best class analysis. Later, the company widened its departments, as
well as expands their reach by opening a new office in Gurugram location in the year 2018, where a team of highly
qualified personnel joins hands for the growth of the company. "Even in the tough times of COVID-19 where the
Virus slowed down everything around the world, the dedicated Team of Data Bridge Market Research worked
round the clock to provide quality and support to our client base, which also tells about the excellence in our
sleeve."

Data Bridge Market Research has over 500 analysts working in different industries. We have catered more than
40% of the fortune 500 companies globally and have a network of more than 5000+ clientele around the globe.

Contact:

Data Bridge Market Research

US: +1 888 387 2818

UK: +44 208 089 1725

Hong Kong: +852 8192 7475

Email: Corporatesales@databridgemarketresearch.com


Load-Date: January 18, 2021


  End of Document

                                                                                                     Page 1 of 2
                                Aggies facilitate a 24-hour hacking event at Huntsman Hall




                  Aggies facilitate a 24-hour hacking event at Huntsman Hall
                                         The Utah Statesman: Utah State University
                                                  March 23, 2022 Wednesday



University Wire
Copyright 2022 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 602 words
Byline: Alexis LeBaron

Body


Spending 24 hours on a creation that could change the world is how some Aggies spent their weekend of March
18-19.

Hosted in Utah State University's Huntsman Hall, HackUSU allowed engineering, computer science students and
anyone interested in coding to enjoy learning together in teams of their friends, coworkers and classmates.

Chelsea Gunther, the HackUSU coordinator and graduate student, has spent months finding sponsors, delicious
food choices and organizing this event.

"HackUSU is an amazing celebration of students-college and high school-coming together and discovering
something new and coming out of a 24-hour event with a marketable product," Gunther said.

According to Meg Despain, a member of the outreach committee for HackUSU expressed her excitement for the
over 30 colleges and high school represented at the event.

Participants also enjoyed networking opportunities with sponsors such as the Space Dynamics Laboratory, Maiden
Voyage Software, USU Career Design Center and Lightning Kite.

Maria Tena, a Member of the Space Dynamics Outreach team and Human Resources Specialist illustrated the
company's interest in HackUSU and opportunities for internships that participants of the event could apply for.

"We are always looking for more internships and bright minds who are willing to work hard. We are at the HackUSU
event because we know that many of the participants here have bright minds and are willing to learn," Tena said.

Throughout the event, teams could go up to any of these sponsor booths and gain insight into internship
opportunities or resources.

Amy Jensen, HackUSU participant said, "I loved the swag that I got from many of the sponsorship booths, I was
able to talk to some of them and get ideas for my project and one potential internship opportunity that I am really
excited about."

                                                                                                      Page 2 of 2
                            Aggies facilitate a 24-hour hacking event at Huntsman Hall

According to Gunther, one of this year's newer additions was workshops that the students could participate in.

Covering topics such as effective interviewing skills to Intro to Kotlin, there were workshops available for all
students at any level of coding or career.

Chandler Peterson, HackUSU participant said, "I really loved the workshops, they helped me get a foot in the door
for many concepts I wanted to learn more about but did not know where I could learn about it."

Yet, the main focus of this event was the coding teams and facilitating them to produce a framework for a product
that they can continue to work on and potentially sell after the event.

According to Gunther, teams could come to this event to get ideas and advice from professionals and other
students and many of the products that have been developed at events like this in the past have gone on to much
success in their careers and even with their products.

Teams participating in the event could enter their finished products to be judged at the end of the event in one of
seven events. Including data analytics and visualization, game development, privacy and security, hardware, AI and
machine learning, health and fitness and general.

For each event, the winning team in each event received prizes ranging from desktop monitors to Fitbit watches.

Gunther encourages all students to participate in this event in the coming years and develop something bigger than
themselves.

"If you have any idea that you want to develop and create, HackUSU is a great place to do it," Gunther said.
"Participants can really alter their communities and careers from the skills that they learn at events like this."

See what products won awards this year's event on the HackUSU website.

Photo by Kate Smith


Load-Date: March 23, 2022


  End of Document

                                                                                                      Page 1 of 4
                                        Translation tech has just scratched the surface




                          Translation tech has just scratched the surface
                                                            USA TODAY
                                                   February 10, 2020 Monday
                                                           FIRST EDITION



Copyright 2020 Gannett Company, Inc. All Rights Reserved

Section: MONEY; Pg. 1B
Length: 1609 words
Byline: Personal Tech, Edward C. Baig, USA TODAY

Body


Feeling lost in translation?

In the sci-fi world crafted by Douglas Adams in "The Hitchhiker's Guide to the Galaxy," you'd just slap a bright
yellow Babel fish in your ear and simply be able to understand any mix of languages around you.

While we aren't quite there yet, language is becoming less of a barrier than in generations past.

"Understanding is going to become the new normal," says Dave Limp, Amazon's senior vice president of devices
and services. Kids "will never grow up in world where they aren't able to hear any language. It'll just happen."

To that end, today's technology is helping to interpret and translate the world around us in ways that are nearing
seamless and in real time. From apps on your phone to increasingly multilingual virtual personal assistants,
communicating as a tourist or with clients, friends and family who don't speak the same language is less of a
challenge.

Yet for all the authentique gains achieved in translation over the past several years, don't count on your phone,
smart speaker, PC or ear device for breaking down all the language barriers anytime soon - or to provide an excuse
to skip French class.

What does it mean:

The need to translate

In this always-on connected world, the need to understand one another is arguably more important than ever.

Half of the internet's content is in English, says Google AI director of product Barak Turovsky, but only 20% of the
global population have any English skills whatsoever.

                                                                                                             Page 2 of 4
                                    Translation tech has just scratched the surface

And while Microsoft's text translation technology now supports up to 70 languages and its speech translation can
decipher around 40, says Microsoft technical fellow and chief technology officer of AI Services, Xuedong Huang,
that's a mere fraction of the 7,000 languages spoken on the planet today.

Meanwhile, more than half of the 2.5 billion people on Facebook post in a language other than English. Facebook
employs artificial intelligence on the social network itself, as well as on Messenger and Instagram, resulting in more
than 6 billion translations a day.

For high-stakes political, legal, financial and health-related exchanges, however, AI-fused machine translation
methods can't possibly substitute for pricey, skilled human interpreters and translators, though some of them rely on
machines at times, too.

And this reliance translates into big business. Florian Faes, managing director of Slator, a Swiss-based provider of
news and analysis on the global language industry, estimates the business-to-business segment of translation to be
a $23-billion annual market.

"When a big pharmaceutical company needs to run a clinical trial, they need supporting documentation in 10
languages; or when a bank wants to publish equity research to Japanese institutional investors, they get it
translated by a B2B translation firm," he says.

For casual or occasional use - spending time with distant kin or a foreign exchange student, say - the state of the
art for near-real-time translation is good and getting better, even if results are often frustrating. But would you trust it
to translate for a United Nations delegate? Maybe not yet.

"How often do you find yourself reprimanding Alexa or Google or Siri for not understanding you," says Julie Hansen,
U.S. CEO for the Babbel language learning app. "But it's good enough that we keep talking to them. The progress
is pretty stunning."

Hey Google, Hey Alexa...

Your smartphone has morphed into the high-tech equivalent of the phrasebook you take on vacation. Traveling
abroad these days, you may summon Google Translate or Microsoft Translator, among other apps, and use
features that let you decipher road signs and menus by snapping a picture.

At home, you can ask your Amazon Echo or Google Home smart speakers how to say or pronounce something in
another language; Alexa and the Google Assistant pipe in with a response, and if your devices have screens, you
can read the words and characters as well.

"People are finding a lot of creative uses in essentially what we think of as two-way, real-time conversation," says
Prem Natarajan, vice president of Alexa AI, who highlights a potential use case as an example: One spouse who is
primarily a Chinese speaker and the other who mainly speaks English. "Neither person has equal fluency in the
other person's language."

Google's Interpreter Mode can handle real-time translation on your phone across 44 languages. You can start by
saying something along the lines of "Hey Google, help me speak Thai." In some instances, the Assistant will
suggest Smart Replies, to let you quickly respond without speaking.

The Google Translate app has more than 1 billion active monthly users, 95% from outside the U.S.; more than 140
billion words are translated daily.

The company plans to launch a live-transcription feature in the next few months that promises to effectively turn
your Android phone into a real-time translator device for long-form speech.

For its part, Microsoft translation capabilities turn up across the product spectrum: PowerPoint, Edge, Outlook,
Word, Skype, and on PCs, iOS and Android devices, even Kindle e-readers.

                                                                                                        Page 3 of 4
                                   Translation tech has just scratched the surface

Two years ago, Microsoft researchers said they created the first machine translation system able to translate
sentences of news articles from Chinese to English with the same quality and accuracy as a person.

Where translation goes wrong

Still, language faux pas are anything but foreign, and they span the          downright embarrassing to potentially
dangerous.

Due to a technical error, Chinese leader Xi Jinping's name recently turned up as a curse wordwhen Facebook posts
were translated from Burmese to English. The Chinese president's name apparently was missing from a database
in Facebook's Burmese language model, so the system tried to replace words with similar syllables. It went terribly
wrong.

"We have taken steps to ensure it doesn't happen again. We sincerely apologize for the offense this has caused," a
Facebook spokesperson said.

Last year, researchers at the University of California-San Francisco found that the machine learning algorithm that
Google rolled out in 2017 was 92% accurate in translating doctor's orders from English to Spanish and 81%
accurate from English to Chinese. Only 2% of the errors in Spanish and 8% in Chinese were deemed to have the
potential to cause "clinically significant harm."

"Great if I'm in the 92%, not so great if I'm in the 8% as a patient who is being communicated something exactly the
opposite of what the doctor (wanted to tell me)," says Jost Zetzsche, a spokesperson at the American Translators
Association and co-author of "Found In Translation: How Language Shapes Our Lives and Transforms the World."

Translation works best in controlled environments, or where there's a lot of data training the models. There's a lot
more data between English and Spanish, for example, than Finnish to Burmese. In training the systems, an
intermediary language may be used, rather than a direct pairing from one less common language to another.

Much like search, through the years machines scraped data from translations of the Bible, U.N. data, multinational
newspapers and other publicly available sources, Turovsky says.

A big breakthrough came in 2016 with the use of deep "neural network" technology that allowed machines to
understand the context of an entire sentence, improving fluency. Earlier systems were limited because they had to
break sentences into chunks, disconnecting intent from the actual words.

Many factors can throw things off, especially when a person is speaking. Think different accents, vocal speeds and
audible disruptions such as "um"s and "uh"s. In addition, idioms and colloquialisms just may not translate.

"Translation is typically a literal interpretation of what's there as opposed to the meaning and the context," says Rob
Thomas, general manager of IBM Data and Watson AI.

The literal English translation for the Spanish phrase "no hay mal porque bien no vengas," says Andrew Ochoa,
CEO and founder of tech startup Waverly Labs in Brooklyn, is "there's no bad that for good doesn't come." What
you're really trying to say: "Every cloud has a silver lining."

"These translation models are designed to pick up on that, but it doesn't always work perfectly," Ochoa says.

The future of language tech

Still, those sci-fi Babel fish translators may yet find their way to our real-world ears sooner than we think - or
something like it.

In April, Waverly Labs plans to ship an over-the-ear $199 interpreter device called Ambassador, which supports 20
languages and 42 dialects.

                                                                                                     Page 4 of 4
                                  Translation tech has just scratched the surface

It follows an earlier Waverly language translation product called Pilot Smart Earbuds and Google's Pixel Buds,
which works in conjunction with the latest Google Translate app on an Android phone with the Google Assistant.

Ambassador uses a set of microphones to capture speech and actively listen for someone speaking in a selected
language within a range of about 8 feet. In this "listen mode," you'll hear an audible translation and can read the
words in a companion app.

In "converse mode," as many as four people wearing Ambassadors in their ears can engage in what the company
claims will be a fluid conversation.

And there's "lecture mode" in which Ambassador will broadcast the words of a speaker wearing the device to
multiple people in a hall by streaming audio translations to the lecturer's smartphone, which then can be played
over a loudspeaker.

Could these advances spell the beginning of the end for human translators? It's possible, American Translators
Association's Zetzsche tells fellow translators - but far in the future.

"But at that point, everyone has been replaced," he says, including doctors and lawyers.


Load-Date: February 10, 2020


  End of Document

                                                                                                      Page 1 of 2
                                    DEC seeking public comment on Unit Management Plan




                   DEC seeking public comment on Unit Management Plan
                                             Advance-News (Ogdensburg, New York)
                                                      February 27, 2022
                                                         Both Edition



Copyright 2022 Johnson Newspaper Corporation
Distributed by Newsbank, Inc. All Rights Reserved

Section: ADV_NEWS; Pg. A2
Length: 479 words
Dateline: WATERTOWN

Body


New York State Department of Environmental Conservation (DEC) Commissioner Basil Seggos has announced
that DEC is seeking public comment on an amendment to the Campground and Day-Use Area Generic Unit
Management Plan (UMP) that would support DEC's ongoing efforts to prevent the spread of harmful aquatic
invasive species (AIS). The proposed amendment would help advance the construction and permanent placement
of storage facilities for decontamination equipment used to remove AIS from watercraft at DEC sites.

AIS are non-native aquatic plants and animals that can cause environmental and economic harm and threaten
human health. AIS have been found in many of New York State's lakes, ponds, and rivers, and these harmful
species can be transported from waterbody to waterbody on watercraft and equipment.

Research shows that recreational watercraft are the greatest vector for transport and introduction of AIS throughout
the U.S. DEC manages 52 campgrounds in the Adirondack and Catskill forest preserves with more than one million
overnight visitors each season. The campgrounds and five special day-use areas at Lake George Beach, Prospect
Mountain Highway, Hinckley Reservoir Picnic Area, Fourth Lake Picnic Area, and Lake George Battlefield Picnic
Area also receive nearly 400,000 day-use visitors annually. Many of these visitors bring recreational watercraft to
the campgrounds, arriving at DEC facilities from across the state, U.S., and Canada.

Watercraft inspection stewards provide education and outreach to many boaters at DEC campgrounds. The
stewards offer voluntary inspections and boat washes using special decontamination units that have high pressure
and hot water to dislodge and remove AIS from the watercraft and trailers. Currently, decontamination units are
housed in sheds that are placed seasonally. Moving the temporary sheds at the end of each season is challenging
and can damage the equipment. The proposed amendment would advance DEC efforts to construct storage
facilities at campgrounds and day-use areas in the Adirondack and Catskill parks to store decontamination
equipment.

The draft amendment is posted on the DEC website. Copies of the draft amendment are available by calling (518)
457-2500. Public comments on the draft amendment are being accepted through April 2, and can be submitted by

                                                                                                      Page 2 of 2
                             DEC seeking public comment on Unit Management Plan

mail or email to: Josh Houghton, NYS DEC Bureau of Recreation, 625 Broadway, Albany, NY 12233-5253, Email:
campinfo@dec.ny.gov

DEC reminds water recreationists to do their part in protecting New York's waters from AIS by remembering to
clean, drain, and dry watercraft and equipment. Taking proactive steps such as cleaning off fishing tackle, removing
aquatic vegetation from rudders, disinfecting boat hulls and water compartments, and properly disposing of bait,
significantly reduces that risk. For more information, go to DEC's website.


Load-Date: February 27, 2022


  End of Document

                                                                                                   Page 1 of 3
                                           Liberty + Leadership News: December 1




                                Liberty + Leadership News: December 1
                                                The Fund For American Studies
                                                    December 1, 2023 Friday



Copyright 2023 Content Engine, LLC.
All Rights Reserved
Copyright 2023 American Studies, USA All Rights Reserved

Length: 1042 words
Byline: Marissa Starkel

Body


We hope you enjoy these news stories about TFAS activities, alumni and events this week. , and visit us on social
media for additional up-to-the-moment TFAS news!


30th Annual TFAS Journalism Awards Dinner

On November 14, The Fund for American Studies (TFAS) hosted the 30th Annual TFAS Journalism Awards Dinner
at the Metropolitan Club in New York. During the evening, TFAS presented our 2023 Robert Novak Journalism
Fellowship Awards and Joseph Rago Memorial Fellowship for Excellence in Journalism to the next
generation of top writers. The evening also honored Brian C. Anderson, editor of City Journal, was presented with
the Thomas L. Phillips Career Achievement Award and Benjamin Hall, a correspondent for FOX News Channel
(FNC), was presented with the Kenneth Y. Tomlinson Award for Courageous Journalism for their remarkable
careers.


30th Annual TFAS Journalism Awards Dinner News

The Manhattan Institute featured Brian C. Anderson for receiving the 2023 Thomas L. Phillips Career
Achievement Award.

Benjamin Hall was featured in Adweek upon receiving the Kenneth Y. Tomlinson Award for Courageous
Journalism.

Benjamin Hall spoke on the importance of journalism in his award acceptance remarks. FOX News featured his
award.

Benjamin Hall's remarks were highlighted in The Wall Street Journal's Notable & Quotable.

Link to Image

                                                                                                        Page 2 of 3
                                      Liberty + Leadership News: December 1

In Memory of William C. Dennis

It is with great sadness that The Fund for American Studies (TFAS) shares the passing of beloved TFAS professor,
supporter and friend, William (Bill) C. Dennis. He passed away surrounded by his loved ones on November 10,
2023 at the age of 81. TFAS was fortunate to have Bill as a faculty member for the spring and fall semesters in
2004.

TFAS president Roger Ream shares his cherished memories of Bill during his time at TFAS.
"Bill Dennis was one of the more intellectually curious people I have known in my life," Ream said. "He was
passionate about history, politics and philosophy, and always welcomed conversation with students and others who
shared his desire to explore the world and human relations. Bill also loved nature. He was a mountain climber, hiker
and bird watcher. All of us at TFAS are grateful for the opportunities we had to work with him, explore ideas with
him and be inspired by him."


Benjamin Hall on Courage Under Fire: Reporting from the War Zones

Join Roger Ream '76 in this week's Liberty + Leadership Podcast as he speaks with FOX
News correspondent, Benjamin Hall. Roger and Benjamin discuss his recent book, "Saved: A War Reporter's
Mission to Make It Home."
The book details the story of his survival, his dramatic rescue along with his arduous and ongoing recovery from a
horrific missile attack that critically wounded him and killed several of his colleagues while they were reporting from
the war in Ukraine. Benjamin recounts the intensity of that day, his long road to recovery and both the physical and
emotional challenges he will face for the rest of his life. Additionally, they discuss Benjamin's experiences reporting
from areas of conflict including Syria, Iraq, and Afghanistan, as well as an especially intense interaction with
Ugandan special forces in Mogadishu.


Post of the Week
Last month, TFAS supporters, alumni, and friends gathered for an inspirational evening at the Metropolitan Club in
New York City during the 30th Annual TFAS Journalism Awards Dinner, where we honored leaders who are paving
the way in journalism.

During the dinner, Benjamin Hall of FOX News was awarded the TFAS's Kenneth Y. Tomlinson Award for
Courageous Journalism, which he announced on Twitter.
Congratulations, Ben!


TFAS Faculty, Alumni, Supporters in the News

TFAS Vice President of Academic Affairs Dr. Anne Bradley reviewed "You Will Own Nothing: Your War with a New
Financial World Order and How to Fight Back" by Carol Roth for the Acton Institute.

Justin Shubow, Novak '15, was interviewed by Rachel Lu, Novak '15, on the Liberty Law Talk podcast, where he
spoke about the architecture of the Republic.

Drew Lingle, PPF 21, started a new role as a professional staff member for the House Committee on Energy and
Commerce.

Connor Merk '22 was named an Inaugural 2025 Tocqueville Scholar at the Pepperdine School of Public Policy.

Joe Lai '01, PPF '07, writes about the business leaders guide to D.C. for 2024 for the DC Journal.

Rym Momtaz '05, '07 was interviewed on the Center for Strategic and International Studies's "The Eurofile"
podcast about Emmanuel Macron and French foreign policy.

                                                                                                   Page 3 of 3
                                     Liberty + Leadership News: December 1

Tim Alberta, Novak '18, appeared on CBS Sunday Morning, where he talked about his new book, "The Kingdom,
the Power, and the Glory: American Evangelicals in an Age of Extremism."

Joseph Lawler, Novak '13, wrote an article for the Washington Examiner about the reasons people are unhappy
about the economy.

Daniel Cochrane, PPF '22, started a new role as a senior research associate at The Heritage Foundation.

Abby Guidera, PPF '19, started a new position as a development and special projects manager at the Economic
Innovation Group.

Kat Timpf, Novak '12, was interviewed on The Hill about the cancel culture and the 'healing mechanism' of
comedy during crisis and war.

Naomi Schaefer Riley, Novak '01, wrote a piece for Deseret News about a conversation with civics educator Jack
Miller about the situation on college campuses as a result of the Israel-Hamas war.

Bill Wirtz '17 launched a new podcast, "Fun Police," with his colleagues at the Consumer Choice Center.

Isaac Schorr, Novak '23, opines for the New York Post the Koch network's endorsement of Nikki Haley.

Rohini Kosoglu '05 was interviewed for Politico about her outlook on AI in health care.

Elliot Kaufman, Rago '18, reviewed "Target Tehran" by Yonah Jeremy Bob and Ilan Evyatar for Commentary
Magazine.

Joseph Simonson, Novak '22, wrote a piece for The Washington Free Beacon about anti-Israel protesters
participating in the protest at Yale University.

TFAS Senior Scholar Dr. Donald Devine wrote an op-ed for The American Spectator about a recent debate in
which he argued that Ronald Reagan was a philosophical fusionist conservative.

TFAS Senior Scholar Dr. Donald J. Boudreaux wrote a two-part (Part I, Part II) article on industrial emissions
regulation for the American Institute for Economic Research (AIER).




Load-Date: December 2, 2023


  End of Document

                                                                                               Page 1 of 2
    DEC announces finalization of campground and day-use area unit management plan to help combat aquatic
                                              invasive species




          DEC announces finalization of campground and day-use area unit
            management plan to help combat aquatic invasive species
                                                    Register-Star (Hudson, New York)
                                                    September 14, 2022 Wednesday
                                                              Print Edition



Copyright 2022 Johnson Newspaper Corporation
Distributed by Newsbank, Inc. All Rights Reserved

Section: H_NEWS BRIEFS; Pg. A11
Length: 544 words
Dateline: ALBANY

Body


New York State Department of Environmental Conservation (DEC) Commissioner Basil Seggos announced the
finalization of a Unit Management Plan amendment to guide siting, construction, and management of watercraft
decontamination facilities at DEC campgrounds and day-use areas. The construction and permanent placement of
watercraft decontamination facilities supports DEC's ongoing efforts to prevent the spread of harmful aquatic
invasive species (AIS).

"New York State is taking action on numerous fronts to help prevent the spread of harmful aquatic invasive plants
and animal species, including at DEC facilities," Commissioner Seggos said. "The finalized UMP amendment helps
authorize the construction of decontamination facilities at DEC campgrounds and day-use areas to further our
efforts to reduce invasives and their negative impacts on our waters."

AIS are non-native aquatic plants and animals that can cause environmental and economic harm and threaten
human health. AIS have been found in many of New York State's lakes, ponds, and rivers, and these harmful pests
can be transported from waterbody to waterbody on watercraft and equipment.

DEC manages 52 campgrounds in the Adirondack and Catskill parks with more than one million visitor camper
nights each season. The campgrounds and five special use areas at Lake George Beach, Prospect Mountain
Highway, Hinckley Reservoir Picnic Area, Fourth Lake Picnic Area, and Lake George Battlefield Picnic Area are
visited by nearly 400,000 people annually. Many of these visitors bring recreational watercraft with them to the
campgrounds, arriving at these DEC facilities from every county in New York, as well as many states and Canadian
provinces.

Research shows that recreational watercraft are a top vector for the transport and introduction of AIS throughout
the country. Watercraft inspection stewards provide education and outreach to many boaters at DEC campgrounds.
The stewards offer voluntary inspections and boat washes using special decontamination units that have high
pressure and hot water to dislodge and remove AIS from the watercraft and trailers. Currently, decontamination

                                                                                              Page 2 of 2
   DEC announces finalization of campground and day-use area unit management plan to help combat aquatic
                                             invasive species

units are housed in seasonal sheds. Moving the temporary sheds at the end of each season is challenging and can
damage equipment. Following a comment period announced earlier this year, DEC finalized the amendment and
will advance efforts to construct storage facilities at campgrounds and day-use areas in the Adirondack and Catskill
parks to store decontamination equipment.

The amendment is posted on the DEC website at https://www.dec.ny.gov/outdoor/camping.html. Copies of the
amendment are available by calling 518-457-2500 or contacting Josh Houghton, NYS DEC Bureau of Recreation,
625 Broadway, Albany, NY 12233-5253, or emailing campinfo@dec.ny.gov

DEC reminds water recreationists to do their part in protecting New York's waters from AIS by remembering to
clean, drain, and dry watercraft and equipment. Taking proactive steps such as cleaning off fishing tackle, removing
aquatic vegetation from rudders, disinfecting boat hulls and water compartments, and properly disposing of bait,
significantly   reduces      that    risk.  For     more      information,   go     to     DEC's       website    at
https://www.dec.ny.gov/animals/48221.html.


Load-Date: September 14, 2022


  End of Document

                                                                                               Page 1 of 2
    DEC announces finalization of campground and day-use area unit management plan to help combat aquatic
                                              invasive species




          DEC announces finalization of campground and day-use area unit
            management plan to help combat aquatic invasive species
                                                    The Daily Mail (Catskill, New York)
                                                    September 14, 2022 Wednesday
                                                               Print Edition



Copyright 2022 Johnson Newspaper Corporation
Distributed by Newsbank, Inc. All Rights Reserved

Section: H_NEWS BRIEFS; Pg. A11
Length: 544 words
Dateline: ALBANY

Body


New York State Department of Environmental Conservation (DEC) Commissioner Basil Seggos announced the
finalization of a Unit Management Plan amendment to guide siting, construction, and management of watercraft
decontamination facilities at DEC campgrounds and day-use areas. The construction and permanent placement of
watercraft decontamination facilities supports DEC's ongoing efforts to prevent the spread of harmful aquatic
invasive species (AIS).

"New York State is taking action on numerous fronts to help prevent the spread of harmful aquatic invasive plants
and animal species, including at DEC facilities," Commissioner Seggos said. "The finalized UMP amendment helps
authorize the construction of decontamination facilities at DEC campgrounds and day-use areas to further our
efforts to reduce invasives and their negative impacts on our waters."

AIS are non-native aquatic plants and animals that can cause environmental and economic harm and threaten
human health. AIS have been found in many of New York State's lakes, ponds, and rivers, and these harmful pests
can be transported from waterbody to waterbody on watercraft and equipment.

DEC manages 52 campgrounds in the Adirondack and Catskill parks with more than one million visitor camper
nights each season. The campgrounds and five special use areas at Lake George Beach, Prospect Mountain
Highway, Hinckley Reservoir Picnic Area, Fourth Lake Picnic Area, and Lake George Battlefield Picnic Area are
visited by nearly 400,000 people annually. Many of these visitors bring recreational watercraft with them to the
campgrounds, arriving at these DEC facilities from every county in New York, as well as many states and Canadian
provinces.

Research shows that recreational watercraft are a top vector for the transport and introduction of AIS throughout
the country. Watercraft inspection stewards provide education and outreach to many boaters at DEC campgrounds.
The stewards offer voluntary inspections and boat washes using special decontamination units that have high
pressure and hot water to dislodge and remove AIS from the watercraft and trailers. Currently, decontamination

                                                                                              Page 2 of 2
   DEC announces finalization of campground and day-use area unit management plan to help combat aquatic
                                             invasive species

units are housed in seasonal sheds. Moving the temporary sheds at the end of each season is challenging and can
damage equipment. Following a comment period announced earlier this year, DEC finalized the amendment and
will advance efforts to construct storage facilities at campgrounds and day-use areas in the Adirondack and Catskill
parks to store decontamination equipment.

The amendment is posted on the DEC website at https://www.dec.ny.gov/outdoor/camping.html. Copies of the
amendment are available by calling 518-457-2500 or contacting Josh Houghton, NYS DEC Bureau of Recreation,
625 Broadway, Albany, NY 12233-5253, or emailing campinfo@dec.ny.gov

DEC reminds water recreationists to do their part in protecting New York's waters from AIS by remembering to
clean, drain, and dry watercraft and equipment. Taking proactive steps such as cleaning off fishing tackle, removing
aquatic vegetation from rudders, disinfecting boat hulls and water compartments, and properly disposing of bait,
significantly   reduces      that    risk.  For     more      information,   go     to     DEC's       website    at
https://www.dec.ny.gov/animals/48221.html.


Load-Date: September 14, 2022


  End of Document

                                                                                                       Page 1 of 3
                                               Artists, researchers pair up for exhibit




                                   Artists, researchers pair up for exhibit
                                                   East Valley Tribune (Mesa, Arizona)
                                                       August 26, 2023 Saturday



Copyright 2023 East Valley Tribune (Mesa, Ariz.)

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 869 words
Byline: Alex Gallagher, East Valley Tribune (Mesa, Ariz.)

Body


Aug. 26—For the second year in a row, Phoenix Bioscience Core launched its Artists + Researchers Exhibition at
the Bentley Gallery in Phoenix.

Ten artists from around the state paired with 10 researchers from the state universities and companies like TGen to
create pieces reflecting each researcher's work.

"As the director of art and medicine for the University of Arizona College of Medicine—Phoenix, I'm always looking
for different things to add to our curriculum for medical students," said Phoenix Bioscience Core Arts Committee
Chair Dr. Cynthia Standley.

So when Standley learned that the Keck School of Medicine at the University of Southern California had partnered
artists with researchers to make artwork based on their projects, she knew she had found a way to bridge the gap
— and artists agreed.

"I think that there is a difference between the disciplines when it comes to academics and art and academics and
science, technology, engineering and math, but historically, science and art have always been very close and we've
worked really closely with scientists," said Mesa artist Zach Valent.

"Leonardo da Vinci and Michelangelo are some pretty prominent artists who have worked with architects and
engineers," added Valent, who created a concrete piece for the exhibit.

The art mirrors more modern scientific studies like the impact of AI from a behavioral health economics standpoint
and the impact that the foster care system has on child development.

"We all realize that the arts are a language for everyone and what better way to try to explain a lot of the research
that tends to be hidden away in labs and in clinics where people just don't have access to it or they don't even know
what's going on," Standley said.

Standley began searching for the second cohort of researchers and artists nearly a year ago.

                                                                                                            Page 2 of 3
                                         Artists, researchers pair up for exhibit

The selected artists were given information about researchers and the cohort met at an event that was like speed
dating, with artists and researchers giving elevator pitches about the work.

Among the artists is Ahwatukee muralist Suzanne Whitaker, who was introduced to Scottsdale resident Amy
Armstrong-Heimsoth, the Department Chair + Associate Clinical professor of occupational therapy at Northern
Arizona University.

Armstrong-Heimsoth has spent the last six years studying the American foster care system.

"This piqued my interest because, as Amy says, nobody really thinks about these children in that demographic and
I knew nothing about them," Whitaker said.

"The subject itself was just heart-wrenching to me, especially because of my work with teens as a facilitator for
grief, because I am an activist and a mother of two young adults finding their way. I just felt like (this research) really
tapped into all of that for me.

So, Whitaker partnered with Armstrong-Heimsoth and the Phoenix nonprofit OCJ Kids, which works with foster and
at-risk children, via Zoom, and learned about the kids' struggles.

Whitaker began thinking of typical memories of playing board games with family, something many foster kids likely
have not experienced, and decided to model her art piece after a gaming board, similar to games like Mouse Trap
and Life, to help educate people about children in the foster care system.

"I'm hoping (this art piece) increases awareness that there is this population of youth that are out there, that despite
all the programming and all the billions of dollars that are spent on helping with transition programming and
extended foster care and things like that, their outcomes are terrible," said Armstrong-Heimsoth.

Valent was paired with Dr. Derek Cridebring, the director of the Molecular Medicine Division at the Translational
Genomics Research Institute (TGen) in Phoenix.

Valent created a glass and cement medical illustration of cellular interactions and extracellular space that might be
seen through a microscope.

"His work relates to some research that I've always been interested in about how we can utilize communication
between cells to better make the body communicate that it has cancer inside of it," Valent said.

"So, I chose to convey his research and the space that he exists in by adding paper documents that were used
inside of his research into the piece while constructing a piece that one might think is like a medical illustration or
something that you would see through a microscope when thinking about genetics research and cellular research."

Standley hopes that throughout this process, the artists will be able to grow through their respective mediums.

"It's really important for us to see that the artist is going to grow in their medium and that they're trying something
they've never tried before," Standley said.

"We want them to grow and try things that they haven't even tried. And I'm really excited about the second cohort."

The exhibition will be on display at the Bentley Gallery, 250 E. McKinley St., Phoenix, Aug. 19-26 and will reappear
at the Phoenix Bioscience Core building Sept. 14.

Information : bentleygallery.com/exhibition and/phoenixbiosciencecore.com/pbc-and-the-arts.

___ (c)2023 East Valley Tribune (Mesa, Ariz.) Visit East Valley Tribune (Mesa, Ariz.) at www.eastvalleytribune.com
Distributed by Tribune Content Agency, LLC.


Load-Date: August 28, 2023

                                                             Page 3 of 3
                  Artists, researchers pair up for exhibit



End of Document

                                                                                                     Page 1 of 3
    Artificial Intelligence In Healthcare Diagnosis Market 2021 Growth Opportunities and Future Scope Till 2027:
                                   Aidoc, Arterys Inc., Icometrix, IDx Technologies In....




    Artificial Intelligence In Healthcare Diagnosis Market 2021 Growth
Opportunities and Future Scope Till 2027: Aidoc, Arterys Inc., Icometrix, IDx
                        Technologies Inc - The Courier
                                              The Courier: Monmouth University
                                                      January 25, 2021 Monday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 804 words

Body

Worldwide Artificial Intelligence In Healthcare Diagnosis Market Analysis to 2027 is a specialized and in-depth study
of the Artificial Intelligence In Healthcare Diagnosis Industry with a focus on the global market trend. The report
aims to provide an overview of global Artificial Intelligence In Healthcare Diagnosis Market with detailed market
segmentation by product/application and geography.

Artificial Intelligence In Healthcare Diagnosis provides the ability for remote medical diagnosis and remote medical
care in the home, which is particularly important for the growing ageing society, which may require assisted living.
Satellite connectivity can also assist in the gathering of data to predict and track disease progression and
associated risks of outbreaks.

Request for Sample PDF Copy @

https://www.theinsightpartners.com/sample/TIPRE00011852/

Key companies Included in Artificial Intelligence In Healthcare Diagnosis Market:-

General Electric Company, Aidoc, Arterys Inc., Icometrix, IDx Technologies Inc, MaxQ AI Ltd., Caption Health, Inc.,
Zebra Medical VisionInc.,Siemens Healthineers AG, Koninklijke Philips N.V

What's included
     •    Market Dynamics
     •    Competitive Analysis
     •    Market Trends And Market Outlook
     •    Market Share And Market Size
     •    Opportunities And Customer Analysis
     •    Product Pricing Research

                                                                                                    Page 2 of 3
   Artificial Intelligence In Healthcare Diagnosis Market 2021 Growth Opportunities and Future Scope Till 2027:
                                  Aidoc, Arterys Inc., Icometrix, IDx Technologies In....

The research report has been compiled by studying the market in-depth along with drivers, opportunities, restraints
& other strategies as well as new developments that can help a reader to understand the exact situation of the
market along with the factors that can limit or hamper the market growth and the report also has been updated with
Impacts & effects of Coronavirus pandemic and how it has influenced consumer behaviour & the growth of the
market as well as industries.

Global Artificial Intelligence In Healthcare Diagnosis market Witness Most Promising Rise in Demand:

The Artificial Intelligence In Healthcare Diagnosis market is anticipated to grow with a significant rate in the coming
years, owing to factors such as rising incidence and prevalence of chronic diseases, increasing healthcare
expenses toward the growth of eHealth, telemedicine, telehealth. Rapid growth in delivery of services to patients,
several technological enlargements in the healthcare industry in the Asia Pacific and Europe are expected to offer
growth opportunities for the players operating in the market.

The global Artificial Intelligence In Healthcare Diagnosis market is segmented on the basis of component,
application, end-user and geography. The component segment includes system and software, services and medical
device. Based on application, the Artificial Intelligence In Healthcare Diagnosis market is segmented as, eHealth
and others. Based on end-user, the market is segmented as, hospitals and clinics, clinical research organization,
research and diagnostic laboratories and others.

 The COVID-19 outbreak is currently going the world over; the Artificial Intelligence In Healthcare Diagnosis Market
report covers the impact of the corona-virus on top company's growth. This research report categorizes as the key
players in the Artificial Intelligence In Healthcare Diagnosis market and also gives a comprehensive study of Covid-
19 impact analysis of the market by regions like (Americas, Europe APAC, and EMEA).

By Diagnostic Tool
    •   Medical Imaging Tool
    •   Automated Detection System
    •   Others

By Application
    •   Eye Care
    •   Oncology
    •   Radiology
    •   Cardiovascular
    •   Others

By Service
    •   Tele-Consultation
    •   Tele Monitoring
    •   Others

By End-User
    •   Hospitals and Clinics
    •   Diagnostic Laboratory
    •   Home Care DoctorsPatients

                                                                                                    Page 3 of 3
   Artificial Intelligence In Healthcare Diagnosis Market 2021 Growth Opportunities and Future Scope Till 2027:
                                  Aidoc, Arterys Inc., Icometrix, IDx Technologies In....

The report offers key drivers that propel the growth in the global Artificial Intelligence In Healthcare Diagnosis
market. These insights help market players in devising strategies to gain market presence. The research also
outlined the restraints of the market. Insights on opportunities are mentioned to assist market players in taking
further steps by determining the potential in untapped regions.

This report focuses on the global Artificial Intelligence In Healthcare Diagnosis market with the future forecast,
growth opportunity, key market, and key players. The study objectives are to present the Artificial Intelligence In
Healthcare Diagnosis market development in North America, Europe, China, Japan, Southeast Asia, India, and
Central & South America.

Purchase Copy of This Report at:

https://www.theinsightpartners.com/sample/TIPRE00011852/

About us: -

The Insight Partners is a one-stop industry research provider of actionable intelligence. We help our clients in
getting solutions to their research requirements through our syndicated and consulting research services. We are a
specialist in Technology, Healthcare, Manufacturing, Automotive and Defence.

Contact us: -

Call: +1-646-491-9876

Email: sales@theinsightpartners.com


Load-Date: January 25, 2021


  End of Document

                                                                                               Page 1 of 2
    DEC announces finalization of campground and day-use area unit management plan to help combat aquatic
                                              invasive species




          DEC announces finalization of campground and day-use area unit
            management plan to help combat aquatic invasive species
                                          Lewiston-Porter Sentinel (Lewiston, New York)
                                                       September 2, 2022



Copyright 2022 Niagara Frontier Publications
Distributed by Newsbank, Inc. All Rights Reserved

Section: CURRENT NEWS
Length: 567 words

Body


Changes will allow construction of facilities to store decontamination equipment, help remove harmful invasives
from watercraft

New York State Department of Environmental Conservation Commissioner Basil Seggos recently announced the
finalization of a unit management plan amendment to guide siting, construction, and management of watercraft
decontamination facilities at DEC campgrounds and day-use areas. The construction and permanent placement of
watercraft decontamination facilities supports DEC's ongoing efforts to prevent the spread of harmful aquatic
invasive species (AIS).

"New York state is taking action on numerous fronts to help prevent the spread of harmful aquatic invasive plants
and animal species, including at DEC facilities," Seggos said. "The finalized UMP amendment helps authorize the
construction of decontamination facilities at DEC campgrounds and day-use areas to further our efforts to reduce
invasives and their negative impacts on our waters."

AIS are non-native aquatic plants and animals that can cause environmental and economic harm and threaten
human health. AIS have been found in many of New York's lakes, ponds and rivers, and, DEC said, "these harmful
pests can be transported from waterbody to waterbody on watercraft and equipment."

DEC manages 52 campgrounds in the Adirondack and Catskill parks, with more than 1 million visitor camper nights
each season. The campgrounds and five special use areas at Lake George Beach, Prospect Mountain Highway,
Hinckley Reservoir Picnic Area, Fourth Lake Picnic Area and Lake George Battlefield Picnic Area are visited by
nearly 400,000 people annually. Many of these visitors bring recreational watercraft with them to the campgrounds,
arriving at these DEC facilities from every county in New York, as well as many states and Canadian provinces.

DEC stated, "Research shows that recreational watercraft are a top vector for the transport and introduction of AIS
throughout the country. Watercraft inspection stewards provide education and outreach to many boaters at DEC
campgrounds. The stewards offer voluntary inspections and boat washes using special decontamination units that
have high pressure and hot water to dislodge and remove AIS from the watercraft and trailers. Currently,

                                                                                              Page 2 of 2
   DEC announces finalization of campground and day-use area unit management plan to help combat aquatic
                                             invasive species

decontamination units are housed in seasonal sheds. Moving the temporary sheds at the end of each season is
challenging and can damage equipment.

"Following a comment period announced earlier this year, DEC finalized the amendment and will advance efforts to
construct storage facilities at campgrounds and day-use areas in the Adirondack and Catskill parks to store
decontamination equipment."

The amendment is posted on the DEC website at https://www.dec.ny.gov/outdoor/camping.html. Copies of the
amendment are available by calling 518-457-2500; contacting Josh Houghton, NYS DEC Bureau of Recreation,
625 Broadway, Albany, NY 12233-5253; or emailing [email protected].

DEC "reminds water recreationists to do their part in protecting New York's waters from AIS by remembering to
clean, drain and dry watercraft and equipment. Taking proactive steps such as cleaning off fishing tackle, removing
aquatic vegetation from rudders, disinfecting boat hulls and water compartments, and properly disposing of bait,
significantly reduces that risk."

For more information, go to DEC's website at https://www.dec.ny.gov/animals/48221.html.


Load-Date: September 3, 2022


  End of Document

                                                                                               Page 1 of 2
    DEC announces finalization of campground and day-use area unit management plan to help combat aquatic
                                              invasive species




          DEC announces finalization of campground and day-use area unit
            management plan to help combat aquatic invasive species
                                               Island Dispatch (Grand Island, New York)
                                                         September 2, 2022



Copyright 2022 Niagara Frontier Publications
Distributed by Newsbank, Inc. All Rights Reserved

Section: STATE NEWS
Length: 567 words

Body


Changes will allow construction of facilities to store decontamination equipment, help remove harmful invasives
from watercraft

New York State Department of Environmental Conservation Commissioner Basil Seggos recently announced the
finalization of a unit management plan amendment to guide siting, construction, and management of watercraft
decontamination facilities at DEC campgrounds and day-use areas. The construction and permanent placement of
watercraft decontamination facilities supports DEC's ongoing efforts to prevent the spread of harmful aquatic
invasive species (AIS).

"New York state is taking action on numerous fronts to help prevent the spread of harmful aquatic invasive plants
and animal species, including at DEC facilities," Seggos said. "The finalized UMP amendment helps authorize the
construction of decontamination facilities at DEC campgrounds and day-use areas to further our efforts to reduce
invasives and their negative impacts on our waters."

AIS are non-native aquatic plants and animals that can cause environmental and economic harm and threaten
human health. AIS have been found in many of New York's lakes, ponds and rivers, and, DEC said, "these harmful
pests can be transported from waterbody to waterbody on watercraft and equipment."

DEC manages 52 campgrounds in the Adirondack and Catskill parks, with more than 1 million visitor camper nights
each season. The campgrounds and five special use areas at Lake George Beach, Prospect Mountain Highway,
Hinckley Reservoir Picnic Area, Fourth Lake Picnic Area and Lake George Battlefield Picnic Area are visited by
nearly 400,000 people annually. Many of these visitors bring recreational watercraft with them to the campgrounds,
arriving at these DEC facilities from every county in New York, as well as many states and Canadian provinces.

DEC stated, "Research shows that recreational watercraft are a top vector for the transport and introduction of AIS
throughout the country. Watercraft inspection stewards provide education and outreach to many boaters at DEC
campgrounds. The stewards offer voluntary inspections and boat washes using special decontamination units that
have high pressure and hot water to dislodge and remove AIS from the watercraft and trailers. Currently,

                                                                                              Page 2 of 2
   DEC announces finalization of campground and day-use area unit management plan to help combat aquatic
                                             invasive species

decontamination units are housed in seasonal sheds. Moving the temporary sheds at the end of each season is
challenging and can damage equipment.

"Following a comment period announced earlier this year, DEC finalized the amendment and will advance efforts to
construct storage facilities at campgrounds and day-use areas in the Adirondack and Catskill parks to store
decontamination equipment."

The amendment is posted on the DEC website at https://www.dec.ny.gov/outdoor/camping.html. Copies of the
amendment are available by calling 518-457-2500; contacting Josh Houghton, NYS DEC Bureau of Recreation,
625 Broadway, Albany, NY 12233-5253; or emailing [email protected].

DEC "reminds water recreationists to do their part in protecting New York's waters from AIS by remembering to
clean, drain and dry watercraft and equipment. Taking proactive steps such as cleaning off fishing tackle, removing
aquatic vegetation from rudders, disinfecting boat hulls and water compartments, and properly disposing of bait,
significantly reduces that risk."

For more information, go to DEC's website at https://www.dec.ny.gov/animals/48221.html.


Load-Date: September 3, 2022


  End of Document

                                                                                               Page 1 of 2
    DEC announces finalization of campground and day-use area unit management plan to help combat aquatic
                                              invasive species




          DEC announces finalization of campground and day-use area unit
            management plan to help combat aquatic invasive species
                                     Niagara-Wheatfield Tribune (Niagara Falls, New York)
                                                     September 2, 2022



Copyright 2022 Niagara Frontier Publications
Distributed by Newsbank, Inc. All Rights Reserved

Section: CURRENT NEWS
Length: 567 words

Body


Changes will allow construction of facilities to store decontamination equipment, help remove harmful invasives
from watercraft

New York State Department of Environmental Conservation Commissioner Basil Seggos recently announced the
finalization of a unit management plan amendment to guide siting, construction, and management of watercraft
decontamination facilities at DEC campgrounds and day-use areas. The construction and permanent placement of
watercraft decontamination facilities supports DEC's ongoing efforts to prevent the spread of harmful aquatic
invasive species (AIS).

"New York state is taking action on numerous fronts to help prevent the spread of harmful aquatic invasive plants
and animal species, including at DEC facilities," Seggos said. "The finalized UMP amendment helps authorize the
construction of decontamination facilities at DEC campgrounds and day-use areas to further our efforts to reduce
invasives and their negative impacts on our waters."

AIS are non-native aquatic plants and animals that can cause environmental and economic harm and threaten
human health. AIS have been found in many of New York's lakes, ponds and rivers, and, DEC said, "these harmful
pests can be transported from waterbody to waterbody on watercraft and equipment."

DEC manages 52 campgrounds in the Adirondack and Catskill parks, with more than 1 million visitor camper nights
each season. The campgrounds and five special use areas at Lake George Beach, Prospect Mountain Highway,
Hinckley Reservoir Picnic Area, Fourth Lake Picnic Area and Lake George Battlefield Picnic Area are visited by
nearly 400,000 people annually. Many of these visitors bring recreational watercraft with them to the campgrounds,
arriving at these DEC facilities from every county in New York, as well as many states and Canadian provinces.

DEC stated, "Research shows that recreational watercraft are a top vector for the transport and introduction of AIS
throughout the country. Watercraft inspection stewards provide education and outreach to many boaters at DEC
campgrounds. The stewards offer voluntary inspections and boat washes using special decontamination units that
have high pressure and hot water to dislodge and remove AIS from the watercraft and trailers. Currently,

                                                                                              Page 2 of 2
   DEC announces finalization of campground and day-use area unit management plan to help combat aquatic
                                             invasive species

decontamination units are housed in seasonal sheds. Moving the temporary sheds at the end of each season is
challenging and can damage equipment.

"Following a comment period announced earlier this year, DEC finalized the amendment and will advance efforts to
construct storage facilities at campgrounds and day-use areas in the Adirondack and Catskill parks to store
decontamination equipment."

The amendment is posted on the DEC website at https://www.dec.ny.gov/outdoor/camping.html. Copies of the
amendment are available by calling 518-457-2500; contacting Josh Houghton, NYS DEC Bureau of Recreation,
625 Broadway, Albany, NY 12233-5253; or emailing [email protected].

DEC "reminds water recreationists to do their part in protecting New York's waters from AIS by remembering to
clean, drain and dry watercraft and equipment. Taking proactive steps such as cleaning off fishing tackle, removing
aquatic vegetation from rudders, disinfecting boat hulls and water compartments, and properly disposing of bait,
significantly reduces that risk."

For more information, go to DEC's website at https://www.dec.ny.gov/animals/48221.html.


Load-Date: September 3, 2022


  End of Document

                                                                                                      Page 1 of 1
                                       Top headlines in major S. Korean newspapers




                          Top headlines in major S. Korean newspapers


                                                        ASEAN Tribune
                                                   December 16, 2023 Saturday



Copyright 2023 ASEAN Tribune All Rights Reserved




Length: 168 words

Body


 16 Dec 2023 (Yonhap News Agency) SEOUL, The following are the top headlines in major South Korean
newspapers on Dec. 16.

Korean-language dailies

-- Ruling party lawmakers debate over appointing justice minister as emergency committee chief (Kyunghyang
Shinmun)

-- Ruling party divided over appointing justice minister as emergency committee leader (Kookmin Daily)

-- Justice minister emerges as candidate for ruling party's emergency committee leader (Donga Ilbo)

-- 20s, 30s in crisis as they forgo marriage due to lower income, bigger debt (Segye Times)

-- Are you looking, King Sejong? (Chosun Ilbo)

-- Key members of ruling party concur on emergency leadership system led by justice minister (JoongAng Ilbo)

-- The Samdobong happiness bus that visits residents to protect their health (Hankyoreh)

-- Heated AI servers cool down when dipped in oil (Hankook Ilbo)

-- MBK hits back by raising price of Hankook and Company (Maeil Business Newspaper)

-- MBK hits back by raising tender offer price (Korea Economic Daily)


Load-Date: December 17, 2023


  End of Document

                                                                                                        Page 1 of 2
                                                  Valadao takes early lead over Salas




                                        Valadao takes early lead over Salas
                                                        The Bakersfield Californian
                                                     November 9, 2022 Wednesday



Copyright 2022 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: NATIONAL POLITICAL NEWS
Length: 470 words
Byline: John Cox, The Bakersfield Californian

Body


Nov. 9—Rep. David Valadao pulled ahead of his Democratic challenger, Assemblyman Rudy Salas, in early results
Tuesday night in the hard-fought race for California's 22nd Congressional District seat.

In a contest seen as one of the tightest and most important in the nationwide battle for control of the U.S. House of
Representatives, the Hanford Republican was ahead of the Bakersfield Democrat, 50.6 percent to 49.4 percent,
with 60.9 percent of districts reporting.

"We always knew this race was going to be tight," Valadao said by text message at 9:13 p.m. "I'm optimistic about
our start but we still have a long way to go."

The race was as notable for the money it attracted from across the country as it was for the negative campaign ads
that proliferated on television and the internet. It was, in that sense, a repeat from two years prior, when Valadao
narrowly defeated former Rep. T.J. Cox, the Democratic incumbent, in the race for what was then the 21st
Congressional District.

Redistricting gave the district more of a Democratic advantage, with 43.4 percent of voter registrations to 26 percent
Republican and 22.7 percent stating no party preference.

In the June primary, which featured three Republicans and a single Democrat, Salas beat the four-term
congressman by almost 20 percentage points with 45.2 percent of the vote.

One question that arose during the campaign was whether Republicans in the district who remain loyal to Donald
Trump would forgive Valadao for voting to impeach the former president after the Jan. 6, 2021, U.S. Capitol riot.

A dairyman who has focused much of his efforts in Congress to help the Central Valley's farming industry, Valadao
has pointed to his work on a 2016 bipartisan infrastructure bill that supports water infrastructure development in the
West. Other successes he noted include a law designed to bring more physicians to the valley, improvements to
Naval Air Station Lemoore and expansion of a Kern County food bank.Salas is the son of a farmworker who has

                                                                                                         Page 2 of 2
                                         Valadao takes early lead over Salas

served 10 years in the Assembly after becoming the first Hispanic to serve on the Bakersfield City Council. He has
pointed to his record of bringing taxpayer money to his district.

Salas highlighted his efforts to steer $50 million from the state to the Kern Community College District for creation of
its new California Renewable Energy Laboratory, plus $10 million for Adventist Health's AIS Cancer Center in
downtown Bakersfield, $8 million for the Farmworkers Institute of Education & Leadership Development facility in
Bakersfield, and $6 million each for nursing education at Bakersfield College and Cal State Bakersfield.

___ (c)2022 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: November 10, 2022


  End of Document

                                                                                                        Page 1 of 2
                                                  Valadao takes early lead over Salas




                                        Valadao takes early lead over Salas
                                                        The Bakersfield Californian
                                                     November 9, 2022 Wednesday



Copyright 2022 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: NATIONAL POLITICAL NEWS
Length: 485 words
Byline: John Cox, The Bakersfield Californian

Body


Nov. 9—Rep. David Valadao pulled ahead of his Democratic challenger, Assemblyman Rudy Salas, in early results
Tuesday night in the hard-fought race for California's 22nd Congressional District seat.

In a contest seen as one of the tightest and most important in the nationwide battle for control of the U.S. House of
Representatives, the Hanford Republican was ahead of the Bakersfield Democrat, 50.6 percent to 49.4 percent,
with 60.9 percent of districts reporting.

"We always knew this race was going to be tight," Valadao said by text message at 9:13 p.m. "I'm optimistic about
our start but we still have a long way to go."

The Salas campaign did not immediately respond to a request for comment shortly after 9 p.m.

The race was as notable for the money it attracted from across the country as it was for the negative campaign ads
that proliferated on television and the internet. It was, in that sense, a repeat from two years prior, when Valadao
narrowly defeated former Rep. T.J. Cox, the Democratic incumbent, in the race for what was then the 21st
Congressional District.

Redistricting gave the district more of a Democratic advantage, with 43.4 percent of voter registrations to 26 percent
Republican and 22.7 percent stating no party preference.

In the June primary, which featured three Republicans and a single Democrat, Salas beat the four-term
congressman by almost 20 percentage points with 45.2 percent of the vote.

One question that arose during the campaign was whether Republicans in the district who remain loyal to Donald
Trump would forgive Valadao for voting to impeach the former president after the Jan. 6, 2021, U.S. Capitol riot.

A dairyman who has focused much of his efforts in Congress to help the Central Valley's farming industry, Valadao
has pointed to his work on a 2016 bipartisan infrastructure bill that supports water infrastructure development in the
West. Other successes he noted include a law designed to bring more physicians to the valley, improvements to

                                                                                                         Page 2 of 2
                                         Valadao takes early lead over Salas

Naval Air Station Lemoore and expansion of a Kern County food bank.Salas is the son of a farmworker who has
served 10 years in the Assembly after becoming the first Hispanic to serve on the Bakersfield City Council. He has
pointed to his record of bringing taxpayer money to his district.

Salas highlighted his efforts to steer $50 million from the state to the Kern Community College District for creation of
its new California Renewable Energy Laboratory, plus $10 million for Adventist Health's AIS Cancer Center in
downtown Bakersfield, $8 million for the Farmworkers Institute of Education & Leadership Development facility in
Bakersfield, and $6 million each for nursing education at Bakersfield College and Cal State Bakersfield.

___ (c)2022 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: November 9, 2022


  End of Document

                                                                                                        Page 1 of 2
                                                  Valadao takes early lead over Salas




                                        Valadao takes early lead over Salas
                                                        The Bakersfield Californian
                                                     November 9, 2022 Wednesday



Copyright 2022 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: NATIONAL POLITICAL NEWS
Length: 470 words
Byline: John Cox, The Bakersfield Californian

Body


Nov. 9—Rep. David Valadao pulled ahead of his Democratic challenger, Assemblyman Rudy Salas, in early results
Tuesday night in the hard-fought race for California's 22nd Congressional District seat.

In a contest seen as one of the tightest and most important in the nationwide battle for control of the U.S. House of
Representatives, the Hanford Republican was ahead of the Bakersfield Democrat, 50.6 percent to 49.4 percent,
with 60.9 percent of districts reporting.

"We always knew this race was going to be tight," Valadao said by text message at 9:13 p.m. "I'm optimistic about
our start but we still have a long way to go."

The race was as notable for the money it attracted from across the country as it was for the negative campaign ads
that proliferated on television and the internet. It was, in that sense, a repeat from two years prior, when Valadao
narrowly defeated former Rep. T.J. Cox, the Democratic incumbent, in the race for what was then the 21st
Congressional District.

Redistricting gave the district more of a Democratic advantage, with 43.4 percent of voter registrations to 26 percent
Republican and 22.7 percent stating no party preference.

In the June primary, which featured three Republicans and a single Democrat, Salas beat the four-term
congressman by almost 20 percentage points with 45.2 percent of the vote.

One question that arose during the campaign was whether Republicans in the district who remain loyal to Donald
Trump would forgive Valadao for voting to impeach the former president after the Jan. 6, 2021, U.S. Capitol riot.

A dairyman who has focused much of his efforts in Congress to help the Central Valley's farming industry, Valadao
has pointed to his work on a 2016 bipartisan infrastructure bill that supports water infrastructure development in the
West. Other successes he noted include a law designed to bring more physicians to the valley, improvements to
Naval Air Station Lemoore and expansion of a Kern County food bank.Salas is the son of a farmworker who has

                                                                                                         Page 2 of 2
                                         Valadao takes early lead over Salas

served 10 years in the Assembly after becoming the first Hispanic to serve on the Bakersfield City Council. He has
pointed to his record of bringing taxpayer money to his district.

Salas highlighted his efforts to steer $50 million from the state to the Kern Community College District for creation of
its new California Renewable Energy Laboratory, plus $10 million for Adventist Health's AIS Cancer Center in
downtown Bakersfield, $8 million for the Farmworkers Institute of Education & Leadership Development facility in
Bakersfield, and $6 million each for nursing education at Bakersfield College and Cal State Bakersfield.

___ (c)2022 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: November 14, 2022


  End of Document

                                                                                             Page 1 of 2
    DEC announces release of draft amendment to campground and day-use area unit management plan to help
                                       combat aquatic invasive species




   DEC announces release of draft amendment to campground and day-use
     area unit management plan to help combat aquatic invasive species
                                                    Register-Star (Hudson, New York)
                                                       March 2, 2022 Wednesday
                                                              Print Edition



Copyright 2022 Johnson Newspaper Corporation
Distributed by Newsbank, Inc. All Rights Reserved

Section: H_NEWS; Pg. A8
Length: 585 words
Dateline: ALBANY

Body


New York State Department of Environmental Conservation (DEC) Commissioner Basil Seggos announced that
DEC is seeking public comment on an amendment to the Campground and Day-Use Area Generic Unit
Management Plan (UMP) that would support DEC's ongoing efforts to prevent the spread of harmful aquatic
invasive species (AIS). The proposed amendment would help advance the construction and permanent placement
of storage facilities for decontamination equipment used to remove AIS from watercraft at DEC sites.

"Recreational watercraft are a common pathway for harmful aquatic invasive plant and animal species to enter and
spread in New York waters," Commissioner Seggos said. "The proposed amendment released today would
advance the construction of decontamination facilities at DEC campgrounds and day-use areas to help reduce the
risk of infestation. New York is a water-rich state with an abundance of lakes, ponds, rivers, and marine waters, and
it's critical that we protect these waters from organisms that have the potential to wreak havoc on these valuable
ecosystems."

AIS are non-native aquatic plants and animals that can cause environmental and economic harm and threaten
human health. AIS have been found in many of New York State's lakes, ponds, and rivers, and these harmful
species can be transported from waterbody to waterbody on watercraft and equipment.

Research shows that recreational watercraft are the greatest vector for transport and introduction of AIS throughout
the U.S. DEC manages 52 campgrounds in the Adirondack and Catskill forest preserves with more than one million
overnight visitors each season. The campgrounds and five special day-use areas at Lake George Beach, Prospect
Mountain Highway, Hinckley Reservoir Picnic Area, Fourth Lake Picnic Area, and Lake George Battlefield Picnic
Area also receive nearly 400,000 day-use visitors annually. Many of these visitors bring recreational watercraft to
the campgrounds, arriving at DEC facilities from across the state, U.S., and Canada.

Watercraft inspection stewards provide education and outreach to many boaters at DEC campgrounds. The
stewards offer voluntary inspections and boat washes using special decontamination units that have high pressure

                                                                                            Page 2 of 2
   DEC announces release of draft amendment to campground and day-use area unit management plan to help
                                      combat aquatic invasive species

and hot water to dislodge and remove AIS from the watercraft and trailers. Currently, decontamination units are
housed in sheds that are placed seasonally. Moving the temporary sheds at the end of each season is challenging
and can damage the equipment. The proposed amendment would advance DEC efforts to construct storage
facilities at campgrounds and day-use areas in the Adirondack and Catskill parks to store decontamination
equipment.

The draft amendment is posted on the DEC website at https://www.dec.ny.gov/outdoor/camping.html. Copies of the
draft amendment are available by calling 518-457-2500. Public comments on the draft amendment are being
accepted through April 2, and can be submitted by mail or email to: Josh Houghton, NYS DEC Bureau of
Recreation, 625 Broadway, Albany, NY 12233-5253, Email: campinfo@dec.ny.gov

DEC reminds water recreationists to do their part in protecting New York's waters from AIS by remembering to
clean, drain, and dry watercraft and equipment. Taking proactive steps such as cleaning off fishing tackle, removing
aquatic vegetation from rudders, disinfecting boat hulls and water compartments, and properly disposing of bait,
significantly reduces that risk. For more information, go to https://www.dec.ny.gov/animals/48221.html.


Load-Date: March 2, 2022


  End of Document

                                                                                                          Page 1 of 3
                  'Chasing Butterflies' | A Penn State alumna's Manhattan journey as a daughter of 9/11




       'Chasing Butterflies' | A Penn State alumna's Manhattan journey as a
                                   daughter of 9/11
                                        Daily Collegian: Pennsylvania State University
                                                      July 8, 2021 Thursday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 762 words
Byline: Samantha Verrelli

Body


Penn State alumna Ashley Bisman suffered a direct loss as a result of the Sept. 11, 2001 attacks on the Twin
Towers in New York City. Just two weeks ago, she published her experience as an adult now living in Manhattan.

Bisman said she wrote "Chasing Butterflies: The True Story of a Daughter of 9/11" to share a "young, fresh and
energetic voice" in regard to the attacks.

"I feel like this is pretty much the first memoir from a daughter of 9/11," Bisman said. "It feels like there's nothing
from a teenager's perspective who was happy and healthy in spite of 9/11, trying to navigate finding a husband and
a life partner having lost my dad."

Bisman's father, Jeffrey Goldflam, was the CFO of Cantor Fitzgerald and worked on the 101st floor of the World
Trade Center. He died as a result of the attacks.

"He was just a great businessman [and was] very successful," Bisman said. "But above everything else, just the
best dad. I had incredible memories with him [and] always felt his love."

Ashley Bisman's father, Jeffrey Goldflam, died as a result of the attacks on 9/11.

Courtesy of Cantor Fitzgerald

Bisman was 16 years old when her dad died and later graduated from Penn State in 2007 with a degree in
journalism. She then went to Hunter College for her master's in elementary general and special education.

She started piecing together her book during her teaching career and began to finalize it when she went on
maternity leave with her first child in 2017.

Bisman described the story as a connection between the loss she experienced and her young adult life in
Manhattan.

                                                                                                               Page 2 of 3
                'Chasing Butterflies' | A Penn State alumna's Manhattan journey as a daughter of 9/11

"I was enjoying the city with all my girlfriends, and I was really enjoying life, but it was a little ironic because I had
the shadow of the Freedom Tower looming over me," Bisman said.

Bisman said she started writing in her 20s, recording stories of her dating life.

"I had a bunch of bad breakups and dating faux pas... at the time nobody was really discussing dating in New York,"
Bisman said.

She said she realized she could turn them into a book if she combined the stories of her young adult life in New
York with memories of her father.

According to Bisman, the title "Chasing Butterflies" came from two things - first, the feeling of butterflies in her
stomach when seeing someone new, and second, a memory she shares with her father.

MORE CAMPUS COVERAGE

A portion of the proceeds from her book are donated to Tuesday's Children, which Bisman said is an "incredible
charity that donates time and money to families affected by mass violence."

Bisman said the hardest part about the writing process was "being so vulnerable" because she described herself as
a "private person."

"I hope that everybody receives it with kindness," Bisman said, adding that it is difficult to "trust strangers with your
heart and take care of your memories."

One of Bisman's best friends, Jenna Goldberg, was in her classroom when she was informed about what happened
on 9/11.

"I've kinda been there every step of the way with her," Goldberg said. She described herself and Bisman as
"inseparable."

Goldberg said writing is "such a passion" for Bisman.

"I could hear her voice reading the book - she poured her heart and soul into this book, she just dug deep,"
Goldberg said. "She's really in a good place."

Goldberg said there are characters based on herself and Bisman's husband, Eric Bisman, in "Chasing Butterflies."

Eric described the book as "courageous" and a "lighthearted spin" on "really deep personal feelings."

He said the genre is similar to "chick lit," and it is a "Sex and the City-type story" but still "impactful" to the reader.

MORE CAMPUS COVERAGE

+2

Penn State students, alumnus develop Reach.AI to address health disparities within marginalized communities

Recent Penn State alumnus Kareem Jelks said he spent his childhood homeless in an "impoveris...

According to Eric, his wife has already sold close to 500 copies of "Chasing Butterflies," and the feedback has been
"resounding" so far.

"I'm really proud of her for seeing it through to the end," Eric said. "The hard part is putting a bone in it and coming
up with a deliverable [message] you can have put out there."

Ashley said she plans to continue writing and wants to write a children's book for her two young kids.

                                                                                                      Page 3 of 3
              'Chasing Butterflies' | A Penn State alumna's Manhattan journey as a daughter of 9/11

"Writing is what I was always meant to do," Bisman said. "I think my dad would be proud of [me], and my mom is
proud of [me] as well."

MORE CAMPUS COVERAGE

Penn State Fostering Lions Program guides foster care youth through postsecondary education

Penn State's Fostering Lions Program, which operates through the Child Maltreatment Solution...


Load-Date: July 8, 2021


  End of Document

                                                                                                     Page 1 of 3
     Four days, 90 speakers, no charge. St. Pete forum tackles global issues. This year's Conference on World
                            Affairs reaches out to include high school students and....




  Four days, 90 speakers, no charge. St. Pete forum tackles global issues.;
 This year's Conference on World Affairs reaches out to include high school
                  students and more conservative voices.
                                                        Tampa Bay Times
                                                  February 11, 2020 Tuesday



Copyright 2020 Times Publishing Company All Rights Reserved

Section: NEWS; Business
Length: 1052 words
Byline: Emily Wunderlich|Times Correspondent

Body


ST. PETERSBURG - Climate change. Infectious disease. Women's equality. Jazz.

Nothing will be off the table at the eighth annual St. Petersburg Conference on World Affairs next week at the
University of South Florida St. Petersburg, the Palladium Theater and Eckerd College.

With a growing emphasis on art and a larger outreach to the community, organizers say there is something for
everyone.

This year's lineup will offer more than "your classic bombs-and-rockets sort of high diplomacy," said Thomas W.
Smith, a political science professor at USFSP and co-founder of the event.

"We want the conference to look like the world looks in terms of the kind of interests and aspirations and problems
that people face in their everyday lives," Smith said.

The conference, which is free and open to the public on a first-come, first-seated basis, will be held Tuesday
through Friday. It will feature nearly 90 speakers from government, academia, business, the military, the news
media and the arts. Advance registration is encouraged.

Carol Bellamy will deliver the keynote address, "The Rights and Plights of the World's Children," at 5 p.m. Tuesday
at the Palladium Theater, 253 Fifth Ave. N.

Bellamy, a former director of the Peace Corps and former executive director of UNICEF, is chair of a Geneva-based
nonprofit that works to strengthen resilience against what it calls "violent extremist agendas" through job creation
and empowering women and youth.

Following the keynote will be a concert by a trio led by Cuban piano master Chuchito Valdes. Attendees can get a
$10 discount on $25 tickets for Tier B seats when they use the code WORLD at checkout on the Palladium's
website.

                                                                                                    Page 2 of 3
    Four days, 90 speakers, no charge. St. Pete forum tackles global issues. This year's Conference on World
                           Affairs reaches out to include high school students and....

This will be the first year the conference expands to Eckerd College. Retired Army Gen. John Nicholson, who
recently commanded NATO and U.S. forces in Afghanistan, will deliver the closing address at 7 p.m. Friday, Feb.
21, in Fox Hall on the campus at 4200 54th Ave. S.

Panels will be held Wednesday through Friday at the USF St. Petersburg University Student Center at 600 Sixth
Ave. S, while film screenings and book talks will convene at the nearby Kate Tiedemann College of Business.

Among the topics: "International Business in the Tampa Bay Region - Opportunities and Challenges"; "Let's Get
Money Out of Politics. Where to Start?"; "Artificial Intelligence (AI) and Health Care"; "Obesity As a Global Public
Health Issue"; and "Should Trump Be Reelected Based on First Term Successes?"

"We have had criticisms from time to time that certain panels were not balanced enough - usually not balanced
enough in favor of more conservative voices," said conference president Diane Seligsohn, a journalist and educator
who divides her time between St. Petersburg and Paris.

"We're aware of that, and we have made an effort to seek out more of those conservative voices."

This year's films are Unsettled: Seeking Refuge in America, by Tom Shepard; Sweet Home Monteverde, by Robin
Truesdale; and Ahead of Time: The Extraordinary Journey of Ruth Gruber, by Bob Richman.

Authors François Savatier, Bruce Eberle, Ann Sussman and Ellen Prager will also discuss their books and serve on
panels throughout the week.

To observe what St. Petersburg Mayor Rick Kriseman has dubbed "International Week," the conference will host
additional artistic and culinary events at local businesses Sunday through Friday.

Parkshore Grill, The Hangar, 400 Beach and 400 Annex will serve international menus Monday through Friday to
guests who mention their attendance at the conference.

Seligsohn said the additions are part of a larger initiative to make the conference more accessible and inclusive.

In November, St. Petersburg in the World hosted a mini-conference on artificial intelligence at the Johns Hopkins All
Children's Hospital Research and Education Building. The featured speaker, Nicholas Sabouret, also spoke to
students attending Lakewood High School and Shorecrest Preparatory School.

This year, two conference speakers - Bellamy and Pierre Guerlain, professor emeritus of American Studies at
Université Paris-Nanterre, France - will also speak to teachers at Countryside High School in Clearwater on
Monday during the school district's professional development day.

"Because the (conference) events are mostly during the day and during the week, you tend to have an older, retired
audience," Seligsohn said. "If we can't get the students to the conference, maybe we can bring at least some of the
conference to the students."

Since 2013, when the conference began as a one-day, 10-panel event that drew 200 attendees, it has sought to
contextualize international affairs across the political spectrum.

"If we don't make people at least a little bit uncomfortable, then we're not doing our job," Smith said. "What we don't
want to see is people simply coming to the conference, expecting to have their preconceptions reaffirmed."

Emily Wunderlich is editor-in-chief of The Crow's Nest, the student newspaper at USF St. Petersburg. Reach her at
(941) 224-1526.

If you go

The St. Petersburg Conference on World Affairs is free and open to the public Feb. 18-21; advance registration is
encouraged.

                                                                                                    Page 3 of 3
    Four days, 90 speakers, no charge. St. Pete forum tackles global issues. This year's Conference on World
                           Affairs reaches out to include high school students and....

For registration, schedule and list of speakers, visit stpetersburgconferenceonworldaffairs.com/.

Parking available at the nearby Mahaffey Theater, 100 Fourth Ave. S, for $10 (cash only). Guests with disabilities
can park in any handicapped space on campus with a visible handicap tag. They also can park in any non-handicap
spot for four hours with a handicap tag.

There are a number of metered parking spaces around campus and downtown, and guests can take the downtown
Looper from the Sundial, South Core and MAACH parking garages.

Keynote address: 5 p.m. Tuesday, Carol Bellamy, Palladium Theater, 253 Fifth Ave. N

Post-keynote concert: 8 p.m. Tuesday,             the   Chuchito    Valdes    Trio,   Palladium     Theater.   Tickets:
mypalladium.org/chuchito-valdes-trio-2/.

Panels and other events: 8:30 a.m. - 5 p.m. Wednesday through Friday, University Student Center and Kate
Tiedemann College of Business, USF St. Petersburg, 200 Sixth Ave. S

Closing address: 7 p.m. Friday, retired Army Gen. John Nicholson, Fox Hall at Eckerd College, 4200 54th Ave. S

Closing reception: 8:30 p.m. Friday, Horse Soldier Bourbon Distillery, 2232 Fifth Ave. S, with performances by
Elona Krasavtseva and Nina Wegmann



Graphic


See image link
At next week's St. Petersburg Conference on World Affairs, panels will be held at USF St. Petersburg's University
Student Center at 600 Sixth Ave. S, while film screenings and book talks will convene at the nearby Kate
Tiedemann College of Business.


Load-Date: April 13, 2020


  End of Document

                                                                                                       Page 1 of 3
                      Prostate cancer support group in Tehachapi has been helping men for 20 years




   Prostate cancer support group in Tehachapi has been helping men for 20
                                    years
                                                 The Bakersfield Californian
                                                   March 2, 2020 Monday



Copyright 2020 The Bakersfield Californian

Distributed by Tribune Content Agency

Section: STATE AND REGIONAL NEWS
Length: 868 words
Byline: Steven Mayer, The Bakersfield Californian

Body


March 02--    Mar. 2--The first time you attend a meeting of the Tehachapi Valley Prostate Cancer Information
Group, you might wonder how many valued members these men have had to say goodbye to.

The number is certainly high. But so is the number of those who have been helped. Just ask Jake Harper, 76.

"This group has saved lives -- mine for sure," he said Thursday.

The independent support group, which meets on the last Thursday of the month at Adventist Health Tehachapi
Valley, marked its 20th year Thursday evening. They celebrated by doing what they always do: educating one
another, supporting one another, and sharing their experiences, advice and knowledge.

"Over the past 20 years, we have helped more than 700 men become informed about prostate cancer and their
options for surviving the disease," said the group's chairman, Jim McDaniel, 86, who was first diagnosed in 2004.

McDaniel said he was lucky. He had da Vinci Robotic Surgery, and the tumor never came back. Much later, he
developed bladder cancer and beat that, too. Most recently, he was told he has stage IV lung cancer -- and still,
he's optimistic.

While it's sobering to realize this grassroots support group for men battling prostate cancer has outlasted many if
not most of its members, it's also inspiring that the group itself is still going strong 20 years after its founding,
McDaniel said.

"It's too good to let it die," he said of the group.

On Thursday evening, as members, wives and a few guests filled the executive conference room at Adventist
Health Tehachapi Valley, Jeff Lingerfelt, president of the hospital, congratulated members for completing 20 years
of service to those battling prostate cancer in Tehachapi and surrounding communities.

                                                                                                                Page 2 of 3
                     Prostate cancer support group in Tehachapi has been helping men for 20 years

"As I sit here and look out at this group, I think of hope," Lingerfelt said. "This isn't a group, it's a family."

Co-founder Rex Haggard, 69, was not yet 50 when he was diagnosed in 1999.

"I tried to find out about different kinds of help, what to do," he told the 30 or so attendees who filled the conference
room.

"There was no one around to help me at all," Haggard said. "I thought, 'This shouldn't happen to anyone else ever
again.'"

With help from longtime Tehachapi dentist Roger LeValley, the group started catching fire. The need was clearly
there. So was the passion and drive to keep it alive. LeValley died in 2007, and yet the group, part of his legacy,
survived.

One roadblock to longevity for support groups such as Tehachapi's is establishing an appropriate place to meet
each month.

That's where Ann Hildebrand stepped up. The cancer registrar at the Adventist Health AIS Cancer Center, was
able to nail down the meeting location for the group. Not only does it have a large conference table and chairs, it
has a counter and sink for coffee and tea service, and a large projection screen for information sharing.

"Ann does something for our little group every day," McDaniel said.

We humans. We are born. We grow into adulthood. We live our lives. Sometimes on autopilot.

Then a symptom shows itself. A PSA test spikes. A biopsy is recommended.

"It's life-changing," said Leonard Zasoski.

The vice president of Colombo Construction Operations was only 49 when he started recognizing -- even before
doctors did -- that something was growing inside him.

Even the first biopsy missed it.

"I told a friend, 'They just didn't find it.' I just had a feeling."

An American Cancer Society Hero of Hope speaker in 2015, and race director of Bakersfield ZERO -- The End of
Prostate Cancer, a nonprofit advocacy organization that hosts an annual run/walk fundraiser, Zasoski was guest
speaker at Thursday evening's meeting.

"Know your numbers," he advises. All men of a certain age should know their PSA numbers, the measurements
from a prostate-specific antigen lab test.

No, it's not definitive. But it can be an indicator, a reason to look deeper.

"Do your research," he said, "so you don't go to Joe's Prostate Emporium."

And talk with your doctor. Really talk. Learn. Be an active patient, not a passive participant.

When Zasoski was told he would need surgery at age 50, he asked lots of questions.

"I had been in construction for 30 years," he told the group. "I know what it's like to go in and mess with 30-year-old
plumbing."

When the laughter subsided, Zasoski said he's 8 1/2 years cancer free -- and he's not about to waste the years he's
been given.

"It can beat you here," he said, pointing to his head. "It can be devastating at times.

                                                                                                         Page 3 of 3
                    Prostate cancer support group in Tehachapi has been helping men for 20 years

"But with this group, you're not alone."

As the evening began to wind down, 73-year-old Larry Stamps leaned toward a reporter and said, "This is fortuitous
I'm even here."

Stamps lives in Reno, but he was in Tehachapi visiting his daughter.

"I have four brothers," he said. "My dad and all four brothers have had prostate cancer."

The visitor had heard about Thursday night's meeting, and decided to come.

"Figured I might learn something," he said.

He's only just begun.

Steven Mayer can be reached at 661-395-7353. Follow him on Facebook and on Twitter: @semayerTBC.

___ (c)2020 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.


Load-Date: March 3, 2020


  End of Document

                                                                                                               Page 1 of 3
                         Penn State NSO leaders contemplate 2nd summer of online orientation




     Penn State NSO leaders contemplate 2nd summer of online orientation
                                        Daily Collegian: Pennsylvania State University
                                                      July 8, 2021 Thursday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 825 words
Byline: Ayden Herold

Body


When the coronavirus led Penn State to shut down last spring, many programs - including its New Student
Orientation - were placed on hold or severely limited to avoid the risk of infecting students.

Despite NSO already asking incoming freshmen to complete many tasks online prior to the pandemic, the
program's typical visit to campus was an in-person activity moved to Zoom.

NSO leaders working for their second summer this year said they remember 2020 as a time of great change that
required adaptability.

"It was a bit new," Marieme Dia said. "COVID happened, and we were thrown into a virtual environment that hasn't
been done before."

Lauren Diperna said the transition to an online-only format forced everyone on the NSO team to move their
priorities and efforts into uncharted territory.

"Everyone was in a new situation. Even the director team... [was] under new circumstances," Diperna (senior-
human development) said. "Orientation in person is such a well-oiled machine, whereas when we went online,
everyone was trying to figure out, 'How can we make an equal experience online?'"

Star Lawson said the extra work the team put in was worth the effort.

"[Everything we learned about] in-person activities got left behind, like how we would interact with people," Lawson
(junior-public relations) said. "We have more rules for what you do online like, 'Don't share your entire screen. Don't
show [the audience] little things that they shouldn't see... like extra tabs or our script.' It was very stressful, but I feel
as though we succeeded."

Diperna said the current role of NSO leaders is still about "being a cheerleader" for students to help them acclimate
to student life - even through the virtual format.

                                                                                                            Page 2 of 3
                       Penn State NSO leaders contemplate 2nd summer of online orientation

"As an NSO leader, my main job is leading small groups," Diperna said. "Small groups are 90-minute interactive
sessions with about 25 students, and we really just teach them about how to be successful in college because the
transition from high school to college is a huge one."

MORE CAMPUS COVERAGE

Despite the difficulty posed by the orientation format, leaders said they were still able to take away several lessons
from the experience.

Lawson said she learned about the importance of verbal and nonverbal communication over Zoom.

"You really do learn that not everyone speaks the way you speak on an everyday basis, especially with international
students," Lawson said. "I have to be more aware of what I say and how I interact with people and how I put my
face on screen."

Diperna said her experience last year prepared her for this summer.

"I grew a lot as a person. We learned adaptability and how to be comfortable on Zoom," Diperna said. "It was a
great learning experience and was necessary for me to become the orientation leader that I am this summer."

Currently, NSO is still primarily online, but Penn State is offering both in-person and virtual events as part of its
Summer Welcome for Summer Session II students.

Dia (junior-economics) said this summer, she was more prepared to speak with incoming freshmen because of last
year's experience.

"I know some tips and tricks to get students engaged," Dia said. "I know what students want to hear and what they
need to hear... the good, the bad and the ugly."

Lawson said despite being unhappy with NSO's continued online format, she was still happy to be able to apply last
year's experience to her current role.

"It was a bit upsetting knowing [NSO] would be online again," Lawson said. "I'm not nervous anymore to speak on
Zoom. I know how to effectively tell what I need to tell to students... I know it's hard to sit down for 90 minutes
without your phone, so I try to make [the information] as entertaining as possible."

MORE CAMPUS COVERAGE

Penn States begins national search, seeks nominations for its 19th president

Penn State will begin a national search and seek nominations for its 19th president this Jul...

Despite the leaders' current situation, Diperna said she still sees her role as gratifying and important.

"I'm a reserved person, so public speaking is out of my wheelhouse, but I think being an orientation leader gave me
purpose for the last two summers," Diperna said. "I needed to do something to be helping other people, and that's
what orientation provided me. It's helped me in so many ways during my Penn State career."

Lawson also said she recommends students with an interest in NSO try their hand in being a leader.

"This is my second year, so that says something," Lawson said. "You're in the life-changing business, truly. You're
the first Penn Stater for a lot of people. They might have never met anyone from Penn State before, and you are
going to exemplify the values of Penn State. If they need me, they can come to me for anything."

MORE CAMPUS COVERAGE

+2

                                                                                                  Page 3 of 3
                     Penn State NSO leaders contemplate 2nd summer of online orientation

Penn State students, alumnus develop Reach.AI to address health disparities within marginalized communities

Recent Penn State alumnus Kareem Jelks said he spent his childhood homeless in an "impoveris...


Load-Date: July 8, 2021


  End of Document

                                                                                                        Page 1 of 3
                           PITTSBURGH REGION READY FOR SUPPLY CHAIN INVESTMENT




         PITTSBURGH REGION READY FOR SUPPLY CHAIN INVESTMENT
                                               Pittsburgh Post-Gazette
                                              January 28, 2022 Friday
                                                 SOONER EDITION



Copyright 2022 P.G. Publishing Co.

Section: OPINION; Pg. A-8
Length: 906 words
Byline: Matt Smith

Body


The extended supply chain crunch is impacting families and businesses alike.

From cars to computers to materials, it has been difficult to get the things we need when we need them.

Our manufacturers and businesses have been working overtime to develop solutions and get their products in
customers' hands. And the federal government has made this a priority as well.

That is why we are especially encouraged by President Joe Biden's visit to our region this week.

We have been fortunate to host key federal policymakers who have toured Pittsburgh's companies, institutions of
higher education and state-of-the-art facilities, including training centers for the building trades. We have welcomed
the opportunity to tell the story of the 10-county Pittsburgh region's economic re-emergence and our leadership in
autonomy and robotics/AI, energy, life sciences, health and manufacturing.

Now, our region is well positioned to act as a model for federal investment to address world-scale issues - including
supply chain problems.

Washington recently made a significant investment in our country by passing the bipartisan infrastructure bill. Here
at home, the funding will fix our roads and bridges, reinvigorate our transit network, help support mobility systems of
the future and move people, goods and products faster and more safely and efficiently.

Thanks to the leadership of Mr. Biden and leaders from the Pittsburgh region including Sen. Bob Casey, Rep.
Conor Lamb, Rep. Mike Doyle and key stakeholders, our region recently secured nearly $1 billion for vital inland
waterway infrastructure. Further investment in other modes of transportation will be transformative for our region.

Now it's our turn to help the federal government as it confronts a historic supply chain bottleneck. We know that we
need stronger, more resilient and sustainable infrastructure to move goods and products to market.

                                                                                                        Page 2 of 3
                       PITTSBURGH REGION READY FOR SUPPLY CHAIN INVESTMENT

As we look to the next phase of infrastructure investment opportunities, we have projects in the Pittsburgh region
that can help ease the supply chain crisis. With federal partnership and discretionary funding from the infrastructure
bill, these projects can become a reality and serve as a model for the country.

These projects are ready-to-go and ripe for federal investment.

For years, our region has sought to expand American-based manufacturing, and we have led the effort to move
more manufacturing back to our shores. With a bottlenecked supply chain, this has never been more important.

Leading institutions, from nonprofits to institutions of higher education to businesses, have come together with a
shared vision for the Hazelwood Green project. A 178-acre river's edge brownfield redevelopment, Hazelwood
Green is poised to be an innovation anchor for the manufacturing ecosystem - locally and beyond.

When completed, it will house worker training and businesses focused on robotics, advanced manufacturing and
life sciences. Investments in the surrounding infrastructure will accelerate business growth and new manufacturing
in the region.

At Pittsburgh International Airport, Neighborhood 91 is at the ready to serve as a reshoring model for
manufacturing. In addition to workforce and backlogs, long distances are constraining supply chains. If we can
shorten the distance to market through reshoring, we can alleviate supply chain pressure.

Neighborhood 91 is a complete manufacturing and transportation ecosystem focused on additive manufacturing.
Build out will enable more domestic manufacturing, bringing products closer to U.S. businesses and consumers.
Neighborhood 91 can serve as a model here in southwestern Pennsylvania, and across the country, as we seek to
make more products domestically.

As our region builds its manufacturing capability, we need the road and bridge infrastructure to support the
movement of products. The Laurel Valley Transportation Improvement Project between the Arnold Palmer Airport
and Route 819 near Mount Pleasant, Westmoreland County, exemplifies how we can make our region's highway
system more accessible to all types of vehicles while improving safety and mobility.

It will connect manufacturing firms and business parks, from our rural areas to our urban cores, and other
multimodal transportation hubs. The project will make our companies more competitive by opening new markets to
their products.

These are just a few of several ready-to-go projects our region has come together to support with a unified voice.
The projects can solve some of the short- and long-term supply chain issues confounding the federal government.
Moreover, these projects will create jobs, fuel economic growth and provide opportunity for residents across our
region regardless of ZIP code.

We are happy to again welcome Mr. Biden to our region, and we are eager to partner with his administration to
address the supply chain crisis with the right investments.

Projects like Hazelwood Green, Neighborhood 91, the Laurel Valley Transportation Improvement Project and others
can help to solve some of our country's most pressing challenges by taking advantage of this region's leadership in
innovation, logistics and manufacturing.

We encourage the federal government to invest in these unique solutions because they are not just good for
Pittsburgh: They are good for America.

Matt Smith is the president of the Greater Pittsburgh Chamber of Commerce, an affiliate of the Allegheny
Conference on Community Development.



Graphic

                                                                                         Page 3 of 3
                    PITTSBURGH REGION READY FOR SUPPLY CHAIN INVESTMENT



PHOTO: Andrew Rush/Post-Gazette: A 133,000-square-foot solar array can be seen on the top of Hazelwood
Green's Mill 19.


Load-Date: January 28, 2022


  End of Document

                                                                                                       Page 1 of 21
                                                 NOTABLE IN HEALTH CARE




                                          NOTABLE IN HEALTH CARE
                                                   Crain's New York Business
                                                          August 10, 2020
                                                           Print Version



Copyright 2020 Crain Communications All Rights Reserved




Section: Pg. 17; Vol. 36
Length: 14455 words

Body


New York's health care sector is no stranger to disaster.

Many of its doctors, nurses and scientists, among other players, have served on the front lines of crises dating back
to the AIDS/HIV outbreak of the 1980s.

Very few, however, were fully prepared for the tragedy that unfolded earlier this year as the novel coronavirus
spread through the region. The Covid-19 outbreak that officially claimed its first life in March at a Brooklyn hospital
became the city's worst mass casualty since the influenza outbreak of 1918.

And yet, as might be expected, the region's health care sector mounted a gritty response. Doctors and nurses
worked to save lives in underfunded public hospitals. Many contracted Covid-19 and, after recovering at home,
returned to the front lines.

Scientists at academic medical centers and drug companies joined the global race to develop therapies, and some
now lead the way. Nonprofits found ways to offer free Covid-19 testing, food and other critical resources to the city's
hardest-hit communities.

The examples of courage, compassion, grit and ingenuity are seemingly endless.

This year's Notable in Health Care special report, presented by Montefiore-Einstein, shines a light on many of
those stories. It features the people who helped bend the region's steep infection curve downward and are still
working to alleviate the economic and humanitarian toll.

This report recognizes the innovation in health care that predates the crisis and arose from it, including the
advances in telemedicine and scientific research.

It honors those working to fight health care disparities and other societal problems that the pandemic accentuated
and that are seen anew through the lens of recent demonstrations against racial injustice.

                                                                                                        Page 2 of 21
                                            NOTABLE IN HEALTH CARE

JUDITH ABERG, MD Chief, division of infectious diseases and immunology, Mount Sinai Health System Director,
infectious diseases, Icahn School of Medicine at Mount Sinai

Dr. Judith Aberg, an HIV and AIDS researcher, is on the leading edge of efforts to develop effective Covid-19
treatments. At Mount Sinai, she's researching the use of plasma from people who have recovered from Covid-19 as
a possible defense against the disease.

Hundreds of Covid-19 patients have participated in her study at Mount Sinai, which recently formed a partnership
with a leading drug manufacturer to test whether a drug derived from the plasma of recovered Covid-19 patients
helps prevent infection. If effective, the drug would offer protection for health care and other essential workers until
a vaccine is available.

LEONARD ACHAN, RN President, Innovation Institute, Hospital for Special Surgery Cofounder and chairman,
Quality Reviews Inc.

As a C-suite executive, entrepreneur and academic, Leonard Achan has worked on the cutting edge of health care
innovation for more than two decades. Achan, who began his med- ical career in nursing, joined the Hospital for
Special Surgery as its chief innovation officer in 2016. Three years later he rose to president of the Innovation
Institute, where he leads commercialization of the hospital's inventions in musculoskeletal care. Achan is the co-
founder and chairman of Quality Reviews Inc., which builds proprietary digital platforms for health care providers
that offer real-time feedback from patients and employees. Before joining HSS, Achan was chief communications
officer and chief of access services of the Mount Sinai Health System. At the same time he served as senior
associate dean for global communications, branding and reputation at the Icahn School of Medicine.

GIL ADDO Co-founder and chief executive officer RubiconMD

Driven by his family's experience navigating the health care system, Gil Addo co-founded RubiconMD in 2013 to
bridge the gap between primary and specialty care. Since then, the Manhattan company has raised more than $40
million in funding, including an $18 million round in March. Through its digital platform, RubiconMD allows primary
care doctors to consult specialists online, making complex care available without patients needing to travel or wait
for the next available appointment. The strategy is well suited for the Covid-19 era. Addo was inspired to start
RubiconMD after his grandmother, diagnosed with a brain tumor, began commuting from her home in Barbados to
Boston for surgery and post-op appointments.

CARA AGERSTRAND, MD Associate professor of clinical medicine, division of pulmonary, allergy and critical care
medicine Columbia University Irving Medical Center/New York-Presbyterian Hospital

To keep up with the surge of Covid-19 patients in city hospitals earlier this year, pulmonologists such as Dr. Cara
Agerstrand acted as clinical supervisors, training and watching over teams of doctors and nurses with less
experience in treating seriously ill patients. How colleagues learned new skills under pressure was impressive,
Agerstrand said, adding she was grateful her skills, education and training enabled her to give back during the
crisis. Agerstrand has extensive experience in clinical care, research and education. She is the director of the
medical extracorporeal membrane oxygenation program, which focuses on a specialized life support that acts as a
temporary artificial lung.

SALOMON AMAR, DDS Vice president for research and professor, New York Medical College Provost for
biomedical research, Touro College and University System

Dr. Salomon Amar has been the driving force behind a partnership between New York Medical College and
pharmaceutical giant Regeneron to determine whether a drug that is used to treat inflammation is an effective
treatment for critically ill Covid-19 patients. Early on in New York's Covid-19 outbreak, he worked closely in a multi-
industry effort to expedite approval for the clinical trial of Regeneron's Kevzara at Westchester Medical Center. The
trial began just three weeks after New York reported its first Covid-19 case. Approval for such clinical trials normally
takes at least six months. His leadership has helped create a model for partnerships among medical schools, drug
companies and hospitals.

                                                                                                      Page 3 of 21
                                           NOTABLE IN HEALTH CARE

ZEYAD BAKER, MD President and chief executive officer OptumCare Tristate Region

OptumCare recently tapped Dr. Zeyad Baker to oversee its physician practices in New York, New Jersey and
southern Connecticut. OptumCare has about 1,500 doctors in the region and, with significant growth in Connecticut,
plans to add hundreds more doctors by year's end. For the past two years, Baker has led OptumCare's ProHealth,
one of the largest medical groups in the Northeast. In that role he spearheaded initiatives to improve care, the
patient experience and access to care. Baker, a former pediatrician, previously was co-president of New Jersey's
Riverside Medical Group, which he helped grow into a group practice of nearly 300 providers before Optum
purchased it in 2016.

GINA BARTASI Founder and chief executive officer Kindbody

An entrepreneur and the mother of in-vitro-fertilization twins, Gina Bartasi is shaking up the fertility care business
with her latest startup, Kindbody. Bartasi founded the health-tech company in 2018 in response to a demand
among employers to buy fertility benefits directly from health care providers. Kindbody raised $32 million in July to
fund further expansion. It has raised about $64 million in all from investors that include the venture capital arm of
Google parent Alphabet. The Manhattan company sells fertility-benefit packages to employers and offers
gynecological services at its clinics and through more than 200 partner clinics. Demand has been strong for virtual
fertility consultations. Kindbody's revenue was 30% higher in June than in February, before the first case of Covid-
19 was identified in New York.

DAVID BATTINELLI, MD Senior vice president and chief medical officer Northwell Health

Dr. David Battinelli was among the highest-profile figures during New York's Covid-19 outbreak, and it's not hard to
see why. Northwell, the state's largest health care provider, treated about 50,000 more Covid-19 patients than any
other provider. Battinelli led a Northwell advisory group charged with overseeing clinical care, policies and
standards for treating Covid-19, and he made media appearances to share insights into the pandemic. Battinelli has
a wide-ranging portfolio at Northwell. Passionate about medical education and professional development, he runs a
Northwell leadership-development program that has trained more than 150 clinicians. In addition, he helped
develop the curriculum for the Zucker School of Medicine, where he is vice dean.

ALLON BLOCH Cofounder, chief executive officer K Health

In 2016 Allon Bloch parlayed his wide-ranging experience as a serial entrepreneur and venture capitalist to cofound
K Health, a digital primary care service that uses artificial intelligence. The startup, which launched its product in
mid-2018, raised $48 million in its Series C round in February, bringing total funding to $97.3 million. K Health
offers a free AI-powered app to assess a patient's symptoms, then lets the user, for a fee, schedule a telehealth
visit with a doctor for personalized care and prescriptions. Bloch previously was the co-CEO of Wix, a website
publishing platform, cofounder and CEO of online car retailer Vroom and CEO of mySupermarket, a digital platform
for grocery shopping. He was a venture partner at Greylock Partners and a general partner at Jerusalem Venture
Partners.

MICHAEL R. BLOOMBERG Chief executive officer Bloomberg LP Former mayor, New York City

Billionaire entrepreneur Michael Bloomberg doesn't suffer from a lack of name recognition. The former New York
City mayor is the CEO of a major media company headquartered in the city, and briefly this year he was a Dem-
ocratic presidential candidate. Not everyone, however, is familiar with his commitment to improve public health, a
major focus of grantmaking by his foundation, Bloomberg Philanthropies. Recently the three-term mayor launched a
major effort to help fight the Covid-19 pandemic, including supporting mayors through a partnership with public
health and management experts at Johns Hopkins and Harvard, and committing $40 million to help low- and
middle-income countries fight the coronavirus. As mayor, he and his team developed a pandemic influenza plan for
New York and led the city through the H1N1 virus outbreak. Bloomberg has been a global ambassador for the
World Health Organization.

PATRICK BORGEN, MD Chair, department of surgery Maimonides Medical Center

                                                                                                      Page 4 of 21
                                           NOTABLE IN HEALTH CARE

Dr. Patrick Borgen helped lead one of New York's hardest-hit hospitals through the Covid-19 crisis, and he
continues to battle the disease through his research efforts. Borgen chairs the surgery department at Maimonides
Medical Center and its medical science committee. He is in charge of the hospital's efforts to participate in clinical
trials for Covid-19 therapies and treatment protocols. As part of a study led by Minnesota's Mayo Clinic, he
manages convalescent plasma research. Under Borgen and other hospital leaders, Maimonides took diverse
measures to care for legions of critically ill Covid-19 patients. In May the 711-bed hospital in Brooklyn's Borough
Park celebrated a milestone, discharging its 1,000th Covid-19 patient.

ANTHONY BOUTIN, MD Interim president and chief executive officer, chief medical officer NuHealth

Dr. Anthony Boutin, a champion for the underprivileged, is leading a safety-net hospital through a leadership
transition and the Covid-19 crisis. In his role at NuHealth, Boutin leads Nassau University Medical Center, a
challenged but essential Nassau County hospital. Boutin, a former chair of the medical center's department of
emergency medicine, was named chief medical officer last year and interim president and CEO in January. A few
months later he rolled out a preparedness plan to help the medical center handle an anticipated surge of Covid-19
patients. The plan called for sourcing and stockpiling critical supplies and launching a staffing task force, among
other steps that ultimately helped the 530-bed hospital care for large numbers of Covid-19 patients.

DANIEL BRILLMAN Cofounder and chief executive officer Unite Us

Studies show the U.S. spends more on health care than many other countries, yet lags on issues such as chronic
disease and obesity. Part of the problem, according to Daniel Brillman's Unite Us, is the long-standing disconnect
between health and social service providers. Brillman, an Air Force Reserve pilot who cofounded Unite Us in 2013,
wants to help bridge that gap. The company has an outcome-tracking technology platform that connects health
care providers and social services groups. It focuses on food, housing and other social determinants of health.
Unite Us, which initially concentrated on matching veterans to support services, has raised more than $45 million.
This year it made its first acquisition, Staple Health, a social-determinants data firm.

KELLIE BRYANT Assistant professor of nursing and executive director Helene Fuld Health Trust Simulation
Center, Columbia University School of Nursing

Known for her calm demeanor and commitment to advancing nursing, Kellie Bryant has transformed the way
Columbia University's School of Nursing educates future health care providers. She's especially proud of her
successful campaign to outfit the Helene Fuld Health Trust Simulation Center with state-of-the-art technology. The
simulation center allows nursing students to practice real-world clinical scenarios. This year Bryant played a lead
role in the school's response to the Covid-19 pandemic. She used simulation training to redeploy nurses in the
hospital to care for Covid-19 patients, and she led the donation of large amounts of protective gear from the
simulation center to New York-Presbyterian Hospital. Bryant also found time to march with students in the recent
protests for racial justice.

JOHN CARDASIS, MD Director, critical care White Plains Hospital

Dr. John Cardasis helped lead White Plains Hospital through the proverbial eye of the storm during New York's
Covis-19 outbreak. He expanded the hospital's intensive care unit capacity by some 500% and created new ICUs
that housed more than 200 critically ill Covid-19 patients. Known for his calm leadership style, Cardasis rapidly
recruited and trained new ICU providers, taking on primary care duties himself. He created a team of orthopedic
and thoracic surgeons to help wean Covid-19 patients off respirators by turning them on their stomachs, a
technique known as proning. Cardasis is credited with helping the Westchester County hospital successfully treat
more than 800 Covid-19 patients.

BRENDAN CARR, MD Chair of emergency medicine Mount Sinai Health System and Ichan School of Medicine at
Mount Sinai

Dr. Brendan Carr joined Mount Sinai in February, about a month before the first Covid-19 case was diagnosed in
New York City. He may have been new to his job by the time the city's Covid-19 outbreak was in full swing, but he

                                                                                                         Page 5 of 21
                                            NOTABLE IN HEALTH CARE

played a central role in the sprawling health system's response to the crisis. Carr spent his days at Mount Sinai's
eight hospitals, ensuring Covid-19 patients were safely transported throughout the system to alleviate pressure on
Mount Sinai's hard-hit community hospitals in Brooklyn and Queens. In addition, he worked to shore up the
system's supply chain and expand capacity in its emergency departments by having tents built outside the
hospitals.

NATALIA CINEAS, DNP, RN Senior vice president and system chief nurse executive NYC Health + Hospitals

As chief nurse executive at NYC Health + Hospitals, Natalia Cineas led the country's largest public health care
system through the city's Covid-19 outbreak. After being appointed to her position in March 2019, Cineas played a
key role in crisis management. Among other initiatives, she oversaw recruitment and deployment of more than
5,000 additional nurses and nursing specialists. With her nurses on the front lines of battling the coronavirus,
Cineas helped implement emotional support and wellness programs specifically for them. She leads initiatives to
support patient-centered care and to ensure patient satisfaction as she heads a staff of more than 9,600 nurses and
970 social workers. In addition, she oversees clinical operations and nurse education. Cineas co-chairs a council
that sets systemwide strategic diversity and inclusion priorities.

JON COHEN, MD Executive chairman BioReference Laboratories Inc.

Under Dr. Jon Cohen's direction, BioReference Laboratories has become a leading provider of Covid-19 diagnostic
and antibody tests in New York and other states. Earlier this year the firm landed a $150 million contract with New
York state for analyzing Covid-19 diagnostic and antibody tests. BioReference, a subsidiary of publicly traded
OPKO Heath, has been testing samples collected at 11 drive-thru facilities around the state. It has run some 20
walk-up testing centers. Cohen's previous public-sector experience as a chief policy adviser to former Gov. David
Paterson helped the company connect quickly with the state and city to ramp up testing. In July, BioReference
signed deals to test for Covid-19 among players and staff of the National Basketball Association and Major League
Soccer.

LOUISE COHEN Chief executive officer Primary Care Development Corp

At the Primary Care Development Corp., Louise Cohen works to expand and strengthen a primary care safety net
that has been damaged by the Covid-19 crisis. PCDC provides capital and technical help to primary care providers.
In addition, the nonprofit advocates for increased primary care access, capacity, reimbursement and capital
resources. The pandemic has put many primary care practices at risk of closure, and it has exacerbated long-
standing health disparities. Under Cohen, PCDC is pushing for rapid and targeted community-level investment in
primary care. Without action, the organization expects health disparities to deepen. Cohen joined PCDC in 2015
from Public Health Solutions, where she oversaw programs to improve community health throughout the city.

LISA DEANGELIS, MD Physician-in-chief and chief medical officer Memorial Sloan Kettering Cancer Center

Dr. Lisa DeAngelis, a brain cancer expert, was named physician-in- chief and chief medical officer of Memorial
Sloan Kettering in the fall of 2019. She directs MSK's clinical effort, overseeing the care of patients at 20 facilities,
including the flagship 500-bed hospital. DeAngelis presides over the care given by more than 1,200 attending
physicians and nearly 4,000 nurses. The 30-year veteran of the hospital previously chaired its department of
neurology, and she co-founded the Brain Tumor Center. DeAngelis conducted clinical research that helped set the
standard of care for central nervous system lymphoma. She first knew she wanted to become a doctor in the third
grade. Her father encouraged her to make the most of her medical education and to commit to treating patients
regardless of their ability to pay.

BENJAMIN DE LA ROSA, MD Infectious-diseases specialist Holy Name Medical Center

Dr. Benjamin De La Rosa has served in the trenches of New Jersey's Covid-19 outbreak and survived the disease.
At Holy Name Medical Center in Teaneck, De La Rosa worked long hours, caring for Covid-19 patients and
investigating new treatments and protocols. He was part of the team that treated the first American-Broadway
producer Edward Pierce-to receive a promising therapy that originated in Israel. Pierce, who had been critically ill,

                                                                                                      Page 6 of 21
                                           NOTABLE IN HEALTH CARE

began to improve soon after receiving the treatment. In March De La Rosa himself tested positive for Covid-19, but
he experienced only mild symptoms. After recovering at home, he returned to work and continues to help lead the
infectious-diseases and clinical research teams.

JACQUELINE DELMONT, MD Chief medical officer Somos Innovation Founder and chief executive officer Delmont
Medical Care

Dr. Jacqueline Delmont has led the charge at Somos, a nonprofit network of 2,500 independent doctors, to ramp up
Covid-19 testing in underserved communities across the city. The native of Venezuela has worked with churches,
government officials, Latin-American consulates, first responders, hospitals and private organizations to set up
more than 50 testing sites. Covid-19 has taken a toll on low-income communities as well as the independent
doctors who serve them. Under Delmont, Somos has helped the physician practices in its network access federal
disaster relief. It encouraged them to look for inefficiencies and embrace telemedicine, among other steps to boost
competitiveness and patient access.

MIKAEL DOLSTEN, MD Chief scientific officer and president, worldwide research, development and medical Pfizer

Dr. Mikael Dolsten is charged with advancing Pfizer's scientific leadership in vaccines and gene therapies, among
other areas-no small task under ordinary cir- cumstances, let alone during a global pandemic. Recognizing the
need for collective action, Dolsten readily agreed earlier this year to have Pfizer participate in an unprecedented
public-private partnership to prioritize vaccine and drug candidates, streamline clinical trials and coordinate
regulatory processes. Under Dolsten, Pfizer's aggressive, multipronged approach to developing a Covid-19 vaccine
appears to be yielding results. In July the pharmaceutical giant began the last stage of an experimental Covid-19
vaccine study that is expected to enroll 30,000 people. The company aims to file for regulatory approval or
emergency-use authorization in October.

MICHELE DONATO, MD Chief of stem cell transplantation and cellular therapy John Theurer Cancer Center
Hackensack University Medical Center

Dr. Michele Donato is in a self-described race against time to develop a treatment for the sickest Covid-19 patients.
Donato is helping to lead a team of researchers and clinical experts at Hackensack University Med- ical Center that
is scrutinizing the blood of recovered Covid-19 patients to discover more about the disease and develop new ways
to fight it. Scientists from Hackensack Meridian Health Center for Discovery and Innovation also are involved in the
research into a convalescent- plasma treatment for the corona- virus. The study, announced in April, is one of
several such clinical trials underway. Convalescent plasma treatments have been used to fight past viral outbreaks.
They entail infusing the antibody-rich blood of recovered patients into infected patients.

AMY DORIN President and chief executive officer The Coalition for Behavioral Health

Amy Dorin is helping the city's behavioral health community get back on its feet in the wake of the Covid-19 crisis.
Dorin is among the industry leaders and public officials calling for more support for behavioral health providers who
face lower revenue and higher costs because of the pandemic. At the same time New Yorkers are under stress
from coping with the coronavirus and its economic impact, resulting in pent-up demand for mental health services.
Dorin's organization provides advocacy, training and other support for community-based behavioral health
providers, many of them new to teletherapy. It recently launched a business recovery initiative to help its members
develop strategies for sustainability.

MICHAEL DOWLING President and chief executive officer Northwell Health

Northwell Health, New York's largest health care provider, has treated more Covid-19 patients-upward of 50,000-
than any other organization in the country. Company CEO Michael Dowling has likened the experience to going to
war. Indeed, he led Northwell through numerous battles, from creating hundreds of beds each day to securing
protective gear for thousands of workers during New York's recent surge. Dowling helped lead New York's hospital
community through the crisis, co-chairing a council to oversee hospitals' efforts to boost their capacity by thousands

                                                                                                         Page 7 of 21
                                            NOTABLE IN HEALTH CARE

of beds. The thought leader has used his platform to take a stand on gun violence and other tough social issues,
including a call for national unity against the pandemic.

JASON FELDMAN Co-founder and chief executive officer Vault Health

After noticing that many of his male friends were reluctant to seek care for certain issues, Jason Feldman co-
founded Vault Health in 2018 to provide specialized, at-home care for men. Some men may be shy about seeking
medical help, but Feldman's startup is getting some attention. Earlier this year it raised $30 million to expand its
reach. The company's services include personalized treatment plans for sexual health, hair loss, prescriptions,
house calls from providers and telemedicine services. In May, the company took its at-home proposition to a new
level, announcing plans to offer a federally approved, at-home saliva test kit for Covid-19. Before launching Vault
Health, Feldman was the head of Amazon Prime Video Direct.

MARKI FLANNERY President and chief executive officer Visiting Nurse Service of New York

Marki Flannery, a 38-year veteran of the Visiting Nurse Service of New York, has been CEO of the huge nonprofit
home-care agency since 2018. In her various roles, she's helped the organization become one of the country's
largest nonprofit home- and community-based health care providers. During the Covid-19 outbreak, Flannery
transitioned thousands of employees to remote work in short order. She helped procure more than $5 million in
protective gear and other supplies, among other initiatives. By providing uninterrupted care, VNSNY helped ease
the burden on hospitals. Under a transition plan, Flannery will turn the organization's reins over to its chief financial
officer, Dan Savitt, early next year.

ROBERT FORONJY, MD Chief of pulmonary and critical care SUNY Downstate Health Sciences University

Dr. Robert Foronjy helped care for some of the hardest-hit communities in the city's Covid-19 outbreak, and he did
so under less-than-ideal conditions. University Hospital was one of three city facilities directed by Gov. Andrew
Cuomo to treat only Covid-19 patients. The 376-bed hospital is publicly funded and has been described in news
reports as under-resourced and aging. Many of its patients are poor and people of color and hail from
neighborhoods with relatively high rates of chronic diseases. Despite worries about his own health and the state of
his hospital's aging facilities, Foronjy cared for an avalanche of Covid-19 patients. He has said the episode
highlighted the city's health care disparities.

OREN FRANK Cofounder and chief executive officer Talkspace

The coronavirus pandemic is pushing more Americans to access health care remotely. Talkspace, founded in 2012
by Oren Frank and his wife, Roni, already has proven that therapy is well-suited to virtual care. The Manhattan
digital mental-health platform connects people to licensed therapists through a mobile application. In May,
Talkspace announced an agreement with Cigna that brought to 40 million the number of insured individuals who are
covered for its services. Talkspace already was growing quickly before the pandemic hit. In May 2019 it raised $50
million to expand its national network. This past May, the company reported that insurance coverage for Talkspace
had increased fivefold year-over-year. Olympian Michael Phelps is both an investor and a spokesman.

LINDA FRIED, MD Dean Columbia University Mailman School of Public Health

The role of public-health experts has never been more important or under greater attack. Dr. Linda Fried leads one
of the country's major public-health schools and has engineered a strong response to Covid-19 on multiple fronts.
In addition to the traditional research role of public health, the school's experts are shaping government responses
and contingency planning. They've served as media sources and mobilized critical volunteer efforts. Fried, an
authority in geriatric medicine, is part of a team of experts on aging that's tracking how people are coping with the
pandemic. The findings of this global study could help governments and policymakers address the pandemic's
mental-health consequences. Social distancing and other containment measures may give rise to unprecedented
levels of loneliness and social isolation, particularly among the elderly.

                                                                                                    Page 8 of 21
                                          NOTABLE IN HEALTH CARE

JAMES GASPERINO, MD Chair, medicine; vice president, critical care perioperative and hospital medicine;
associate chief medical officer Brooklyn Hospital Center

Brooklyn Hospital Center, a 450-bed, acute-care hospital in Downtown Brooklyn, was hit hard by the Covid-19
outbreak. Many of its doctors and nurses were sickened during the outbreak. The hospital ran out of critical
supplies, from protective gowns to the main sedative for patients on ventilators. Under the leadership of Dr. James
Gasperino, the hospital dealt with the flood of patients to its emergency department by building an outdoor tent to
screen people for Covid-19. It redeployed health care workers from departments that had cut back on services,
among other emergency measures. In 2017 Gasperino transformed critical-care medicine at Brooklyn Hospital by
hiring new faculty, redesigning critical operations and adding a fellowship program in critical care.

ROSA GIL Founder, president and chief executive officer Comunilife

Earlier this year, Rosa Gil's housing nonprofit, Comunilife, stepped up to provide what she called "the last leg of
recuperation" for the city's homeless Covid-19 patients. Comunilife worked with New York-Presbyterian and Mount
Sinai hospitals to expand its medical respite program. It established an 84-bed facility in Manhattan to provide
short-term housing for Covid-19 patients who had been discharged from the hospitals and needed a safe place to
quarantine while recovering. Gil has had a long and distinguished career in the city's health, mental health,
supportive housing, social service and higher education sectors. Among other roles, she chaired NYC Health +
Hospitals and served as a health policy adviser to former Mayor Rudy Giuliani.

JASON GOREVIC Chief executive officer Teladoc Health

A pandemic is an ideal time to specialize in telehealth services. In the first quarter, Teladoc's revenues climbed
41% compared to the year-earlier period, to more than $180 million. Total visits rose 92% to 2 million. Teladoc is
poised for growth as virtual care becomes a necessity for all health care providers. Driven by a passion for
improving health care outcomes and access, Jason Gorevic has helped to turn Teladoc into a telemedicine
powerhouse since he took over its reins in 2009. With more than 3 million members, the Purchase-based publicly
traded company provides access to affordable care through videoconferencing and telephone consultations with
board-certified physicians. Teladoc is expected to become an even-larger player in telemedicine when its planned
merger with Livongo Health, a provider of digital health management for chronic conditions, closes later this year.

SCOTT HAYWORTH, MD President and chief executive officer CareMount Medical

With many patients putting off preventative services and screenings during the pandemic, health care leaders
worry that there's another crisis in the making. Telehealth is one way to give patients access to care. Under Dr.
Scott Hayworth, CareMount Medical performed 1,500 telehealth visits a day during the peak of the Covid-19
outbreak compared with the typical six telehealth visits a day. CareMount, one of the country's largest independent
multispecialty groups, expects usage to remain high after the pandemic. Hayworth, an obstetrics and gynecology
specialist who started practicing medicine at CareMount in 1988, oversaw a major expansion of the medical group.
It grew from 40 physicians to 650 providers, including 500 doctors in the Hudson Valley and New York City.

DAVID HO, MD Founding scientific director and chief executive officer, Aaron Diamond AIDS Research Center
Professor of medicine, Columbia University Vagelos College of Physicians and Surgeons

Dr. David Ho made a name for himself decades ago with his pioneering HIV research, which led him to advocate for
a therapy that has dramatically reduced AIDS deaths. More than 10 million patients have benefited from
combination antiretroviral therapy since the mid-1990s. Ho is now leading research teams that are applying lessons
learned from decades of HIV research to fighting the novel coronavirus. Ho's team has isolated antibodies from
several Covid-19 patients that are potent in neutralizing the SARS-CoV-2 virus. Such antibodies could be produced
in large quantities to treat patients and prevent infection. Recently the foundation founded by Jack Ma of Alibaba
fame gave Ho and his research teams $2.1 million to support their efforts.

KATHERINE HOCHMAN, MD Associate professor, New York University Grossman School of Medicine Associate
chair for quality of care, director of hospitalist program, NYU Langone Health-Tish Hospital

                                                                                                        Page 9 of 21
                                            NOTABLE IN HEALTH CARE

Even while quarantined, Dr. Katherine Hochman helped lead NYU Langone's response to the Covid-19 crisis. She
created a "Covid Army" by redeploying more than 850 doctors, front-line staff and even medical students to provide
support. Through daily Covid-19 update emails, often dotting clinical care policy updates with personal reflections or
anecdotes, Hochman kept personnel updated and spirits high. When Covid-19 patients were in isolation and
separated from friends and family, she implemented the Family Connect program to enhance communications.
Many health systems restricted visitors to reduce the spread of infections. By reviewing charts and consulting with
care teams, Family Connect teams monitored the progress of Covid-19 patients and regularly updated their families
through phone calls and videoconferences.

CAROL HOROWITZ, MD Professor of population health science and policy Professor of medicine, and dean for
gender equity in science and medicine at Icahn school of medicine at Mount Sinai

Dr. Carol Horowitz, a professor, researcher and practicing internist, leads a fledgling research initiative at Mount
Sinai that seeks to understand and combat health disparities in underserved communities. Horowitz directs the
Institute for Health Equity Research, announced in May. The Covid-19 pandemic has had a disproportionate impact
on nonwhite, low-income and immigrant communities, underscoring the need for research on health disparities and
initiatives that shaped the findings. Earvin "Magic" Johnson and state Sen. Brian Benjamin are in a task force
helping to steer and publicize the institute's research. In addition, Horowitz leads Mount Sinai's gender equity efforts
to correct inequities in compensation, hiring and promotion, and eliminate bias.

KAREN IGNAGNI President and chief executive officer EmblemHealth

Karen Ignagni took the reins of EmblemHealth in 2015 and has since worked to improve the experience of its more
than 3 million members and expand its regional reach. As head of one of the largest nonprofit health insurers, she
has been outspoken about the need to restore federal funding for public health and address disparities in health
care. With the Covid-19 crisis accelerating the use of telehealth, a recent study from EmblemHealth shined a light
on the link between access to technology in lower-income communities and health care disparities. Ignagni says
the crisis illuminates the need for both quality home care and the full integration of behavioral health and acute
care. Ignagni previously led the trade group America's Health Insurance Plans. In that role she helped shape the
Affordable Care Act.

LETITIA 'TISH' JAMES Attorney general, New York state Former public advocate, New York City

Letitia James has demonstrated a fierce commitment to public health throughout her career in public service-from
fighting for access to women's reproductive health care to pressing for measures to protect the public from gun
violence and ensuring access to health insurance. She is the first woman of color to hold statewide office in New
York and the first woman to be elected state attorney general. In January she led a coalition of Democratic
attorneys general in petitioning the U.S. Supreme Court to hear a case on the future of the Affordable Care Act. She
was part of a coalition of 16 attorneys general who supported legal action to ensure states can enact restrictions to
protect against gun violence.

WALTER JIN Chairman and chief executive officer Pager

Walter Jin, who has overseen more than $5 billion in investments in the health care sector during his equity and
venture capital career, took over the reins of the mobile health tech firm Pager in 2017. Amid growing demand for
telehealth services, Pager raised $33 million in financing in March to expand its offering to new markets. Pager's
virtual care companion, marketed to health insurers and providers, allows patients to interact with health care
providers through chat, voice and video. Pager said the process is designed to mimic what it is like to have "a
doctor in the family" by providing a personalized, connected care experience. Since its launch in 2014, Pager has
raised some $64 million.

PAT KANE, RN Executive director New York State Nurses Association

Pat Kane, a registered nurse and longtime leader of the New York State Nurses Association, took the reins of the
union in December, just months before many of its members were hit hard by the Covid-19 outbreak. Under Kane,

                                                                                                        Page 10 of 21
                                            NOTABLE IN HEALTH CARE

the union, which represents 42,000 nurses, responded by advocating for protective gear and pressuring the state
Department of Health and certain hospitals to do more to protect the health and safety of nurses treating Covid-19
patients. Kane, a former operating-room nurse, joined the union in 1986 and became its treasurer in 2012, a
position she held until last year. During her tenure, she's helped steer the union toward successful contract
campaigns and focused on safe staffing, climate justice and guaranteed universal health care.

OLIVER KHARRAZ, MD Founder and chief executive officer Zocdoc

By this own account, Dr. Oliver Kharraz comes from a line of doctors dating back 300 years. Now he's making a
name for Zocdoc by bringing some aspects of medicine into the modern age. Kharraz, a former McKinsey
consultant, co-founded Zocdoc, an online, medical appointment-booking platform, to make it easier and faster for
consumers to find nearby doctors and schedule visits. With a growing demand for telehealth, the company added
an option for doctors to offer video visits. Some 8,000 providers initially signed on. It rolled out a videoconferencing
service that doctors can use, for free, for telehealth visits. With its recent expansion into telehealth, Zocdoc is going
up against companies that specialize in the field as well as consumer-facing platforms, such as Skype and Zoom.

ANUJA KHEMKA Executive director Children's Hope India

As the new executive director of Children's Hope India, Anuja Khemka already has made her mark with the
nonprofit's response to Covid-19. The organization, which works to lift children in India and New York from poverty,
launched a rapid-relief program that has provided 500,000 meals, 15,000 pieces of protective gear and about 2,500
soaps, sanitizers and handwashing units to people in need. Before joining Children's Hope this year, Khemka was
executive director at The Steve Fund, where she forged partnerships with universities to create more culturally
sensitive campus environments. In addition to overseeing Children's Hope, Khemka is a Forbes contributor. She is
developing a book series to help children build self-esteem and greater resilience.

ERIC KINARIWALA Founder and chief executive officer Capsule

The coronavirus pandemic has taken a human and economic toll, but it's also benefited certain businesses. Count
Capsule among them. As Americans hunker down, they've become less inclined to venture out to brick-and-mortar
pharmacies. Capsule is an app-based pharmacy offering free, same-day delivery. It has attracted new customers
and seen sales among existing customers rise because of Covid-19. Eric Kinariwala, a former investment analyst,
launched Capsule in 2015 after a self-described miserable drugstore experience. The company was already seeing
robust growth before the pandemic. In 2018 its revenue and its customer count more than tripled. In all, the firm has
raised more than $250 million in venture capital to fund its expansion.

RANDY KLEIN Chief executive officer Vesta Healthcare

During the city's Covid-19 outbreak, Vesta seized an opportunity to prove its value and make a difference. Led by
veteran health care executive Randy Klein, the tech and clinical-services firm connects patients and caregivers to
the rest of the care team through telehealth and other resources. The startup recently entered into a partnership
with JASA, a home-care agency, to support thousands of vulnerable New Yorkers. JASA is a nonprofit that serves
more than 40,000 older adults. Vesta is giving its digital tools and clinical program, including a Covid-19-specific
module, to JASA clients and their caregivers for free. The platform is designed to serve as an early warning system
that helps prevent unnecessary hospitalizations. It addresses social isolation, among other issues.

MARIELLE KRESS Executive director NYC Care

Marielle Kress, a native New Yorker, returned home last year from Washington, D.C., to take a job that would allow
her to give back to her hometown. Little did she know just how much her help would be needed. Kress has spent
about a year managing the rollout of Mayor Bill de Blasio's $100 million care access program. NYC Care
guarantees low- and no-cost care through NYC Health + Hospitals to New Yorkers who don't qualify for or can't
afford health insurance. It has enrolled more than 25,000 people in a city that until recently was the epicenter of the
Covid-19 crisis. Thousands more are expected to enroll in the program when it expands to Manhattan and Queens
in September.

                                                                                                        Page 11 of 21
                                            NOTABLE IN HEALTH CARE

SETH LEDERMAN, MD Cofounder, chief executive officer and chairman Tonix Pharmaceuticals

In the race to develop a novel coronavirus vaccine, publicly traded biopharma firm Tonix is collaborating with the
nonprofit Southern Research of Alabama to develop a live, replicating-virus vaccine intended to confer long-term
immunity. The vaccine candidate is based on a virus that Dr. Seth Lederman thinks is closely related to the first
smallpox vaccine developed by the pioneering English physician Edward Jenner. In July Tonix announced a
research collaboration with Columbia University focused on studying the immune responses to Covid-19 in people
who recovered from it or were asymptomatic. The research collaboration will focus on T-cell and antibody
responses to the virus at the cellular level. Lederman founded cancer-drug developer Targent Pharmaceuticals.

BENJAMINE LIU Co-founder and chief executive officer TrialSpark

While doing graduate work as a Rhodes scholar, Benjamine Liu first noticed that the traditional process of designing
and conducting clinical trials often creates bottlenecks. That realization motivated him to cofound TrialSpark in
2013. The tech firm is shaking up the world of clinical trials and drug development, just in time to fight the
coronavirus pandemic. TrialSpark partners with doctors to create trial sites within their practices, which the
company says boosts participant recruitment rates and patient access to clinical trials. TrialSpark is part of an effort,
supported by tech investor Sam Altman, to speed up Covid-19 research. The project's first study enrolled 500
patients just 10 days after its launch in July.

THERESA MADALINE, MD Health care epidemiologist Montefiore Health System

As a key player in Montefiore Health System's response to Covid-19, Dr. Theresa Madaline helped manage a
surge of patients and implemented protocols to protect staff from infection. Madaline has been Montefiore's trusted
voice on Covid-19, acting as a media source and sharing critical public health messages. She has been on the
front lines of outbreaks before. In 2019 she helped oversee Montefiore's response to a nationwide measles
outbreak. Her work on that front has guided other health care institutions. She's also has driven improvements
across Montefiore, a system that serves more than 3 million people in the Bronx and the Hudson Valley. Last year
Modern Healthcare named her to its Top 25 Emerging Leaders list.

CAROLYN MAGILL Chief executive officer Aetion

As CEO of Aetion, Carolyn Magill delivers real-world analytics and evidence needed to inform critical health care
decisions-which treatments work best, for whom and when. The company's mission is even more urgent in the
Covid-19 era. Aetion landed a research-collaboration agreement in May with the Food and Drug Administration to
use real-world data to advance the understanding of Covid-19 and the response to the disease. The research
supports FDA efforts to understand the natural history of the disease and diagnostic and treatment patterns. Real-
time data can include medical and pharmacy claims, lab test results and electronic medical record information.
Magill's 20 years of leadership experience in health care has focused on the shift from fee-for-service to value-
based care.

SAMIR MALIK Executive vice president and general manager Genoa Telepsychiatry

Samir Malik has spent much of his career breaking down barriers to mental health care. In 2011 he co-founded
1DocWay, a telepsychiatry network operator. Telepsychiatry has helped alleviate the imbalance between growing
demand for mental health services and the number of mental health professionals. Amid the Covid-19 pandemic,
many community mental health centers are relying heavily on telemedicine. Malik's 1DocWay was acquired by
Genoa Healthcare in 2015 and became its telepsychiatry platform. In 2018 UnitedHealth Group acquired Genoa
Healthcare for some $2.5 billion. Under Malik, Genoa Telepsychiatry has become a leader in its field. In the past
year, the platform has provided 250,000 visits, connecting 330 providers to behavioral health centers in more than
30 states.

JOHN MARSHALL, MD Chair, emergency medicine Maimonides Medical Center

                                                                                                      Page 12 of 21
                                            NOTABLE IN HEALTH CARE

Long before the pandemic, Dr. John Marshall had triaged more than a few disaster victims. During his residency in
emergency medicine, he treated victims of the Columbine High School shooting. While serving in the Air Force, he
tended to military personnel in war-torn Afghanistan. But New York's Covid-19 outbreak was like nothing he had
ever seen. Borough Park, home to the 711-bed Maimonides Medical center, was swamped with cases. Marshall led
the hospital's emergency management team through uncharted waters. Drawing on the experiences of doctors in
Italy and elsewhere, he and his team created best practices in real time. During the height of the outbreak, he
shared his team's findings on the use of ventilators with a U.S. Senate subcommittee.

KONSTANTIN MEHL Co-founder and chief executive officer Kaia Health

Getting physical therapy for chronic back pain can be, well, a pain. Now, there's an app for that. Konstantin Mehl, a
self-described serial entrepreneur, co-founded Kaia Health, a digital therapeutic company, in 2016 after years of
struggling to manage chronic back pain. The firm's app-based, mind-body therapies are used to treat back pain,
knee and hip osteoarthritis, and chronic obstructive pulmonary disease. The app works with a smartphone camera
to give users audio feedback as they perform exercises. The Brooklyn company has raised $50 million in venture
capital since its launch. With many medical offices temporarily closed as a result of Covid-19, Kaia Health has seen
an uptick in demand for digital-health services, particularly among high-risk COPD patients.

PARVEZ MIR, MD Director of pulmonary and critical care Wyckoff Heights Medical Center

New York state's first reported Covid-19 death took place at Wyckoff Heights Medical Center, where Dr. Parvez Mir
has practiced for more than two decades. The 350-bed hospital on the border of Brooklyn and Queens would
eventually treat more than 2,000 Covid-19 patients. Hundreds died, as did staff. Many refused to come to work, but
not Mir, who at one point worked for six weeks without a day off. With staff in short supply, he recruited a
pulmonologist from Arkansas. He turned to the blogs of doctors abroad for insight into treating Covid-19. As the
crisis unfolded, Mir told Time magazine that caring for Covid-19 patients is a way to practice living his Muslim faith.

CHERYL MOORE President and COO New York Genome Center

Cheryl Moore has been a driving force behind the New York Genome Center's decision to take on the coronavirus
pandemic. Together with Chief Executive Officer Tom Maniatis, she sets the strategic direction of the nonprofit
research institution, which seeks to better understand the genetic basis of cancer and other diseases. Earlier this
year the center expanded its research to include the study of the genomics underlying the novel coronavirus and
Covid-19, the disease caused by the virus. Its Covid-19 Genomics Research Network, a consortium of 250
scientists and clinicians, is seeking answers to such critical questions as how the coronavirus spreads, and why
some infected people have only mild symptoms and others become critically ill.

MARK MULLIGAN, MD Director, division of infectious diseases and immunology and the Vaccine Center NYU
Langone Health

Dr. Mark Mulligan, a physician-scientist who has studied some of the world's deadliest viruses, has expanded his
focus to the novel coronavirus. Mulligan leads NYU Langone's Vaccine Center, which earlier this year was one of
the first U.S. centers to enroll patients in a clinical trial of Covid-19 vaccine candidates developed by Pfizer and
Germany's BioNTech. The lead vaccine candidate to emerge from the trial has now entered its final phase of study.
That research is taking place at NYU Langone's Vaccine Center and more than 100 other sites worldwide. NYU
Langone was selected for the trial partly because of the expertise of Mulligan, whose infectious-disease research
programs have produced vaccine candidates for HIV and other viruses.

ALAN MURRAY President and chief executive officer Empire BlueCross BlueShield

Alan Murray joined Empire BlueCross BlueShield in 2018 and this year led New York's largest health insurer
through the Covid-19 outbreak. With the pandemic greatly restricting patients' ability to see their doctors, Murray
has worked to expand access to telemedicine for Empire's roughly 4 million members. Empire, for instance,
recently reached an agreement with CityMD to give members access to the urgent care provider's doctors in New
York through LiveHealth Online, Empire's telemedicine platform. Before joining Empire, Murray led Northwell

                                                                                                        Page 13 of 21
                                            NOTABLE IN HEALTH CARE

Health's CareConnect, the state's first provider-owned commercial insurance plan. Murray, a native of Scotland and
a former British Merchant Navy officer, has held senior roles in the New York area at United Healthcare and
Anthem.

MONSIGNOR GREGORY MUSTACIUOLO Chief executive officer Mother Cabrini Health Foundation

Monsignor Gregory Mustaciuolo is the first CEO of the Mother Cabrini Health Foundation. The mammoth
organization launched in 2018 from the proceeds of the Roman Catholic Church's nearly $3.8 billion sale of its
nonprofit health plan, Fidelis Care, to publicly traded Centene Corp. The $3.2 billion foundation, among the largest
in the country, focuses on increasing access to health care in underserved communities across New York state. In
early March the foundation announced inaugural grants of nearly $150 million to fund more than 500 programs and
initiatives that work to improve the health and quality of life for low-income and underserved communities. That
same month, the foundation announced an additional $50 million in emergency funding to support nonprofits
addressing the health needs of New Yorkers affected by Covid-19.

FLORIAN OTTO, MD Co-founder and chief executive officer Cedar

Florian Otto, an entrepreneur and former physician, co-founded Cedar in 2016 after what he describes as a terrible
medical billing experience. The company helps health care providers bring greater convenience, transparency and
personalization to medical billing, ideally resulting in higher collection rates and greater patient satisfaction. Cedar
now serves some of the city's largest providers. In June it announced $102 million in funding, bringing total capital
raised to $157 million. It plans to use the money to attract new clients and expand its product beyond billing and
collection to new areas, such as appointment reminders and digital-registration forms. That strategy will move
Cedar beyond patient billing to what Otto calls a "comprehensive health care consumer engagement platform."

PHILIP OZUAH, MD President and chief executive officer Montefiore Medicine

Dr. Philip Ozuah, who joined Montefiore Medicine as a pediatric intern and resident in 1989, succeeded
Montefiore's retired leader, Dr. Steven Safyer, in November 2019. Ozuah has held a number of leadership positions
at Montefiore Medicine, which includes the Montefiore Health System and the Albert Einstein College of Medicine.
Ozuah is credited with expanding access for underserved communities, recruiting top talent and fostering medical
education innovation, among other achievements. He has used his platform during the pandemic to highlight health
care inequities and Montefiore's efforts to make a difference. "I find it maddening that individuals who live within
blocks of my hospital are made more vulnerable by their physical and social environments," he wrote in a recent
editorial.

LORENZO PALADINO, MD Associate professor, emergency medicine SUNY Downstate and Kings County Medical
Center

Dr. Lorenzo Paladino has served on the front lines of earthquakes and other disasters abroad. This year he found
himself on the front lines of a crisis in his hometown. Paladino's role in the crisis wasn't limited to caring for Covid-
19 patients. Because of his earlier research on ventilators, he was part of a White House task force that established
protocols for how to put multiple patients on ventilators designed for single-patient use. New York was facing the
grim prospect of running out of the machines, leading hospitals to contemplate such drastic measures. In addition,
Paladino is a flight surgeon in the New York Air National Guard's 106th Rescue Wing.

ARTEM PETAKOV Cofounder and president Noom

Artem Petakov's weight-loss app Noom is almost a household name. But it wasn't an overnight success. Petakov,
who discovered his passion for programming at age 9, cofounded Noom with his best friend, Saeju Jeong, in 2008.
Petakov said the two made every startup mistake imaginable, spent years refining Noom and, more than once,
nearly ran out of money. In 2016 they found the right market fit for the app. Last year Noom generated $237 million
in revenue (the bulk of it from users of the app), up from $61 million in 2018 and $12 million in 2017. More people
may turn to Noom this year to fight the weight gain so common it's been dubbed the "Quarantine 15."

                                                                                                    Page 14 of 21
                                           NOTABLE IN HEALTH CARE

ALEXANDER POLLAK Chief executive officer ParaDocs Worldwide Inc.

Alexander Pollak is no stranger to the pivot. Early in his career, he left a high-paying finance job to work in
medicine. The entrepreneur and paramedic launched ParaDocs in 2011, and it soon became a leading provider of
on-site medical treatment at music festivals, among other big events. When the Covid-19 pandemic struck New
York, he turned his company on a dime. Rather than staffing big events, the firm's paramedics and emergency
medical technicians staffed ambulances. Some of its doctors worked in hospitals. ParaDocs handled employee
health screenings to help keep essential businesses and services open. Today ParaDocs is running testing sites,
health screenings and temperature checks at construction sites and office buildings. In addition, it provides on-site
medical care and Covid-19 compliance work for film productions and fashion shows.

DAVID V. POMERANZ Chief operating officer Hebrew Home at Riverdale by RiverSpring Health

Nursing home residents have been devastated by Covid-19, as have the workers who care for them. At Hebrew
Home at Riverdale in the Bronx, keeping workers and residents safe and emotionally grounded while complying
with government mandates falls to David Pomeranz. Since May, the Hebrew Home has been testing its 1,000
employees for Covid-19 every week at an estimated cost of $600,000 a month. To tackle that task, Hebrew Home
repurposed its own nursing staff, secured testing supplies and partnered with New York-Presbyterian to expedite
the test processing. Pomeranz made headlines by championing a new program that uses a drive-in movie model to
allow residents to visit with family from a safe distance. Visitors stay in their parked cars and communicate through
a wireless speaker with loved ones visible in an enclosed vestibule.

CLAIRE POMEROY, MD President Lasker Foundation

Dr. Claire Pomeroy, an expert in infectious diseases, is a longtime public health advocate, with a focus on patients
with HIV and AIDS. As head of the Lasker Foundation since 2013, Pomeroy is responsible for advancing the
group's mission to "improve health by accelerating support for medical research through recognition of research
excellence, education and advocacy." She passionately supports continued investment in medical research and
has an interest in health care policy and the importance of the social determinants of health. Throughout the
pandemic, Pomeroy has served as a media source. She has framed the crisis as an opportunity to gain medical
research insight to help form a response to the pandemic and prepare society for future outbreaks of disease.

JULIA RAMIREZ Community outreach manager Immigrant Health and Cancer Disparities Service Memorial Sloan
Kettering Cancer Center

The pandemic has exacerbated health care disparities. For Julia Ramirez, these disparities have been the heart of
her career. Ramirez runs Memorial Sloan Kettering programs, including a hospital-based food pantry initiative, that
help eliminate disparities in health and cancer treatment among underserved patients. Her Food to Overcome
Outcomes Disparities program is a lifeline for many New Yorkers. The Covid-19 crisis worsened food insecurity and
made many cancer patients fearful of leaving their homes. Ramirez responded by rolling out a delivery service. She
enlisted the help of redeployed MSK jitney drivers, food-delivery companies and even laid-off cabdrivers. In recent
months the Food program has delivered nearly 20,000 meals to more than 400 cancer patients.

RAM RAJU, MD Former senior vice president and community health investment officer Northwell Health

The pandemic has created a sense of greater urgency when it comes to tackling health care disparities. But Dr.
Ram Raju has long been on the front lines of the fight for greater equity. Raju spent the past several years working
to better understand the needs of Northwell's most-vulnerable communities and finding ways to meet those needs.
Before joining Northwell, he was the president and CEO of NYC Health + Hospitals, the country's largest public
health system and a major safety-net provider. He was tapped for the position at Northwell, New York's largest
health care provider, because of his leadership experience, dedication to caring for vulnerable communities and
deep understanding of the state's health care system. Raju recently retired.

KENNETH RASKE President Greater New York Hospital Association

                                                                                                      Page 15 of 21
                                            NOTABLE IN HEALTH CARE

As health care workers toiled on the front lines of the city's Covid-19 outbreak, Kenneth Raske and his colleagues
at the Greater New York Hospital Association worked behind the scenes to juggle hospitals' response to the crisis
and shore up their finances. As president of the trade group since 1984, Raske is the direct liaison between
hospitals and state officials. He recently co-led a group to oversee hospital efforts to expand their capacity by
thousands of beds in response to an order by Gov. Andrew Cuomo. He oversaw efforts to help hospitals deal with
huge financial hits because of higher labor and equipment costs and suspended elective procedures. The
association's aggressive lobbying campaign helped hospitals land $5 billion in federal Covid-19 funding in May.

ZACHARIAH REITANO Cofounder and chief executive officer Ro

Motivated by his own health care struggles, Zachariah Reitano, a former entrepreneur-in-residence at venture
capital firm Prehype, cofounded the online pharmacy and telemedicine startup Ro in 2017. Among the most well-
capitalized firms in the health-tech sector, Ro has since raised $376 million in funding. It is among the companies
that have recently taken a strong public stand in support of the Black Lives Matter movement. In early June, Ro
posted a Twitter statement in support of Black Lives Matter that told followers "if you disagree with this statement or
feel it's in any way controversial, don't use our services and unfollow us."

DARA RICHARDSON-HERON, MD Chief patient officer Pfizer Inc.

Dr. Dara Richardson-Heron has dedicated her career to reducing health care disparities and improving patient
outcomes. As chief patient officer, Richardson-Heron leads Pfizer's efforts to advance patient-focused programs
and platforms. Before joining Pfizer in February, she was the chief engagement officer and scientific executive for
the National Institutes of Health's All of Us research program. With the goal of improving the prevention and
treatment of diseases, she led outreach efforts from 2017 to this year to enroll and retain more than a million
volunteers to share their health data. Her other leadership roles include CEO of YWCA USA, CEO of the Greater
New York City Affiliate of Susan G. Komen for the Cure and national chief medical officer for the United Cerebral
Palsy Association.

NAVARRA RODRIGUEZ, MD President and chief medical officer AdvantageCare Physicians

Under Dr. Navarra Rodriguez's guidance, AdvantageCare Physicians has helped bring New York's once-
skyrocketing Covid-19 infection rate under control. Rodriguez, who has been in her position since 2016, oversees
medical leadership and health improvement activities at AdvantageCare, one of the largest primary and specialty
care practices in the metropolitan area. In May she brokered partnerships with New York City and the state that led
to the opening of more than 20 Covid-19 testing sites at the network's community-based medical offices in low-
income areas. In addition to ramping up the city's Covid-19 testing in hard-hit neighborhoods, AdvantageCare
helped alleviate the strain on hospitals by offering telehealth services and patient referrals to Cityblock and
EmblemHealth Neighborhood Care, among other partners.

RAMON RODRIGUEZ President and chief executive officer Wyckoff Heights Medical Center

If New York had a ground zero for the pandemic, it might be Wyckoff Heights Medical Center. The community
hospital had the state's first reported Covid-19 death and went on to treat 2,000 Covid-19 patients. Ramon
Rodriguez led the overburdened hospital through the crisis. While other hospital executives scrambled for protective
gear and ventilators, Wyckoff was mostly short on staff. Out of fear and exhaustion, some employees stopped
showing up. Many workers became infected. Today Rodriguez is working to put Wyckoff-which, like other hospitals,
saw revenues decline as a result of the outbreak-back on firm financial footing. Rodriguez joined Wyckoff in 2011
with a promise to improve the hospital's patient care and fiscal stability.

KATE RYDER Founder and chief executive officer Maven

After stints in venture capital and business journalism, Kate Ryder became an entrepreneur in 2014 with a mission
to transform health care for women and their families. Ryder founded Maven, which offers virtual care and health
services in fertility, maternity care and pediatrics, among other areas. Maven aims to help employers and health
plans achieve improved maternal outcomes and lower costs while attracting and retaining more working parents.

                                                                                                    Page 16 of 21
                                           NOTABLE IN HEALTH CARE

The company has raised more than $87 million from investors, among them Sequoia Capital, Oak HC/FT and Icon
Ventures. Before founding Maven, Ryder wrote for The Economist from Southeast Asia, New York and London, and
for the New Yorker. In 2009, she helped the former U.S. Treasury Secretary Hank Paulson write his memoirs about
the financial crisis.

DAVID SANDMAN President and chief executive officer New York State Health Foundation

David Sandman, a public-health thought leader, has overseen the New York State Health Foundation since 2016.
The private foundation works to improve the health of New Yorkers, especially its most vulnerable residents. Earlier
this year it committed $5 million to support the Covid-19 response and relief efforts in New York state. Since 2006,
the foundation has invested more than $150 million in health care initiatives. It has helped millions of New Yorkers
gain health insurance with its support of the Affordable Care Act and the Essential Plan, an optional benefit for
insuring lower-income people ineligible for Medicaid. Sandman was drawn to the field of public health during the
AIDS/HIV crisis of the 1980s and early 1990s. His career in health care has been "bookended" by AIDS/HIV and
Covid-19.

BARBARA SAMPSON Chief medical examiner City of New York

Dr. Barbara Sampson, a forensic pathologist, is the city's first female chief medical examiner. She also will go down
in history as a pivotal player in its response to its worst mass casualty since the 1918 flu pandemic. Borrowing from
its 9/11 playbook, her office mounted a Herculean effort to deal with the surge of Covid-19 deaths that overwhelmed
hospital morgues and funeral homes. Her office set up four temporary morgue sites throughout the city and sent
more than 100 refrigerated trucks to hospitals. The office, with National Guard reinforcement, dramatically scaled
up its ability to investigate deaths and respond to at-home deaths. It credits stringent safety measures for keeping
infections among its staff to a small number.

CHARLES SCHLEIEN, MD Senior vice president of Cohen Children's Medical Center & Pediatric Services Chair of
the Department of Pediatrics at the Donald and Barbara Zucker School of Medicine at Hofstra/Northwell Health

Dr. Charles Schleien has experienced the coronavirus pandemic from two sides: as a doctor on the front lines and
as a Covid-19 patient. While helping to plan Northwell Health's response to the pandemic, Schleien was diagnosed
with Covid-19 and struggled for 12 days at home before he was admitted to North Shore University Hospital.
Schleien recovered and returned to his pivotal role at Cohen Children's Medical Center, part of Northwell Health,
and in April he chronicled the harrowing health experience in an op-ed for The New York Times. The pediatric
hospital has been a leader in treating children with Covid-19 and helped identify a potentially severe inflammatory
syndrome linked to the disease.

TALYA SCHWARTZ, MD President and chief executive officer MetroPlusHealth

MetroPlusHealth, owned by NYC Health + Hospitals Corp., has ranked among the top insurers in the state for
quality under the leadership of CEO Talya Schwartz. Schwartz, who rose to the top post in May 2019, has led
technology solutions that enhance access to health care and pertinent health information for its more than 500,000
members. During the Covid-19 pandemic, Schwartz rapidly initiated outreach and support efforts to serve the plan's
membership. Previously she was MetroPlusHealth's chief medical officer, leading the medical management
division. In that role, she transformed the care management program into a holistic, field-based program that
tackles social determinants of health with a special focus on housing the homeless.

CHANAKA SENEVIRATNE Pulmonologist and critical care specialist Maimonides Medical Center

Dr. Chanaka Seneviratne, or "Dr. Sen" as colleagues and house staff affectionately call him, "reminds you of those
lofty reasons you went to medical school but somehow forgot in the reality that medicine is today," a former student
wrote. Senevirantne's "profound sense of dedication to patients" has inspired generations of critical care fellows to
whom he remains a mentor long after their graduation. Seneviratne, extremely knowledgeable and skilled, trains
young doctors in the intensive care unit to embrace "a lifelong enthusiasm for learning and an everlasting empathy

                                                                                                        Page 17 of 21
                                             NOTABLE IN HEALTH CARE

for your patient," his former student added. "Never one to push for personal accolades, he is most recognized and
valued by the people who ultimately matter most: his patients and his students.

ALLISON SESSO Executive director RIP Medical Debt

RIP Medical Debt takes aim at the nation's medical debt crisis, which is expected to worsen because of the
coronoavirus's toll on the nation's health and the economy. The nonprofit raises money to buy medical debt at a
steep discount in bundled portfolios for pennies on the dollar. It reports it has abolished $2 billion in debt so far for
1.5 million low-income families. Under Allison Sesso, who joined RIP Medical Debt in January, the nonprofit
recently launched a Helping Covid Heroes Fund that pays down medical debt owed by front-line health care
workers, emergency responders and service workers hurt by the recession. The fund has wiped out more than
$100 million in debt.

RAHUL SHARMA, MD Professor and chairman, department of emergency medicine, Weill Cornell Medicine
Emergency physician-in-chief, New York Presbyterian/Weill Cornell Medical Center

Dr. Rahul Sharma saw the promise of telemedicine long before the novel coronavirus fueled a surge in demand for
health care delivered digitally. In the past four years, he has launched several telemedicine programs at Weill
Cornell Medicine, including an initiative that allows patients whose conditions aren't life threatening to visit virtually
with an emergency-medicine doctor. By targeting patients with minor conditions who are already in the emergency
department, the program has significantly reduced wait times while maintaining patient safety and satisfaction.
Recognizing the importance of teaching virtual care skills to physicians and medical students, Sharma launched a
center within the emergency department that has trained hundreds of practitioners.

PETER SHEARER, MD Chief medical officer and vice president of medical staff Mount Sinai Brooklyn

Dr. Peter Shearer has been a leader in emergency medicine in the city for two decades. Since 2018 he has been
chief medical officer at Mount Sinai Brooklyn, which treated many Covid-19 patients. Although most recovered, the
hospital saw so many deaths that it brought in a cooler truck in case its small morgues reached capacity. Many of
its staff grew ill during the outbreak, and Shearer worries about the pandemic's impact on the mental health of
front-line workers. Throughout this experience, Shearer has bravely served the hospital and its community. He led
his team to quickly triage, treat and stabilize emergency department patients. If needed, his team facilitated safe
transfer of patients to Mount Sinai Hospital in Manhattan.

ANTHONY SHIH, MD President United Hospital Fund

Since Dr. Anthony Shih took the helm of the United Hospital Fund in 2017, he has taken the nonprofit in new
directions. UHF focuses on improving access to quality, affordable care for all New Yorkers. Passionate about
improving health care for the underserved, Shih built clinical and community partnerships and put a greater
emphasis on the welfare of children and on diversity, equity and inclusion. Under Shih, for example, UHF has
brought national attention to children affected by the opioid crisis. In May he was appointed to one of Mayor Bill de
Blasio's councils working on a post-pandemic recovery plan. In addition, Shih is on a mayoral committee that's
focused on building a more resilient and just city.

CRAIG SPENCER, MD Director, global health in emergency medicine New York-Presbyterian/Columbia University
Medical Center

Dr. Craig Spencer was prepared for his time on the front lines of the city's Covid-19 outbreak in more ways than
one. In 2014 he became the first person in the city to be diagnosed with Ebola, a disease he contracted while caring
for Ebola patients in Guinea as a Doctors Without Borders volunteer. Even when the U.S. had just a handful of
diagnosed coronavirus infections, he was among the first public health experts to sound an alarm about the
country's lack of preparedness for a pandemic. Spencer, a board member of Doctors Without Borders, now divides
his time between providing clinical care in New York and working internationally in public health.

ADAM REED STRACHER, MD Chief medical officer, director of primary care division Weill Cornell Medicine

                                                                                                     Page 18 of 21
                                           NOTABLE IN HEALTH CARE

Dr. Adam Stracher was a driving force behind Weill Cornell Medicine's early adoption of telehealth. When the
Covid-19 outbreak struck the city, Weill Cornell Medicine was able to quickly scale up its capacity to offer primary
care through digital tools. Through its expanded telehealth platform, Weill Cornell Medicine offered uninterrupted
care to patients with chronic conditions and those managing Covid-19 at home, which, in turn, reduced the strain on
hospitals. Weill Cornell Medicine's digital transformation has led to a more patient-friendly and safer experience
during the pandemic. Stracher, an internal medicine physician with a specialty in infectious diseases, has said that
telemedicine will continue to play a big role at Weill Cornell and other health care institutions even after the
pandemic ends.

RAMON TALLAJ, MD Cofounder and chairman Somos Community Care

Dr. Ramon Tallaj oversees a network of more than 2,500 primary care doctors who care for hundreds of thousands
of New Yorkers in underserved communities across the city. Tallaj, a native of the Dominican Republic, has led
health care missions to the Caribbean, including a delegation of Somos doctors who cared for victims of Hurricane
Maria in remote areas of Puerto Rico. Since the start of the pandemic, Tallaj has focused on ensuring equitable
access to care, Covid-19 testing, and resources for the city's minority and immigrant communities. In June, for
instance, Somos announced a partnership with Community Organized Relief Effort, the emergency-relief nonprofit
cofounded by actor Sean Penn, to open five testing sites in marginalized communities.

ALEX TANG Clinical director Coalition of Asian-American IPA

Alex Tang directs the clinical operations of the Coalition of Asian-American IPA, an independent practice
association of more than 1,000 providers in 70 health care specialties. He spearheaded the network's rollout of
mobile Covid-19 testing sites in several low-income communities during the city's outbreak. More than 1,500 free
tests were administered at the sites, which followed safety protocols similar to those used in South Korea to reduce
the risk of accidental infection at testing facilities. Tang, a licensed physician assistant with extensive clinical
experience, led a team of physician assistants to launch the sites in Lower Manhattan, Sunset Park in Brooklyn,
and Elmhurst and Flushing, Queens, all neighborhoods with large Asian populations.

GARY TERRINONI President and chief executive officer Brooklyn Hospital Center

The Brooklyn Hospital Center is the borough's oldest hospital. This year it also became known as an epicenter of
the city's Covid-19 outbreak. The safety-net hospital captured national attention for the valiant fight it mounted
under Gary Terrinoni, who has led the hospital since 2015. Terrinoni has worked to build a culture of inclusion,
which served the hospital well during its darkest hour. Many nurses and other staff members fell ill, but the hospital
redeployed workers to keep up with the surge of Covid-19 patients. Some employees even volunteered for front-line
service. The hospital also marked some happy milestones this year. It opened a state-of-the-art physicians pavilion,
a Terrinoni initiative, and celebrated its 175th anniversary.

FLORIAN THOMAS, MD Chair, department of neurology and the Neuroscience Institute Hackensack University
Medical Center and Hackensack Meridian School of Medicine

Though physicians first classified Covid-19 as a respiratory illness, they soon recognized a range of symptoms
associated with the disease, from kidney failure to altered smell. Dr. Florian Thomas, a neurologist and researcher,
is working to understand how Covid-19 can affect the nervous system. He is in an ideal position to undertake the
research, which entails documenting neurological complaints from hospital patients and reviewing records of
discharged patients. Hackensack Meridian Health has treated thousands of Covid-19 patients, more than any other
health system in New Jersey. Thomas notes that Covid-19 can damage the heart muscle and lead to congestive
heart failure, which can bring on irregular heartbeats that trigger strokes. Covid-19 can cause inflammation that can
make the blood clot more quickly.

NANCY THORNBERRY Chief executive officer Kallyope

In 2016 Nancy Thornberry got in on the ground floor of a Manhattan biotech startup that seeks to develop drugs to
treat diseases linked to the gut-brain axis. Defects in the gut-brain axis-a two-way communication highway between

                                                                                                        Page 19 of 21
                                             NOTABLE IN HEALTH CARE

the stomach and the central nervous system-have been linked to obesity, diabetes, gastrointestinal disorders,
Parkinson's and other diseases. Under Thornberry, a 30-year veteran of the pharmaceutical industry, Kallyope has
made major strides in understanding the gut-brain axis and is considering its first clinical trials. In March it raised
$112 million from investors, including Bill Gates, to advance existing programs and undertake clinical trials. Its initial
focus is on drugs to treat metabolic and central nervous system disorders.

VALERIE VERMIGLIO-KOHN Vice president and chief nursing officer Burke Rehabilitation Hospital

Since joining Burke Rehabilitation Hospital in January 2019, Valerie Vermiglio-Kohn has worked to foster a culture
of trust and excellence in the nursing department and other areas of the hospital, part of the Montefiore Health
System. While she's passionate about improving patient care through evidence-based practice, Vermiglio-Kohn
also champions staff wellness. Earlier this year she was a key player in the hospital's Covid-19 response. She
helped the hospital increase its capacity to care for recovering patients on an inpatient basis to alleviate pressure
on acute-care hospitals, and she quickly established training for redeployed staff. In addition, Vermiglio-Kohn led
the implementation of rapidly changing clinical practice guidelines for infection control and care for survivors of the
coronavirus.

ANTHONY VICEROY Chief executive officer Westmed Medical Group

Westmed Medical Group is one of several large physician practices that have reshaped the medical landscape in
the New York City suburbs. Under Anthony Viceroy's direction, Westmed has played a critical role in shaping the
response to the Covid-19 pandemic in its backyard. During the outbreak earlier this year, Viceroy overcame difficult
odds to secure outpatient Covid-19 testing for the Westchester community, along with a supply of protective gear
that allowed Westmed to provide uninterrupted care. He led Westmed's telehealth expansion- rolling out virtual
access to more than 300 doctors in a matter of days-and developed a plan to keep the practice on firm financial
footing in the face of pandemic-induced disruptions.

DARREN WALKER President, Ford Foundation Chair, NYC Census 2020

As president of the Ford Foundation, a $13 billion international social justice philanthropy, Darren Walker took an
unprecedented step in June in response to the Covid-19 crisis. The foundation announced it would issue $1 billion
in 30-and 50-year taxable social bonds, applying the net proceeds to support social justice, human services, arts
and cultural organizations. "We are facing a once-in-a-century crisis, and we must respond in unprecedented ways
to sustain organizations that are advancing the fight against inequality at a time when the need is more pressing
than ever," Walker said at the time. Walker joined Ford in 2010 as vice president of education, creativity and free
expression. He became president in 2013. Previously he was president at the Rockefeller Foundation, where he
oversaw global and domestic programs.

ANDREW B. WALLACH, MD Ambulatory care chief, NYC Health + Hospitals/Bellevue Chief medical officer for
ambulatory care, NYC Health + Hospitals Chief medical officer, NYC Test & Trace Corps

Dr. Andrew B. Wallach, a dedicated physician and a natural leader, has headed ambulatory care at Bellevue
Hospital since 2013. He has guided his team four times to achieve Level 3 Recognition-the highest grade issued by
the National Committee for Quality Assurance-as a patient-centered medical home for Bellevue's Primary Care
Services. Under his leadership, the health system reduced primary care wait times for appointments from more
than 60 to less than 14 days. In response to the Covid-19 crisis, Wallach has led testing initiatives at the public
hospital system. As chief medical officer for the NYC Test & Trace Corps, he oversees all clinical activity for Covid-
19 testing and contact tracing citywide. Earlier this year NYC Health+Hospitals promoted Wallach to chief medical
officer for ambulatory care.

LOUISE WEADOCK Chief executive officer and chief nursing officer Access Nursing Services

In January, long before Covid-19 was on everyone's radar, Dr. Louise Weadock anticipated the fatalities and the
disruptions and strains on hospital capacity. She launched the Covid Care Force, which recruited, screened and
Covid-19-trained 1,500 nurses to work in hospitals, nursing homes and testing sites in some of the hardest-hit

                                                                                                       Page 20 of 21
                                            NOTABLE IN HEALTH CARE

communities in New York, New Jersey and Connecticut. Later, she founded a new Access Nursing company, Covid
Clear Services, which helps employers meet the Centers for Disease Control and Prevention's Phase I, II and II
guidelines to safely reopen essential, nonessential and high-risk business operations in the U.S. With five city-
center offices and seven hospital-based offices, Weadock doubled her organization's workforce, employing more
than 2,000 registered nurses, licensed practical nurses, assistants, technicians and phlebotomists to work within
every clinical setting.

CAROLYN WITTE Cofounder and chief executive officer Tia

Carolyn Witte's venture-backed startup is building a personalized, care-delivery model for women. Although they
control more than 80% of U.S. health care spending, women have been underserved by a medical system that
treats them as "small men with different parts," Tia claims. Witte, a veteran of Google's creative lab, first came up
with the idea for Tia-a network of digital wellness apps, clinics and telehealth services delivering holistic care-after
her own health issues led her to become disillusioned with the status quo in women's care. Tia recently raised
more than $24 million in a new round of funding to support the expansion of its telehealth and clinical services to
new markets.

GEORGE YANCOPOULOS Cofounder, president and chief scientific officer Regeneron

Dr. George Yancopoulos has been the lead inventor and drug developer at Regeneron since the company's launch
in 1988. The biotech firm has developed blockbuster drugs for blindness-causing diseases and asthma, among
other conditions. Regeneron is among the companies that have begun human trials of experimental therapies for
the coronavirus. In June, Regeneron began clinical trials of its antibody cocktail to treat people with Covid-19 and
prevent infection. Yancopoulos has deep roots in New York. After graduating from the Bronx High School of
Science and Columbia College, he received his medical degree and doctorate in biochemistry and molecular
biophysics from Columbia University. He began his career as an academic scientist in the field of molecular biology
at Columbia.

MICHELLE ZETTERGREN President MagnaCare

Michelle Zettergren, known for her entrepreneurial spirit, spearheaded MagnaCare's recent partnership with
BioReference Laboratories to offer Covid-19 antibody testing to labor members. The initiative could help guide
decision-making about return-to-work procedures and safety measures to protect workers and the general public.
MagnaCare started in 1992 by serving organized labor and public sector clients, and it now administers health
plans for self-insured labor and commercial clients. Labor is especially worried about how to operate work spaces
safely during the pandemic, given that skilled laborers were among the first group of employees to return to work.
MagnaCare recently noted that for Covid-19 claims between March and April, patients on ventilators had average
hospitalization costs of $100,000 to $300,000.

ANDREI ZIMILES Cofounder and chief executive officer Doctor.com

Since launching Doctor.com in 2013, Andrei Zimiles has nurtured it from a small team to 200 employees. The
health care marketing company now serves more than 200 hospitals and health systems and thousands of private
and group practices. Zimiles, who began his career at age 16 building websites, recently expanded Doctor.com into
telemedicine. In May, his firm rolled out a telemedicine platform that the company says allows providers to begin
practicing medicine virtually in a matter of minutes, free of charge. Doctor.com has seen a huge uptick in
telemedicine usage. In an April survey of Doctor.com doctors, telemedicine use soared from 25% in 2019 to more
than 85%.

BARRY ZINGMAN, MD Clinical director, infectious diseases, Moses division of Montefiore Health System Medical
director of the Montefiore AIDS Center Professor of medicine, Albert Einstein College of Medicine

Dr. Barry Zingman, a pioneer in the field of HIV/AIDS, is helping to lead the charge to develop therapies for the
sickest Covid-19 patients. Earlier this year he oversaw a study at Montefiore Health System of the antiviral drug
Remdesivir that yielded promising results. Under a multicenter trial sponsored by the National Institutes of Health,

                                                                                                    Page 21 of 21
                                           NOTABLE IN HEALTH CARE

his team is studying other Covid-19 treatments. Zingman is leading an initiative to offer Covid-19 vaccine studies to
Bronx residents. His interest in infectious diseases began in the early 1980s, when he was a medical student caring
for people with a then-unnamed illness that disproportionately affected young men, drug users and people of color.


Load-Date: August 13, 2020


  End of Document

                                                                                                          Page 1 of 3
                                            How Tech Dreams Go Up in Smoke




                                  How Tech Dreams Go Up in Smoke
                                                  The New York Times
                                               December 7, 2023 Thursday
                                                   Late Edition - Final



Copyright 2023 The New York Times Company

Section: Section B; Column 0; Business/Financial Desk; Pg. 1
Length: 1243 words
Byline: By Erin Griffith

Body


After staving off collapse by cutting costs, many young tech companies are out of options, fueling a cash bonfire.

WeWork raised more than $11 billion in funding as a private company. Olive AI, a health care start-up, gathered
$852 million. Convoy, a freight start-up, raised $900 million. And Veev, a home construction start-up, amassed
$647 million.

 In the last six weeks, they all filed for bankruptcy or shut down. They are the most recent failures in a tech start-up
collapse that investors say is only beginning.

 After staving off mass failure by cutting costs over the past two years, many once-promising tech companies are
now on the verge of running out of time and money. They face a harsh reality: Investors are no longer interested in
promises. Rather, venture capital firms are deciding which young companies are worth saving and urging others to
shut down or sell.

  It has fueled an astonishing cash bonfire. In August, Hopin, a start-up that raised more than $1.6 billion and was
once valued at $7.6 billion, sold its main business for just $15 million. Last month, Zeus Living, a real estate start-up
that raised $150 million, said it was shutting down. Plastiq, a financial technology start-up that raised $226 million,
went bankrupt in May. In September, Bird, a scooter company that raised $776 million, was delisted from the New
York Stock Exchange because of its low stock price. Its $7 million market capitalization is less than the value of the
$22 million Miami mansion that its founder, Travis VanderZanden, bought in 2021.

 ''As an industry we should all be braced to hear about a lot more failures,'' said Jenny Lefcourt, an investor at
Freestyle Capital. ''The more money people got before the party ended, the longer the hangover.''

  Getting a full picture of the losses is difficult since private tech companies are not required to disclose when they
go out of business or sell. The industry's gloom has also been masked by a boom in companies focused on artificial
intelligence, which has attracted hype and funding over the last year.

                                                                                                        Page 2 of 3
                                         How Tech Dreams Go Up in Smoke

 But approximately 3,200 private venture-backed U.S. companies have gone out of business this year, according to
data compiled for The New York Times by PitchBook, which tracks start-ups. Those companies had raised $27.2
billion in venture funding. PitchBook said the data was not comprehensive and probably undercounts the total
because many companies go out of business quietly. It also excluded many of the largest failures that went public,
such as WeWork, or that found buyers, like Hopin.

 Carta, a company that provides financial services for many Silicon Valley start-ups, said 87 of the start-ups on its
platform that raised at least $10 million had shut down this year as of October, twice the number for all of 2022.

  This year has been ''the most difficult year for start-ups in at least a decade,'' Peter Walker, Carta's head of
insights, wrote on LinkedIn.

 Venture investors say that failure is normal and that for every company that goes out of business, there is an
outsize success like Facebook or Google. But as many companies that have languished for years now show signs
of collapse, investors expect the losses to be more drastic because of how much cash was invested over the last
decade.

 From 2012 to 2022, investment in private U.S. start-ups ballooned eightfold to $344 billion. The flood of money
was driven by low interest rates and successes in social media and mobile apps, propelling venture capital from a
cottage financial industry that operated largely on one road in a Silicon Valley town to a formidable global asset
class akin to hedge funds or private equity.

  During that period, venture capital investing became trendy -- even 7-Eleven and ''Sesame Street'' launched
venture funds -- and the number of private ''unicorn'' companies worth $1 billion or more exploded from a few dozen
to more than 1,000.

 But the advertising profits gushing from the likes of Facebook and Google proved elusive for the next wave of
start-ups, which have tried untested business models like gig work, the metaverse, micromobility and
cryptocurrencies.

  Now some companies are choosing to shut down before they run out of cash, returning what remains to investors.
Others are stuck in ''zombie'' mode -- surviving but unable to grow. They can muddle along like that for years,
investors said, but will most likely struggle to raise more money.

 Convoy, the freight start-up that investors valued at $3.8 billion, spent the last 18 months cutting costs, laying off
staff and otherwise adapting to the difficult market. It wasn't enough.

 As the company's money ran low this year, it lined up three potential buyers, all of whom backed out. Coming so
close, said Dan Lewis, Convoy's co-founder and chief executive, ''was one of the hardest parts.'' The company
ceased operations in October. In a memo to employees, Mr. Lewis called the situation ''the perfect storm.''

  Such port-mortem assessments, where founders announce their company is closing and reflect on lessons
learned, have become common.

  One entrepreneur, Ishita Arora, wrote this week that she had to ''confront reality'' that Dayslice, her scheduling
software start-up, was not attracting enough customers to satisfy investors. She returned some of the cash she had
raised. Gabor Cselle, a founder of Pebble, a social media start-up, wrote last month that despite feeling that he had
let the community down, trying and failing was worth it. Pebble is returning to investors a small portion of the money
it had raised, Mr. Cselle said. ''It felt like the right thing to do.''

 Amanda Peyton was surprised by the reaction to her blog post in October about the ''dread and loneliness'' of
shutting down her payments start-up, Braid. More than 100,000 people read it, and she was flooded with messages
of encouragement and gratitude from fellow entrepreneurs.

 Ms. Peyton said she had once felt that the opportunity and potential for growth in software was infinite. ''It's
become clear that that's not true,'' she said. ''The market has a ceiling.''

                                                                                                              Page 3 of 3
                                           How Tech Dreams Go Up in Smoke

 Venture capital investors have taken to gently urging some founders to consider walking away from doomed
companies, rather than waste years grinding away.

  ''It might be better to accept reality and throw in the towel,'' Elad Gil, a venture capital investor, wrote in a blog post
this year. He did not respond to a request for comment.

  Ms. Lefcourt of Freestyle Ventures said that so far, two of her firm's start-ups had done exactly that, returning 50
cents on the dollar to investors. ''We're trying to point out to founders, 'Hey, you don't want to be caught in no man's
land,''' she said.

 One area that is thriving? Companies in the business of failure.

 SimpleClosure, a start-up that helps other start-ups wind down their operations, has barely been able to keep up
with demand since it opened in September, said Dori Yona, the founder. Its offerings include helping prepare legal
paperwork and settling obligations to investors, vendors, customers and employees.

 It was sad to see so many start-ups shutting down, Mr. Yona said, but it felt special to help founders find closure --
both literally and figuratively -- in a difficult time. And, he added, it is all part of Silicon Valley's circle of life.

 ''A lot of them are already working on their next companies,'' he said.

 Kirsten Noyes contributed research.Kirsten Noyes contributed research.


https://www.nytimes.com/2023/12/07/technology/tech-startups-collapse.html



Graphic


PHOTO: In September, Bird, a scooter company and app that raised $776 million, was delisted from the New York
Stock Exchange because of its low stock price. (PHOTOGRAPH BY TARA PIXLEY FOR THE NEW YORK TIMES)
(B4) This article appeared in print on page B1, B4.


Load-Date: December 7, 2023


  End of Document

                                                                                                          Page 1 of 3
                        From Unicorns to Zombies: Tech Start-Ups Run Out of Time and Money




    From Unicorns to Zombies: Tech Start-Ups Run Out of Time and Money
                                                     The New York Times
                                          December 7, 2023 Thursday 18:32 EST



Copyright 2023 The New York Times Company All Rights Reserved

Section: TECHNOLOGY
Length: 1273 words
Byline: Erin Griffith &lt;p&gt;Erin Griffith covers tech companies, start-ups and the culture of Silicon Valley from San
Francisco.&lt;/p&gt;
Highlight: After staving off collapse by cutting costs, many young tech companies are out of options, fueling a cash
bonfire.

Body


After staving off collapse by cutting costs, many young tech companies are out of options, fueling a cash bonfire.

WeWork raised more than $11 billion in funding as a private company. Olive AI, a health care start-up, gathered
$852 million. Convoy, a freight start-up, raised $900 million. And Veev, a home construction start-up, amassed
$647 million.

In the last six weeks, they all filed for bankruptcy or shut down. They are the most recent failures in a tech start-up
collapse that investors say is only beginning.

After staving off mass failure by cutting costs over the past two years, many once-promising tech companies are
now on the verge of running out of time and money. They face a harsh reality: Investors are no longer interested in
promises. Rather, venture capital firms are deciding which young companies are worth saving and urging others to
shut down or sell.

It has fueled an astonishing cash bonfire. In August, Hopin, a start-up that raised more than $1.6 billion and was
once valued at $7.6 billion, sold its main business for just $15 million. Last month, Zeus Living, a real estate start-up
that raised $150 million, said it was shutting down. Plastiq, a financial technology start-up that raised $226 million,
went bankrupt in May. In September, Bird, a scooter company that raised $776 million, was delisted from the New
York Stock Exchange because of its low stock price. Its $7 million market capitalization is less than the value of the
$22 million Miami mansion that its founder, Travis VanderZanden, bought in 2021.

“As an industry we should all be braced to hear about a lot more failures,” said Jenny Lefcourt, an investor at
Freestyle Capital. “The more money people got before the party ended, the longer the hangover.”

Getting a full picture of the losses is difficult since private tech companies are not required to disclose when they go
out of business or sell. The industry’s gloom has also been masked by a boom in companies focused on artificial
intelligence, which has attracted hype and funding over the last year.

                                                                                                         Page 2 of 3
                      From Unicorns to Zombies: Tech Start-Ups Run Out of Time and Money

But approximately 3,200 private venture-backed companies around the world have gone out of business this year,
according to data compiled for The New York Times by PitchBook, which tracks start-ups. Those companies had
raised $27.2 billion in venture funding. PitchBook said the data was not comprehensive and probably undercounts
the total because many companies go out of business quietly. It also excluded many of the largest failures that went
public, such as WeWork, or that found buyers, like Hopin.

Carta, a company that provides financial services for many Silicon Valley start-ups, said 87 of the start-ups on its
platform that raised at least $10 million had shut down this year as of October, twice the number for all of 2022.

This year has been “the most difficult year for start-ups in at least a decade,” Peter Walker, Carta’s head of insights,
wrote on LinkedIn.

Venture investors say that failure is normal and that for every company that goes out of business, there is an
outsize success like Facebook or Google. But as many companies that have languished for years now show signs
of collapse, investors expect the losses to be more drastic because of how much cash was invested over the last
decade.

From 2012 to 2022, investment in private U.S. start-ups ballooned eightfold to $344 billion. The flood of money was
driven by low interest rates and successes in social media and mobile apps, propelling venture capital from a
cottage financial industry that operated largely on one road in a Silicon Valley town to a formidable global asset
class akin to hedge funds or private equity.

During that period, venture capital investing became trendy — even 7-Eleven and “Sesame Street” launched
venture funds — and the number of private “unicorn” companies worth $1 billion or more exploded from a few
dozen to more than 1,000.

But the advertising profits gushing from the likes of Facebook and Google proved elusive for the next wave of start-
ups, which have tried untested business models like gig work, the metaverse, micromobility and cryptocurrencies.

Now some companies are choosing to shut down before they run out of cash, returning what remains to investors.
Others are stuck in “zombie” mode — surviving but unable to grow. They can muddle along like that for years,
investors said, but will most likely struggle to raise more money.

Convoy, the freight start-up that investors valued at $3.8 billion, spent the last 18 months cutting costs, laying off
staff and otherwise adapting to the difficult market. It wasn’t enough.

As the company’s money ran low this year, it lined up three potential buyers, all of whom backed out. Coming so
close, said Dan Lewis, Convoy’s co-founder and chief executive, “was one of the hardest parts.” The company
ceased operations in October. In a memo to employees, Mr. Lewis called the situation “the perfect storm.”

Such post-mortem assessments, where founders announce their company is closing and reflect on lessons
learned, have become common.

One entrepreneur, Ishita Arora, wrote this week that she had to “confront reality” that Dayslice, her scheduling
software start-up, was not attracting enough customers to satisfy investors. She returned some of the cash she had
raised. Gabor Cselle, a founder of Pebble, a social media start-up, wrote last month that despite feeling that he had
let the community down, trying and failing was worth it. Pebble is returning to investors a small portion of the money
it had raised, Mr. Cselle said. “It felt like the right thing to do.”

Amanda Peyton was surprised by the reaction to her blog post in October about the “dread and loneliness” of
shutting down her payments start-up, Braid. More than 100,000 people read it, and she was flooded with messages
of encouragement and gratitude from fellow entrepreneurs.

Ms. Peyton said she had once felt that the opportunity and potential for growth in software was infinite. “It’s become
clear that that’s not true,” she said. “The market has a ceiling.”

                                                                                                          Page 3 of 3
                      From Unicorns to Zombies: Tech Start-Ups Run Out of Time and Money

Venture capital investors have taken to gently urging some founders to consider walking away from doomed
companies, rather than waste years grinding away.

“It might be better to accept reality and throw in the towel,” Elad Gil, a venture capital investor, wrote in a blog post
this year. He did not respond to a request for comment.

Ms. Lefcourt of Freestyle Ventures said that so far, two of her firm’s start-ups had done exactly that, returning 50
cents on the dollar to investors. “We’re trying to point out to founders, ‘Hey, you don’t want to be caught in no man’s
land,’” she said.

One area that is thriving? Companies in the business of failure.

SimpleClosure, a start-up that helps other start-ups wind down their operations, has barely been able to keep up
with demand since it opened in September, said Dori Yona, the founder. Its offerings include helping prepare legal
paperwork and settling obligations to investors, vendors, customers and employees.

It was sad to see so many start-ups shutting down, Mr. Yona said, but it felt special to help founders find closure —
both literally and figuratively — in a difficult time. And, he added, it is all part of Silicon Valley’s circle of life.

“A lot of them are already working on their next companies,” he said.

Kirsten Noyes contributed research.

Kirsten Noyes contributed research.

PHOTO: In September, Bird, a scooter company and app that raised $776 million, was delisted from the New York
Stock Exchange because of its low stock price. (PHOTOGRAPH BY TARA PIXLEY FOR THE NEW YORK TIMES)
(B4) This article appeared in print on page B1, B4.


Load-Date: January 9, 2024


  End of Document

                                                                                                      Page 1 of 1
                   EFCC Arraigns Former Attorney General, Mohammed Adoke , On Fresh Charges




     EFCC Arraigns Former Attorney General, Mohammed Adoke, On Fresh
                                 Charges
                                                        The Will (Nigeria)
                                                   June 17, 2020 Wednesday



Copyright 2020 The Will Newspaper All Rights Reserved

Length: 173 words

Body


Former Minister of Justice, Mr. Mohammed Bello Adok Former Attorney General of the Federation, Mohammed
Adoke has been arraigned by the Economic and Financial Crimes Commission (EFCC), on fresh charges.

Adoke was arraigned alongside Mr. Aliyu Abubakar.

 THEWILL recalls that both men had earlier been arraigned on a seven-count charge bordering on money
laundering, bribery, and abuse of office. A Federal High Court sitting in Abuja had granted Adoke bail in the sum of
N50m with one surety in like sum after he pleaded not guilty to all charges stemming from his alleged fraudulent
involvement in the Malabo oil deal.

 The former AGF was first arraigned in December 2019 before the Federal Capital Territory (FCT) High Court upon
his return to the country from Dubai. Adoke's lawyer and Senior Advocate of Nigeria, Mike Ozekhome, at the last
hearing of the case earlier in the year, accused the EFCC of holding his client "in permanent custody," adding "This
has further jeopardized his very poor and fragile health.

" !-- AI CONTENT END 1 --


Load-Date: June 18, 2020


  End of Document

                                                                                                            Page 1 of 2
                           NE India 's relation with ASEAN on trade & investment: Post COVID-19




      NE India's relation with ASEAN on trade & investment: Post COVID-19
                                                              The Sentinel
                                                          July 5, 2020 Sunday



Copyright 2020 Omega Printers & Publishers Pvt Ltd, distributed by Contify.com All Rights Reserved

Length: 914 words
Byline: S.M.Farid

Body


(The writer can be reached at shahfarid90@gmail.com)

India and ASEAN trade ties grew 22% annually during 2005-2011 and more than 37% in 2011-12. It is set for a
growth to USD 300 billion by 2025. It has a promising trend to grow at a much faster pace in years to come with
India's Look East Policy. The signing of ASEAN-India Trade in goods agreement involve over 1.8 billion people with
a combined GDP of over USD 3 trillion creating the world's largest FTA ( Free Trade Agreement).

The FTA and Cooperation among the ASEAN members signify a great opportunity in the field of culture, trade and
commerce with India, that too through land transport along the border of approximately 1,645 km that India shares
with Myanmar. The most popular and the busiest border towns are Moreh (Manipur) and Tamu (Myanmar in
Sagaing Region).The other two yet to be developed and not fully operational border points are Zokathar in Mizoram
(that shares approximately 515 km border with Myanmar) and the Pangsu Pass (Lido) in Arunachal Pradesh ( that
shares approximately 525 km border with Myanmar).

The Government of India's initiative to develop Border Haats (markets) along the three border points with Myanmar
of which Moreh (operational on a daily basis) and Pangsu Pass through Lido (operational on a weekly basis) is a
big step forward for people to people interaction and encourage culture exchange programs. The border Haats in
this border town are most active with people from either side crossing over with issued permits from the concerned
authorities for their daily trading and shopping within a time limit from dawn to dusk. The Border Haats will go a long
way in years to come in promoting trade and commerce with Myanmar and the rest of ASEAN. The other two
borders, Pangsau Pass in Arunachal and Zokathar in Mizoram are not as active as the Moreh border but have
equally huge potential in border trade. The Arunachal Government has taken various steps to promote border trade.
One such annual event is the Pangsau Pass Winter Festival held every year during the month of January. The
border is situated in Nampong village.

The Mizoram-Myanmar border trade through the land custom station started formally in March 2005. Zokhawthar, in
eastern Mizoram has an international border of 510 km with Myanmar. The Border Haats are being set up along the
border to promote local products of both the countries. A lot more need to be done in this border too to promote
trade like infrastructure, connectivity from the capital city, Aizawl. Initially, border trade was allowed from this border
but was discontinued in November 2015 to give way to normal imports and exports.

                                                                                                       Page 2 of 2
                      NE India 's relation with ASEAN on trade & investment: Post COVID-19

Here are some of the core issues that need to be addressed to boost trade, investment and employment in these
areas.

Officially only Moreh in Manipur and Zorinpui in Mizoram (287 km from the Sittwe Port in Myanmar) have been
recognized with LCS (Land Custom Station) along the Indo-Myanmar border. A lot more can be done if we have
more LCS along the Pangsau Pass in Arunachal and in Mon district in Nagaland.

Border Haats (markets) can be set up in all the border points along the Indo - Myanmar border for close border
trade on either side of the border. Currently, only a few functional Haats are operational along the Indo-Bangladesh
border in Meghalaya. A better and upgraded model needs to be developed along the Indo-Myanmar border to boost
trade.

For trade promotion in any form, state of the art warehousing facility along the border areas is a must, exclusively
for perishable products. In most cases the border areas are far off from the nearest towns and cities.

Our region is blessed with beautiful hills, flora and fauna. When things return to a new normal, we need to promote
tourism and club tour packages with our state festivals like the Sangai festival in Manipur, the Hornbill festival in
Nagaland, the Tawang festival in Arunachal Pradesh and the Bihu festival in Assam along with the Tai - Ahom
villages in Upper Assam etc.

The 2019 ASEAN Community Leadership and Partnership Forum, held in conjunction with the 34th ASEAN Summit
in Bangkok which was organised by Kingsley Strategic Institute (KSI), ASEAN Business Advisory Council (ASEAN -
BAC), ASEAN Studies Centre, Nation building Institute and the Asia Centre in June, 2019 at Park Hyatt, Bangkok,
which I attended, was as eye opening experience and a very informative meet.

Some of the areas the forum focused on were cyber security, trade facilitation for 24 x 7, the use of Artificial
Intelligence (AI) to empower public health care system and building a strong digital infrastructure to empower
digital trade connectivity within ASEAN. There were separate focused sessions on empowering ASEAN 4.0, single
window clearance, non tariff barriers (NTB), Intra ASEAN Trade (2025). With an eye on the future, the forum also
had sessions to discuss ASEAN's next generation - reimagining ASEAN and fuelling Innovation.

The post-pandemic Trade and Commerce model of International Trade will definitely change with the gig economy
mode of businesses taking centre stage. However, the basics for goods and services will remain the same across
all international borders with ASEAN, Bangladesh, Bhutan, Nepal and China.

The writer is the founder Director of Northeast India - ASEAN Chamber of Commerce and Advisor to the Garo hills
Border Trade and Chamber of Commerce, Tura, Meghalaya and Border Trade and Chamber of Commerce, Moreh
Town, Manipur.


Load-Date: July 5, 2020


  End of Document

                                                                                                       Page 1 of 5
         Global Pharma Clinical Trial Digitization Market by : Complete Analysis of Key Players, Growth Rate,
                                       Opportunities, Challenges - The Courier




   Global Pharma Clinical Trial Digitization Market by : Complete Analysis of
      Key Players, Growth Rate, Opportunities, Challenges - The Courier
                                              The Courier: Monmouth University
                                                      January 7, 2021 Thursday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 1880 words

Body

DBMR has added a new report titled Global Pharma Clinical Trial Digitization Market with analysis provides the
insights which bring marketplace clearly into the focus and thus help organizations make better decisions. The
research report includes a thorough analysis of the market drivers, restraints, threats, and opportunities while it also
addresses the lucrative investment options for the market players in the coming years. This analysis gives an
examination of various segments that are relied upon to witness the quickest development amid the estimate
forecast frame. All the statistics are signified in graphical and tabular format for a clear understanding on facts and
figures. By accomplishing an inspiration from the marketing strategies of rivals, businesses can set up inventive
ideas and striking sales targets which in turn make them achieve competitive advantage over its competitors.

Pharma clinical trial digitization market is expected to gain market growth in the forecast period of 2020 to 2027.
Data Bridge Market Research analyses the market to grow at a CAGR of 5.7% in the above-mentioned forecast
period. Growing demand for personalized medicine is expected to create new opportunity for the pharma clinical
trial digitization market.

Get Sample Report + All Related Graphs & Charts @https://www.databridgemarketresearch.com/request-a-
sample/?dbmr=global-pharma-clinical-trial-digitization-market&pm

The major players covered in the pharma clinical trial digitization market report are Antidote Technologies, Inc.,
Aparito, Clinerion Ltd., CliniOps, Inc., Consilx, Deep 6 AI, Koneksa Health Inc. Medidata Solutions, Oracle,
PatientsLikeMe, Trialbee, TriNetX, Inc., Veeva Systems among other domestic and global players. Market share
and data is available for Global, North America, Europe, Asia-Pacific , Middle East and Africa and South America
separately. DBMR analysts understand competitive strengths and provide competitive analysis for each competitor
separately.

Clinical trial digitization allows the processing in different forms of voluminous patient-related data. Such data are
being used by pharmaceutical companies to improve the effectiveness of trial execution.

Growing demand for quality data is expected to drive the market growth. Some of the other factors such as
increasing demand for personalized drugs, increasing adoption of new technology in clinical research, growing

                                                                                                      Page 2 of 5
        Global Pharma Clinical Trial Digitization Market by : Complete Analysis of Key Players, Growth Rate,
                                      Opportunities, Challenges - The Courier

research & development promoting outsourcing and increasing diseases prevalence will drive the market in the
forecast period of 2020 to 2027

Competitive Landscape and Pharma Clinical Trial Digitization Market Share Analysis

Pharma clinical trial digitization market competitive landscape provides details by competitor. Details included are
company overview, company financials, revenue generated, market potential, investment in research and
development, new market initiatives, global presence, production sites and facilities, production capacities,
company strengths and weaknesses, product launch, product width and breadth, application dominance. The above
data points provided are only related to the companies' focus related to pharma clinical trial digitization market.

Table of Contents:
    •    Introduction
    •    Market Segmentation
    •    Market Overview
    •    Executive Summary
    •    Premium Insights
    •    By Component
    •    Product Type
    •    Delivery
    •    Industry Type
    •    Geography OverviewNorth AmericaEuropeAsia-PacificSouth AmericaMiddle East & Africa
    •    Company Landscape
    •    Company Profiles
    •    Related Reports



Insights of the Market in Report

1. The study provides an in-depth analysis of theGlobal Pharma Clinical Trial Digitization Market along with the
current trends and future estimations to elucidate the imminent investment pockets.

2. Comprehensive analysis of the factors that drive and restrict the market growth is provided in the report.

3. Comprehensive quantitative analysis of the industry is provided for the period of 2018-2025 to assist
stakeholders to capitalize on the prevailing market opportunities.

4. Extensive analysis of the key segments of the industry helps in understanding the trends in types ofGlobal
Pharma Clinical Trial Digitization Market across Glob.

5. Key market players and their strategies have been provided to understand the competitive outlook of theGlobal
Pharma Clinical Trial Digitization Market industry

Pharma Clinical Trial Digitization Market Scope

The pharma clinical trial digitization market is segmented on the basis of countries into U.S., Canada and Mexico in
North America, Germany, France, U.K., Netherlands, Switzerland, Belgium, Russia, Italy, Spain, Turkey, Rest of
Europe in Europe, China, Japan, India, South Korea, Singapore, Malaysia, Australia, Thailand, Indonesia,

                                                                                                      Page 3 of 5
        Global Pharma Clinical Trial Digitization Market by : Complete Analysis of Key Players, Growth Rate,
                                      Opportunities, Challenges - The Courier

Philippines, Rest of Asia-Pacific in the Asia-Pacific , Saudi Arabia, U.A.E, South Africa, Egypt, Israel, Rest of Middle
East and Africa as a part of Middle East and Africa , Brazil, Argentina and Rest of South America as part of South
America.
    •    All country based analysis of pharma clinical trial digitization market is further analyzed based on maximum
         granularity into further segmentation. On the basis of services, the pharma clinical trial digitization market is
         segmented into drug dose adjustment, drug impact monitoring, medical prescription system, bioprinting,
         preventive therapy, and individualized drug printing. Based on application, the market is segmented into
         clinical data management, trial monitoring, patient recruitment and enrollment. The pharma clinical trial
         digitization market on the basis of theme is segmented into digital continuity across clinical trial IT systems,
         patient-centric remote and virtual trial design and direct-to-patient home services.

Grab      Your    Report      at    an      Impressive     30%      Discount!     Please        click       Here
@https://www.databridgemarketresearch.com/inquire-before-buying/?dbmr=global-pharma-clinical-trial-digitization-
market&pm

Key Pointers Covered in the Pharma Clinical Trial Digitization Market Industry Trends and Forecast to 2027
    •    Market Size
    •    Market New Sales Volumes
    •    Market Replacement Sales Volumes
    •    Market Installed Base
    •    Market By Brands
    •    Market Procedure Volumes
    •    Market Product Price Analysis
    •    Market Healthcare Outcomes
    •    Market Cost of Care Analysis
    •    Market Regulatory Framework and Changes
    •    Market Prices and Reimbursement Analysis
    •    Market Shares in Different Regions
    •    Recent Developments for Market Competitors
    •    Market Upcoming Applications
    •    Market Innovators Study

Pharma Clinical Trial Digitization Market Scenario

According to Data Bridge Market Research the market for pharma clinical trial digitization is increasing owing to the
penetration of technology in the clinical research. The adoption of patient-centric remote and virtual trial design and
direct-to-patient home services is helping the pharma clinical trial digitization to expand. Germination of health
problems day by day is catering a good demand of research and technology, which on the whole is basic and keen
parameter aiding to pharma clinical trial digitization market growth during the forecast period of 2020 to 2027.

Now the question is which are the other regions intuitive is targeting? Data Bridge Market Research has forecasted
a large growth in the North America, owing to the advanced healthcare infrastructure. On the contrary Asia-Pacific
is expected to bounce the market growth exponentially due to surging players' penetration and government
initiatives taken.

                                                                                                      Page 4 of 5
        Global Pharma Clinical Trial Digitization Market by : Complete Analysis of Key Players, Growth Rate,
                                      Opportunities, Challenges - The Courier

For More Insights Get Detailed TOC @https://www.databridgemarketresearch.com/toc/?dbmr=global-pharma-
clinical-trial-digitization-market&pm

Global Pharma Clinical Trial Digitization Market Scope and Market Size

Pharma clinical trial digitization market is segmented of the basis of services, application and themes. The growth
amongst these segments will help you analyse meagre growth segments in the industries, and provide the users
with valuable market overview and market insights to help them in making strategic decisions for identification of
core market applications.
    •      On the basis of services, the pharma clinical trial digitization market is segmented into drug dose
           adjustment, drug impact monitoring, medical prescription system, bioprinting, preventive therapy, and
           individualized drug printing.
    •      Based on application, the market is segmented into clinical data management, trial monitoring, patient
           recruitment and enrollment.
    •      The pharma clinical trial digitization market on the basis of theme is segmented into digital continuity
           across clinical trial it systems, patient-centric remote and virtual trial design and direct-to-patient home
           services.

Pharma Clinical Trial Digitization Market Country Level Analysis

Pharma clinical trial digitization market is analysed and market size insights and trends are provided by services,
application and themes as referenced above.

The countries covered in the pharma clinical trial digitization market report are U.S., Canada and Mexico in North
America, Germany, France, U.K., Netherlands, Switzerland, Belgium, Russia, Italy, Spain, Turkey, Rest of Europe
in Europe, China, Japan, India, South Korea, Singapore, Malaysia, Australia, Thailand, Indonesia, Philippines, Rest
of Asia-Pacific in the Asia-Pacific , Saudi Arabia, U.A.E, South Africa, Egypt, Israel, Rest of Middle East and Africa
as a part of Middle East and Africa , Brazil, Argentina and Rest of South America as part of South America.

The country section of the pharma clinical trial digitization market report also provides individual market impacting
factors and changes in regulation in the market domestically that impacts the current and future trends of the
market. Data points such as consumption volumes, production sites and volumes, import export analysis, price
trend analysis, cost of raw materials, down-stream and upstream value chain analysis are some of the major
pointers used to forecast the market scenario for individual countries. Also, presence and availability of global
brands and their challenges faced due to large or scarce competition from local and domestic brands, impact of
domestic tariffs and trade routes are considered while providing forecast analysis of the country data.

Healthcare Infrastructure Growth Installed Base and New Technology Penetration

Pharma clinical trial digitization market also provides you with detailed market analysis for every country growth in
healthcare expenditure for capital equipment's, installed base of different kind of products for pharma clinical trial
digitization market, impact of technology using life line curves and changes in healthcare regulatory scenarios and
their impact on the pharma clinical trial digitization market. The data is available for historic period 2010 to 2018.

About Data Bridge Market Research:

Data Bridge Market Research set forth itself as an unconventional and neoteric Market research and consulting firm
with unparalleled level of resilience and integrated approaches. We are determined to unearth the best market
opportunities and foster efficient information for your business to thrive in the market. Data Bridge endeavors to
provide appropriate solutions to the complex business challenges and initiates an effortless decision-making
process.

Contact:

                                                                                                     Page 5 of 5
       Global Pharma Clinical Trial Digitization Market by : Complete Analysis of Key Players, Growth Rate,
                                     Opportunities, Challenges - The Courier

Data Bridge Market Research

US: +1 888 387 2818

UK: +44 208 089 1725

Hong Kong: +852 8192 7475

Corporatesales@databridgemarketresearch.com


Load-Date: January 7, 2021


  End of Document

                                                                                                        Page 1 of 12
                      The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems




       The Superclusters Initiative: An Opportunity to Reinforce Innovation
                                    Ecosystems
                                      The Foundation For Research On Equal Opportunity
                                                 October 8, 2020 Thursday



Copyright 2020 Content Engine, LLC.
All Rights Reserved
Copyright 2020
All Rights Reserved

Length: 10038 words
Byline: Catherine Beaudry and Laurence Solar-Pelletier

Body


      Introduction
Canada has been performing below expectations when it comes to turning its excellent science and technology into
innovation. This is worrisome because there is ample empirical evidence of a positive relationship between
scientific research, technological innovation and economic growth.[1] Canada does well in terms of science and
technology outputs. It ranks 5th worldwide in the number of publications per thousand inhabitants, 6th for research
impact and 11th in the share of patents filed at three major patent offices, known as triadic patents (Council of
Canadian Academies 2018; OECD 2014). But both gross domestic expenditure on research and development and
business expenditure on research and development as percentages of gross domestic product are declining
(OECD 2017). Canada’s ranking in innovation is also falling. Its commercialization successes are limited and the
rate of cluster development is low (Canada 2016; Schwab 2019). This jeopardizes the country’s ability to
innovate.[2]

In addition to having difficulty translating science and technology performance into efficient solutions and
commercial successes, the country is dealing with the rapid dissemination of discontinuous and potentially
disruptive technologies.[3] These include big data analytics; artificial intelligence (AI); the Internet of things;
advanced materials; additive manufacturing such as 3D printing; and blockchain, a digital ledger of transactions
duplicated and distributed across a computer network. These technologies are drastically changing the way firms
are designing, prototyping, testing and manufacturing new products and services. As Daniele Archibugi wrote in
2017: “One of the key characteristics of disruptive technologies is that they do not knock gently at the door: they
enter social and economic life suddenly and unexpectedly” (2017, 541). Clear illustrations of this phenomenon
include the emergence of Uber, the exponential doubling of computer chip power and the rapid advances in DNA
sequencing.
Schumpeterian creative destruction forces such as autonomous vehicles, personalized medicine and the ongoing
automation of traditional manufacturing and industrial processes using smart technology are forcing businesses and
public organizations to rethink how they generate ideas and innovate. Governments are also under pressure to
provide better adapted regulation and innovation policies. Given their slow rates of technology adoption, most

                                                                                                       Page 2 of 12
                  The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

Canadian firms appear ill equipped to overcome the challenges that stem from these technologies. Canada’s
innovation policy framework needs to be redesigned to accommodate new ways of organizing and governing
innovation.

The Innovation Superclusters Initiative, which was put forward by the federal government in 2017, is the
centrepiece of its plan to resolve Canada’s innovation paradox (Canada 2017b). Under this initiative, Ottawa is
investing $950 million over five years to support five superclusters involving small, medium-sized and large
companies, academic institutions and not-for-profit organizations. Each supercluster has its own focus: digital
technologies, protein industries, next-generation manufacturing, supply chains powered by AI, and ocean
technologies. The government says its aim is to promote commercial innovation and global presence, from ideation
to value creation, while providing the means to organize innovation ecosystems to collectively face and benefit from
groundbreaking technologies.[4] The objectives of the initiative are quite ambitious. The superclusters are expected
to increase business spending on research and development, promote widespread collaboration, attract and retain
the right talent, and increase the size and global reach of firms.
Increasing domestic firms’ size and reach, also called scaling up, has been a top priority for decades for most
countries. Yet Canada still fails to produce multinationals. Repeatedly hammering the same “scaling up” nail has not
provided the expected benefits. It is time to try something else. We at the Partnership for the Organisation of
Innovation and New Technologies hypothesize that the advantages accrued from collectively developing and
commercializing innovations within ecosystems may counterbalance the extent of scaling up required, or expected,
of firms to succeed. The superclusters initiative might prove that well-organized innovation ecosystems provide the
necessary agility and performance to become engines of economic growth and wealth creation in the country.
Working together could yield a collective performance that is larger than the sum of its parts, a win-win situation for
the ecosystem and its constituents. In our view, the concept of innovation ecosystems provides the appropriate
framework to rethink Canada’s innovation strategy.
Even though the name of the initiative includes the word “cluster”, the superclusters are in fact more akin to
innovation ecosystems. Unlike clusters, they are not locally or geographically constrained, and many of their
constituent members are part of extensive networks of national and international firms or organizations. The
concept of ecosystem, and more specifically of innovation ecosystem, is increasingly used by academics,
practitioners and policy-makers. It provides a new lens for studying and understanding innovation that goes beyond
clusters or networks. However, the concept is still not well defined and understood. And the empirical tools to
measure its broad impact have yet to be designed. In this study, we briefly survey the relevant literature on clusters
and superclusters, or innovation ecosystems, to examine the theoretical and empirical foundations that underlie the
government’s initiative. We then explore the challenges and opportunities presented by this novel policy approach.
The Building Blocks of Innovation Ecosystems
While the concept of an innovation ecosystem was inspired by ecology, its foundations within the economics and
management sciences derive from numerous strands of the literature that study and describe the way individuals
and organizations interact and collaborate formally and informally. The theoretical foundations of the concept span
industrial clusters, knowledge networks, geographic, social and cognitive proximities, collaboration and open
innovation — all of which have been shown to have a positive impact on a firm’s propensity to innovate. To fully
understand why and how innovation ecosystems have the potential to boost Canada’s innovation capacity, it is
important to understand the foundations on which they are built.
Industrial clusters
There has long been a strong interest in clusters within the scientific community and among policy-makers. Since
Michael Porter introduced the idea of clusters in 1990, few economic concepts have provoked such enthusiasm.
Still, the benefits of clustering were studied long before Porter’s seminal work. He drew on the work of Alfred
Marshall who, in his 1890 book Principles of Economics, emphasized the importance and advantages of
geographical proximity for economic growth in reducing transportation and other transaction costs. Porter initially
defined an industrial cluster as a group of geographically colocated, interconnected firms and organizations within a
sector that share common elements and are complementary to each other. Silicon Valley is a well-known and
envied example of a highly efficient and productive cluster. Other names have been given to this local concentration
of enterprises, skills, cooperation and competition, including regional systems of innovation (Lundvall 1992), flexible
specialization (Piore and Sabel 1984), smart specialization (Foray 2014) and industrial districts (Beccatini 1990).

                                                                                                           Page 3 of 12
                  The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

These concepts all focus on the importance of geographical proximity, which allows trust-building among
stakeholders and access to a highly specialized labour force.
Research has shown that firms that operate in clusters are more innovative than firms that operate in isolation.
They generate more patents and have greater employment and revenue growth, partly due to specialization or
diversification effects.[5] The presence of strong research universities as integral parts of clusters increases the
propensity of small, local firms to patent and that of universities to coevolve along with local, private sector
patenting (Helmers and Rogers 2015; Blankenberg and Buenstorf 2016). Silicon Valley would not be the same
without the fundamental role played by Stanford University and the University of California, Berkeley. Researchers
and students created spinoffs and start-ups, and went back and forth between private enterprises and the
universities.
The better performance of firms located in clusters is generally attributed to the geographical proximity that defines
them. Reducing the distance of interactions improves coordination between members of the cluster and facilitates
the sharing of tacit knowledge gained through experience or shared expertise (Bathelt and Cohendet 2014; Gertler
2003). But geographical proximity is by no means essential when knowledge is exchanged more formally (Bathelt
and Henn 2014). In other words, clusters are not a universal panacea.
Since Porter’s seminal work, interpretations of the concept of “cluster” have multiplied and evolved to incorporate
other types of proximity. The literature has shown that the degree of geographical proximity varies across local
systems of innovation, or innovation clusters.[6] Table 1 portrays a four-quadrant framework for clusters. It was
developed by André Torre in his 2006 work Clusters et systèmes locaux d’innovation. This framework helps us
analyze two crucial dimensions of innovation clusters: the degree of colocalization or geographical proximity and
the degree of organization of interfirm links or organizational proximity. The latter refers to the capacity to
coordinate the transfer and exchange of information and knowledge either within or between organizations
(Boschma 2005). Establishments within the same firm that share a common organizational culture are more likely to
have strong links. So too do firms that share a common knowledge space and have developed formal collaborative
agreements. This conceptual framework can be used to compare clusters and innovation ecosystems, as it shows
there are various ways to organize both.
Quadrant 1 represents clusters as defined by Porter. They rely to a significant degree on colocation and strong
organizational ties. Emerging clusters very likely start this way, with strong relationships between a few local actors.
They are often the result of a specific regional policy to create a cluster. Silicon Valley fits in this category. Quadrant
2 illustrates the case of clusters with weak local anchoring and strong interfirm relations. These clusters can exist at
a national and regional level. They are more akin to knowledge or innovation networks. The development and
production of Airbus aircraft, which spans the European continent and other countries, is a clear example. Airbus
has plants in China, France, Germany, Spain and the United States. Yet interfirm relations are strong. Quadrant 3
shows the third type of cluster, characterized by a high spatial concentration of firms but weak interfirm links where
knowledge is exchanged more formally. Synergy in this case can be encouraged through various national policies,
for example by bringing together firms that may benefit from fiscal incentives to colocate their research and
development activities in a science park. This type of incentive gave rise to the strong electronic games industry in
Montreal. Over time, interactions between individuals often lead to more organized links between firms in these
clusters. Quadrant 4 is not considered to be a type of cluster because it lacks both geographical and organizational
proximity.
The measured impact of clusters depends on the type of cluster being considered as well as the precision and level
of aggregation of the indicators used to gauge this impact (Beaudry and Schiffauerova 2009). Performance
indicators commonly found in the literature include the propensity to innovate and the number of innovations; the
number of patents and their citation-based quality or value; and employment and revenue growth. There is a need
to better define and assess these indicators. They are measured either at the firm level, to assess the performance
of firms within clusters compared to more isolated firms, or at the cluster level, to examine the overall performance
of the organizations therein. Rarely are both levels examined jointly to assess the extent to which the arrangement
is a win-win for the firm and the cluster. This is something that the ecosystem framework enables.
Although some view geographical proximity as an advantage in facilitating collaboration, it is neither sufficient nor
necessary for successful collaboration. Collaboration can be coordinated at a distance through temporary proximity
(Torre 2008), for instance short trips of a few days to a few weeks or months for the team to meet face to face.
Researchers have also come to recognize the importance of cognitive and social proximity for the success of
ecosystems. Cognitive proximity measures the degree to which individuals or organizations share a common

                                                                                                      Page 4 of 12
                  The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

knowledge base. Social proximity refers to how socially close individuals are, or how well they know each other and
interact. Several researchers argue that cognitive proximity is the principal cause of tacit knowledge spillovers from
one firm to another (Breschi and Lissoni 2001). This can happen regardless of whether the firms are colocated or
geographically dispersed within a community that shares a common knowledge base. For more efficient knowledge
transmission (Agrawal, Kapur and McHale 2008), however, a degree of social proximity is also required, that is,
strong trust relations between actors based on friendship, kinship and experience (Boschma 2005).
Coherent and efficient coordination of innovation can take place at the subnational level, such as in the provinces,
territories or smaller regions in Canada. Yet national and international links to other organizations are often
beneficial to the innovation process (Walshok, Shapiro and Owens 2014). To fully understand innovation
ecosystems, we must consider another layer of links and relationships beyond geographically bound clusters. The
literature on knowledge networks provides this second building block.
Knowledge networks
The literature on innovation ecosystems often refers to the networking aspects of the relationships (the links of the
networks) between actors (the nodes of the networks), which are not necessarily geographically bound as is often
assumed in the cluster literature (figure 1). Marco Iansiti and Roy Levien describe ecosystems as being “formed of
large, loosely connected networks of entities” (2004 35). Erik Den Hartigh, Michiel Tol and Wouter Visscher
describe them as consisting of “a network of actors around a core technology, who depend on each other for their
success and survival” (2006, 2). The geographical proximity of actors is rarely considered in this literature.
Organizations, units within organizations and individuals that occupy a key network position are generally more
productive and innovative.[7] This can be a function of how highly connected (or central) these individuals and
organizations are within the network and whether their collaborators are interconnected (form a close-knit
community). For example, firms that collaborate with multiple university teams, collaborate with both suppliers and
clients to codevelop technologies, and use technologies from several providers are considered technology
integrators. They occupy central positions in their respective networks.
In highly interconnected or dense networks, knowledge and information travels relatively fast. This facilitates
knowledge sharing. Basic science networks are predominantly highly dense networks (Wagner 2018), where
access to the opposite side of the networks requires only a few handshakes. The individuals and organizations that
link different parts of a network that would otherwise be disjointed (see nodes highlighted in figure 1), often bridge
the gaps between communities, sectors, disciplines or industries. Burt refers to such gaps as structural holes
(1992). The firms and researchers that first combined biology, computer science and information engineering to
create the bioinformatics interdisciplinary field occupied such intermediary positions in their network (Freeman
1977). Since innovation often stems from the new combination of existing knowledge, these intermediaries play an
important role.
At the other end of the spectrum in terms of network structure are less dense or sparser networks. An example is
shown in figure 2. Such networks are characteristic of applied science fields and most innovation networks. As a
technology matures, moves toward market application and transforms into product innovation, firms require fewer
collaborators with which they have strong relationships, and they distance themselves from governments and
universities. That is not say that they completely isolate themselves from centres of science and knowledge
generation, but the latter are no longer in the immediate network surroundings of the firm for the technology in
question.
As such, innovation ecosystems and the superclusters are networks built to integrate different strong science
communities, well-integrated sectors and supply chains, as well as other organizations and firms interested in the
use of common key technologies. We therefore expect to find that the networks of members and researchers within
the superclusters are relatively sparse, with dense clusters of nodes united by structural holes occupied by
innovative individuals or organizations.
There is an ongoing debate in the literature about which type of knowledge network, dense or sparse, is more
conducive to innovation. Both have their strengths and weaknesses. A dense network can facilitate close
collaboration but may be impervious to outside innovation. A sparse network, with its structural holes, can
contribute to the creative process by combining ideas from diverse sectors. But it may lack the capacity for intensive
collaboration. Both models can be complementary within a sparser network structure, however. Pockets of dense,
closely linked communities connected by one or more structural holes can create strong ties among members and
intersectoral exchanges that are beneficial to knowledge exchange, idea generation and exploration (Wang 2016),
as well as innovation (Rost 2011).

                                                                                                       Page 5 of 12
                  The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

The literature on knowledge networks is neither abundant nor conclusive regarding their role in generating
innovation in the case of the specific disruptive technologies[8] at the heart of the Innovation Superclusters
Initiative. It remains to be seen whether the players developing these technologies will be able to successfully
establish strong links with organizations using other technologies or with other sectors within the superclusters. Will
the individuals and organizations expected to occupy structural holes between technologies, and between new and
more traditional sectors, foster the recombination of knowledge necessary to accelerate innovation?
Beyond their structure, the strength of network links is also important (Baum, Cowan and Jonard 2014). Informal
relationships and collaborations, such as social ties, participation in associations and their events, trade fairs and
international community gatherings, and even knowledge trading, play a crucial role in catalyzing knowledge within
innovation ecosystems as well as in open innovation (Henkel, Schöberl and Alexy 2014; West et al., 2014). These
informal ties, which are implicit in the cluster literature and are formally acknowledged but considered difficult to
measure in the network literature, are what make innovation ecosystems work. This is particularly important in the
case of disruptive technologies, where problem solving requires more extensive collaboration and a certain degree
of openness. As AnnaLee Saxenian pointed out, Silicon Valley engineers who once worked together remained in
contact after moving firms and often interacted formally and informally to exchange information and solve
technological problems (1994). Social, organizational and cognitive proximity between individuals was crucial to the
rise and maintenance of the Silicon Valley advantage. This collaboration culture blurred the boundaries of firms.
Collaboration
If innovation clusters and knowledge networks are the building blocks of innovation ecosystems, collaboration is the
glue that brings both concepts together. Collaboration within and between organizations or sectors acts as a
catalyst. It accelerates the sharing of information, skills and resources; improves the generation, valuation and
validation of ideas; increases the capacity of organizations to innovate; and spans disciplines, organizations,
sectors and users.[9] Firms that collaborate with their clients, suppliers and universities are generally more
innovative. Firms are often located close to their clients or to their suppliers, but that does not necessarily mean
they collaborate with them. Collaboration can occur across different types of proximity, be it geographical, cognitive
or social, and at different stages of the innovation value chain, such as at the knowledge, ideas or project stage.
The challenges posed by discontinuous and potentially disruptive technologies will demand broader intersectoral
and interdisciplinary collaboration from firms seeking to benefit from such changes. The speed at which these
technologies impose themselves on the market will force the codevelopment of new innovation practices, policies
and regulation involving all stakeholders. It is therefore imperative to rethink the roles of and collaborative
relationships between policy-makers, decision-makers, experts, academics and final users.
For instance, universities and other contributors to science and technology are expected to help develop new
technologies and commercialize the fruits of their research through mechanisms such as technology transfers,
licensing and the creation of spinoffs, or with the help of the private sector (Breznitz and Feldman 2012). In
particular, research collaboration between the private and public sectors is seen as essential, which is why
university-industry links have become an integral part of the university funding landscape (Goldfarb 2008). The
nature, process and value of the resulting innovations are well documented (OECD 2015). Far from being
detrimental to science, university-industry links lead to research that has more impact (Lebeau et al. 2008). This
raises the question of Canada’s poor performance in this regard. University-industry links that bridge the gaps
between knowledge, technology and innovation[10] were expected to be the key to improving Canada’s innovation
performance. The results have been disappointing.
Innovation Ecosystems as a Metaphor
The concept of innovation ecosystems draws broadly on the literature and research investigating the benefits of
innovation clusters, various types of proximities, knowledge networks and collaboration. Because innovation
clusters and knowledge networks are known to have a positive influence on innovation, we expect that
organizations involved in strong innovation ecosystems should also be more innovative (Adner 2006).
The economist Michael Rothschild was the first to use the term “ecosystem” as a metaphor in the economics and
management of innovation literature. His 1990 book, Bionomics: Economy as Ecosystem, inspired James Moore to
describe firms and their networks as business ecosystems. “In a business ecosystem, companies coevolve
capabilities around a new innovation: they work cooperatively and competitively to support new products, satisfy
customer needs, and eventually incorporate the next round of innovation” (Moore 1993, 76). By transposing the
notion of the biological ecosystem to the economy, he also redefined the economic system as an ecosystem where

                                                                                                         Page 6 of 12
                  The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

organizations and consumers represent living organisms intertwined in mutually dependent relationships (Moore
1996).[11]

Business ecosystems include small and large businesses, universities, research centres and public sector
organizations and tend to position themselves around a leading company (Peltoniemi 2005). Such ecosystems may
include a company’s competitors as well as its customers, whose behaviour is likely to influence the company’s
performance. The diversity of the actors involved is partly attributable to the digital transformation of several
industrial sectors. It also reflects the convergence of a variety of technologies and industries, such as data science
in precision medicine, industrial Internet of things in aerospace, 3D printing in health, and AI in mobility services. By
coevolving their skills, the various organizations that constitute the business ecosystem create value for their
customers (Moore 1996). The term “ecosystem” emphasizes the crucial role of networking and the participation of
varied actors in the innovation process (Smorodinskaya et al. 2017).
The concept of business ecosystem focuses on the firm and its network. Some researchers built on this concept as
they examined the way firms were using external as well as internal resources in the innovation process. This led to
the notion of innovation ecosystems and of open innovation ecosystems (Adner 2006; Rohrbeck, Hölzle and
Gemünden 2009). Open innovation provides key insights on how innovation ecosystems work and perform.
Open innovation
Collaboration, cooperation and open innovation are of paramount importance to well-functioning ecosystems. This
was implied in the cluster literature and formally measured in the literature on knowledge networks. Many firms had
already adopted at least some forms of open innovation before the concept was first described by Henry
Chesbrough in his 2003 book, Open Innovation: The New Imperative for Creating and Profiting from Technology.
Indeed, since the 1970s, research and development is no longer performed entirely within the firm. The locus of
innovation has migrated out of a company and into the value network to which it belongs (Brandenburger and
Nalebuff 1996). The value network has replaced the concept of value chain because products and services have
become dematerialized and the value chain no longer has a purely physical dimension. In value networks, value is
cocreated by a combination of players in the network. This compels a degree of open innovation, defined as “the
use of purposive inflows and outflows of knowledge to accelerate internal innovation, and to expand the markets for
external use of innovation respectively” (Chesbrough, Vanhaverbeke and West 2006).
Open innovation encompasses three main groups of activities: inbound activities, outbound activities and a mixture
of the two generally referred to as coupled activities.[12] An organization undertakes inbound activities when it
mobilizes external resources and knowledge acquired, for example, through licensing or crowd-sourcing. Firms with
greater market knowledge may acquire new innovations in order to sell them to other organizations. Outbound
activities refer to the external use and exploitation of internal knowledge. Such activities consist of transferring
knowledge and the results of internal research and development to external partners for them to commercialize. For
example, a firm could benefit from selling or granting access to some of its intellectual property to a company that
has a business model better suited to the commercialization of that technology. A company may also decide to
externalize the commercialization of internal knowledge when the latter does not match its strategic objectives. This
can generate revenues from technologies, goods or services that would otherwise have remained on the shelf.
Coupled activities are a combination of the first two, where sharing complementary resources among partners can
lead to critical innovation.
As the previous paragraph suggests, open innovation does not necessarily involve collaboration. A firm may, for
instance, find an external path to market for a technology that it does not want or need to commercialize itself.
Conversely, firms may contract out research and development activities or obtain a licence for patented
technologies without signing a collaborative agreement.
With open innovation, innovation is no longer confined to the boundaries of a firm. It is developed at least partly
outside the organization with other firms, governments or universities. Many factors contributed to this change in the
way organizations innovate, among them the increasing complexity and cost of research and development, and
accelerated technological change. Opening to other organizations allows firms to break down silos, acquire more
resources, reduce risk and share knowledge and resources.[13] Linear and closed innovation processes, as well as
traditional business models, have evolved toward more open and interactive structures, where informal links adjoin
formal relationships (Cohendet and Simon 2017; Autio and Thomas 2014). The concept of open innovation
perfectly complements the literature on clusters and networks in characterizing the links between different types of
organizations within innovation ecosystems.

                                                                                                      Page 7 of 12
                  The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

Ecosystem diversity
Open innovation underscores the importance of collaboration between diverse stakeholders, each of whom
contributes to innovation in its own way. Within innovation ecosystems, the focus of analysis is on the interactions
between interdependent actors whose objective is to create and market innovations benefiting the end user. While
business ecosystem studies concentrate on the firm and its environment, innovation ecosystem studies focus on
innovation and the constellation of actors that support it.
An organization can be involved in various ecosystems (knowledge, innovation or business ecosystems) and play a
different role in each (Valkokari 2015). Similarly, while the same set of diverse actors from different sectors,
businesses, universities or government institutions may populate business and innovation ecosystems, their role
and importance differ from one ecosystem to another. A firm can be the leader of an ecosystem, but leadership can
also fall to another type of organization, such as a university or a government entity. Relationships are not strictly
hierarchical among ecosystem members but rather collaborative. This makes network literature useful when
studying these interorganization links.
The core of business ecosystems consists of firms, suppliers, consumers and distributors. Other organizations are
only weakly involved. In contrast, innovation ecosystems are characterized by the importance of research
institutions, local intermediaries and policy-makers. They include participants from outside the traditional value
chain (Valkokari 2015). These can be customers, universities that provide science and technology, regulators,
innovation coordinators or intermediaries, and firms that coevolve with the ecosystem, often in symbiotic
relationships (Mazzucato and Robinson 2017).These participants are often geographically concentrated, which is
why the cluster literature remains relevant in studying innovation ecosystems.
Silicon Valley clearly functions as an innovation ecosystem. While governments have tried to imitate or reproduce
Silicon Valley, few have succeeded by adopting a simple cluster approach. With the superclusters initiative,
deliberately anchored in Canada’s technological, sectoral and economic strengths, Ottawa is experimenting with
something different. It is trying to encourage intersectoral collaboration, which does not come naturally to most
firms.[14]
Innovation Ecosystems in Practice — the Canadian Superclusters
According to the government’s program overview, the Innovation Superclusters Initiative is meant to encourage the
establishment of “large-scale industry partnerships, supported by other innovation ecosystems players.” Aspiring
superclusters were asked “to work together on ambitious market-driven proposals to supercharge their regional
innovation ecosystems, enhancing the growth and competitiveness of participating firms and maximizing economic
benefits, including good, well-
paying jobs and prosperity for Canada” (Canada 2017a). A key objective is to promote widespread wealth creation
through the adoption of new and potentially disruptive technologies within innovation ecosystems, particularly by
small and medium-sized enterprises.
This bold approach aims to reverse Canada’s deteriorating innovation performance, accelerate the adoption by
Canadian firms of several key transformative technologies and foster a strong entrepreneurial or start-up culture.
The government hopes that by facilitating the involvement of all stakeholders in the superclusters, bottlenecks such
as the snakes-and-ladders game between regulation and innovation and other difficulties in translating science and
technology into successful products can be overcome. Under the initiative, universities, government laboratories,
innovation intermediaries and firms of all sizes are having to work together to develop a functional governance
structure for these very large innovation ecosystems. This is expected to help flag problems along the innovation
value chain and create the climate of trust necessary for greater collaboration among different disciplines and
sectors.
More generally, promoting the emergence of strong innovation ecosystems that span several sectors, even beyond
those involved in the superclusters initiative, has the potential to strengthen Canada’s innovation capacity and
competitiveness. The literature surveyed in this article certainly hints at the potential benefits of innovation
superclusters, although their true economic impact has yet to be accurately measured. Learning from the
experience of the innovation superclusters and that of other innovation ecosystems is timely and crucial for the
Canadian economy.
Despite their names, the five superclusters are centred on technologies rather than industrial sectors. These are
detailed in box 1. While all superclusters have a strong local base, they span several regions of the country,
building on numerous strong, local technology hubs. The concept of innovation ecosystem is the appropriate
framework to study the supercluster initiative but, as we have shown, it is a concept that encompasses several

                                                                                                        Page 8 of 12
                  The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

others. No single strand of the literature can fully describe the ways in which the superclusters initiative can help
reverse Canada’s downward innovation spiral, nor how it can become a successful Canadian innovation in and of
itself. The lens needed to understand how the superclusters operate, to measure whether they achieve their goals
and to evaluate their performance does not yet exist. More research is needed to equip organizational actors with a
comprehensive conceptual framework and the appropriate indicators and decision-making tools to bring about the
necessary transformations.[15]
Key performance indicators: Measuring what matters
The initial program guide provided to applicants wishing to take part in the superclusters initiative included four
clearly stated objectives and a list of seven key performance indicators to measure expected outcomes over the life
of the program. These are detailed in box 2. This signalled the government’s intention to monitor the impact of its
investment. Although they broadly cover the main goals of the initiative, the initial key performance indicators
consist mainly of generic indicators that, in our view, overemphasize basic metrics such as the number of
collaborative projects, participating companies and organizations, and the number of jobs created in small and
medium-sized enterprises. These provide a good starting point to measure results, but are too simplistic to gauge
the full impact of the superclusters initiative on innovation and collaboration. Since the initiative was launched,
Innovation, Science and Economic Development Canada has been consulting with experts and working with
members of the five superclusters to develop a more detailed and precise set of indicators. Some of these are
included in box 3. [16]
The first group of key performance indicators in box 3 underline the need to boost investment in industrial research
and development. Business enterprise research and development has been chronically below par in this country.
Canada has been falling behind other OECD countries on this indicator for more than a decade (CCA 2018). The
revised indicators are an improvement on the initial indicators proposed by recognizing the importance of investing
in demonstration and commercialization activities, which often become increasingly costly as the technology moves
toward the market. It will be important to track whether and where these investments take place.
More generally, the updated performance indicators are directly aligned with the government’s strategy to advance
business-led innovation and technology leadership activities, and to boost productivity, performance and
competitiveness. The dollar value of such investments provides a strong indication of business commitment to
innovate, but we also need to be able to monitor how the superclusters go about implementing the necessary
changes. Boosting a firm’s productivity, performance and competitiveness requires putting together the best teams
and mobilizing the right set of resources to foster innovation. The former requirement can be gauged in part by the
number of science and technology professionals participating in supercluster activities, the number of jobs created
and the rate of employment growth in small and medium-sized enterprises. Whether the right set of resources has
been assembled can be measured by the outcomes: the number of products and processes developed, improved
and commercialized.
The third set of indicators also includes the number of patents or copyrights. This is an important addition to the list
because, in some cases, the technologies being promoted by the superclusters are at a relatively embryonic stage
of development. It is likely that some of the most ambitious projects will only reach a relatively early stage of
technology maturity by the end of the five-year program. Having an interim indicator, such as the number of patents
and copyrights, will provide an idea of the innovation potential of the supercluster.

Translating investment in research and development into innovation is a necessary step to improving economic
growth. Yet the actual economic impact of these activities in terms of increases in revenue, market share or exports
was absent from the government’s initial list of indicators, although such indicators are included in the strategic
plans of most superclusters. They are now on the government’s list, focusing on two elements: increases in
contributions to gross domestic product and in the share of small and medium-sized enterprises that export goods
or services. This definition of wealth creation, however, is considerably narrower than the aggregate economic,
social and environmental benefits contemplated by the Council of Canadian Academies in its 2018 report.
Canadians expect government investments in innovation to lead to improved quality of life, pollution reduction,
health improvements and poverty reduction. Ultimately, these are the types of outcomes that we should be
measuring. But it is notoriously difficult to do so.
The idea behind the second set of key performance indicators is that more collaboration between private, academic
and public sector organizations will improve the country’s commercialization performance. The extent of university-
industry collaboration is used as an input indicator in the innovation literature and by the World Economic

                                                                                                      Page 9 of 12
                  The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

Forum.[17] But simply counting the number of collaborative projects will not be conducive to large-scale
collaboration and may even be counterproductive as it encourages a multiplicity of small projects. Having an
excessive number of small projects or larger projects broken down into smaller ones to meet performance indicator
requirements will make it more difficult to coordinate and to measure the overall impact. These biases may be
partially counterbalanced by also counting the number of member organizations involved in each project, although
this is more suitable for larger or more important projects. And, while these metrics may be indicators of scale and
potential reach, they fail to convey any information about the quality of the links and relationships within the
ecosystem or how productive they are in terms of outcomes. Indicators aimed at characterizing these relationships
should be developed to monitor progress over the course of the initiative. Finding ways to measure the benefits of
collaboration would be a further challenge, but it would help offset potential biases linked to simple project counts.
The expanded set of indicators emphasizes innovation ecosystems’ growth, monitoring employment growth in
participating small and medium-sized enterprises and the number of new jobs created overall. Tracking the number
of new firms created and the number of high-growth firms involved in the supercluster is consistent with the scale-
up objective. Some caution is warranted, however. Beyond the desired spinoffs, start-ups and gazelles alluded to in
the government’s objectives, many of the high-growth firms that will be added to the count likely already belong to
existing sectors. Many of the so-called new employees come from somewhere else. Although this is not a zero-sum
game, employees who leave their current employment to move to small and medium-sized firms involved in the
superclusters will deplete firms, sectors, regions and ecosystems elsewhere.
The inevitable but beneficial workforce mobility involved in the innovation process should be taken into account. For
example, when an aerospace firm is developing a new aircraft, its workforce is likely to decrease if demand is
declining for its older aircraft models. Yet this is often the most innovative period for the company. Simply counting
the number of employees, or employment growth, will not reflect the firm’s innovative capacity embodied in its
employees. We suggest that measures of the quality and innovative capacity of human capital in relation to the
stage of development of the technology be added to the indicator list. Existing innovation surveys already gather
information on the number of employees with technical, science and engineering degrees, PhDs, or those devoted
to research and development or tasks related to commercialization. A culture that encourages employees to
innovate is an important contributor to the innovation process. Mercan and Goktas (2011) used elements of the
Global Innovation Index developed by the World Economic Forum and INSEAD, a graduate business school
(Schwab 2019), to measure innovation culture. With the power of big data analytics at our fingertips, we can go one
step further and account for the experience employees have had in past projects and their involvement in
successful innovations.

Given the government’s focus on technologies rather than sectors in designing the superclusters program, an
important missing performance indicator relates to the transfer and adoption of technologies by firms and
organizations in sectors other than those that produce them. As shown in box 1, there is a particular focus on
promoting the adoption of digital technologies and AI by Canadian firms. How transformative these technologies will
be for the firms that adopt them will need to be assessed. Successful adoption is likely to occur through informal
relationships and the sharing of tacit knowledge, which are difficult to measure. It is the key to greater competitive
advantage and wealth creation for the adopting firms and organizations.
The contribution of innovation ecosystems to economic growth, competitiveness and wealth creation cannot simply
be measured in terms of the number of new products or processes or increases in exports, productivity and gross
domestic product. Some of the superclusters such as NGen, the supercluster focused on next- generation
manufacturing, have adopted more extensive performance ­indicators. Yet their overall approach is the same as
that of the government.[18] Such indicators may be easier to quantify, but they are at best proxies for innovation
and its impact. Ultimately, the government and the superclusters will need to develop more sophisticated indicators
to truly measure the potential and the impact of innovation ecosystems. This will enable stakeholders to adapt
innovation practices and policies to provide a win-win environment for the ecosystems and their constituent
organizations.
Supporting effective innovation ecosystems: Addressing knowledge gaps
The Innovation Supercluster Initiative provides a unique opportunity to advance knowledge about superclusters
beyond a few simple metrics aimed at demonstrating value for the public investment. Gaining a better
understanding of supercluster dynamics would benefit not only policy-makers but all stakeholders. Indeed, the
supercluster initiative should be viewed as somewhat of a Canadian experiment. Identifying the factors that facilitate

                                                                                                    Page 10 of 12
                 The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

the emergence and success of these superclusters and other ecosystems will help policy-makers better design and
fine-tune innovation policies and programs. The timing is certainly propitious. Having mobilized their communities
around specific technologies or sectors, groups that applied but were not chosen to become superclusters in 2017
have tried to maintain momentum by setting up more formal governance structures and accessing various
government programs. Identifying and measuring the commonalities and divergences of other innovation
ecosystems as they emerge would help governments target the right policies to foster their success.
We urgently need to design and test new metrics adapted to the reality of innovation ecosystems. The tools
currently at our disposal provide measurements that are at best proxies for true innovation potential. We need
indicators that accurately reflect the complex dynamics of collaborating across provinces, sectors and organizations
on the digital transformation of traditional sectors while making the most of the discontinuous and potentially
disruptive technologies.
There is still much we need to learn. For instance, the way in which innovation ecosystems emerge, adapt to
paradigm shifts brought about by new disruptive technologies, and bridge the gap between science and technology
and the commercialization of innovation is still poorly understood. Ecosystems are not static. They evolve as
innovations develop. It is therefore important to identify the characteristics and similarities of different types of
innovation ecosystems at different points in their life cycle. This includes their contribution to and impact on the
generation and conversion of ideas and on the commercialization and implementation of innovation.
We do not yet know how to assess the different governance structures that span informal and formal relationships
within innovation ecosystems. To ensure that the superclusters and other innovation ecosystems operate efficiently
requires a deeper understanding of the organizations and individuals at the core of these networks and the specific
roles they play as the convenors or facilitators of their ecosystems. There are numerous examples of successful
governance structures, shared intellectual property and trust-based collaborative groups in Canada. But they are
often well-guarded secrets. The Consortium de recherche et d’innovation en aérospatiale au Québec (CRIAQ) is
one example. Under the CRIAQ contract between universities and aerospace firms, all prior intellectual property is
declared and new intellectual property is shared among the industrial partners, without preventing academics from
conducting further research on the subject. This model has existed for several years and has contributed to
enhancing Quebec’s aerospace innovation performance.
A crucial task is to accurately gauge the win-win conditions for both individual organizations and ecosystems. It
would be counterproductive to adopt key performance indicators at the level of the individual organization, whether
it is a firm, university, government organization or innovation intermediary, that are incompatible with those at the
level of the innovation ecosystem. A minimum degree of coherence is necessary to ensure the success of well-
organized innovation ecosystems. That raises questions. How much self-organization or self-governance do
ecosystem members require as opposed to, or in addition to, a more top-down approach? How loose or formalized
should the decision-making process be within the ecosystem? How should its convenors oversee decision-making
to foster innovation? In the case of the superclusters, a strong sectoral governance structure may dominate and
impose itself, but it may not produce the expected innovation boost.
Developing new and validated key performance indicators for innovation ecosystems is one of the main goals of the
Partnership for the Organisation of Innovation and New Technologies. Although the scope of our project is broader
than measuring the impact of the superclusters, our research community has much to learn from innovation
ecosystem dynamics and the success factors underlying their performance. The superclusters initiative provides
fertile ground to test new ways to assess industrial and ecosystem performance and to compare those results with
more traditional metrics such as those mentioned in boxes 2 and 3. It is encouraging that the department of
Innovation, Science and Economic Development wishes to remain at the forefront of new research and is open to
developing news ways to measure the impact of its supercluster program. It has been a partner of our organization
since the beginning and is codeveloping with us these new indicators of ecosystem innovation and performance.
Challenges for Innovation Ecosystems and the Superclusters
In Canada, we are still looking for the recipe to scale up firms. How to scale up ecosystems is an even greater
challenge. We know, for instance, that stakeholders take part in ecosystems because they see an opportunity to
resolve issues and develop market opportunities. Firms scale up when their market expands locally or
­internationally. Ecosystems should help in that regard. However, multiorganization collaboration requires the
integration of working practices and processes. This can be challenging, especially when multiple organizations
from multiple sectors are involved. But aligning scaling up with multiorganization or sectoral collaboration is
precisely where the potential advantage of innovation ecosystems and superclusters lies.

                                                                                                        Page 11 of 12
                  The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

A related question to be investigated is whether innovation ecosystems are agile enough to provide an alternative to
the need for firms to scale up to succeed. Organizations and ecosystems are increasingly seeking to coordinate a
variety of activities that were formerly scattered across diverse entities focused on different technologies. They are
doing this not only to accelerate the innovation trajectory toward commercialization but also to overcome the cost
pressures, technological complexity and social acceptability issues that are making innovation projects more
complex. Complexity is forcing firms to collaborate. More research is needed to develop and implement new
practices, platforms, roles and functions to operationalize and govern ecosystems and their member firms as they
scale up. This is particularly important when multiple sectors are involved, as is the case for most superclusters.

As traditional economic sectors (aerospace and manufacturing in general) look to benefit from advances in big data
analytics and AI technologies, it is important to document and understand how ecosystems successfully evolve in
response to the challenges brought about by these technologies. Gaining better knowledge of these new networks
and collaborative spaces will contribute to the development of effective public policies and industry practices that
are conducive to the sustainability of ecosystems.

In this context, it is particularly important to understand the “modularity of technological artifacts” within innovation
ecosystems (Beltagui, Rosli and Candi 2020). This term refers to the degree to which the components of a
technology can be separated and recombined. At the heart of the supercluster initiative is the government’s wish for
a wide-scale digital transformation of the Canadian industrial fabric. Adoption of new digital modules within an
industry or sector, such as manufacturing or health care, will disrupt traditional innovation processes and constitute
a paradigm shift in all the sectors that will be affected. For instance, big data analytics is transforming the health
care ecosystem by recombining specific technological and medical modules (such as AI, genomics and
pharmacology), further personalizing medical treatment and fostering the emergence a new digital health
ecosystem. In the manufacturing sector, 3D printing will revolutionize and shorten the product development
process, displacing some of the traditional ways used to produce and assemble complex objects. The
manufacturing sector will need to evolve to benefit from these new technologies.
The integration of new technologies in more traditional sectors may require the use of specific creativity methods,
such as design thinking, to explore how to best combine knowledge from unrelated disciplines and sectors.[19] This
will likely involve other ­stakeholders, such as users and non-experts, which adds a level of complexity.
Organizations must come up with new configurations to support the development of creative ideas through both
internal and external initiatives (Cohendet, Grandadam and Simon 2010). Identifying the instigators of these
transformations will help trigger change in laggard sectors, clusters or ecosystems.

To fully benefit from their innovation ecosystems, individual firms will also need to adopt more open and agile
business models adapted to constant ecosystem evolution (Attour and Burger-Helmchen 2014). Analyzing how
sectors that have successfully adopted these advanced technologies have managed the transition would provide
invaluable knowledge for other sectors and ecosystems about to experience similar transformations. Worldwide,
efforts are being deployed to implement industry 4.0 (the adoption of digital technologies by manufacturing), smart
cities, self-driving cars, personalized medicine and smart electric grids. What these innovations have in common is
that they combine knowledge and technologies from a variety of sectors or disciplines. Their impact is also cross-
cutting. For instance, industry 4.0 and its underlying technologies will not only affect the manufacturing sector, but
also health, transport and agri-food. Breaking down disciplinary and sectoral silos within ecosystems will be crucial.
Yet public policy and regulation are still developed in sectoral silos that struggle to adapt to these disruptive
technologies. Moreover, the speed at which these radical innovations enter the market leaves decision-makers in
catch-up mode. This limits the innovation potential of the country.

Canadian public policy needs to change to enable the necessary transformations within firms, universities,
government and society in general. New policies are needed to support the extensive combination of knowledge
that spans multiple disciplines and sectors. Regulatory harmonization for sectors such as aerospace and health,
which are already undergoing a vast digital transformation, and information and communication technology is
urgently needed to avoid stopping transdisciplinary and cross-industry innovation in its tracks. To take one example,
the extent of data collection and the stringency of the cybersecurity required for precision medicine to fully deploy
suggest a clear shift is needed in the way we address regulation. One avenue that holds promise is for
governments to codevelop targeted public policies and appropriate regulations with innovation intermediaries in

                                                                                                      Page 12 of 12
                    The Superclusters Initiative: An Opportunity to Reinforce Innovation Ecosystems

ecosystems. Innovation support mechanisms also have to be developed in parallel with regulation. This would
provide a reinforcing policy framework where regulation is no longer seen as an obstacle to the adoption of new
technologies and to innovation in heavily regulated domains. [20]
Conclusion
At the beginning of this study, we highlighted the growing concern that Canada has failed to benefit from its strength
in science and technology when it comes to ­successfully commercializing innovation. The last two decades have
seen a proliferation of university-industry funding programs. Yet these have failed to produce the desired outcomes.
Something different is needed. Taking the bull by the horns, so to speak, the government initiated the Innovation
Superclusters Initiative to try to reverse the downward trajectory of innovation. Starting from the premise that united
we stand, the program aims to build a critical mass of partnerships between research facilities and industry that will
boost innovation, productivity and competitiveness. Encouraging a more coordinated approach to ensure that
transformative technologies[21] reinvigorate industrial capabilities is a bold move that is being followed closely by
other countries.
Noting that the Canadian superclusters are in fact more akin to innovation ecosystems than clusters, we briefly
surveyed the pertinent literature on the building blocks of innovation ecosystems. These include industrial clusters,
knowledge networks, collaboration and open innovation. As none of the lenses suffices to comprehend the
dynamics of innovation ecosystems, we argued that a multidisciplinary framework needs to be developed to fully
understand how the superclusters operate, to measure whether their goals are achieved, and to evaluate their
performance.

Furthermore, as they prepare for the adoption, diffusion and impact of discontinuous and potentially disruptive
technologies such as AI and industry 4.0, Canadian firms are having to acquire a whole new set of skills that they
may not have the capacity to absorb on their own. The speed at which new technologies are being developed
forces all stakeholders to be involved from the beginning in well-coordinated collaborative entities, such as
innovation ecosystems or superclusters. Accurately monitoring the success of innovation ecosystems and of the
firms and organizations therein requires the development of new indicators. These indicators would complement the
traditional key performance indicators that we automatically turn to because they are relatively easy to measure,
master and understand. Herein lies the challenge. The extent of the coordination required to ensure the success of
the superclusters, or to propose how to change tack in real time if need be, is unprecedented. So too is the task
entailed in accurately measuring that success.
Developing, testing and providing new and more appropriate performance indicators for innovation ecosystems is
the challenge our team took on in 2018. Such indicators will be invaluable. They will ensure that the cross-cutting
impact and innovation potential of integrating knowledge and technology from multiple sectors and disciplines is
taken into account. They will also help Canada develop effective and reinforcing innovation policies and regulatory
frameworks adapted to innovation ecosystems. The results of our research will help Canadian innovation
ecosystems, including the superclusters, evolve and have a long-lasting positive impact on our economy.


Load-Date: October 9, 2020


  End of Document

                                                                                                         Page 1 of 2
                                                       No Headline In Original




                                                    No Headline In Original
                                              Record-Journal (Meriden, Connecticut)
                                                       August 8, 2023 Tuesday



Distributed by Newsbank, Inc. All Rights Reserved
Copyright 2023 Record-Journal

Section: RECORDJOURNAL; Pg. A007
Length: 397 words

Body


Artificial intelligence

From A2

partisan AI legislation in Congress, which Senate Majority Leader Chuck Schumer said in June would maximize the
technology's benefits and mitigate significant risks. Yet the New York senator did not commit to specific details. In
July, President Joe Biden announced his administration had secured voluntary commitments from seven U.S.
companies meant to ensure their AI products are safe before releasing them.

Maroney said ideally the federal government would lead the way in AI regulation. But he said the federal
government can't act at the same speed as a state legislature.

"And as we've seen with the data privacy, it's really had to bubble up from the states," Maroney said.

Some state-level bills proposed this year have been narrowly tailored to address specific AI-related concerns.

Proposals in Massachusetts would place limitations on mental health providers using AI and prevent "dysto p ian
work environments" where workers don't have control over their personal data. A proposal in New York would place
restrictions on employers using AI as an "automated employment decision tool" to filter job candidates.

North Dakota passed a bill defining what a person is, making it clear the term does not include artificial intelligence.
Republican Gov.

Doug Burgum, a long-shot presidential contender, has said such guardrails are needed for AI but the technology
should still be embraced to make state government less redundant and more responsive to citizens.

In Arizona, Democratic Gov.

Katie Hobbs vetoed legislation that would prohibit voting machines from having any artificial intelligence software. In
her veto letter, Hobbs said the bill "attempts to solve challenges that do not currently face our state."

                                                                                                   Page 2 of 2
                                             No Headline In Original

In Washington, Democratic Sen. Lisa Wellman, a former systems analyst and programmer, said state lawmakers
need to prepare for a world in which machine systems become ever more prevalent in our daily lives.

She plans to roll out legislation next year that would require students to take computer science to graduate high
school.

"AI and computer science are now, in my mind, a foundational part of education," Wellman said. "And we need to
understand really how to incorporate it."

Associated Press Writers Audrey McAvoy in Honolulu, Ed Komenda in Seattle and Matt O'Brien in Providence,
Rhode Island, contributed to this rep ort.


Load-Date: August 11, 2023


  End of Document

                                                                                                          Page 1 of 3
                   22nd Congressional District: Valadao-Salas race may come down to political loyalties




22nd Congressional District: Valadao-Salas race may come down to political
                                 loyalties
                                                        The Bakersfield Californian
                                                          October 9, 2022 Sunday



Copyright 2022 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: NATIONAL POLITICAL NEWS
Length: 896 words
Byline: John Cox, The Bakersfield Californian

Body


Oct. 9—In the big race for California's 22nd Congressional District seat, surely there's a lesson to be learned from
the results of the June primary. But which lesson?

Assemblyman Rudy Salas, the Democratic challenger who beat incumbent Rep. David Valadao by almost 20
percentage points in that election, said the key takeaway is that "more Republicans voted against (Valadao) than
for him."

They did, by a margin of 3.6 points, but the Hanford Republican sees it differently. Valadao noted he and the other
two candidates from his party won a greater share of votes in the primary than Salas' 45.2 percent.

Even if Valadao did lose support by voting to impeach former President Donald Trump after the Jan. 6, 2021, U.S.
Capitol riot, he said, they're not about to let a Democrat win on Nov. 8.

"By leaving a ballot blank, I think, they're going to make sure Salas wins," Valadao said, "and I don't think they're
going to do that."

Uncertainty over whose view is correct has caught the national attention — again, in a sense — in a contest
observers see as one of the tightest and most important nationwide in the battle for control of the U.S. House of
Representatives.

"This is one of the most watched (races) in the country," said University of Southern California political scientist
Christian Grose, who said Salas may have a "very, very slight" advantage over Valadao.

Valadao, a four-term congressman, narrowly defeated former Rep. T.J. Cox, the Democratic incumbent, two years
ago in the race for what was then the 21st Congressional District. Redistricting since then has given the district
more of a Democratic advantage, with 43.5 percent of voter registrations to 26 percent Republican and almost 22.6
percent stating no party preference.

                                                                                                         Page 2 of 3
                22nd Congressional District: Valadao-Salas race may come down to political loyalties

The combination of high stakes and a close contest has attracted not just attention but campaign and outside
money, and with it, attack ads — another carryover from Valadao's race against Cox.

Whether it's helpful to go negative on political commercials remains an open question. Grose said swing voters like
those who may determine the winner of the 22nd District seat don't generally like negative ads. But not everyone
agrees.

Longtime Bakersfield Republican political strategist Cathy Abernathy said free speech allows candidates to praise
or criticize. Swing voters may respond to negative ads, she added, because they're less committed to a particular
political philosophy.

Ivy Cargile, associate professor of political science at Cal State Bakersfield, said the body of literature on negative
ads has not shown whether they help or hinder political campaigns. But she said that, in a race as important as the
22nd, it's no surprise the gloves came off. Still, she's unsure who has come out ahead.

"I don't know that either one of them has a stronger narrative than the other," she said, adding it's likely some
Republicans still sore over Valadao's impeachment vote will "hold their noses" and support him come November.

Cargile noted Trump has not made an endorsement either way in the race, and that unlike in the 2020 race,
Democrats don't seem to be linking Valadao to the former president as a means of undercutting the congressman's
support.

Salas, the son of a farmworker who has served 10 years in the Assembly after becoming the first Hispanic to serve
on the Bakersfield City Council, points to his record of bringing taxpayer money to his district.

He takes credit for steering $50 million from the state to the Kern Community College District for creation of its new
California Renewable Energy Laboratory, plus $10 million for Adventist Health's AIS Cancer Center in downtown
Bakersfield, $8 million for the Farmworkers Institute of Education & Leadership Development facility in Bakersfield,
and $6 million each for nursing education at Bakersfield College and Cal State Bakersfield.

"I tell people, look," he said, "my job is to get all of our taxpayer money back into the community."

Valadao, a dairyman who has focused much of his efforts in Congress to help the Central Valley's farming industry,
points to his work on a 2016 bipartisan infrastructure bill that supports water infrastructure development in the West.
Other successes he notes include a law designed to bring more physicians to the valley, improvements to Naval Air
Station Lemoore and expansion of a Kern County food bank.

By his reckoning, Valadao enjoys an advantage over Salas in attracting resources from Republicans around the
country. He said it's helpful to him when voters see President Joe Biden's policies as increasing inflation and raising
gasoline prices.

"We know we've got a tough race," he said, "but I think we're in a really good spot."

The chairman of the Kern County Republican Party, Bakersfield City Councilman Ken Weir, said Central Valley
farmers appreciative of Valadao's legislative work on water and other matters "will return him to Washington."

But Robin Walters, president of the Democratic Women of Kern, said Salas has done much for the Central Valley,
and that Valadao's impeachment vote still looms large for some.

What bothers her is the negativity on both sides.

"I think people will be glad when it's over," she said, "because of the ads."

___ (c)2022 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.

                                                                                                      Page 3 of 3
               22nd Congressional District: Valadao-Salas race may come down to political loyalties


Load-Date: October 12, 2022


  End of Document

                                                                                                          Page 1 of 3
                   22nd Congressional District: Valadao-Salas race may come down to political loyalties




22nd Congressional District: Valadao-Salas race may come down to political
                                 loyalties
                                                        The Bakersfield Californian
                                                          October 9, 2022 Sunday



Copyright 2022 The Bakersfield Californian (Bakersfield, Calif.)

Distributed by Tribune Content Agency

Section: NATIONAL POLITICAL NEWS
Length: 896 words
Byline: John Cox, The Bakersfield Californian

Body


Oct. 9—In the big race for California's 22nd Congressional District seat, surely there's a lesson to be learned from
the results of the June primary. But which lesson?

Assemblyman Rudy Salas, the Democratic challenger who beat incumbent Rep. David Valadao by almost 20
percentage points in that election, said the key takeaway is that "more Republicans voted against (Valadao) than
for him."

They did, by a margin of 3.6 points, but the Hanford Republican sees it differently. Valadao noted he and the other
two candidates from his party won a greater share of votes in the primary than Salas' 45.2 percent.

Even if Valadao did lose support by voting to impeach former President Donald Trump after the Jan. 6, 2021, U.S.
Capitol riot, he said, they're not about to let a Democrat win on Nov. 8.

"By leaving a ballot blank, I think, they're going to make sure Salas wins," Valadao said, "and I don't think they're
going to do that."

Uncertainty over whose view is correct has caught the national attention — again, in a sense — in a contest
observers see as one of the tightest and most important nationwide in the battle for control of the U.S. House of
Representatives.

"This is one of the most watched (races) in the country," said University of Southern California political scientist
Christian Grose, who said Salas may have a "very, very slight" advantage over Valadao.

Valadao, a four-term congressman, narrowly defeated former Rep. T.J. Cox, the Democratic incumbent, two years
ago in the race for what was then the 21st Congressional District. Redistricting since then has given the district
more of a Democratic advantage, with 43.5 percent of voter registrations to 26 percent Republican and almost 22.6
percent stating no party preference.

                                                                                                         Page 2 of 3
                22nd Congressional District: Valadao-Salas race may come down to political loyalties

The combination of high stakes and a close contest has attracted not just attention but campaign and outside
money, and with it, attack ads — another carryover from Valadao's race against Cox.

Whether it's helpful to go negative on political commercials remains an open question. Grose said swing voters like
those who may determine the winner of the 22nd District seat don't generally like negative ads. But not everyone
agrees.

Longtime Bakersfield Republican political strategist Cathy Abernathy said free speech allows candidates to praise
or criticize. Swing voters may respond to negative ads, she added, because they're less committed to a particular
political philosophy.

Ivy Cargile, associate professor of political science at Cal State Bakersfield, said the body of literature on negative
ads has not shown whether they help or hinder political campaigns. But she said that, in a race as important as the
22nd, it's no surprise the gloves came off. Still, she's unsure who has come out ahead.

"I don't know that either one of them has a stronger narrative than the other," she said, adding it's likely some
Republicans still sore over Valadao's impeachment vote will "hold their noses" and support him come November.

Cargile noted Trump has not made an endorsement either way in the race, and that unlike in the 2020 race,
Democrats don't seem to be linking Valadao to the former president as a means of undercutting the congressman's
support.

Salas, the son of a farmworker who has served 10 years in the Assembly after becoming the first Hispanic to serve
on the Bakersfield City Council, points to his record of bringing taxpayer money to his district.

He takes credit for steering $50 million from the state to the Kern Community College District for creation of its new
California Renewable Energy Laboratory, plus $10 million for Adventist Health's AIS Cancer Center in downtown
Bakersfield, $8 million for the Farmworkers Institute of Education & Leadership Development facility in Bakersfield,
and $6 million each for nursing education at Bakersfield College and Cal State Bakersfield.

"I tell people, look," he said, "my job is to get all of our taxpayer money back into the community."

Valadao, a dairyman who has focused much of his efforts in Congress to help the Central Valley's farming industry,
points to his work on a 2016 bipartisan infrastructure bill that supports water infrastructure development in the West.
Other successes he notes include a law designed to bring more physicians to the valley, improvements to Naval Air
Station Lemoore and expansion of a Kern County food bank.

By his reckoning, Valadao enjoys an advantage over Salas in attracting resources from Republicans around the
country. He said it's helpful to him when voters see President Joe Biden's policies as increasing inflation and raising
gasoline prices.

"We know we've got a tough race," he said, "but I think we're in a really good spot."

The chairman of the Kern County Republican Party, Bakersfield City Councilman Ken Weir, said Central Valley
farmers appreciative of Valadao's legislative work on water and other matters "will return him to Washington."

But Robin Walters, president of the Democratic Women of Kern, said Salas has done much for the Central Valley,
and that Valadao's impeachment vote still looms large for some.

What bothers her is the negativity on both sides.

"I think people will be glad when it's over," she said, "because of the ads."

___ (c)2022 The Bakersfield Californian (Bakersfield, Calif.) Visit The Bakersfield Californian (Bakersfield, Calif.) at
www.bakersfield.com Distributed by Tribune Content Agency, LLC.

                                                                                                      Page 3 of 3
               22nd Congressional District: Valadao-Salas race may come down to political loyalties


Load-Date: October 9, 2022


  End of Document

                                                                                                      Page 1 of 7
                     THE COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's




         THE COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and
                                  Valentine's
                                          The Brown Daily Herald: Brown University
                                                      February 12, 2021 Friday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: NEWS; Pg. 1
Length: 4471 words

Body


On Friday, Feb. 12, the COVID Pod team sits down with Ashish Jha, dean of the School of Public Health, to
discuss the variations underlying the COVID-19 pandemic and efforts to stop its spread: virus variants, new
vaccines in development - and even a COVID-19-conscious approach to socializing on Valentine's Day. Jha also
touches on the recently launched COVID-19 vaccination tracker established in-part through the School of Public
Health, as well as Brown's new Pandemic Problem-Solving course for civil servants and other leaders, which will
begin Feb. 16.

Subscribe to the podcast on Spotify, Apple Podcasts or listen via the RSS feed and email us to contribute a
question for the next episode: herald@browndailyherald.com

Cate Ryan

Welcome back to The COVID Pod with Dr. Ashish Jha. Today, we are talking about variation. And this year has
been filled with so much change, but on today's episode, we are specifically focusing on virus variants, new vaccine
types and possibly some variations to typical Valentine's day plans. Today is Friday, February 12, 2021. My name
is Cate Ryan and I am joined by Emilija and Rahma from the Brown Daily Herald.

Emilija Sagaityte

Hello, my name is Emilija Sagaityte, and I am a senior editor at The Herald.

Rahma Ibrahim

And my name is Rahma Ibrahim. I am a science and research section editor.

Cate Ryan

As always we are so grateful to welcome Ashish Jha who is Dean of the School of Public Health here at Brown
University. Thanks for listening, and feel free to email us if you have any questions.

Cate Ryan

                                                                                                            Page 2 of 7
                    THE COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's

The first thing that we were thinking about is the Centers for Disease Control and Prevention (recent change of)
guidelines to say that anyone who is asymptomatic and has received the second dose of their vaccine does not
need to quarantine if exposed to COVID-19. And last time, we talked about how it was sort of unclear whether the
vaccine would completely reduce transmission. So what do you think is the implication of these new guidelines?

Ashish Jha

Yeah, so this is like the million dollar question, right? Do vaccines reduce transmission? And I think the C.D.C. is
right in their decision or their recommendations. I think they're coming in line with what I think the emerging
evidence is, and the emerging evidence is that vaccines reduce transmission. Am I 110 percent sure? No. But that's
what all the data seem to suggest. And by the way, almost every vaccine, not every vaccine, but almost every
vaccine reduces transmission of the disease, so why would we think this one is going to be different?

And then the question is, how much? And could we envision that these vaccines would reduce transmission 100
percent? I don't think so. So there probably will be still a little, but my best guess, based on all the data, is that it's
probably in the 70 to 90 percent reduction range. But we're not sure. And I think the C.D.C. is basically saying, but
that's where all the evidence is pointing and that's what we should focus on. And we will get better data. And I
suspect that that's the range it will come out. And that's great news, by the way, because if it didn't reduce
transmission, then my gosh, then we have a whole different set of problems.

Emilija Sagaityte

So speaking of vaccines, we wanted to transition to speaking about another development, the U.S. and Worldwide
Vaccine Tracker that was developed through a collaboration between Brown's School of Public Health and
Microsoft AI for Health, which just launched online February 5th. Could you tell us about the purpose of this tool,
describe what all those numbers and maps show and explain a bit about how this tracker was created?

Ashish Jha

Absolutely. So we've had a collaboration with Microsoft for a while now. And if you go to the website,
globalepidemics.org, which is run by us at the School of Public Health, we've been tracking cases by community,
by congressional district. We've been doing a whole lot of work on testing and testing targets. And so vaccines
seem like the obvious next place to go in terms of tracking the data.

The data largely comes from - and there are other vaccine trackers, like Bloomberg has one - they all sort of come
from the same place. They come from states, and they come from the C.D.C. So we're not doing our own personal
tracking, but we're really pulling in data. And the idea behind this, and what I hope will be really useful for people,
there are two sets of things that I think are going to be important.

One is, there's a lot of information that we need to have beyond just how many people have gotten vaccines. We
need to know who's getting vaccinated (and) how much it varies by age, by race and ethnicity. And we're starting to
pull those together into one place. We're hoping that that's going to be a useful set of insights. But the other part is,
I've described three sets of things now that we're tracking: cases, testing, vaccines. They are not unrelated to each
other. In fact, you may think that it's really important to vaccinate people in places where there's a high number of
cases happening, and I would agree with that. So what this tracker lets you do is start pulling these three things
together. And so you can go to your community - and again, we don't have the data quite as granular as we would
like, just because it isn't available yet, and it will be - but ideally, what we'd like to be able to get to in the weeks
ahead, is you can go to your county, certainly your state, look at infection numbers, look at vaccination numbers,
look at testing numbers and really get a sense of how the broader pandemic control's happening. And we're not
aware, or I'm not aware, of any tracker that's really pulling it all together like that.

Emilija Sagaityte

Have you been able to notice any trends so far between those three factors?

Ashish Jha

                                                                                                            Page 3 of 7
                    THE COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's

Yeah. So I would say right now, we're just, well, a couple of things. I mean, we're just starting to pull this stuff
together. It is true that we see no real correlation between places with high infections versus places that are doing a
good job on vaccinations or a bad job, or vaccines are getting out. And that's unfortunate, because you actually
want to see more aggressive vaccinations happening in places with high infection numbers. We don't see that yet.
We don't see that happening, so that's a problem. And my hope is that we can take these kinds of data, go back to
policymakers and say, 'You've got to really push on vaccinations, and especially in those areas.'

Emilija Sagaityte

And the tool also mentioned trying to see whether the U.S. can reach that goal of 100 million doses in 100 days,
and kind of looking at the status of vaccine distribution right now, what does it seem to suggest about our nation's
ability to reach that goal? And what factors or efforts do you think may influence those trends?

Ashish Jha

The 100 million in 100 days is what President Biden said in early December when he was President-Elect Biden, he
wasn't in office yet. And that seemed like a really ambitious goal at the time. To be perfectly honest, we're at almost
1.5 million doses a day right now, and that's what we've been averaging. So my gosh, we got to be able to hit 100
million in 100 days, it's like something's gonna have to go horribly wrong for that not to happen.

Personally - and the people in the administration don't like me saying this I don't think, but I'll say it - I think we
should be hitting two million a day, like that's where we need to be. And I'm not saying they don't like me for saying
this; I'm just saying that's a very ambitious agenda. And that's what I would like for us to do, and so we're targeting
1 million a day. I think we're gonna hit that easily. You know President Biden did come out and say he thought we
could do 150 (million). That's 1.5 (million) a day. I think we're gonna blow through that. I think the question is, are
we going to get to 2 million a day? And the reason why I say 2 million a day is my target is, I'm not just making up a
random number, I'm thinking about two things. I'm thinking about the U.K. variant, and how it's spreading and when
it will become widespread in the United States. And I'm thinking about, what is it going to take to vaccinate all
elderly, older, high-risk individuals. And if you try to get older, high-risk individuals all vaccinated before the U.K.
variant becomes widespread, you (have) to be at 2 million a day in order to get there. And that's the challenge. So
that's why that should be our internal target.

Rahma Ibrahim

Speaking of variants, which is a term that's been in the news a lot recently, could you give us and our listeners a
quick overview on the difference between variants and strains?

Ashish Jha

You know, so it's a really good question. And ultimately, these things are really about functionality. So let's take a
moment and actually take one more step back and talk about mutations versus variants versus strains.

The way to understand the biology here is that RNA viruses, like this virus, are notorious at making mistakes. Every
time they replicate, they're just a ton of mistakes that they make, a ton of mutations, and 99.9999 percent of those
mutations are irrelevant, they have like little to no meaning. And the helpful part about these mutations is actually
you can use them to track where the virus is spreading and who's spreading it to whom through these genomic
sequencing analyses. But all of those different mutations are functionally the same.

So what causes something to be a strain? It's a different strain if it takes on different functional capabilities. So if it
becomes more contagious, if it becomes more or less deadly, if it is able to evade immune response much more
effectively, if there's something functionally meaningfully different about it, then you call it a different strain. And
while you're sorting out whether a set of mutations is a strain or not, we often talk about it as a variant. And variant
is really kind of meant as a short-term, shorthand for, this probably is a different strain, but we're not 100 percent
sure, and we're still sorting it out. So I think most biologists and immunologists I talked to would call the U.K. variant
a different strain because I think we have pretty good evidence now that it really is functionally really different. And

                                                                                                               Page 4 of 7
                    THE COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's

some of the other variants like, you know, there was a little talk of the L.A. variant that popped up in Los Angeles,
and calling that a variant made sense because we didn't know, is it really a different strain, or is it just gonna turn
out to be nothing? So I see variant as a short-term terminology used when you're not sure whether there's a
different strain or not, and you're sorting it out.

Rahma Ibrahim

We've also heard of other variants, the South African, the Brazilian variants, and you've mentioned the U.K. - which
might be a strain - and the L.A. variant. So how many variants do we know of so far? And what do we know about
them? And how far have been traveled?

Ashish Jha

There are lots of variants. And the ones that I think we're all paying super close attention to right now are the U.K.
one, the other one found initially in U.K. B.1.1.7. There's B.1.351 that's from South Africa. And there's one that's
called P.1, which is the one from Brazil. And we don't, by the way, know that that's where they originated; that's
where we first identified them. So that's the other part of it.

But if we're going to shorthand it and say, the U.K., the South Africa and the Brazil, those are three that are all here
in the United States. And we think the U.K. variant is circulating reasonably widely. I suspect it's in all 50 states or
most of the states. It's been identified, I think, in 35, but my take is, the other 15 probably just haven't identified
them yet. The South Africa variant is interesting in that it may be a bit more contagious. The U.K. variant is clearly
more contagious. The South Africa variant may be more contagious, but it does seem to be more effective at
evading immune response. I still am very optimistic, and we can talk more about this that our vaccines will work
against it, but we're less sure - it may work a little less well, I wouldn't say we're less sure. And then on the Brazil
variant, we know much less about it. There is some data to suggest that people who have been previously infected
may not have protection against the Brazil variant. But I don't think we know enough about that right now, and
there's a lot of work being done to sort that out.

Rahma Ibrahim

On that same note of people being previously infected with COVID-19 and their risks for being infected again with
these variants, I know you mentioned we don't necessarily know much about that, but what does the data that we
have currently say about people's ability to be infected twice, by another variant?

Ashish Jha

So the vast majority of the infections right now of the virus circulating is still the native strain, the original strain. And
people getting reinfected with the original strain we think (is) exceedingly unlikely. We don't know the real number.
Officially, it's about 10 or 12 people have been reinfected in the United States out of 25 million. I suspect the real
reinfection rate is higher than that, but probably not much higher, meaning bottom line, if you've been infected, your
chances of getting reinfected are not zero, but they're really, really low.

How does the variant stuff change that? I don't know that I've seen any data that suggests that the U.K. variant
changes that at all, so if you were previously infected, recovered, now you get exposed to the U.K. variant, I don't
think it changes your likelihood of getting reinfected. But we're not sure. There is some evidence that South Africa
and Brazil variants lead to more reinfections because of some amount of immune escape, but the evidence is really
weak and certainly not perfect. I wouldn't be surprised if there is a little bit of immune escape, certainly from the
South Africa variant where we may have the best data on that. But I actually think that the vaccines will protect us
against that.

What's interesting, right, here's the bottom line, natural immunity from having been previously infected may not
protect you against the South Africa variant, but vaccines probably will. And that's interesting, just a reminder that
vaccines can generate much, much better immunity than natural infection can. I think a lot of people assume that

                                                                                                        Page 5 of 7
                    THE COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's

natural immunity is the best immunity, but we have very good evidence for lots of diseases that's not true, that we
can generate much, much better immunity using vaccines than natural infection does.

Emilija Sagaityte

Kind of going back to vaccines, and how many have come about from research in recent months: I do think that
Pfizer and Moderna seem to have become household names when talking about the COVID-19 vaccines. But last
time, you had alluded to some other companies who are in the process of developing and testing their own
vaccines, like Johnson and Johnson, Novavax, AstraZeneca, as well as some developed in other countries, like I
believe Sputnik V was being developed in Russia. So what do you make of all of these different versions? How are
they different? How are they similar?

Ashish Jha

So there are a lot of different ways of making vaccines, and you've seen companies around the world trying to
make them in different ways. And my personal take is, we need all the vaccines we can get. As long as they're safe
and effective, we should be able to come up with different modalities. Different modalities have advantages and
disadvantages. mRNA vaccines, like the Moderna and Pfizer, which are fabulous vaccines, are really hard to store
and manage, they need to be frozen. The Pfizer one particularly needs to be frozen, minus 96 degrees for extended
periods of time, whereas (vaccines) like the Johnson and Johnson vaccine can be refrigerated, does not need to be
frozen. And so you can imagine why that would be a huge advantage in many, many places.

Here's where we are, as of today, February 12th. The Johnson and Johnson vaccine has been submitted for
authorization to the F.D.A., and the F.D.A. is going to meet on February 26, two weeks from today, they're going to
make a decision. I would be shocked if they don't authorize it based on the data we've seen, but they might not.
F.D.A. has a pretty high bar, they're gonna do a very vigorous review. But I say I'd be shocked because I know the
people that are working on developing that vaccine, and they wouldn't have submitted it unless the data was really
very good. And so I expect an authorization in the day or two that follows. There are a few million doses sitting
around, but not tens of millions. So in March, probably not a huge impact of the Johnson and Johnson vaccine;
you'll start seeing some people get vaccinated. And then once we enter April and May, you'll see that become much
more widespread.

The one thing I will say about the Johnson and Johnson vaccine is its headline numbers seem to be not as good as
Moderna and Pfizer. People are like, Oh, it's only 65 or 85 (percent effective). It's a very good vaccine based on all
of the data I have seen so far. We'll see more in the next couple of weeks. It's a very, very good vaccine, I would
recommend it for any family member. I would not be hesitant to get it myself. I've gotten the first dose of the
Moderna vaccine, I'll be getting my second soon, but the point is, I would be very supportive of my wife getting it.
She has not been vaccinated yet. So it's a very, very high quality vaccine. And I would not pay too much attention to
the headline number.

Novavax again, we were going to get more data on that. I think the AstraZeneca trials that are being done in the
United States, I expect them to read out, meaning get some data on those, in the next month, so by the time we get
to mid-March. And I can imagine a late March, early April F.D.A. review and an authorization.

Sputnik V came out with their data. It's really good.

So the good news here is, this is a virus where we figured out how to make good, effective vaccines, thank
goodness. But there are just going to be challenges of producing enough, getting them out. And then by the time
we get to May, we're gonna have a different problem, which is we're gonna have so much vaccines in the United
States, and we're going to have not enough people who want to get vaccinated because we're going to run into all
the people who have vaccine hesitancy, people who are worried about taking the vaccines, and we've got to start
working on addressing those concerns now.

Emilija Sagaityte

                                                                                                            Page 6 of 7
                   THE COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's

And so I know you touched upon this a little bit before, but given the evidence to date, what do you think it suggests
about then these vaccines' potential help with distribution as well as minimizing the impact from those variants we
talked about both here in the U.S., as well as looking more globally?

Ashish Jha

So I think the evidence we have right now says that certainly the Moderna, Pfizer vaccine, also I think Johnson and
Johnson, is going to work very well against the U.K. variants. So I'm not worried about that. I think it will work a little
less well against the South Africa variant, but well enough that, if you got vaccinated, you're gonna do fine. Even if
you might have a slightly higher risk of getting infected, I think people will not get sick and die, which is what we
care about, preventing severe illness. So I'm really, really, at this point, very confident that these vaccines are going
to hold up well against the variants we have. It doesn't mean that there won't be a variant in the future that will
escape our immune response, and I actually think one of the things we need to be doing is much more genomic
surveillance to look for those variants. And then if you see one emerging that looks like that, working on updating
our vaccines so that they can be more effective.

There's a lot of work here. This is not a one and done, like it's not going to be we all get vaccinated. We have to
continue monitoring, continue paying attention. And the last point on this is because it's a global pandemic, if we
just get America vaccinated, but the world isn't vaccinated, it's going to be a huge problem, obviously just from an
equity point of view, but also if we see large outbreaks happening elsewhere, America's largely vaccinated, it's
going to be the ground for emergence of new variants that will render our vaccines less effective. So there's both a,
I think, a selfish as well as a more solidarity-oriented set of reasons for really having a global approach to vaccines.

Cate Ryan

Speaking of all of these complex problems, we sort of wanted to highlight something hopeful, which is the course
that you're teaching with Dr. Megan Ranney called Pandemic Problem-Solving, which is for civil servants and other
leaders. What do you think that will look like over the next month or so, and what are you looking forward to with
that course?

Ashish Jha

I'm super excited about this. And the reason is, you know, the pandemic has felt kind of paralyzing, right? Like, it's
just sort of disrupted our lives. And people feel like, I don't know how to manage problems, and like, what can I do,
and we're all in this sort of suspended animation just waiting for these vaccines so we can start getting things back.

And what Megan and I and our whole team realized was, there are lots of people who, during the pandemic, have
confronted problems, and solved them, and made progress and done really remarkable things. And they have
lessons for all of us on how we get through the rest of this pandemic, and how we deal with future ones. And so it's
a very problem-solving kind of oriented course, where we have experts in business, political leaders, all sorts of
folks who are going to participate and talk about how they dealt with uncertainty, how they made decisions. And
then the hope is that the students in the course - a lot of them are from N.G.O.s or government or private sector -
are going to talk about how those lessons apply to their real life. So it is very practical, supposed to be hands-on.
And I guess for me, it's meant to give people hope and something they can actually do and teach them a set of
skills. But I have to tell you, I'm going to learn a ton because while it's been really fun watching people make
decisions and watching leaders figure out how to do this stuff, the course will actually teach us how to apply this to
a much broader swath of issues. And so I expect to learn a lot about how to think about these things.

And the last point is, it's an interesting foray for Brown, right, because we don't do this kind of stuff. We teach
courses in pretty traditional ways to undergrads, graduate students, but I think the way in which the world is
changing, universities have an obligation to teach people who are not our traditional students. And it's not even like
executive education. It's just a different model. It's in the middle of crises, universities have to step up and pull
together knowledge and share it widely and in constructive ways. And that's what this is about. So I think this is part
of a broader strategy that Brown is thinking about, which is, how do we engage and be more relevant in the world in

                                                                                                             Page 7 of 7
                    THE COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's

the middle of crises? How do we bring our expertise to bear, and I love that by the way, because that's, of course,
what I think all universities should be doing, and I'm particularly excited that Brown is doing it.

Cate Ryan

Yeah, that sounds like such a great resource for so many people. So before we end, we wanted to also touch on
something else kind of fun, which I guess is Valentine's Day, and we specifically wanted to bring up this article that
was published in The Brown Noser, which is the satirical newspaper that's written by Brown undergrads. So this is a
joke, but it was headlined, "Paxson Clarifies That Every Student Allowed One Little Kiss On Valentine's Day," and
that it's obviously a joke, but we just wanted to ask in all seriousness, how should students on college campuses
like Brown be approaching making new friends or new romantic relationships during this COVID semester?

Ashish Jha

Oh, boy, that is a really hard question. Because those are really important things. Social, personal, romantic
relationships are like the heart of being human, right? And so how long can you continue to suspend these things?
So look, I mean, first of all, it's much easier if you can do stuff in pods, you can't always. The issue around this, in
my mind, is we have added a set of protections that obviously make life much, much easier here in terms of not just
the mask stuff, but I think the fact that people are getting tested on an ongoing basis. I think it's totally safe for
people to spend time outdoors together; I think there's things that people can do. And, obviously, I'm not going to
say people should feel comfortable on Valentine's Day violating their pod rules because, you know, it is risky. And
right now is particularly so with these variants circulating. But so I feel like I don't have a great answer beyond, I'm
really sympathetic to the moment we're in, I think there are ways of socializing with people that is safer than others.
And I guess the other thing I will say is, I expect that all of this is going to start really meaningfully turning around in
the next couple of months, I think there'll be more vaccines, there'll be plenty of vaccines by April, May. So if people
can hold on a little bit longer, that will help; if you can't, try to do things more safely. There is no perfect thing here.
But it's hard to tell people to just completely ignore Valentine's Day if that's important to you. So some amount of
risk is probably just a reality of life in a pandemic.

How is that for a non-answer? I feel like I didn't really give you an answer. I went right up to the edge. It's very hard,
right? Because on one hand, like the right answer is, you can't do anything. But the reality is like, that's just not life.
And asking people to suspend life forever, I think it's not realistic. So I think people have to make trade-offs. And
people have to make choices and understand there are risks. And as long as we're, I think, all open and transparent
about it, that's really all you can expect.

Cate Ryan

Yeah, thank you, that makes a lot of sense. And we're all looking forward to these changes with the vaccination
rates going up and everything over the next few months. So we'll continue to see everything unfold and hopefully a
more bright way. But thanks so much, again, for being here with us this week, and we look forward to more
conversations to come this semester.

Ashish Jha

That sounds great. See you all very soon and stay well.


Load-Date: February 13, 2021


  End of Document

                                                                                                    Page 1 of 6
       The COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's - The Brown Daily Herald




          The COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and
                      Valentine's - The Brown Daily Herald
                                          The Brown Daily Herald: Brown University
                                                      February 12, 2021 Friday



University Wire
Copyright 2021 UWIRE via U-Wire All Rights Reserved

Section: UNIVERSITY-NEWS; Pg. 1
Length: 4522 words

Body


On Friday, Feb. 12, the COVID Pod team sits down with Ashish Jha, dean of the School of Public Health, to
discuss the variations underlying the COVID-19 pandemic and efforts to stop its spread: virus variants, new
vaccines in development - and even a COVID-19-conscious approach to socializing on Valentine's Day. Jha also
touches on the recently launched COVID-19 vaccination tracker established in-part through the School of Public
Health, as well as Brown's new Pandemic Problem-Solving course for civil servants and other leaders, which will
begin Feb. 16. Subscribe to the podcast on Spotify, Apple Podcasts or listen via the RSS feed and email us to
contribute a question for the next episode:

herald@browndailyherald.comCate RyanWelcome back to The COVID Pod with Dr. Ashish Jha. Today, we are
talking about variation. And this year has been filled with so much change, but on today's episode, we are
specifically focusing on virus variants, new vaccine types and possibly some variations to typical Valentine's day
plans. Today is Friday, February 12, 2021. My name is Cate Ryan and I am joined by Emilija and Rahma from the
Brown Daily Herald. Emilija SagaityteHello, my name is Emilija Sagaityte, and I am a senior editor at The
Herald.Rahma IbrahimAnd my name is Rahma Ibrahim. I am a science and research section editor.Cate RyanAs
always we are so grateful to welcome Ashish Jha who is Dean of the School of Public Health here at Brown
University. Thanks for listening, and feel free to email us if you have any questions. Cate RyanThe first thing that
we were thinking about is the Centers for Disease Control and Prevention (recent change of) guidelines to say that
anyone who is asymptomatic and has received the second dose of their vaccine does not need to quarantine if
exposed to COVID-19. And last time, we talked about how it was sort of unclear whether the vaccine would
completely reduce transmission. So what do you think is the implication of these new guidelines?Ashish Jha Yeah,
so this is like the million dollar question, right? Do vaccines reduce transmission? And I think the C.D.C. is right in
their decision or their recommendations. I think they're coming in line with what I think the emerging evidence is,
and the emerging evidence is that vaccines reduce transmission. Am I 110 percent sure? No. But that's what all the
data seem to suggest. And by the way, almost every vaccine, not every vaccine, but almost every vaccine reduces
transmission of the disease, so why would we think this one is going to be different? And then the question is, how
much? And could we envision that these vaccines would reduce transmission 100 percent? I don't think so. So
there probably will be still a little, but my best guess, based on all the data, is that it's probably in the 70 to 90
percent reduction range. But we're not sure. And I think the C.D.C. is basically saying, but that's where all the
evidence is pointing and that's what we should focus on. And we will get better data. And I suspect that that's the

                                                                                                   Page 2 of 6
      The COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's - The Brown Daily Herald

range it will come out. And that's great news, by the way, because if it didn't reduce transmission, then my gosh,
then we have a whole different set of problems.Emilija SagaityteSo speaking of vaccines, we wanted to transition to
speaking about another development, the U.S. and Worldwide Vaccine Tracker that was developed through a
collaboration between Brown's School of Public Health and Microsoft AI for Health, which just launched online
February 5th. Could you tell us about the purpose of this tool, describe what all those numbers and maps show and
explain a bit about how this tracker was created?Ashish Jha Absolutely. So we've had a collaboration with
Microsoft for a while now. And if you go to the website, globalepidemics.org, which is run by us at the School of
Public Health, we've been tracking cases by community, by congressional district. We've been doing a whole lot of
work on testing and testing targets. And so vaccines seem like the obvious next place to go in terms of tracking the
data. The data largely comes from - and there are other vaccine trackers, like Bloomberg has one - they all sort of
come from the same place. They come from states, and they come from the C.D.C. So we're not doing our own
personal tracking, but we're really pulling in data. And the idea behind this, and what I hope will be really useful for
people, there are two sets of things that I think are going to be important. One is, there's a lot of information that we
need to have beyond just how many people have gotten vaccines. We need to know who's getting vaccinated (and)
how much it varies by age, by race and ethnicity. And we're starting to pull those together into one place. We're
hoping that that's going to be a useful set of insights. But the other part is, I've described three sets of things now
that we're tracking: cases, testing, vaccines. They are not unrelated to each other. In fact, you may think that it's
really important to vaccinate people in places where there's a high number of cases happening, and I would agree
with that. So what this tracker lets you do is start pulling these three things together. And so you can go to your
community - and again, we don't have the data quite as granular as we would like, just because it isn't available yet,
and it will be - but ideally, what we'd like to be able to get to in the weeks ahead, is you can go to your county,
certainly your state, look at infection numbers, look at vaccination numbers, look at testing numbers and really get a
sense of how the broader pandemic control's happening. And we're not aware, or I'm not aware, of any tracker
that's really pulling it all together like that.Emilija SagaityteHave you been able to notice any trends so far between
those three factors? Ashish Jha Yeah. So I would say right now, we're just, well, a couple of things. I mean, we're
just starting to pull this stuff together. It is true that we see no real correlation between places with high infections
versus places that are doing a good job on vaccinations or a bad job, or vaccines are getting out. And that's
unfortunate, because you actually want to see more aggressive vaccinations happening in places with high infection
numbers. We don't see that yet. We don't see that happening, so that's a problem. And my hope is that we can take
these kinds of data, go back to policymakers and say, 'You've got to really push on vaccinations, and especially in
those areas.'Emilija SagaityteAnd the tool also mentioned trying to see whether the U.S. can reach that goal of 100
million doses in 100 days, and kind of looking at the status of vaccine distribution right now, what does it seem to
suggest about our nation's ability to reach that goal? And what factors or efforts do you think may influence those
trends?Ashish Jha The 100 million in 100 days is what President Biden said in early December when he was
President-Elect Biden, he wasn't in office yet. And that seemed like a really ambitious goal at the time. To be
perfectly honest, we're at almost 1.5 million doses a day right now, and that's what we've been averaging. So my
gosh, we got to be able to hit 100 million in 100 days, it's like something's gonna have to go horribly wrong for that
not to happen. Personally - and the people in the administration don't like me saying this I don't think, but I'll say it -
I think we should be hitting two million a day, like that's where we need to be. And I'm not saying they don't like me
for saying this; I'm just saying that's a very ambitious agenda. And that's what I would like for us to do, and so we're
targeting 1 million a day. I think we're gonna hit that easily. You know President Biden did come out and say he
thought we could do 150 (million). That's 1.5 (million) a day. I think we're gonna blow through that. I think the
question is, are we going to get to 2 million a day? And the reason why I say 2 million a day is my target is, I'm not
just making up a random number, I'm thinking about two things. I'm thinking about the U.K. variant, and how it's
spreading and when it will become widespread in the United States. And I'm thinking about, what is it going to take
to vaccinate all elderly, older, high-risk individuals. And if you try to get older, high-risk individuals all vaccinated
before the U.K. variant becomes widespread, you (have) to be at 2 million a day in order to get there. And that's the
challenge. So that's why that should be our internal target.Rahma IbrahimSpeaking of variants, which is a term
that's been in the news a lot recently, could you give us and our listeners a quick overview on the difference
between variants and strains?Ashish Jha You know, so it's a really good question. And ultimately, these things are
really about functionality. So let's take a moment and actually take one more step back and talk about mutations
versus variants versus strains. The way to understand the biology here is that RNA viruses, like this virus, are
notorious at making mistakes. Every time they replicate, they're just a ton of mistakes that they make, a ton of

                                                                                                   Page 3 of 6
      The COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's - The Brown Daily Herald

mutations, and 99.9999 percent of those mutations are irrelevant, they have like little to no meaning. And the helpful
part about these mutations is actually you can use them to track where the virus is spreading and who's spreading it
to whom through these genomic sequencing analyses. But all of those different mutations are functionally the
same. So what causes something to be a strain? It's a different strain if it takes on different functional capabilities.
So if it becomes more contagious, if it becomes more or less deadly, if it is able to evade immune response much
more effectively, if there's something functionally meaningfully different about it, then you call it a different strain.
And while you're sorting out whether a set of mutations is a strain or not, we often talk about it as a variant. And
variant is really kind of meant as a short-term, shorthand for, this probably is a different strain, but we're not 100
percent sure, and we're still sorting it out. So I think most biologists and immunologists I talked to would call the
U.K. variant a different strain because I think we have pretty good evidence now that it really is functionally really
different. And some of the other variants like, you know, there was a little talk of the L.A. variant that popped up in
Los Angeles, and calling that a variant made sense because we didn't know, is it really a different strain, or is it just
gonna turn out to be nothing? So I see variant as a short-term terminology used when you're not sure whether
there's a different strain or not, and you're sorting it out. Rahma IbrahimWe've also heard of other variants, the
South African, the Brazilian variants, and you've mentioned the U.K. - which might be a strain - and the L.A. variant.
So how many variants do we know of so far? And what do we know about them? And how far have been
traveled?Ashish Jha There are lots of variants. And the ones that I think we're all paying super close attention to
right now are the U.K. one, the other one found initially in U.K. B.1.1.7. There's B.1.351 that's from South Africa.
And there's one that's called P.1, which is the one from Brazil. And we don't, by the way, know that that's where
they originated; that's where we first identified them. So that's the other part of it. But if we're going to shorthand it
and say, the U.K., the South Africa and the Brazil, those are three that are all here in the United States. And we
think the U.K. variant is circulating reasonably widely. I suspect it's in all 50 states or most of the states. It's been
identified, I think, in 35, but my take is, the other 15 probably just haven't identified them yet. The South Africa
variant is interesting in that it may be a bit more contagious. The U.K. variant is clearly more contagious. The South
Africa variant may be more contagious, but it does seem to be more effective at evading immune response. I still
am very optimistic, and we can talk more about this that our vaccines will work against it, but we're less sure - it
may work a little less well, I wouldn't say we're less sure. And then on the Brazil variant, we know much less about
it. There is some data to suggest that people who have been previously infected may not have protection against
the Brazil variant. But I don't think we know enough about that right now, and there's a lot of work being done to sort
that out.Rahma IbrahimOn that same note of people being previously infected with COVID-19 and their risks for
being infected again with these variants, I know you mentioned we don't necessarily know much about that, but
what does the data that we have currently say about people's ability to be infected twice, by another variant?Ashish
Jha So the vast majority of the infections right now of the virus circulating is still the native strain, the original strain.
And people getting reinfected with the original strain we think (is) exceedingly unlikely. We don't know the real
number. Officially, it's about 10 or 12 people have been reinfected in the United States out of 25 million. I suspect
the real reinfection rate is higher than that, but probably not much higher, meaning bottom line, if you've been
infected, your chances of getting reinfected are not zero, but they're really, really low.How does the variant stuff
change that? I don't know that I've seen any data that suggests that the U.K. variant changes that at all, so if you
were previously infected, recovered, now you get exposed to the U.K. variant, I don't think it changes your likelihood
of getting reinfected. But we're not sure. There is some evidence that South Africa and Brazil variants lead to more
reinfections because of some amount of immune escape, but the evidence is really weak and certainly not perfect. I
wouldn't be surprised if there is a little bit of immune escape, certainly from the South Africa variant where we may
have the best data on that. But I actually think that the vaccines will protect us against that. What's interesting, right,
here's the bottom line, natural immunity from having been previously infected may not protect you against the South
Africa variant, but vaccines probably will. And that's interesting, just a reminder that vaccines can generate much,
much better immunity than natural infection can. I think a lot of people assume that natural immunity is the best
immunity, but we have very good evidence for lots of diseases that's not true, that we can generate much, much
better immunity using vaccines than natural infection does. Emilija SagaityteKind of going back to vaccines, and
how many have come about from research in recent months: I do think that Pfizer and Moderna seem to have
become household names when talking about the COVID-19 vaccines. But last time, you had alluded to some other
companies who are in the process of developing and testing their own vaccines, like Johnson and Johnson,
Novavax, AstraZeneca, as well as some developed in other countries, like I believe Sputnik V was being developed
in Russia. So what do you make of all of these different versions? How are they different? How are they

                                                                                                   Page 4 of 6
      The COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's - The Brown Daily Herald

similar?Ashish Jha So there are a lot of different ways of making vaccines, and you've seen companies around the
world trying to make them in different ways. And my personal take is, we need all the vaccines we can get. As long
as they're safe and effective, we should be able to come up with different modalities. Different modalities have
advantages and disadvantages. mRNA vaccines, like the Moderna and Pfizer, which are fabulous vaccines, are
really hard to store and manage, they need to be frozen. The Pfizer one particularly needs to be frozen, minus 96
degrees for extended periods of time, whereas (vaccines) like the Johnson and Johnson vaccine can be
refrigerated, does not need to be frozen. And so you can imagine why that would be a huge advantage in many,
many places. Here's where we are, as of today, February 12th. The Johnson and Johnson vaccine has been
submitted for authorization to the F.D.A., and the F.D.A. is going to meet on February 26, two weeks from today,
they're going to make a decision. I would be shocked if they don't authorize it based on the data we've seen, but
they might not. F.D.A. has a pretty high bar, they're gonna do a very vigorous review. But I say I'd be shocked
because I know the people that are working on developing that vaccine, and they wouldn't have submitted it unless
the data was really very good. And so I expect an authorization in the day or two that follows. There are a few
million doses sitting around, but not tens of millions. So in March, probably not a huge impact of the Johnson and
Johnson vaccine; you'll start seeing some people get vaccinated. And then once we enter April and May, you'll see
that become much more widespread. The one thing I will say about the Johnson and Johnson vaccine is its
headline numbers seem to be not as good as Moderna and Pfizer. People are like, Oh, it's only 65 or 85 (percent
effective). It's a very good vaccine based on all of the data I have seen so far. We'll see more in the next couple of
weeks. It's a very, very good vaccine, I would recommend it for any family member. I would not be hesitant to get it
myself. I've gotten the first dose of the Moderna vaccine, I'll be getting my second soon, but the point is, I would be
very supportive of my wife getting it. She has not been vaccinated yet. So it's a very, very high quality vaccine. And
I would not pay too much attention to the headline number. Novavax again, we were going to get more data on that.
I think the AstraZeneca trials that are being done in the United States, I expect them to read out, meaning get some
data on those, in the next month, so by the time we get to mid-March. And I can imagine a late March, early April
F.D.A. review and an authorization. Sputnik V came out with their data. It's really good. So the good news here is,
this is a virus where we figured out how to make good, effective vaccines, thank goodness. But there are just going
to be challenges of producing enough, getting them out. And then by the time we get to May, we're gonna have a
different problem, which is we're gonna have so much vaccines in the United States, and we're going to have not
enough people who want to get vaccinated because we're going to run into all the people who have vaccine
hesitancy, people who are worried about taking the vaccines, and we've got to start working on addressing those
concerns now.Emilija SagaityteAnd so I know you touched upon this a little bit before, but given the evidence to
date, what do you think it suggests about then these vaccines' potential help with distribution as well as minimizing
the impact from those variants we talked about both here in the U.S., as well as looking more globally?Ashish
Jha So I think the evidence we have right now says that certainly the Moderna, Pfizer vaccine, also I think Johnson
and Johnson, is going to work very well against the U.K. variants. So I'm not worried about that. I think it will work a
little less well against the South Africa variant, but well enough that, if you got vaccinated, you're gonna do fine.
Even if you might have a slightly higher risk of getting infected, I think people will not get sick and die, which is what
we care about, preventing severe illness. So I'm really, really, at this point, very confident that these vaccines are
going to hold up well against the variants we have. It doesn't mean that there won't be a variant in the future that will
escape our immune response, and I actually think one of the things we need to be doing is much more genomic
surveillance to look for those variants. And then if you see one emerging that looks like that, working on updating
our vaccines so that they can be more effective. There's a lot of work here. This is not a one and done, like it's not
going to be we all get vaccinated. We have to continue monitoring, continue paying attention. And the last point on
this is because it's a global pandemic, if we just get America vaccinated, but the world isn't vaccinated, it's going to
be a huge problem, obviously just from an equity point of view, but also if we see large outbreaks happening
elsewhere, America's largely vaccinated, it's going to be the ground for emergence of new variants that will render
our vaccines less effective. So there's both a, I think, a selfish as well as a more solidarity-oriented set of reasons
for really having a global approach to vaccines.Cate RyanSpeaking of all of these complex problems, we sort of
wanted to highlight something hopeful, which is the course that you're teaching with Dr. Megan Ranney called
Pandemic Problem-Solving, which is for civil servants and other leaders. What do you think that will look like over
the next month or so, and what are you looking forward to with that course? Ashish Jha I'm super excited about
this. And the reason is, you know, the pandemic has felt kind of paralyzing, right? Like, it's just sort of disrupted our
lives. And people feel like, I don't know how to manage problems, and like, what can I do, and we're all in this sort

                                                                                                   Page 5 of 6
      The COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's - The Brown Daily Herald

of suspended animation just waiting for these vaccines so we can start getting things back. And what Megan and I
and our whole team realized was, there are lots of people who, during the pandemic, have confronted problems,
and solved them, and made progress and done really remarkable things. And they have lessons for all of us on how
we get through the rest of this pandemic, and how we deal with future ones. And so it's a very problem-solving kind
of oriented course, where we have experts in business, political leaders, all sorts of folks who are going to
participate and talk about how they dealt with uncertainty, how they made decisions. And then the hope is that the
students in the course - a lot of them are from N.G.O.s or government or private sector - are going to talk about
how those lessons apply to their real life. So it is very practical, supposed to be hands-on. And I guess for me, it's
meant to give people hope and something they can actually do and teach them a set of skills. But I have to tell you,
I'm going to learn a ton because while it's been really fun watching people make decisions and watching leaders
figure out how to do this stuff, the course will actually teach us how to apply this to a much broader swath of issues.
And so I expect to learn a lot about how to think about these things. And the last point is, it's an interesting foray for
Brown, right, because we don't do this kind of stuff. We teach courses in pretty traditional ways to undergrads,
graduate students, but I think the way in which the world is changing, universities have an obligation to teach
people who are not our traditional students. And it's not even like executive education. It's just a different model. It's
in the middle of crises, universities have to step up and pull together knowledge and share it widely and in
constructive ways. And that's what this is about. So I think this is part of a broader strategy that Brown is thinking
about, which is, how do we engage and be more relevant in the world in the middle of crises? How do we bring our
expertise to bear, and I love that by the way, because that's, of course, what I think all universities should be doing,
and I'm particularly excited that Brown is doing it.Cate Ryan Yeah, that sounds like such a great resource for so
many people. So before we end, we wanted to also touch on something else kind of fun, which I guess is
Valentine's Day, and we specifically wanted to bring up this article that was published in The Brown Noser, which is
the satirical newspaper that's written by Brown undergrads. So this is a joke, but it was headlined, "Paxson Clarifies
That Every Student Allowed One Little Kiss On Valentine's Day," and that it's obviously a joke, but we just wanted
to ask in all seriousness, how should students on college campuses like Brown be approaching making new friends
or new romantic relationships during this COVID semester?Ashish Jha Oh, boy, that is a really hard question.
Because those are really important things. Social, personal, romantic relationships are like the heart of being
human, right? And so how long can you continue to suspend these things? So look, I mean, first of all, it's much
easier if you can do stuff in pods, you can't always. The issue around this, in my mind, is we have added a set of
protections that obviously make life much, much easier here in terms of not just the mask stuff, but I think the fact
that people are getting tested on an ongoing basis. I think it's totally safe for people to spend time outdoors
together; I think there's things that people can do. And, obviously, I'm not going to say people should feel
comfortable on Valentine's Day violating their pod rules because, you know, it is risky. And right now is particularly
so with these variants circulating. But so I feel like I don't have a great answer beyond, I'm really sympathetic to the
moment we're in, I think there are ways of socializing with people that is safer than others. And I guess the other
thing I will say is, I expect that all of this is going to start really meaningfully turning around in the next couple of
months, I think there'll be more vaccines, there'll be plenty of vaccines by April, May. So if people can hold on a little
bit longer, that will help; if you can't, try to do things more safely. There is no perfect thing here. But it's hard to tell
people to just completely ignore Valentine's Day if that's important to you. So some amount of risk is probably just a
reality of life in a pandemic. How is that for a non-answer? I feel like I didn't really give you an answer. I went right
up to the edge. It's very hard, right? Because on one hand, like the right answer is, you can't do anything. But the
reality is like, that's just not life. And asking people to suspend life forever, I think it's not realistic. So I think people
have to make trade-offs. And people have to make choices and understand there are risks. And as long as we're, I
think, all open and transparent about it, that's really all you can expect.Cate RyanYeah, thank you, that makes a lot
of sense. And we're all looking forward to these changes with the vaccination rates going up and everything over
the next few months. So we'll continue to see everything unfold and hopefully a more bright way. But thanks so
much, again, for being here with us this week, and we look forward to more conversations to come this
semester.Ashish Jha That sounds great. See you all very soon and stay well.This transcript has been edited for
length and clarity.____________________Produced by: Cate RyanReporting contributed by: Emilija Sagaityte and
Rahma IbrahimSound mixing by: Cate RyanMusic composed by: Katherine Beggs '22.5Special thanks to Bilal
Ismail Ahmed and Elise Ryan for cover design.

ADVERTISEMENT

                                                                                                  Page 6 of 6
     The COVID Pod with Dr. Ashish Jha: Virus Variants, Vaccines and Valentine's - The Brown Daily Herald


Load-Date: May 30, 2024


 End of Document

                                                                                                        Page 1 of 2
                                                        No Headline In Original




                                                    No Headline In Original
                                                    The Malone Telegram (New York)
                                                     September 18, 2021 Saturday
                                                             Both Edition



Copyright 2021 Johnson Newspaper Corporation
Distributed by Newsbank, Inc. All Rights Reserved

Section: MT_AGRICULTURE
Length: 691 words
Byline: Justin Tucker AgEducator Cornell Cooperative Extension

Body


a Goat Reproduction Clinic being held at Tucker's Ranch. 299 Hazen Road, North Lawrence, on Sept. 25, at 10
a.m.

The most common reasons for breeding goats is for the production of milk, meat, and fiber. A male goat is called a
buck, unless it's castrated, and then it's called a wether. Female goat's, also called doe's, will typically give birth
(kidding) in the springtime, usually having one to three kids. Did you know that baby goats are called kids?

 Farmers are trying to keep up with the demand for goat products. Artificial insemination helps farmers maximize
their herd genetics and profits. Keeping good records throughout the year helps to ensure a successful breeding
program. If you're using a buck to breed then be sure to keep records of when the doe's come into cycle. Some
breeders will choose to use a hand selected buck to breed their does and others use artificial insemination (AI).
Both ways have some pros and cons depending on what your goals are and depending on how much time, labor,
and money you want to put into your breeding program.

 There are 14 common breeds in America: Nubian, Alpine, LaMancha, Oberhasli, Saanen, Sable, Toggenburg,
Boer, Nigerian Dwarf, Angora, Pygmy, Myotonic (2 types), and Crossbred breeds. Each breed has some individual
characteristics that compliment their individual qualities. Goats are a hardy, small ruminant breed that can be very
adaptable, fun, and profitable. They are the perfect size for many situations such as raising a few as pets or in
larger numbers for the production of dairy products or meat. Many different products are made from raw goat's milk
such as soaps, lotions, fluid beverage products (low fat, flavored, or fortified), frozen products such as ice cream or
frozen yogurt, and ultra-high temperature (UHT) milk and fermented products such as cheese and yogurt. Many
other products are produced as well.

 There are several reasons for AI which include herd health improvements such as; conception rate, number of
kids (newborn goats) born alive, multiple pregnancies of twins and triplets, number of surviving kids at weaning age,
and their performance at each phase. By breeding with AI, the breeder can use superior sires to maximize genetic
improvements in the herd.

                                                                                                          Page 2 of 2
                                                No Headline In Original

 Using AI also prevents the spread of diseases and helps limit the genetic base by only using a few bucks, in turn
reducing the spread of any unwanted genetic defects. One buck can naturally breed anywhere from 20-30 doe's, if
using AI, the breeder could use semen from one buck to breed an entire herd, eliminating the need for a buck
entirely in some situations. Some breeders will choose to lease their buck to other farms and might trade the use of
the buck during breeding season, in exchange for boarding the animal for the winter months. Sometimes this is a
good option for someone that does not have housing for a buck all year. Bucks can be difficult to keep separate
from the doe's if the correct fencing is not used. They can also be somewhat obnoxious, especially during the
breeding season. They tend to have a very distinct smell of urine during the fall months.

 Determining the health of the doe at breeding time is critical to how the doe might respond to each reproduction
method. Always make sure your bucks and doe's are in optimal health prior to breeding because the health of
each animal will determine the efficiency of your breeding program.

 A doe's estrous cycle is twenty-one days and usually takes place in the fall and lasts for 24-48 hours. Their
gestation cycle lasts 145-155 days. Hormones can be used in sequence to stimulate follicular development, control
CL function, and regulate ovulation. Sometimes breeders will choose an Estrus Synchronization protocol to ensure
a uniform kid crop and to properly manage the pregnant doe's. Take good notes throughout the entire process and
make the correct adjustments to your breeding program along the way. Each situation is unique, so try to evaluate
what fits your situation best (Natural or AI). Establish a list of genetic traits you are looking to improve in your herd
and see which method works best for your farm.


Load-Date: September 18, 2021


  End of Document

                                                                                                      Page 1 of 17
                                           NOTABLE DIVERSE LEADERS IN LAW




                                 NOTABLE DIVERSE LEADERS IN LAW
                                                   Crain's New York Business
                                                          July 11, 2022
                                                          Print Version



Copyright 2022 Crain Communications All Rights Reserved




Section: Pg. 13; Vol. 38
Length: 11009 words

Body


IN THE 19TH CENTURY the first fissures emerged in the old-guard conventions of the New York legal industry.

Katherine Stoneman and George Boyer Vashon broke barriers when they became the first woman and the first
Black person, respectively, to be admitted to the New York bar. Since then, the state's legal industry has diversified
year after year, growing to look more and more like the city it serves.

It is only fitting that a city with such a fabulously diverse population-58.7% people of color, 6.9% people with
disabilities, 5.1% members of the LGBTQ community and millions of immigrants-should be represented by talented
lawyers of equal variety. Indeed, the heterogeneity of New York's legal industry goes a long way toward ensuring
that residents of all stripes can find legal advocates and defenders sensitive to their unique backgrounds and
needs.

With this in mind, Crain's New York Business selected 80 Notable Diverse Leaders in Law. These individuals excel
in their practice at New York's leading law firms across a range of specialties. They stand out for their counseling
and the nature of their pro bono work. They likewise demonstrate a commitment to community service,
philanthropy, professional mentorship, and diversity, equity and inclusion initiatives. As diverse professionals in a
traditionally conservative industry, they are forging a path for others-women, minorities and members of other
underrepresented groups-to travel.

To qualify for the list, the honorees had to be nominated by their colleagues and based in New York City or nearby
counties. They had to self-identify as representing diversity in the workplace-including women, people with
disabilities, African Americans, Latinos, Asians and other underrepresented groups.

The nominees had to be serving in a senior role at a law firm with a staff of at least 10 individuals. Each was
required to be a practicing attorney at a law firm with at least 10 years of experience. In addition, the nominees had
to be role models or mentors or promoters of inclusive practices in the workplace. They had to have had an impact

                                                                                                     Page 2 of 17
                                      NOTABLE DIVERSE LEADERS IN LAW

on the types of cases they handled, their clients and their pro bono work. The nominees had be involved in either
community or philanthropic activities and diversity and inclusion initiatives.

Read on to learn how these honorees use their skills daily to elevate the legal profession.

ROBIN ADELSTEIN Global head of antitrust and competition, Norton Rose Fulbright

At Norton Rose Fulbright, Robin Adelstein develops global strategies and leads a team of nearly 200 lawyers in the
U.S., South Africa, Australia and Canada, among other countries. As the firm's global head of antitrust and
competition practice and U.S. co-head of its commercial litigation practice, Adelstein is committed to positively
positioning clients and ensuring their fair treatment in court. She has been featured on Global Competition Review's
2021 Women in Antitrust list and Crain's Notable Women in Law list this year and in 2019. Adelstein frequently
speaks at events hosted by the American Bar Association's Antitrust Law Section, the American Conference
Institute, and the Program on Corporate Compliance and Enforcement at the New York University School of Law.

MALA AHUJA HARKER Partner and management committee member, Friedman Kaplan Seiler & Adelman

Mala Ahuja Harker oversees Friedman Kaplan Seiler & Adelman's business development functions and its diversity
and inclusion efforts. As a partner and management committee member at the firm, Ahuja Harker focuses on
complex financial frauds and public corruption. She has represented the founder of WeWork, a major
pharmaceutical manufacturer and many clients in various regulatory investigations. Ahuja Harker helped lead her
firm through pandemic-related challenges. She was recognized in the 2021 and 2022 editions of Chambers USA
and the Legal 500 for her defense work. Ahuja Harker helps economically disadvantaged communities as a
member of the board of trustees of Volunteer Lawyers for Justice.

CARMITA ALONSO Partner, Fragomen, Del Rey, Bernsen & Loewy

Carmita Alonso represents a wide range of clients as a partner at Fragomen, Del Rey, Bernsen & Loewy, from
global financial services companies and technology organizations to small and medium corporate clients and
individuals involved in business-critical immigration issues. Alonso is charged with making strategic decisions
regarding immigration programs, risk management and compliance. As co-chair of her firm's global diversity, equity
and inclusion committee, she guides efforts to prioritize diversity in recruitment, education and career development
efforts. Alonso has supported pro bono efforts aimed at helping underrepresented immigrants of color. She was on
the board of the City Bar Fund for six years.

MERIAM AL-RASHID Partner, Eversheds Sutherland

As partner, global co-chair of international arbitration and co-head of the Latin America practice at Eversheds
Sutherland, Meriam Al-Rashid guides international commercial and investment disputes. With a focus on public
international law, Al-Rashid has worked with teams across seven countries since the pandemic and recently
created a charter for a new ministry to document war crimes in Ukraine. She investigated, analyzed and
documented human rights atrocities and genocide in Myanmar, leading to a recommendation to the U.N. Human
Rights Council that would establish an independent mechanism to collect, consolidate and preserve evidence of
international crimes. Al-Rashid co-chairs her firm's racial justice steering committee. She is a founder and board
member of the Arab Legal Forum. In addition, Al-Rashid is involved with Women in International Law, among
similar organizations.

JUDITH ARCHER Co-partner-in-charge, Norton Rose Fulbright

Implementing policy changes, integrating new lawyers, coordinating events, supporting staff-Judith Archer has a lot
on her plate as co-partner-in-charge at Norton Rose Fulbright. Archer oversees the firm's operations and policies as
a member of the management committee; she helped develop a flexible work program as a member of the diversity
and inclusion committee. Archer worked on a proceeding to recover hundreds of millions of dollars related to the
Bernie Madoff fraud. She was on her firm's attorney evaluation committee for nine years, overseeing reviews for

                                                                                                         Page 3 of 17
                                       NOTABLE DIVERSE LEADERS IN LAW

non-partner attorneys. Archer previously advised associates as the mentor leader in the firm's New York office. She
chairs the Women in the Legal Profession Committee of the New York City Bar Association.

JUAN ARTEAGA Partner Crowell & Moring

Juan Arteaga represents Fortune 500 companies and senior executives in civil and criminal antitrust investigations
and commercial litigation. As a partner at Crowell & Moring, Arteaga has worked with Samsung, Mozilla, CSX
Transportation and Blue Cross Blue Shield, among other high-profile clients. He co-chairs his firm's New York
antitrust practice and its diversity council, which develops and implements training and metrics related to the
recruitment and retention of diverse talent. In addition, Arteaga is involved in pro bono efforts for victims of domestic
violence, senior citizens, undocumented immigrants and indigent criminal defendants. He has received a Chambers
USA ranking as an antitrust practitioner, and he has been recognized by Law360 and the New York Law Journal,
among other publications.

SARAH ASHFAQ Partner Goodwin

Focusing on the biotechnology and pharmaceutical industries, Sarah Ashfaq provides strategic advice to a wide
range of clients, management teams and boards. As a partner at Goodwin, Ashfaq represents publicly traded
biotechnology companies in Securities and Exchange Commission compliance and corporate governance matters
and represents investment banks in corporate, securities law and financing transactions. Ashfaq, who has
counseled companies such as Deciphera Pharmaceuticals, Entrada Therapeutics and Nuvalent, provides business-
related pro bono services through her firm's initiatives in support of communities facing discrimination. These
include Goodwin's Neighborhood Business Initiative and Project Citizenship. Ashfaq is a member and a previous
board member of the Muslim Bar Association of New York.

LANDIS BEST Partner Cahill Gordon & Reindel

At Cahill Gordon & Reindel, Landis Best represents global corporations, multinational financial institutions and
media companies. Best's wide-ranging work as a partner involves government investigations, insurance disputes,
economic sanctions, intellectual property matters and appellate work. She is a member of her firm's executive
committee, and she chairs Cahill's Women's Initiatives Committee, overseeing a program that recruits experts to
deliver training and workshops. Best previously worked on the firm's diversity, equity and inclusion committee and
co-chaired its associate liaison committee. She has been among Benchmark Litigation's Top 250 Women in
Litigation for eight consecutive years.

MAYAN BOUSKILA Partner Helbraun & Levey

As a partner at Helbraun & Levey and chair of the firm's real estate group, Mayan Bouskila leads a team in
providing legal counsel to restaurants, hospitality groups, bars and developers nationwide. Throughout the
pandemic, Bouskila has offered legal support to community businesses, including supporting business owners in
renewing and renegotiating commercial leases. She previously chaired the firm's diversity, equity and inclusion
committee; she now mentors female colleagues through individualized coaching. Bouskila was recently a sponsor
of the Cherry Bombe Jubilee, a networking conference for female entrepreneurs in the food industry. She was
selected as a 2021 Rising Star by Super Lawyers.

SETH BRYANT Managing partner Bryant Rabbino

Managing partner Seth Bryant is responsible for Bryant Rabbino's operations and administration. Bryant places a
legal focus on minority- and women-owned business enterprise matters, and he was involved in a coalition that
advocated for changes to MWBE laws in New York in 2010 and 2020. Bryant is a founding member of the Council
of Urban Professionals, a nonprofit focused on diversity and equity, and he previously chaired a diversity-related
committee of the New York City Bar Association. Bryant was elected a trustee of the Citizens Budget Commission.
He formerly was on the board of directors of the National Association of Minority & Women Owned Law Firms.

ROBIN COHEN Chair Cohen Ziffer Frenchman & McKenna

                                                                                                       Page 4 of 17
                                      NOTABLE DIVERSE LEADERS IN LAW

At the insurance recovery litigation boutique Cohen Ziffer Frenchman & McKenna, Robin Cohen is involved in all
aspects of the firm's operations. She represents policyholders in business interruption cases. Her clients have
included Spirit Airlines, Pfizer and Verizon. Cohen, active in recruiting and retaining diverse lawyers, has written
articles for publications, including Barron's, and lectured on diversity at universities nationwide. She was on the
Insurance Coverage Law Center's editorial advisory board. When she was a board member for the Legal Help
Center, Cohen aided underprivileged women in the Philadelphia region.

DAVID CRICHLOW Partner Katten Muchin Rosenman

David Crichlow works on complex commercial disputes, representing American and European banks, major oil and
industrial companies, private-equity firms and large pension funds. As a partner and national chair of the
commercial litigation practice at Katten Muchin Rosenman, he oversees more than 40 attorneys in the U.S. and
England. Crichlow, who mentors diverse young lawyers at Katten and elsewhere, has led trial counsel on
commercial, class-action and bankruptcy litigation. He is on his firm's board of directors and executive committee.
Crichlow was named to the New York Law Journal's list of distinguished leaders of 2020. He helps lead a program
in the Newark, New Jersey, area that provides social and academic support to underserved male high school
students.

GABRIEL YOMI DABIRI Office managing partner Polsinelli

At Polsinelli, Gabriel Yomi Dabiri advises clients on buy-and-hold credit strategies and syndicated finance
transactions. Dabiri leads the firm's private credit and cross-border finance practice while he mentors diverse
attorneys and works to ensure inclusion in the firm's hiring, retention and promotion. The office managing partner
sits on the board of the Black BigLaw Pipeline, a nonprofit composed of senior Black attorneys, and has held
leadership positions as a volunteer for the American Heart Association. Dabiri is on the board and on the finance
committee of the Women First International Fund, which provides microfinancing to grassroots projects led by
women.

LISA E. DAVIS Partner Frankfurt Kurnit

Lisa E. Davis boasts more than three decades of experience representing businesses and celebrities spanning film,
television, publishing, music, theater and sports. Davis is a partner in the entertainment group at Frankfurt Kurnit, a
member of the firm's policy committee and co-chair of its diversity committee. She recently helped create a hiring
practices working group and organized anti-racism and anti-harassment training. In addition, she oversees the
firm's attorney sponsorship and mentorship programs. Davis, whose clients have included Black Theater United,
has received the Woman of Power Award from the National Urban League and has been featured in Super Lawyers
Magazine.

MYLAN L. DENERSTEIN Partner Gibson, Dunn & Crutcher

At Gibson, Dunn & Crutcher, Mylan L. Denerstein leads criminal and civil litigation and internal investigations. The
partner and co-partner in charge of the firm's New York office also co-chairs the public policy practice group. In
addition, Denerstein is global chair of the diversity committee, through which she has led the firm's support for the
Equal Justice Initiative and the NAACP Legal Defense and Educational Fund. In 2021 she was one of Benchmark
Litigation's Top 250 Women in Litigation. Denerstein is a member of the Women's White Collar Defense
Association, and she sits on the boards of the Legal Aid Society and the American Red Cross of Greater New York.

ESTELA DÍAZ Partner Akin Gump Strauss Hauer & Feld

Estela Díaz provides guidance to companies regarding sensitive matters in criminal, regulatory and internal
investigations. As a partner at Akin Gump Strauss Hauer & Feld, she has represented Morgan Stanley, Papa
John's and Starbucks, among other high-profile clients. Díaz chairs the firm's Latinx firmwide resource group, which
focuses on recruiting and retaining Latinx lawyers. She led her firm's pro bono partnership with the Bronx
Defenders Immigrant Family Unity Project, which provided representation to immigrants facing deportation. Díaz

                                                                                                       Page 5 of 17
                                      NOTABLE DIVERSE LEADERS IN LAW

was selected as a fellow at the Leadership Council on Legal Diversity, where she was on the program development
committee. She sits on the board of directors of Bronx Defenders, a legal services nonprofit.

KIM DOHYUN Partner Skadden, Arps, Slate, Meagher & Flom

Kim Dohyun, a partner at Skadden, Arps, Slate, Meagher & Flom, advises public and private companies on
corporate governance, acquisitions and dispositions, investments and private equity. Having represented clients
such as BuzzFeed and NCR Corporation, she is a lead attorney on Elon Musk's pending $44 billion acquisition of
Twitter. Dohyun serves as a partner liaison for her firm's global Asian American and Pacific Islander affinity network
and provides pro bono services to nonprofits, such as the DreamYard Project, which helps Bronx youth access
opportunity through the arts. She is a member of the Partnership for New York City's David Rockefeller Fellows
program, through which private-sector executives build civic leadership skills.

NICOLE FANJUL Partner Latham & Watkins

At Latham & Watkins, Nicole Fanjul is a partner and co-deputy office managing partner for the firm's New York
office. Fanjul oversees strategic planning for practice growth and development, large acquisition financings, lateral
partner hiring, associate recruitment and retention, and community engagement. She has lead anti-racism and
allyship discussions and helped establish a diversity, equity and inclusion working group to formalize connections
among various affinity groups and committees. Fanjul's pro bono practice includes advising on immigration matters
and helping immigrant victims of domestic violence obtain protections. She is a board member at the Acceleration
Project, a nonprofit that assists small and minority-owned businesses. In addition, Fanjul is an alumni executive
board member of Rye Country Day School.

MUHAMMAD FARIDI Partner Patterson Belknap Webb & Tyler

Muhammad Faridi is a litigator of complex commercial matters involving torts and breaches of contracts. As a
partner at Patterson Belknap Webb & Tyler, he has represented commercial real estate, software, pharmaceutical
and nonprofit organizations. Faridi, who has also represented death-row inmates, refugees and runaway homeless
children, focuses his pro bono work on assisting underrepresented communities in New York and the nation. He is
co-chair of Patterson Attorneys of Color, a firm resource group that helps attorneys of color grow and develop their
skills. Faridi is on the board of directors of the TEAK Fellowship and of the National Center for Law and Economic
Justice.

JULIE FINK Managing partner Kaplan Hecker & Fink

At Kaplan Hecker & Fink, Julie Fink leads a commercial and public-interest litigation practice and oversees the
firm's operations. Under her leadership, the firm has pioneered innovative recruitment methods to attract diverse
talent, resulting in the selection of summer associate classes composed entirely of female individuals and
individuals who are either people of color or LGBTQ+ or both for the past two summers. In addition, the firm has
filed a lawsuit challenging Florida's "Don't Say Gay" law. The managing partner is a frequent speaker on civil rights
issues and pro bono work. Fink led an independent investigation into gender equity issues in the NCAA. She is on
the board of New York Lawyers for the Public Interest. Fink was previously the audit chair at Gay Men's Health
Crisis.

DARRELL GAY Partner ArentFox Schiff

Darrell Gay is an expert on employment-related issues, including hiring and discharge, discrimination matters, labor
relations, internal investigations, workplace training, privacy and international labor. The partner at ArentFox Schiff
is the chief negotiator for his clients during collective bargaining sessions. Gay served as a member of the New
York governor's task force on sexual harassment, and he was selected as a fellow in the College of Labor and
Employment Lawyers. He was a commissioner with the New York State Civil Service Commission. Gay is a
founding board member of the National Employment Law Council and the Metropolitan Black Bar Association.

RACHEL GOLDMAN Partner Bracewell

                                                                                                     Page 6 of 17
                                     NOTABLE DIVERSE LEADERS IN LAW

Rachel Goldman is a litigation partner in Bracewell's New York office and co-chair of its environmental, social and
governance practice and pro bono committee. Focusing on the energy, construction, infrastructure and finance
sectors, Goldman is involved in climate change, social responsibility and social governance, among other issues.
She has represented wind farm developers and solar power energy companies domestically and abroad, and she
has advised large lenders regarding litigation and arbitration risks involving borrowers. As a member of the firm's
associate committee, Goldman provides mentorship and develops policies related to associate development and
diversity, equity and inclusion efforts. In addition, she coordinates the firm's partnership with the nonprofit Her
Justice. Goldman has taught at Columbia Law School.

ELIZABETH GONZALEZ-SUSSMAN Partner Olshan Frome Wolosky

At Olshan Frome Wolosky, Elizabeth Gonzalez-Sussman is a partner in the shareholder activist and equity
investment practice as well as the corporate-securities law group. Gonzalez-Sussman is on the women's committee
and the diversity committee, organizing networking groups that connect women in finance and law. In addition, she
is head of environmental, social and governance activist investing. She speaks and writes on ESG issues; the
Harvard Law School Forum on Corporate Governance, a high-profile online blog, has published her work.
Gonzalez-Sussman has been acknowledged by Chambers USA and the Legal 500. She is on the board of directors
of the Columbia Law School Association, where she assists with alumni initiatives and fundraising.

KEISHA-ANN GRAY Partner Proskauer

At Prokauer, Keisha-Ann Gray advises companies, brands and individuals on various issues. Gray, a trial lawyer
who has secured victories in federal and state courts for organizations facing "bet the company" and reputational
risk claims, connects with diverse groups and advocates for clients. She handles sensitive litigation and workplace
investigations involving allegations of sexual harassment, discrimination and financial misconduct. The Proskauer
partner speaks and writes about trial practice and employment matters and mentors junior female lawyers and
lawyers of color. Gray co-chairs the Federal Bar Council's employment litigation committee. Recently, she was
appointed to the New York Mayor's Advisory Committee on the Judiciary.

SANDRA HAUSER Partner and head of U.S. commercial litigation Dentons

Sandra Hauser leads the U.S. commercial litigation practice at Dentons, serving on the global litigation and dispute
resolution leadership team. Hauser regularly defends companies in class-action and complex commercial cases in
trial and appellate courts. The Dentons partner is a member of the pro bono committee. Hauser has helped develop
the firm's business practices and professional development and diversity initiatives. Through Dentons' Preparing for
Rain program, which she helps to lead, she mentors young female lawyers on business development matters.
Hasuer is involved with the New York Says Thank You Foundation, a nonprofit that supports communities
recovering from disaster.

CAROLINE HELLER Shareholder Greenberg Traurig

At Greenberg Traurig, Caroline Heller focuses on complex commercial litigation. The litigation shareholder has led
the firm's efforts to train attorneys to file humanitarian parole applications and temporary protected status
applications. As chair of the global pro bono program, Heller oversees pro bono coordinators and mentors
associates. She is on the criminal justice and projects committees of the Law Firm Anti-racism Alliance and the pro
bono committee of the Advocates for Children board. Heller is president of the Holly Skolnick Fellowship
Foundation, where she leads selected fellows in work related to racial and social justice. In addition, she is on the
board of the Fund for Modern Courts.

MARCELLE HENRY Partner Pitta

Marcelle Henry, partner and chair of the ERISA/employee benefits group at Pitta, is charged with all aspects of
work related to employee benefit plans. Henry ensures that plans are compliant with applicable law and manages
more than 35 plans. In addition, she mentors female attorneys to navigate client issues and develop professional
pathways. Henry was appointed to the U.S. Department of Labor's advisory council on employee welfare and

                                                                                                        Page 7 of 17
                                      NOTABLE DIVERSE LEADERS IN LAW

pension benefit plans. For the American Bar Association's Labor and Employment Law Employee Benefits
Committee, she is a liaison to the Diversity in the Legal Profession Committee.

ELLEN HOLLOMAN Partner Cadwalader, Wickersham & Taft

At Cadwalader, Wickersham & Taft, Ellen Holloman is a partner in the global litigation group, a partner sponsor for
the Black and Latino Association, and a member of the global diversity committee. She works with large companies,
banks, and broker-dealers, handling complex commercial litigation, internal investigations, corporate governance
issues and crisis management. Holloman, whose pro bono work focuses on veterans, immigrants and incarcerated
individuals, provides career advice to junior and midlevel attorneys. She sits on the board of New York Lawyers for
the Public Interest. Holloman, who has been named one of Lawdragon's 500 Leading Lawyers in America, is on
several New York City Bar Association committees.

MEEGAN HOLLYWOOD Partner Robins Kaplan

As a partner at Robins Kaplan and a member of its antitrust and trade regulation group, Meegan Hollywood
prosecutes actions involving price fixing, unlawful monopolization and anti-competitive practices. She leads a team
serving on the plaintiffs' steering committee concerning advertising antitrust litigation, and she is sole counsel for a
case involving two large freight railroads charged with price fixing. Hollywood, who is the New York office's pro
bono chair, is also involved with the gender inclusion working group of the firm's diversity committee. Her personal
pro bono practice includes working with the Kids in Need of Defense organization and the Transgender Legal
Defense & Education Fund.

BRIAN HSU Partner Goldstein Hall

As a partner at Goldstein Hall, Brian Hsu focuses on affordable housing development, banking, cooperative and
condominium law, and real estate finance. Hsu frequently presents on housing issues, including affordable housing
policy matters, and he has led workshops for the New York Housing Conference and the Local Initiatives Support
Corporation, among others. Recently, he helped close Habitat Net Zero, a project for Habitat for Humanity New
York City and Westchester that designs energy-efficient homes. He leads Goldstein Hall's developer program,
which aims to reduce barriers for underrepresented contractors and developers in the affordable housing
development industry. Hsu is on the board of directors of the Habitat for Humanity NYC Fund.

ANNIE HUANG Partner Robins Kaplan

As deputy managing partner at Robins Kaplan, Annie Huang develops solutions to help clients achieve business
goals and navigate complex legal problems. Huang represents companies in intellectual property and business
disputes and has experience in a multitude of industries, including consumer electronics, medical devices and
variable data printing. She has been on various trial teams in district courts and the International Trade
Commission, managing teams at all stages of litigation from pre-suit and case initiation to mediation and trial.
Huang focuses her pro bono practice on individuals seeking political asylum. She has been a volunteer attorney for
the New York Legal Assistance Group.

SHAIMAA HUSSEIN Partner Willkie Farr & Gallagher

Shaimaa Hussein represents multinational corporations and financial institutions in complex commercial litigation
arising out of mergers and acquisitions, corporate-control transactions and government investigations. As a partner
at Willkie Farr & Gallagher and co-chair of its mergers-and-acquisitions litigation practice, Hussein has represented
Men's Wearhouse and Xerox Corporation, among other high-profile clients. She is committed to hiring and retaining
diverse candidates, mentoring associates and organizing initiatives to advance diverse attorneys and staff. As a
member of the firm's pro bono committee, Hussein supervises work involving immigration and housing. She is the
recipient of the Federal Bar Council's Thurgood Marshall Award for exceptional pro bono service.

CORRINE IRISH Partner Squire Patton Boggs

                                                                                                        Page 8 of 17
                                      NOTABLE DIVERSE LEADERS IN LAW

Corrine Irish directs Squire Patton Boggs' pro bono practice in the U.S., Asia and several of the firm's European
offices. Irish, experienced in commercial and intellectual property disputes and issues of constitutional law, won a
settlement related to violations of the First and Fourth amendments. In addition, she obtained a pardon for one of
the four U.S. sailors, dubbed the Norfolk Four, who were wrongfully charged with rape and murder. Through the
firm's public service initiative, the law partner has handled pro bono matters involving indigent people with limited
access to legal services, mentored diverse associates regarding professional development, and advised law
students through the Squire Patton Boggs Foundation. Irish has been recognized as a rising star in New York by
Super Lawyers.

RANDALL JACKSON Partner Willkie Farr & Gallagher

Randall Jackson co-chairs Willkie Farr & Gallagher's white-collar defense and compliance, investigations and
enforcement practice groups. As a partner in the firm's litigation department, Jackson focuses on government and
internal investigations, civil litigation and regulatory compliance. In addition, he is on the firm's business, pro bono
and recruiting committees, and he is a partner mentor for diverse associates. Jackson previously was assistant U.S.
attorney for the Southern District of New York. He made Savoy magazine's list of the Most Influential Black Lawyers
of 2022. Jackpon sits on the board of the New York Legal Assistant Group, a legal services organization that
advocates economic and racial justice.

TALEAH JENNINGS Partner Schulte Roth & Zabel

Taleah Jennings manages all phases of litigation, developing strategies and overseeing the teams of lawyers that
represent her clients. As a partner at Schulte Roth & Zabel, Jennings chairs the firm's diversity, equity and inclusion
committee, and she led the formation of the firm's Task Force for Racial Justice. Jennings was awarded the
Sanctuary for Families' Excellence in Pro Bono Advocacy Award for her work in assisting victims of domestic
violence and sex trafficking, and she received the Burton Award for Distinguished Legal Writing. Savoy Magazine
named her to its Most Influential Black Lawyers list. Jennings is on the advisory board of Legal Information for
Families Today, a pro bono legal adviser for underserved families, and on the board of directors for Sanctuary for
Families.

M. JANINE JJINGO Partner Skadden, Arps, Slate, Meagher & Flom

At Skadden, Arps, Slate, Meagher & Flom, M. Janine Jjingo represents investment and commercial banks, private-
equity funds, financial institution investors, and corporations in global financings, acquisition financings and asset-
backed loans. The Sladden, Arps partner has respresented Adtalem Global Education, BlackRock and Fintech
Bottomline Technologies, among other high-profile clients. Jjingo is involved in her firm's promotion efforts on law
school campuses, and she frequently speaks at Columbia Law School and the University of Pennsylvania. She is
on her law firm's Global Women's Initiatives Committee, which supports female attorneys. Jjingo was named one of
Savoy magazine's Most Influential Black Lawyers in 2022.

GLENN JONES Partner Abrams Fensterman

Whether at the federal, state or local level, Glenn Jones represents individuals and companies in various criminal
and civil matters as a partner at Abrams Fensterman. Jones chairs the health care fraud and white-collar criminal
defense practice group at the firm. His clients have included a nursing home and the board of directors of a drug
treatment center. Jones previously worked in the New York state attorney general office, where he was was special
assistant attorney general in the Medicaid Fraud Control Unit. He was a trial attorney with the U.S. Commodity
Futures Trading Commission. Jones, president of the board of directors of the Brooklyn Urban Garden Charter
School, has taught environmental law .

ATIF KHAWAJA Partner Kirkland & Ellis

Atif Khawaja offers strategic advice and litigation services for clients in business disputes as a partner at Kirkland &
Ellis, where he has spent his entire legal career. Khawaja's accomplish-ments include securing asylum for survivors
of domestic and gang violence and resolving antitrust and patent infringement claims. He co-chairs the firm's

                                                                                                       Page 9 of 17
                                      NOTABLE DIVERSE LEADERS IN LAW

diversity and inclusion and associate review committees, developing attorney affinity groups and overseeing pro
bono efforts. Khawaja is committed to developing a diverse trial bar and prioritizing diverse recruitment. He focuses
his pro bono practice on underrepresented populations, victims of domestic violence, disabled children, and
individuals with limited access to medical services. Khawaja volunteers as a director of the Legal Aid Society.

ALVIN LEE Partner King & Spalding

At King & Spalding, Alvin Lee specializes in complex commercial litigation, mass torts and class-action defense.
Working with clients in the financial services, energy and technology sectors, the King & Spalding partner has been
involved in litigation regarding renewable energy. These days he represents JPMorgan Chase in a series of
lawsuits related to the February 2021 winter storm in Texas. Lee has served in leadership roles within the firm and
throughout the legal industry regarding diversity and inclusion, leading initiatives surrounding anti-Asian hate crimes
and combating violence against transgender women of color. He previously was on the board of directors of the
National LGBTQ+ Bar Association. Lee has worked on transgender rights materials for the American Civil Liberties
Union.

EDWARD LEE Partner Kirkland & Ellis

Edward Lee has built a career advising public companies and private-equity firms on domestic and cross-border
mergers and acquisitions. The Kirkland & Ellis partner counsels companies on securities, corporate governance
and crisis management, helping develop the firm's mergers-and-acquisitions practice in New York and globally.
Motivated by his commitment to diversity and inclusion initiatives, Lee has pushed to organize firmwide discussions
and panels on related topics while he collaborates with leading Asian American and Pacific Islander organizations.
He was a 2017-18 David Rockefeller Fellow. Lee is on the boards of the Asian American Bar Association and the
Korean American Community Foundation.

JESSICA LEE Partner Loeb & Loeb

As a partner and chair of privacy, security and data innovations at Loeb & Loeb, Jessica Lee leads a team of more
than 40 lawyers who support companies, brands and media organizations in their efforts to use data to market and
monetize a range of digital products. Advising on technologies. including artificial intelligence, virtual reality and
facial recognition, Lee worked with Northwell Health on a deal with Aegis Ventures to develop and commercialize
AI for health care. She co-chairs Loeb & Loeb's affinity group for attorneys of color and ethnic diversity, sits on the
pro bono committee of her firm's New York office, and leads an advisory group of Loeb lawyers for the Bail Fund
Project.

KELLIE LERNER Partner and co-chair Robins Kaplan

Robins Kaplan's Kellie Lerner focuses on high-stakes disputes and counsels organizations in the pharmaceutical,
alternative energy and entertainment industries. The partner and co-chair has initiated antitrust class-action lawsuits
and recovered billions of dollars for victims of anti-competitive conduct. As chair of a group of women focused on
antitrust work, Lerner advocates for women and other diverse members of the legal industry, leading events and
programs that foster mentorship and inclusive dialogue. She is chair of diversity for the Antitrust Section of the New
York State Bar Association and co-chair of the National Association of Women Lawyers' litigation affinity group.

ERIKA LEVIN Partner Fox Rothschild

As a partner at Fox Rothschild, Erika Levin represents clients in complex international commercial disputes, serves
as an international arbitrator and provides transactional support. In her pro bono work, Levin represents people who
require additional support in understanding and navigating American law. Levin, co-chair of her firm's Latin America
practice and head of the diversity initiative for the New York office, establishes and facilitates formal connections
between minority attorneys and clients. She was named to Latinvex's list of Latin America's Top 100 Female
Lawyers in 2021. Levin is a fellow at the Chartered Institute of Arbitrators.

LORI MARKS-ESTERMAN Partner Olshan Frome Wolosky

                                                                                                   Page 10 of 17
                                     NOTABLE DIVERSE LEADERS IN LAW

Lori Marks-Esterman chairs the litigation practice group at Olshan Frome Wolosky. As the firm's youngest person
and only woman to lead a practice group, Marks-Esterman has directed the firm's litigation practice toward subtle
and high-stakes cases in New York's Southern District and other influential jurisdictions. The partner is involved
with her firm's committees for women and for diversity and inclusion; in addition, she works with larger
organizations for women in finance and law. Marks-Esterman advances legislation promoting the involvement of
women and minorities in business while mentoring women attorneys on executive leadership responsibilities, client
obligations and family demands.

HAIMAVATHI MARLIER Partner Morrison Foerster

Haimavathi Marlier is global co-chair of Morrison Foerster's securities litigation, enforcement and white-collar
defense group. Serving on its board of directors, diversity strategy committee and New York hiring committee,
Marlier has helped develop a comprehensive training program for associates with a focus on thought leadership
and the inclusion of first-generation law students from non-elite schools. Her pro bono practice focuses on
increasing marginalized communities' access to nature and public lands. In addition, Marlier mentors aspiring
lawyers of color. The law firm partner, who served on the Securities and Exchange Commission's Division of
Enforcement, has received accolades from the Legal 500. Marlier is on the board of trustees of the SEC Historical
Society.

LINDA MARTIN Partner Freshfields

At Freshfields, partner Linda Martin is co-head of its U.S. commercial litigation practice and co-head of its global
class and collective actions group. Martin, a leader in diversity and inclusion, has been recognized for her work by
Crain's, Benchmark Litigation and Chambers, among others. In her pro bono work, Martin defeated a motion in
2021 to dismiss civil rights litigation filed by a client brutalized during an arrest. She hosts periodic "Zoomside
Chats" with female partners to share professional guidance, and she has participated in Freshfields' Reverse
Mentoring Program, which pairs the firm's leaders with diverse associates. Martin has been a board member of the
Children's Tumor Foundation since 2006.

WALFRIDO MARTINEZ Managing partner Hunton Andrews Kurth

Since Walfrido Martinez became a managing partner at Hunton Andrews Kurth in 2006-one of the youngest leaders
of the global law firm and the rare Hispanic American in the role-the firm has engaged 100% of its lawyers in
diversity and inclusion initiatives and projects and in its pro bono services. As a previous chair of the Leadership
Council on Legal Diversity, Martinez developed a diverse team of office, practice and committee leaders, engaged
proactively with diverse attorneys and supported programs that facilitate productive discussion. Martinez, a
specialist in complex business litigation and white-collar criminal defense, has been recognized by the National Law
Journal. He received the U.S. Coast Guard's Meritorious Public Service Award in 2017.

BRIAN McGRATH Partner Hinshaw & Culbertson

Hinshaw & Culbertson partner Brian McGrath co-chairs the firm's consumer financial services practice group.
McGrath represents and advises major companies nationwide, manages a high-volume litigation practice and has
led large scale attorney-recruitment efforts. As a recognized thought leader on state and federal financial services
laws, he is a legal resource for the New York Mortgage Bankers Association, where is on the mortgage servicing
committee. McGrath, who has been consistently involved with LGBTQ issues, has held leadership roles for the New
York City Bar LGBTQ Rights Committee, and he is a member of the Human Rights Campaign Federal Club
Council. McGrath was a 2018-19 fellow at the Leadership Council on Legal Diversity. He is on the board of the
Development Authority of the North Country, a public benefit corporation.

JOSEPH MILIZIO Managing partner Vishnick McGovern Milizio

Joseph Milizio oversees all aspects of operations and growth at Vishnick McGovern Milizio, leading the firm's
practices in LGBTQ representation, business and transactional law, mergers and acquisitions and real estate. The
managing partner recently represented LGBTQ clients in connection with estate planning, health care

                                                                                                       Page 11 of 17
                                      NOTABLE DIVERSE LEADERS IN LAW

discrimination and surrogacy. In his community work, Milizio has collaborated with Northwell Health to run a
yearlong LGBTQ Health & Life Planning webinar series and to establish an upcoming free medical-legal clinic for
transgender people. In 2021 Milizio co-founded the Long Island chapter of the LGBT Chamber of Commerce and
joined the national board of governors of the Human Rights Campaign.

MORGAN F. MOUCHETTE Partner Blank Rome

Blank Rome partner Morgan F. Mouchette handles and settles high-net-worth financial, matrimonial and family
matters. After representing a female Army veteran in a custody battle upon her return from the Iraq War, Mouchette
received Blank Rome's highest pro bono honor in 2015. She has been recognized by the New York Law Journal,
Super Lawyers and the Women's Bar Association of the State of New York. She co-chairs Blank Rome's United
Affinity Group and frequently lectures on mentorship and authenticity. Mouchette, who is focused on increasing
diversity in the legal community, holds a leadership position at Black BigLaw Pipeline, a mentorship group for Black
attorneys.

TREY MULDROW Partner Weil, Gotshal & Manges

At Weil, Gotshal & Manges, Trey Muldrow advises corporations, sovereign wealth groups, private-equity sponsors
and assent managers on complex and market-leading transactions. Muldrow, a partner in the private-equity
practice, has worked with the New York Yankees, Northleaf Capital and Siemens, among other major clients. He
has been recognized by the Metropolitan Black Bar Association, the Council of Urban Professionals and Bloomberg
Law. Muldrow is a leader in his firm's Black Attorney Affinity Group and a participant in Jumpstart, a mentoring
program for Black associates. Active in diversity recruiting, he helped revive the Black alumni program and launch a
microsite to showcase Black partner talent to clients and law students.

BONNIE NEUMAN Co-chair of the finance group Cadwalader, Wickersham & Taft

Bonnie Neuman, a recognized leader in real estate finance law, has headed multiple headline transactions and
leads a transatlantic team of more than 100 attorneys. Neuman is a co-chair of the finance group, the head of the
real estate finance practice and a member of the management committee at Cadwalader, Wickersham & Taft,
where she has spent her entire legal career. Neuman's pro bono work includes involvement with her firm's
Transgender Name Change Clinic and Immigration Clinic. She is a committed leader on diversity and inclusion
initiatives, including the firm's sponsorship program and the CRE Finance Council Women's Network, where she
raises funds for Girls Inc., a nonprofit that focuses on female empowerment. Neuman was recognized in 2021 as
one of the nation's top commercial real estate attorneys by Connect CRE.

JESSE NEVAREZ Partner Goodwin

Goodwin partner Jesse Nevarez uses a client-centered approach to advise companies on capital markets, complex
transactions, and mergers and acquisitions in the technology and life sciences sectors. Nevarez, who provides
counsel for matters throughout the corporate lifecycle, ensures equal opportunity in all aspects of his professional
life. He accomplishes this through mentoring associates and law students, working with venture capitalists and
incubators that invest in women- and minority-owned companies and serving as a Leadership Council on Legal
Diversity fellow. Nevarez is active on Goodwin's Black Anti-racism Task Force, a leader on the New York Council of
its Committee on Racial and Ethnic Diversity, and a diversity, equity and inclusion co-chair for its tech business unit.

INOSI NYATTA Partner Sullivan & Cromwell

As co-head of Sullivan and Cromwell's global project development and finance practice, Inosi Nyatta works on
innovative financing techniques that provide infrastructure to developing regions. Recently, she advised Belize on a
restructuring project to support ocean conservation and represented Sempra and Sempra Infrastructure Partners in
financing efforts to build capital and credit. As a member of her firm's diversity and women's initiative committees,
Nyatta has co-founded and launched initiatives to promote female colleagues, cultivate an alumni network and
provide career mentorship. The law partner delivered a virtual training session on financial models for energy

                                                                                                      Page 12 of 17
                                      NOTABLE DIVERSE LEADERS IN LAW

products for government lawyers and officials in Nigeria, Kenya and Ethiopia through the Cyrus R. Vance Center for
International Justice.

MARY POKOJNY O'REILLY Partner Meltzer, Lippe, Goldstein & Breitstone

As a co-chair of the trusts and estates practice group of Meltzer, Lippe, Goldstein & Breitstone, Mary Pokojny
O'Reilly manages, counsels and mentors a team of 25 estate-planning attorneys across the country. O'Reilly, the
first female equity partner at her firm, guides individuals and family businesses on preserving and protecting assets
and minimizing taxes. Committed to mentorship, she advises dozens of young attorneys at the firm, emphasizing
the path to success for other working parents. O'Reilly participates in the American Bar Association and sits on the
board of Our Lady Victory School. She has planned professional development events in concert with the Hofstra
University School of law.

KRISHNAN PADMANABHAN Partner Winston & Strawn

At Winston & Strawn, partner Krishnan Padmanabhan co-chairs the firm's technology, media and telecom industry
group. With extensive experience in patent litigation, Padmanabhan promotes diversity, equity and inclusion efforts
through his position on Winston's executive committee and as the diversity committee liaison to the attorney
assignment committee. He has been recognized for his work by the Legal 500, Super Lawyers and IAM Patent
1000. Outside of the firm, Padmanabhan sits on the board of governors of the University of California, Hastings
College of Law as a mentor to diverse students. In addition, he is on the Edgemont Scholarship Council, which
grants scholarships to students in need of financial aid.

CARMEN I. PAGAN Partner Romer Debbas

As head of Romer Debbas' agency lending practice-a diverse and all-female department-partner Carmen I. Pagan
helps clients navigate complex multifamily lending matters, including conventional loans, senior housing and
student housing. Pagan has spoken at global real estate forums and legal conferences, and she hosted the
"Diversity and Inclusion in Institutional Real Estate" networking roundtable at the seventh annual Global Institutional
Real Estate Investor Forum. Pagan, who is committed to diversity and inclusion in the workplace, is an active
career mentor. She represents immigrants in pro bono cases regarding petitions to obtain legal permanent status
and regularly counsels military veterans, senior citizens and minority business owners.

ALI PANJWANI Partner Pryor Cashman

At Pryor Cashman, Ali Panjwani provides transactional advice to small- and mid-cap companies, investment banks
and funds. As a co-chair and assigning partner of the firm's corporate group, Panjwani shapes associates'
professional development, ensures corporate team engagement and mentors diverse associates. He led the initial
public offering for the first minority-led special-purpose acquisition company to be listed on the Nasdaq and has
represented Crown Electrokinetics, a smart-glass technology company that offers carbon emissions-reduction
benefits. Panjwani is a member of his firm's summer associate hiring committee, which supports diversity-a cause
of importance to him as a first-generation American. Panjwani holds frequent informal mentoring conversations with
young people and has hosted high school students at Pryor Cashman through the Elevate New York program.

LUIS PENALVER Partner Cahill Gordon & Reindel

Cahill Gordon & Reindel partner Luis Penalver represents leading global banks involved in leveraged buyouts
across a wide range of industries. Penalver sits on the firm's executive committee and provides counsel on the
long-term strategic direction and day-to-day management of the firm. In addition, he chairs Cahill's diversity and
inclusion committee, which he has served on since its inception, and supervises firmwide efforts in setting and
achieving internal goals for diverse recruiting, retention, promotion and mentorship. Outside of work, Penalver, a
longtime board member of the NAACP's Legal Defense Fund, chairs its pension committee.

SHIVANI PODDAR Partner Herrick, Feinstein

                                                                                                   Page 13 of 17
                                     NOTABLE DIVERSE LEADERS IN LAW

For more than a decade, Shivani Poddar has worked with clients in high-profile cases, including commercial,
securities, real estate and employment disputes. The Herrick, Feinstein partner has represented the trustee of an
energy company in a large leveraged buyout as well as Ample Hills Holdings, the iconic Brooklyn-based ice-cream
company, in Chapter 11 bankruptcy protection proceedings. Poddar, founder of the Diverse Working Attorneys'
Group and creator of the newsletter Diversity Matters, has launched programs aimed at increasing her firm's efforts
in recruiting and retaining diverse attorneys. She was recognized as a rising star by the New YorkLaw Journal in
2020. Poddar is co-director of the litigation committee of the South Asian Bar Association in New York.

EDWARD PROKOP Partner Jenner & Block

As co-chair of the firm's corporate department and cross-border transaction practice, Jenner & Block partner
Edward Prokop counsels clients in domestic and international transactions, corporate governance, fiduciary, ethics
and disclosure issues. Prokop co-led a team that represented Snyder's-Lance in Campbell Soup Company's
multibillion-dollar acquisition of the snack manufacturer. He is an active member of Jenner & Block's diversity and
inclusion committee and co-chair of the firm's multicultural affinity group. In addition, Prokop is on the New York
office's summer associate committee. He mentors law school fellows from underrepresented backgrounds and is
himself a fellow with the Leadership Council on Legal Diversity. Prokop's pro bono work focuses on prison
education, renewable energy and public school equity.

DOROTHEA REGAL Founding and co-managing partner Hoguet Newman Regal & Kenney

Since co-founding the women-owned litigation boutique Hoguet Newman Regal & Kenney more than a quarter-
century ago, Dorothea Regal has recovered hundreds of millions of dollars from insurers for various corporate
policyholders. As a co-managing partner, she heads the firm's insurance recovery group and has represented
global companies in disputes that include product liability claims, insurance coverage, business interruption and
employment discrimination. Regal, who mentors interns, associates and younger partners, is involved with the
Women's Leadership Circle of Brooklyn Law School, a program aimed at advancing women lawyers. She is the
policyholder-side co-chair of the Business Interruption Insurance Subcommittee of the American Bar Association's
Insurance Coverage Litigation Committee.

ANN RICHARDSON KNOX Partner Mayer Brown

Ann Richardson Knox, who represents large domestic and international lenders in fund finance matters, led some of
the first environmental, social and governance and green fund financings on the U.S. market. Richardson Knox
heads the firm's global fund finance team and serves as a banking and finance partner at the New York office. She
has supported women through the founding of the Women in Fund Finance initiative, which aims to increase the
engagement, recognition and promotion of women leaders in alternative investment fund finance. At numerous
events for the Fund Finance initiative and other financial organizations, Richardson Knox has given presentations
and facilitated industry discussion, with special attention to addressing audiences of female lawyers.

NINA ROKET Co-administrative partner Olshan Frome Wolosky

As leader of the commercial leasing practice at Olshan Frome Wolosky, Nina Roket closes leases, acquisitions and
financings while she develops new businesses. With her experience in real estate and business, Roket works with a
diverse roster of clients, leading national and global financing platforms in office, retail and bio-manufacturing
spaces. The founder and chair of the firm's women's committee mentors female lawyers; she also mentors in the
Urban Land Institute Mentorship Program. Olshan's co-administrative partner is a member of WX New York Women
Executives in Real Estate. Roket, committed to advancing principles of diversity and inclusion, heads the law firm's
hiring committee.

ANJAN SAHNI Partner-in-charge, New York office WilmerHale

Anjan Sahni, partner-in-charge of WilmerHale's New York office, advises individuals and institutions on high-stakes
government investigations and litigation across various agencies and issues. Sahni has been lead counsel in a
dozen federal criminal trials since 2005, including the prosecution of terrorism offenses and the prosecution of an

                                                                                                     Page 14 of 17
                                      NOTABLE DIVERSE LEADERS IN LAW

attempted bombing of Times Square. Sahni, committed to mentoring young lawyers and working with a diverse
team, is on his firm's management, diversity and compensation committees. Outside the firm, Sahni provides legal
support to the Sikh Coalition and offers pro bono work to assault victims and people involved in FBI terrorism
investigations.

TERRI SELIGMAN Partner Frankfurt Kurnit

At Frankfurt Kurnit, Terri Seligman is a partner and co-chair of advertising, marketing and public relations. Seligman
regularly practices before the National Advertising Division, representing companies in regulatory matters and
advertising disputes. She helped create the racial justice task force and co-chairs it. The task force has been
instrumental in facilitating discussions and learning opportunities around race, updating the firm's policies, and
formalizing racial justice tenets to guide hiring practices and workplace culture. Seligman, who also co-chairs the
reproductive rights task force, creates opportunities for underrepresented groups in the legal field through drafting
work-life balance and caregiver leave policies. She regularly provides pro bono counsel to city organizations.

UMAR SHEIKH Principal and chair Offit Kurman

Umar Sheikh's work as principal and chair of Offit Kurman's real estate law and business transactions practice
concentrates on all aspects of real estate law, from financing and foreclosures to asset protection and estate
planning. Sheikh, who has experience with Islamic shariah-compliant finance, has represented clients on
sustainable hospitality and energy storage, and he has litigated matters involving real estate and corporate interests
in all levels of courts. He mentors younger attorneys of color, often speaks at local mosques about the importance
of estate planning, and sits on the board of Muslims 4 Peace, a nonprofit that connects people from various
backgrounds through interfaith dialogue. Sheikh heads the recruitment and retention subcommittee of Offit
Kurman's diversity committee.

CYNTHIA SHOSS Partner Eversheds Sutherland

At Eversheds Sutherland, partner Cynthia Shoss assists clients with insurance regulatory matters and corporate
governance. Shoss leads a team of advisers on a transaction to transform Columbian Mutual Life Insurance
Company into a stock life insurance company. In addition, she is involved in negotiating the definitive merger
agreement, policyholder disclosure documents and regulatory approvals. Shoss was the first woman and second
lawyer in private practice to receive the Distinguished Service Award for Lifetime Services from the Association of
Life Insurance Counsel. Recently, she finished serving the maximum term on her firm's global board. Shoss is on
the board of the Greenberg School of Risk Management at St. John's University. She is the chair of the Economic
Mobility Corporation board of directors.

DAWN SMALLS Partner Jenner & Block

Dawn Smalls works with clients from tier-one financial institutions to homeless New Yorkers and leads high-stakes
matters. The Jenner & Block partner is a member of the firm's management committee, which oversees the firm's
daily operations. Smalls worked in the Clinton and Obama administrations as assistant to the White House chief of
staff and as the chief regulatory officer at the Department of Health and Human Services, respectively. She was a
candidate in 2019 for New York City public advocate. Smalls mentors, advises and supports diverse candidates on
the local, state and federal level. She is on the boards of the Roosevelt Institute and the Stone Barns Center for
Food and Agriculture.

RUTI SMITHLINE Partner Morrison Foerster

Ruti Smithline co-chairs Morrison Foerster's investigations and white-collar defense group and the firm's Latin
American desk. The native Colombian and fluent Spanish speaker advises on matters of corruption, fraud and
compliance in Latin America. Smithline, who has been recognized by the Legal 500 and by LatinVex, leads the
firm's Visiting International Attorney program and oversees more than 70 attorneys as head of the New York
litigation department. She has been on the selection committee for the TotalLaw Prep program, which supports
lawyers of Afro-descendant and indigenous Latin American backgrounds. Smithline is a member of the Women's

                                                                                                      Page 15 of 17
                                      NOTABLE DIVERSE LEADERS IN LAW

White Collar Defense Association. She mentors junior lawyers and contributes to pro bono initiatives at the Cyrus
R. Vance Center for International Justice.

ALISON STEIN Partner Jenner & Block

As a partner and co-chair of the content, media and entertainment practice at Jenner & Block, Alison Stein
represents media companies, such as Nintendo and ViacomCBS, in high-profile intellectual property counseling,
content moderation and litigation. She works on the firm's associate management and evaluation committees and
co-chairs the Media Law Resource Center's Internet and Technology Law Committee. Stein is on the board of
directors of Volunteer Lawyers for the Arts and the Irving Fine Society. She has published articles about issues
relating to women and the workplace, and she has worked on women's and development issues in Haiti, Ghana,
Tanzania and Uganda. Stein's pro bono practice includes reproductive rights and civil rights work.

DUVOL THOMPSON Partner Holland & Knight

Duvol Thompson has represented clients in litigation and business disputes spanning many industries, from
financial services to multinational energy, media and entertainment. The Holland & Knight partner has spent his
entire career at the firm, where he co-chairs the New York office's diversity committee. Thompson, named a 2019
Fellow of the Leadership Council on Legal Diversity, has worked to establish a welcoming workplace environment
for attorneys of color. He is a board member for the Pipeline to Practice Foundation, an organization that advances
diversity in the legal profession, and for Strategies for Youth, a nonprofit that seeks to improve interactions between
young people and the police and reduce unnecessary and forceful arrests.

LATISHA THOMPSON Partner Morrison Cohen

Morrison Cohen partner Latisha Thompson is chair of the firm's business litigation. Thompson, who focuses on
complex business disputes, real estate litigation and restructuring, has represented a large global auction house in
employee raiding and breach of restrictive covenant action. She is a member of the firm's diversity and inclusion
committee. Thompson mentors female and minority associates, and she has hosted and organized affinity group
events to support diverse attorneys. She devotes many hours to training associations and leads associate training
workshops in the firm's business litigation department. Thompson is a member of the New York City Bar
Association, the New York State Bar Association and the Metropolitan Black Bar Association.

HECTOR TORRES Partner Kasowitz Benson Torres

At Kasowitz Benson Torres, partner Hector Torres is co-chair of the firm's antitrust group. In that role he represents
domestic and international corporations in high-profile antitrust and commercial litigation and arbitration. Torres has
handled some of the largest antitrust matters in the country; he represented Ford Motor Co. in connection with the
Department of Justice's largest criminal antitrust investigation. As co-chair of the firm's diversity and inclusion
committee, Torres has helped promote minority and women partners. Under his leadership, Kasowitz is a mentor
law firm for John Dewey High School students and runs their mock trial program. Torres is on the Committee on
Character and Fitness for the New York state Supreme Court, Appellate Division, First Judicial Department.

SERGIO URIAS Partner Akin Gump Strauss Hauer & Feld

Law firm partner Sergo Urias represents diverse middle-market private-equity funds and their portfolio companies in
complex mergers-and-acquisitions transactions globally. His practice focuses on recapitali-zations, leveraged
buyouts, growth-equity investments and related corporate transactions, working with private-equity and investment
funds in the U.S. and Latin America. Before recently joining Akin Gump Strauss Hauer & Feld, Urias was partner
and co-chair of Covington & Burling's private-equity practice group, head of the firm's Latin America initiative and a
member of its corporate practice group. He co-founded Project Paz, a nonprofit that raises funds for young people
in Mexico affected by drug-related violence. Urias has participated in conversations with Mexico's Ministry of
Foreign Affairs on disability protection practices. He is a member of the governing body of the Vance Center for
International Justice.

                                                                                                    Page 16 of 17
                                     NOTABLE DIVERSE LEADERS IN LAW

PHOEBE A. WILKINSON Partner Hogan Lovells

At Hogan Lovells, Phoebe A. Wilkinson represents manufacturers and retailers in class actions and other
commercial litigation and arbitration. As global managing partner of advancement at the firm, Wilkinson leads efforts
to promote a pipeline of top talent and works on the global leadership team for the firm's litigation practice.
Recently, she led a team that defeated class certification efforts against LG Electronics and Best Buy and obtained
a defense verdict in a dispute between a product manufacturer and an asset-based lender. In collaboration with the
firm's diversity and inclusion team, Wilkinson oversees the setting and achievement of goals for diverse hiring. She
is a board member of the Brown University Sports Foundation and a past board member of New York Lawyers for
the Public Interest.

MILTON WILLIAMS Partner Walden Macht & Haran

Milton Williams has a white-collar defense practice focusing on trial work, regulation, internal investigations,
employment law and complex commercial litigation. The Walden Macht & Haran partner was an assistant U.S.
attorney in New York's Southern District and an assistant district attorney in Manhattan. Williams, a founding
member of his firm's diversity and inclusion committee, supports increased representation across the legal industry.
He was co-chair of the Moreland Commission, and he holds leadership positions with the Cardinal's Review Board,
the Governor's Screening Panel, Sanctuary for Families and Prisoners' Legal Services of New York. Williams ran
the Sponsors for Educational Opportunity Corporate Law Program for 16 years.

AMY WOLLENSACK Partner Akin Gump Strauss Hauer & Feld

Before Amy Wollensack recently became a partner in the private-equity practice at Akin Gump Strauss Hauer &
Feld, she was a partner and co-chair of the private-equity practice at Covington & Burling. She was a member of
that firm's corporate practice group, co-chair of its diversity and inclusion committee, and a leader of its affinity
group for Black attorneys. Wollensack represents private-equity funds in leveraged buyouts, recapitalizations and
mergers and acquisitions, among other complex transactions. She has mentored law students through the
Leadership Council on Legal Diversity. Wollensack is on the board of the nonprofit Housing Plus; she previously
was on the Young Leadership Committee of Lighthouse International. She is a member of Apollo Young Patrons, a
community of next-generation theater leaders.

AYSE YUKSEL Global head of corporate, M&A and securities Norton Rose Fulbright

At Norton Rose Fulbright, Ayse Yuksel develops global strategy and supervises the law practice. Although Yuksel is
based in New York, she leads the firm's office in Istanbul. The firm's global head of corporate, mergers and
acquisitions, and securities is a member of its global executive committee. In that role she regularly leads cross-
border legal teams on client matters. Yuksel has been recognized by The American Lawyer and Chambers. She
participated in the Turkey-based Global Relationship Forum, serving on a task force with former Secretary of State
Madeleine Albright and former CIA director David Petraeus. Yuksel is a member of the American Turkish Society's
Young Society Leaders, a member of the board of trustees for Robert College high school and a leader in recent
pro bono reports for the World Bank.

LISA ZEIDERMAN Managing partner Miller Zeiderman

Lisa Zeiderman is a matrimonial and family lawyer, divorce financial analyst and litigator at Miller Zeiderman. The
firm's managing partner, a vocal supporter of the Judiciary of New York during a budgetary crisis, wrote an op-ed in
the New York Law Journal on the subject. Her legal achievements, which draw from her experience as a former
fashion business owner, have been recognized by many legal authorities. She regularly appears on panel
discussions and mentors law students at the Fordham University School of Law. Zeiderman works closely with
Legal Information for Families Today, a pro bono adviser for underserved families. She is involved with numerous
female empowerment initiatives, Jewish organizations and anti-racist efforts.


Load-Date: July 14, 2022

                                                   Page 17 of 17
                  NOTABLE DIVERSE LEADERS IN LAW



End of Document

                                                                                               Page 1 of 1
                                                      No Headline In Original




                                               No Headline In Original
                                                    The Philadelphia Inquirer
                                                    October 29, 2023 Sunday



Copyright 2023 Philadelphia Newspapers, LLC All Rights Reserved

Section: HEALTH; Pg. G1
Length: 17 words

Body


Racist AI?

A study testing chatbots about racial medical differences reveals some troubling advice. G5.


Load-Date: October 29, 2023


  End of Document

